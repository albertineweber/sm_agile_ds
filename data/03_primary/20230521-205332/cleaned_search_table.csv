entry,database,title,abstract,author_keywords,authors,authors_affiliations,publication_year,source_title,publisher,url,doi,query_date,processing_date,sanitized_title,duplicated_exclusion_flag,duplicated_validation_date,metadata_exclusion_flag,metadata_validation_date,fulltext_exclusion_flag,fulltext_validation_date
1,acm,Agile Construction of Data Science DSLs (Tool Demo),"Domain Specific Languages (DSLs) have proven useful in the domain of data science, as witnessed by the popularity of SQL. However, implementing and maintaining a DSL incurs a significant effort which limits their utility in context of fast-changing data science frameworks and libraries. We propose an approach and a Python-based library/tool NLDSL which simplifies and streamlines implementation of DSLs modeling pipelines of operations. In particular, syntax description and operation implementation are bundled together as annotated and terse Python functions, which simplifies extending and maintaining a DSL. To support ad hoc DSL elements, NLDSL offers a mechanism to define DSL-level functions as first-class DSL elements. Our tool automatically supports each DSL by code completions and in-editor documentation in a multitude of IDEs implementing the Microsoft's Language Server Protocol. To circumvent the problem of a limited expressiveness of a external DSL, our tool allows embedding DSL statements in the source code comments of a general purpose language and to translate the DSL to such a language during editing. We demonstrate and evaluate our approach and tool by implementing a DSL for data tables which is translated to either Pandas or to PySpark code. A preliminary evaluation shows that this DSL can be defined in a concise and maintainable way, and that it can cover a majority of processing steps of popular Spark/Pandas tutorials.","Apache Spark, DSL development, Data analysis frameworks, Code generation, Assisted editing and IntelliSense, Python Pandas","Andrzejak A,Kiefer K,Costa DE,Wenz O",,2019.0,Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences,Association for Computing Machinery,,10.1145/3357765.3359516,20230520-160000,20230521-044735,"['agile', 'construction', 'of', 'data', 'science', 'dsls', '(tool', 'demo)']",False,20230521-205332,,,,
2,acm,DESIGN AN AGILE OF MACHINE LEARNING TO PREDICTIVE HOUSE PRICING AND TARGETING SEGMENTED MARKET,"Because of too high expectations or having a wrongly segmented target market, the developer hasn't received a good response from the target market. Developers need a new marketing tool that is based on data. The use of machine learning systems as marketing tools to help solve the problems in house price prediction is an important topic in the real estate industry. The design of machine learning will use CRISP-DM as a framework and to analyze using linear regression and random forest as the best possible accuracy. Besides that, to find a potential market, we will use K-Means as a clustering method. The modeling and experiments to design a machine learning engine that can predict a range of selling prices using linear regression can give maximum accuracy and analyze the target market. The research focusing on different attributes will bring different dominant attributes to the table too.","house development market, linear regression, influence factor, predictive pricing, data science, random forest, machine learning, target market, data analytics, Agile","Wijaya J,Ipung HP,Soetomo MA",,2022.0,Proceedings of the 2022 International Conference on Engineering and Information Technology for Sustainable Industry,Association for Computing Machinery,,10.1145/3557738.3557856,20230520-160000,20230521-044735,"['design', 'an', 'agile', 'of', 'machine', 'learning', 'to', 'predictive', 'house', 'pricing', 'and', 'targeting', 'segmented', 'market']",False,20230521-205332,,,,
3,acm,Summary of the International Conference on Software AndSystem Processes (ICSSP 2018),"The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the eld of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand"" by recognizing the demands on processes that include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across di erent domains, providing concepts, evidence, and experiences.","product quality, agile methods, project management, deployment, hybrid systems development, continuous development, data science","Kuhrmann M,O'Connor RV,Houston D,Hebig R,Raffo D",,2019.0,SIGSOFT Softw. Eng. Notes,Association for Computing Machinery,,10.1145/3282517.3302403,20230520-160000,20230521-044735,"['summary', 'of', 'the', 'international', 'conference', 'on', 'software', 'andsystem', 'processes', '(icssp', '2018)']",False,20230521-205332,,,,
4,acm,Summary of the International Conference on Software and System Processes (ICSSP 2018),"The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the field of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand"" by recognizing the demands on processes that include the need for both welldeveloped plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across different domains, providing concepts, evidence, and experiences.","data science, project management, product quality, deployment, agile methods, hybrid systems development, continuous development","Kuhrmann M,O'Connor RV,Houston D,Hebig R,Raffo D",,2019.0,SIGSOFT Softw. Eng. Notes,Association for Computing Machinery,,10.1145/3282517.3302415,20230520-160000,20230521-044735,"['summary', 'of', 'the', 'international', 'conference', 'on', 'software', 'and', 'system', 'processes', '(icssp', '2018)']",False,20230521-205332,,,,
5,acm,Unlocking the Potential of NextGen Multi-Model Databases for Semantic Big Data Projects,"A new vision in semantic big data processing is to create enterprise data hubs, with a 360° view on all data that matters to a corporation. As we discuss in this paper, a new generation of multi-model database systems seems a promising architectural choice for building such scalable, non-native triple stores. In this paper, we first characterize this new generation of multi-model databases. Then, discussing an example scenario, we show how they allow for agile and flexible schema management, spanning a large design space for creative and incremental data modelling. We identify the challenge of generating sound triple-views from data stored in several, interlinked models, for SPARQL querying. We regard this as one of several appealing research challenges where the semantic big data and the database architecture community may join forces.","schema evolution, semantic data management, multi-model DBMS","Holubová I,Scherzinger S",,2019.0,Proceedings of the International Workshop on Semantic Big Data,Association for Computing Machinery,,10.1145/3323878.3325807,20230520-160000,20230521-044735,"['unlocking', 'the', 'potential', 'of', 'nextgen', 'multi-model', 'databases', 'for', 'semantic', 'big', 'data', 'projects']",False,20230521-205332,,,,
6,acm,A Scalable Methodology to Guide Student Teams Executing Computing Projects,"This article reports on a sequential mixed-methods research study, which compared different approaches on how to guide students through a semester-long data science project. Four different methodologies, ranging from a traditional “just assign some intermediate milestones” to other more Agile methodologies, were first compared via a controlled experiment. The results of this initial experiment showed that the project methodology used made a significant difference in student outcomes. Surprisingly, the Agile Kanban approach was found to be much more effective than the Agile Scrum methodology. Based on these initial results, in the second semester, we focused on use of the Kanban methodology. The findings in the second, more qualitative phase, confirmed the methodology's usefulness and scalability. A key issue when using the scrum methodology was that the students had a very difficult time estimating what could be completed in each of their two-week sprints. The Kanban board, which visually shows and limits work-in-progress, was found to be an effective way for students to communicate with each other as well as with their instructor. In addition, Agile Kanban also streamlined the work required for instructors to efficiently provide guidance to student teams and to understand each team's status. In summary, a scalable Kanban methodology, which can be applied to a wide variety of student computing projects, was found to an effective methodology to guide and manage student projects, improving student outcomes and minimizing instructor workload.","project methodologies, Project-based learning, scalable methodologies","Saltz JS,Heckman RR",,2018.0,ACM Trans. Comput. Educ.,Association for Computing Machinery,,10.1145/3145477,20230520-160000,20230521-044735,"['a', 'scalable', 'methodology', 'to', 'guide', 'student', 'teams', 'executing', 'computing', 'projects']",False,20230521-205332,,,,
7,acm,An Approach for the Implementation of Semantic Big Data Analytics in the Social Business Intelligence Process on Distributed Environments (Cloud Computing),"Managing and extracting useful knowledge from social media sources is a challenge. It has attracted a lot of attention from universities and industry. To meet this challenge, semantic analysis of textual data is the subject matter.Today, with the connection present everywhere and at any time, considerable data is born. These data or data become a key player for understanding, analyzing, anticipating and solving major economic, political, social and scientific problems. Data also changes our working procedures, our cultural environment, even restructuring our way of thinking. And just as the scientific, managerial and financial world is interested in Big Data, a new discipline is growing: Fast Data. In addition to the salient volume of data; another variant becomes decisive, the ability to efficiently process data in all their diversity, transforming it into knowledge by providing the right information to the right person at the right time, or even using it to predict the future.The exploitation of Big Data requires the proposition of new adapted mathematical and IT approaches but also a reengineering of managerial approaches for the control of the informational environment of a public or private organization. While basing itself on a strategic information management approach such as Economic Intelligence (EI). The latter combines and encompasses Business Intelligence techniques for internal data management and business intelligence techniques for monitoring and controlling external information flows. However, Big Data, as a boundless source of information for EI, has upset the traditional EI process, which requires a reengineering of the EI approach. My research works perfectly in this context characterized by an uncertain and unpredictable environment.We ask to propose an ontology-based, service-oriented, agile and scalable Social Business Intelligence approach to extract the semantics of textual data and define the domain of massive data. In other words, we semantically analyze social data at two levels, namely the level of the entity and the level of the domain.","Fast Data, Big Data, Social BI, Distributed Processing, Ontology, Cloud","Alcabnani S,Oubezza M,Elkafi J",,2020.0,Proceedings of the 4th International Conference on Big Data and Internet of Things,Association for Computing Machinery,,10.1145/3372938.3373003,20230520-160000,20230521-044735,"['an', 'approach', 'for', 'the', 'implementation', 'of', 'semantic', 'big', 'data', 'analytics', 'in', 'the', 'social', 'business', 'intelligence', 'process', 'on', 'distributed', 'environments', '(cloud', 'computing)']",False,20230521-205332,,,,
8,acm,Research on the Middle Platform Service System of Battlefield Data Governance Information Based on 5G Technology,"In order to enable fast and agile battlefield data service support capabilities, orderly advance the construction of military big data, and accelerate the implementation of digital battlefields, this paper makes full use of 5G technology and service center integration ideas to build a battlefield data governance information service system. Network slicing technology is used to guarantee differentiated network transmission capabilities for different data requirements, cloud-edge coordination technology is used to guarantee real-time computing power for distributed battlefield data, and service capability opening technology is used to guarantee agile data customization services in complex and changeable environments. New technologies are systematically integrated to achieve value-added empowerment of different operational application data, and provide fast and flexible digital service guarantee for the battlefield.",,"Ou X,Liao J,Chen K,Hu Z",,2022.0,2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture,Association for Computing Machinery,,10.1145/3495018.3495109,20230520-160000,20230521-044735,"['research', 'on', 'the', 'middle', 'platform', 'service', 'system', 'of', 'battlefield', 'data', 'governance', 'information', 'based', 'on', '5g', 'technology']",False,20230521-205332,,,,
9,acm,Best Practices for Engineering AI-Infused Applications: Lessons Learned from Microsoft Teams,"Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML.","AI, machine learning, industry practice",Begel A,,2019.0,Proceedings of the Joint 7th International Workshop on Conducting Empirical Studies in Industry and 6th International Workshop on Software Engineering Research and Industrial Practice,IEEE Press,,10.1109/CESSER-IP.2019.00008,20230520-160000,20230521-044735,"['best', 'practices', 'for', 'engineering', 'ai-infused', 'applications:', 'lessons', 'learned', 'from', 'microsoft', 'teams']",False,20230521-205332,,,,
10,acm,Information Resilience: The Nexus of Responsible and Agile Approaches to Information Use,"The appetite for effective use of information assets has been steadily rising in both public and private sector organisations. However, whether the information is used for social good or commercial gain, there is a growing recognition of the complex socio-technical challenges associated with balancing the diverse demands of regulatory compliance and data privacy, social expectations and ethical use, business process agility and value creation, and scarcity of data science talent. In this vision paper, we present a series of case studies that highlight these interconnected challenges, across a range of application areas. We use the insights from the case studies to introduce Information Resilience, as a scaffold within which the competing requirements of responsible and agile approaches to information use can be positioned. The aim of this paper is to develop and present a manifesto for Information Resilience that can serve as a reference for future research and development in relevant areas of responsible data management.","Value creation, Data quality, Information Resilience, Responsible data science, Effective information use","Sadiq S,Aryani A,Demartini G,Hua W,Indulska M,Burton-Jones A,Khosravi H,Benavides-Prado D,Sellis T,Someh I,Vaithianathan R,Wang S,Zhou X",,2022.0,The VLDB Journal,Springer-Verlag,,10.1007/s00778-021-00720-2,20230520-160000,20230521-044735,"['information', 'resilience:', 'the', 'nexus', 'of', 'responsible', 'and', 'agile', 'approaches', 'to', 'information', 'use']",False,20230521-205332,,,,
11,acm,A Cost-Efficient Container Orchestration Strategy in Kubernetes-Based Cloud Computing Infrastructures with Heterogeneous Resources,"Containers, as a lightweight application virtualization technology, have recently gained immense popularity in mainstream cluster management systems like Google Borg and Kubernetes. Prevalently adopted by these systems for task deployments of diverse workloads such as big data, web services, and IoT, they support agile application deployment, environmental consistency, OS distribution portability, application-centric management, and resource isolation. Although most of these systems are mature with advanced features, their optimization strategies are still tailored to the assumption of a static cluster. Elastic compute resources would enable heterogeneous resource management strategies in response to the dynamic business volume for various types of workloads. Hence, we propose a heterogeneous task allocation strategy for cost-efficient container orchestration through resource utilization optimization and elastic instance pricing with three main features. The first one is to support heterogeneous job configurations to optimize the initial placement of containers into existing resources by task packing. The second one is cluster size adjustment to meet the changing workload through autoscaling algorithms. The third one is a rescheduling mechanism to shut down underutilized VM instances for cost saving and reallocate the relevant jobs without losing task progress. We evaluate our approach in terms of cost and performance on the Australian National Cloud Infrastructure (Nectar). Our experiments demonstrate that the proposed strategy could reduce the overall cost by 23% to 32% for different types of cloud workload patterns when compared to the default Kubernetes framework.","cost efficiency, resource heterogeneity, Cluster management, container orchestration","Zhong Z,Buyya R",,2020.0,ACM Trans. Internet Technol.,Association for Computing Machinery,,10.1145/3378447,20230520-160000,20230521-044735,"['a', 'cost-efficient', 'container', 'orchestration', 'strategy', 'in', 'kubernetes-based', 'cloud', 'computing', 'infrastructures', 'with', 'heterogeneous', 'resources']",False,20230521-205332,,,,
12,acm,Software Engineering for Machine Learning: A Case Study,"Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.","data, AI, software engineering, process","Amershi S,Begel A,Bird C,DeLine R,Gall H,Kamar E,Nagappan N,Nushi B,Zimmermann T",,2019.0,Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice,IEEE Press,,10.1109/ICSE-SEIP.2019.00042,20230520-160000,20230521-044735,"['software', 'engineering', 'for', 'machine', 'learning:', 'a', 'case', 'study']",False,20230521-205332,,,,
13,acm,Exploiting Page Table Locality for Agile TLB Prefetching,"Frequent Translation Lookaside Buffer (TLB) misses incur high performance and energy costs due to page walks required for fetching the corresponding address translations. Prefetching page table entries (PTEs) ahead of demand TLB accesses can mitigate the address translation performance bottleneck, but each prefetch requires traversing the page table, triggering additional accesses to the memory hierarchy. Therefore, TLB prefetching is a costly technique that may undermine performance when the prefetches are not accurate.In this paper we exploit the locality in the last level of the page table to reduce the cost and enhance the effectiveness of TLB prefetching by fetching cache-line adjacent PTEs ""for free"". We propose Sampling-Based Free TLB Prefetching (SBFP), a dynamic scheme that predicts the usefulness of these ""free"" PTEs and prefetches only the ones most likely to prevent TLB misses. We demonstrate that combining SBFP with novel and state-of-the-art TLB prefetchers significantly improves miss coverage and reduces most memory accesses due to page walks.Moreover, we propose Agile TLB Prefetcher (ATP), a novel composite TLB prefetcher particularly designed to maximize the benefits of SBFP. ATP efficiently combines three low-cost TLB prefetchers and disables TLB prefetching for those execution phases that do not benefit from it. Unlike state-of-the-art TLB prefetchers that correlate patterns with only one feature (e.g., strides, PC, distances), ATP correlates patterns with multiple features and dynamically enables the most appropriate TLB prefetcher per TLB miss.To alleviate the address translation performance bottleneck, we propose a unified solution that combines ATP and SBFP. Across an extensive set of industrial workloads provided by Qualcomm, ATP coupled with SBFP improves geometric speedup by 16.2%, and eliminates on average 37% of the memory references due to page walks. Considering the SPEC CPU 2006 and SPEC CPU 2017 benchmark suites, ATP with SBFP increases geometric speedup by 11.1%, and eliminates page walk memory references by 26%. Applied to big data workloads (GAP suite, XSBench), ATP with SBFP yields a geometric speedup of 11.8% while reducing page walk memory references by 5%. Over the best state-of-the-art TLB prefetcher for each benchmark suite, ATP with SBFP achieves speedups of 8.7%, 3.4%, and 4.2% for the Qualcomm, SPEC, and GAP+XSBench workloads, respectively.",,"Vavouliotis G,Alvarez L,Karakostas V,Nikas K,Koziris N,Jiménez DA,Casas M",,2021.0,Proceedings of the 48th Annual International Symposium on Computer Architecture,IEEE Press,,10.1109/ISCA52012.2021.00016,20230520-160000,20230521-044735,"['exploiting', 'page', 'table', 'locality', 'for', 'agile', 'tlb', 'prefetching']",False,20230521-205332,,,,
14,ieeex,Achieving Agile Big Data Science: The Evolution of a Team’s Agile Process Methodology,"While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams.",Big Data Science;Agile;Process Methodology,J. S. Saltz; I. Shamshurin,"School of Information Studies Syracuse University, Syracuse, NY, USA; School of Information Studies Syracuse University, Syracuse, NY, USA",2019.0,2019 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005493,10.1109/BigData47090.2019.9005493,20230520-160000,20230521-044735,"['achieving', 'agile', 'big', 'data', 'science:', 'the', 'evolution', 'of', 'a', 'team’s', 'agile', 'process', 'methodology']",False,20230521-205332,,,,
15,ieeex,SKI: An Agile Framework for Data Science,"This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrumlike time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus, SKI implements the Kanban process, but with a more repeatable and structured approach.",Data Science;Big Data;Agile;Process Methodology,J. Saltz; A. Suthrland,Syracuse University; Scrum Inc.,2019.0,2019 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005591,10.1109/BigData47090.2019.9005591,20230520-160000,20230521-044735,"['ski:', 'an', 'agile', 'framework', 'for', 'data', 'science']",False,20230521-205332,,,,
16,ieeex,On the Application of SCRUM in Data Science Projects,"The emerging discipline of Data Science poses several challenges for teams conducting projects in the field as notably, the majority of Data Science teams fail to deliver the expected outcomes. To improve the results, researchers tried to adapt agile project methodologies like Scrum for Data Science projects. Scrum in particular is often implemented due its success in software engineering. However, the basic Scrum framework has proven itself to be too strict for Data Science, due to frequent unpredictabilities of Data Science tasks. Consequently, adaptions were made to traditional Scrum to make it more suitable for the new challenges. This article discusses further adaptations and suggests that Scrum in itself is usable in Data Science, however, additional adaptations of the core concepts need to be envisioned.",SCRUM;data science;project management,N. Kraut; F. Transchel,"Faculty of Business Studies, Harz University of Applied Sciences, Wernigerode, Germany; Faculty of Automation & Computer Science, Harz University of Applied Sciences, Wernigerode, Germany",2022.0,2022 7th International Conference on Big Data Analytics (ICBDA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760341,10.1109/ICBDA55095.2022.9760341,20230520-160000,20230521-044735,"['on', 'the', 'application', 'of', 'scrum', 'in', 'data', 'science', 'projects']",False,20230521-205332,,,,
17,ieeex,The Waterfall Model with Agile Scrum as the Hybrid Agile Model for the Software Engineering Team,"Hybrid agile is a software development model that combines the agile approach with a non-agile development strategy. A software engineering team chooses the hybrid agile to best fit the development process based on project needs; some projects require a plan-driven approach, and at the same time, agility is a must. However, among many agile methodologies and plan-driven development models, which methodologies or models adopted by a software engineering team lead to hybrid agile. This research aims to identify the software engineering team's approach and model that resulted in the emergence of a hybrid agile model. Data for this research were acquired through a qualitative study using interviews as the data collection instrument and thematic analysis is used to analyze the data and identify the theme. In the context of this paper, we focus on only one (1) theme, which is “models used in a software project”. According to the research findings, the agile Scrum and Waterfall models are the models that have been practised in software projects that have resulted in the hybrid agile model. In the near future, further research will be conducted to determine which process model is employed in certain software process phases of a software project.",Hybrid agile;Scrum;Waterfall model;Software engineering team,N. Yahya; S. S. Maidin,"Department of Computer Science, Kulliyyah of Information and Communication Technology, International Islamic University Malaysia (IIUM), Malaysia; Faculty of Data Science and Information Technology (FDSIT), INTI International University, Malaysia",2022.0,2022 10th International Conference on Cyber and IT Service Management (CITSM),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936036,10.1109/CITSM56380.2022.9936036,20230520-160000,20230521-044735,"['the', 'waterfall', 'model', 'with', 'agile', 'scrum', 'as', 'the', 'hybrid', 'agile', 'model', 'for', 'the', 'software', 'engineering', 'team']",False,20230521-205332,,,,
18,ieeex,Identifying the most Common Frameworks Data Science Teams Use to Structure and Coordinate their Projects,"This paper presents the results of a study focused on exploring which framework, if any, teams use to execute data science projects. The study consisted of a survey of 109 industry professionals, as well as an evaluation of relevant framework terms searched at Google. Overall, CRISP-DM was the most commonly used framework, with Scrum and Kanban being the second and third most frequently used. We note that CRISP-DM is a life cycle framework, whereas Scrum and Kanban are team coordination frameworks. Hence, this research also notes the potential demand for a framework that integrates both life cycle and team coordination aspects of leading a data science project.",Data Science;Big Data;Process Methodology,J. S. Saltz; N. Hotz,Syracuse University; Indiana University,2020.0,2020 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377813,10.1109/BigData50022.2020.9377813,20230520-160000,20230521-044735,"['identifying', 'the', 'most', 'common', 'frameworks', 'data', 'science', 'teams', 'use', 'to', 'structure', 'and', 'coordinate', 'their', 'projects']",False,20230521-205332,,,,
19,ieeex,Adopting Agile Software Development Methodologies in Big Data Projects – a Systematic Literature Review of Experience Reports,"During the last decade, agile software development methodologies have been widely adopted in various project contexts. Big data projects are different from software engineering projects in all three aspects - people, processes and technologies. Recent research has shown that agile approaches are suitable and beneficial when applied in big data projects. The aim of the current study is to investigate which of the agile software development methodologies are currently applied in big data projects and what are the key considerations for their application. As a first step towards achieving this aim, the paper presents a systematic literature review of research articles reporting real-world experience of adopting agile methodologies in different big data science contexts. The findings of the study are beneficial to both practitioners and researchers to define and adopt agile approaches which are well suited for their big data projects.",agile software development;big data science;methodology adoption;real-world experience;systematic literature review,I. Krasteva; S. Ilieva,"GATE Institute, Software University ""St. Kliment Ohridski"", Sofia, Bulgaria; GATE Institute, Software University ""St. Kliment Ohridski"", Sofia, Bulgaria",2020.0,2020 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378118,10.1109/BigData50022.2020.9378118,20230520-160000,20230521-044735,"['adopting', 'agile', 'software', 'development', 'methodologies', 'in', 'big', 'data', 'projects', '–', 'a', 'systematic', 'literature', 'review', 'of', 'experience', 'reports']",False,20230521-205332,,,,
20,ieeex,Applying Scrum in Data Science Projects,"The rise of big data has led to an increase in data science projects conducted by organizations. Such projects aim to create valuable insights by improving decision making or enhancing an organization's service offering through data-driven services. However, the majority of data science projects still fail to deliver the expected value. To increase the success rate of projects, the use of process models or methodologies is recommended in the literature. Nevertheless, organizations are hardly using them because they are considered too rigid and they do not support the typical iterative and open nature of data science projects. To overcome this problem, this research suggests applying Agile methodologies to data science projects. Agile methodologies were originally developed in the software engineering domain and are characterised by their iterative approach towards software development. In this study, we selected the Scrum approach and integrated it into the CRISP-DM methodology for data science projects using a Design Science Research approach. This new methodology was then evaluated in three different case organizations using expert interviews. Analysis of the expert interviews resulted in a further refinement of the Agile data science methodology proposed by this research.",Data Science;Agile;Scrum,J. Baijens; R. Helms; D. Iren,"Department of Information Science, Open University, Heerlen, The Netherlands; Department of Information Science, Open University, Heerlen, The Netherlands; Department of Information Science, Open University, Heerlen, The Netherlands",2020.0,2020 IEEE 22nd Conference on Business Informatics (CBI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140255,10.1109/CBI49978.2020.00011,20230520-160000,20230521-044735,"['applying', 'scrum', 'in', 'data', 'science', 'projects']",False,20230521-205332,,,,
21,ieeex,Managing and Composing Teams in Data Science: An Empirical Study,"Data science projects have become commonplace over the last decade. During this time, the practices of running such projects, together with the tools used to run them, have evolved considerably. Furthermore, there are various studies on data science workflows and data science project teams. However, studies looking into both workflows and teams are still scarce and comprehensive works to build a holistic view do not exist. This study bases on a prior case study on roles and processes in data science. The goal here is to create a deeper understanding of data science projects and development processes. We conducted a survey targeted at experts working in the field of data science (n=50) to understand data science projects’ team structure, roles in the teams, utilized project management practices and the challenges in data science work. Results show little difference between big data projects and other data science. The found differences, however, give pointers for future research on how agile data science projects are, and how important is the role of supporting project management personnel. The current study is work in progress and attempts to spark discussion and new research directions.",Data science;agile practices;teamwork;project management,T. Aho; T. Kilamo; L. Lwakatare; T. Mikkonen; O. Sievi-Korte; S. Yaman,"TietoEvry, Tampere, Finland; Computing Sciences, Tampere University, Tampere, Finland; Computer Science, University of Helsinki, Helsinki, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Computing Sciences, Tampere University, Tampere, Finland; KPMG Finland, Helsinki, Finland",2021.0,2021 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671737,10.1109/BigData52589.2021.9671737,20230520-160000,20230521-044735,"['managing', 'and', 'composing', 'teams', 'in', 'data', 'science:', 'an', 'empirical', 'study']",False,20230521-205332,,,,
22,ieeex,Using Agile Frameworks in Big Data projects,"Considering the main problems of Big Data projects - huge amounts of data, uncertainty and the need to take into account constant changes, the study decided to investigate the process of managing Big Data projects using Agile. The problem of choosing Agile techniques is complicated by the fact that each of the known frameworks has its own advantages and disadvantages. Depending on the type of project, a particular tool can influence various criteria for the success of the project. In addition, research has shown that some enterprises use separate elements of a particular framework. Therefore, the scientific novelty of the article lies in the study of the influence of individual elements of Agile techniques on the success of the project and its course. With the help of expert assessment in the work, a quantity of separate elements of Agile were formed. These techniques are the most common among practicing managers of Big Data project. The data were prepared to create a regression model.",Agile;project management;Big Data;statistics;questionnaire;expert assessment,K. Kolesnikova; O. Mezentseva; O. Kolesnikov; D. J. Obenewaa,"Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine",2021.0,2021 IEEE 16th International Conference on Computer Sciences and Information Technologies (CSIT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648622,10.1109/CSIT52700.2021.9648622,20230520-160000,20230521-044735,"['using', 'agile', 'frameworks', 'in', 'big', 'data', 'projects']",False,20230521-205332,,,,
23,ieeex,Scrum Best Practices Recommendation: a Media and Community Startup Case Study,"XYZ Company is a media and community company that applies Scrum in the process of developing key business support applications. The results of problem identification through interviews with the Chief Technology Officer (CTO) and Chief Product Officer (CPO) showed that one of the root causes of the problem was the Scrum team did not implement the Scrum guidelines strictly. This research evaluates the maturity level of Scrum implementation using the Standard CMMI Appraisal Method for Process Improvement (SCAMPI C). Researchers used the Scrum Maturity Model (SMM) as a model for calculating maturity. This SMM has been updated by following the Scrum Guide 2020 and best practices in 2020-2021 obtained from the literature study. To affirm the appraisal result, This research also distributed questionnaires to 33 respondents from the product team and the technology team. This research recommends implementation improvements using the Plan, Do, Check, Act (PDCA) Cycle approach. The results of the Scrum implementation maturity assessment are on Level 2. This research recommends some practices to be implemented and improved in the objectives: (a) Scrum Role Exist; (b) Scrum Meetings Occur and are Participated, and (c) Daily Scrum Succeed. If applied consistently, XYZ will have a quality improvement in Scrum implementation.",Evaluation;Best practices;SCAMPI C;Scrum;Scrum maturity model,A. Kurniawan; E. K. Budiardjo; K. Mahatma,"Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia",2021.0,"2021 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701958,10.1109/ICADEIS52521.2021.9701958,20230520-160000,20230521-044735,"['scrum', 'best', 'practices', 'recommendation:', 'a', 'media', 'and', 'community', 'startup', 'case', 'study']",False,20230521-205332,,,,
24,ieeex,Story and Task Issue Analysis for Agile Machine Learning Projects,"The usage of Agile methodology in planning and executing machine learning (ML) and data science related software engineering projects is increasing. However, there are very few studies using real data on how effective such planning is or guidelines on how to plan such projects. In this paper, we analyze data taken from several software projects using Scrum tools. We compare the data for data science/ML and non-ML projects, in an attempt to understand if data science and ML projects are planned or executed any differently compared to normal software engineering projects. We also perform a story classification task using machine learning to analyze story logs for agile tasks for several teams. We find there are differences in what makes a good ML story as opposed to a non ML story. After analyzing this data, we propose a few ways in which software projects, whether machine learning related or not, can be better logged and executed using Scrum tools like Jira.",scrum;machine learning project;software engineering;agile methodology,K. Singla; T. M. Vinayak; A. S. Arpitha; C. Naik; J. Bose,"Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India",2020.0,2020 IEEE-HYDCON,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9242803,10.1109/HYDCON48903.2020.9242803,20230520-160000,20230521-044735,"['story', 'and', 'task', 'issue', 'analysis', 'for', 'agile', 'machine', 'learning', 'projects']",False,20230521-205332,,,,
25,ieeex,A Typical Practical Team Structure and Setup in Agile Software Development,"Agile software development provides a different approach to Agile projects. This approach emphasizes employing experienced and committed individuals. In this approach, team management is different from what the disciplined methods defined. In this condition, team organization, team members’ roles, and responsibilities, and project control methods need to be defined in a new form. Although some Agile methods define particular roles, it seems that team structure in Agile projects in real projects is different from what is expected. This paper aimed to propose a common team structure and setup for Agile teams in practice. Differences in the Agile and plan-driven approaches in software development lead to define new concepts such as team self-organization, on-site customer, leadership, and collaboration in Agile teams. Also, some new roles and responsibilities have been defined in Agile teams, including Technical Lead, Product Owner, Architecture Owner, Developer, etc.",Agile software development;Agile methods;Agile team;Agile team setup;Agile team structure,M. Afshari; T. J. Gandomani,"Data Science Research Center, Shahrekord University, Shahrekord, Iran; Department of Computer Science, Data Science Research Center, Shahrekord University, Shahrekord, Iran",2021.0,"2021 7th International Conference on Electrical, Electronics and Information Engineering (ICEEIE)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616743,10.1109/ICEEIE52663.2021.9616743,20230520-160000,20230521-044735,"['a', 'typical', 'practical', 'team', 'structure', 'and', 'setup', 'in', 'agile', 'software', 'development']",False,20230521-205332,,,,
26,ieeex,A big data on private cloud agile provisioning framework based on OpenStack,"On the bases of the OpenStack private cloud delivery big data platform, numerous entities yearn for attaining agile and standardized big data delivery platform, reclaiming the resources, managing the total cost of ownership (TCO) and adapting to multiple big data open source or commercial off-the-shelf (COTS) solutions. Nevertheless, as regards the big data platform running on cloud computing, the big data platform is disintegrated from the cloud computing system by virtual machines since neither being based on OpenStack private cloud nor on big data platform can achieve end-to-end resource delivery, together with ensuring that it is quite convenient for the long-term operations. Accordingly, establishing an across framework between private cloud and big data platform is quite essential. The big data on cloud agile provision framework could realize fast resource delivery based on predefined orchestration template of private cloud, operating system, big data platform, monitor, inspection system, etc. Through the deployment of this framework, it is capable of attaining the delivery of agile, low cost, standardized and high adaptability the big data on cloud, as well as the high-quality operation of the big data on cloud with the help of integration configuration management database (CMDB) with the automatic inspection system.",cloud computing;agile resource provisioning;big data platform orchestration;inspection and rule engine,M. Lu; X. Zhou,"Infrastructure as a Service, BT/IT, Lenovo, Beijing, China; Infrastructure as a Service, BT/IT, Lenovo, Beijing, China",2018.0,2018 IEEE 3rd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386522,10.1109/ICCCBDA.2018.8386522,20230520-160000,20230521-044735,"['a', 'big', 'data', 'on', 'private', 'cloud', 'agile', 'provisioning', 'framework', 'based', 'on', 'openstack']",False,20230521-205332,,,,
27,ieeex,Research on Enterprise Agile High Potential Talent Identification System Based on Big Data Technology,"In the era of VUCA, enterprises need to quickly and accurately identify high-potential talents to achieve enterprise development and transformation. This article will talent radar, data, image, big data technologies, such as tendency analysis and Merce post evaluation methods, behavioral event interview, evaluation center technology and so on to carry on the organic combination, build agile high latent talent identification system, to establish high latent talent ability quality model, establish other agile high dive into the well path and the specification, as to provide theoretical basis for enterprise agile high latent talent identification.",VUCA agile;high potential talents;talent recognition system;competency model,M. Yang; W. Wang,"School of Management, Shanghai Sanda University, Shanghai, China; School of Economics and Management, Harbin University of Science and Technology, Harbin, China",2021.0,2021 9th International Conference on Orange Technology (ICOT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680668,10.1109/ICOT54518.2021.9680668,20230520-160000,20230521-044735,"['research', 'on', 'enterprise', 'agile', 'high', 'potential', 'talent', 'identification', 'system', 'based', 'on', 'big', 'data', 'technology']",False,20230521-205332,,,,
28,ieeex,"CRISP-DM for Data Science: Strengths, Weaknesses and Potential Next Steps","This paper explores the strengths and weaknesses of CRISP-DM when used for data science projects. The paper then explores what key actions data science teams using CRISP-DM should consider that addresses CRISP-DM’s weaknesses. In brief, CRISP-DM, which is the most popular framework teams use to execute data science projects, provides an easy to understand description of the data science project workflow (i.e., the data science life cycle). However, CRISP-DM’s project phases miss some key aspects of the data science project life cycle. In addition, CRISP-DM’s task-focused approach fails to address how a team should prioritize tasks, and in general, collaborate and communicate. Hence, this paper also describes how CRISP-DM could be combined with a team coordination framework, such as Scrum or Data Driven Scrum, which is a newer collaboration framework developed to address the unique data science coordination challenges.",,J. S. Saltz,Syracuse University,2021.0,2021 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671634,10.1109/BigData52589.2021.9671634,20230520-160000,20230521-044735,"['crisp-dm', 'for', 'data', 'science:', 'strengths,', 'weaknesses', 'and', 'potential', 'next', 'steps']",False,20230521-205332,,,,
29,ieeex,Identifying and Addressing 6 Key Questions when Using Data Driven Scrum,"Data Driven Scrum (DDS) enables lean data science project agility and addresses the key challenges that have been identified when using Scrum in a data science context. However, little has been written with respect to the questions or challenges teams might encounter when trying to use DDS. Based on a survey of 18 team leads trying to use DDS, this paper describes six common questions teams might encounter when trying to implement DDS, as well as how to address these challenges.",,J. S. Saltz; A. Sutherland; T. Jombart,Syracuse University; Scrum Inc; London School of Hygiene & Tropical Medicine,2021.0,2021 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671930,10.1109/BigData52589.2021.9671930,20230520-160000,20230521-044735,"['identifying', 'and', 'addressing', '6', 'key', 'questions', 'when', 'using', 'data', 'driven', 'scrum']",False,20230521-205332,,,,
30,ieeex,Analysis of Software Engineering for Agile Machine Learning Projects,"The number of machine learning, artificial intelligence or data science related software engineering projects using Agile methodology is increasing. However, there are very few studies on how such projects work in practice. In this paper, we analyze project issues tracking data taken from Scrum (a popular tool for Agile) for several machine learning projects. We compare this data with corresponding data from non-machine learning projects, in an attempt to analyze how machine learning projects are executed differently from normal software engineering projects. On analysis, we find that machine learning project issues use different kinds of words to describe issues, have higher number of exploratory or research oriented tasks as compared to implementation tasks, and have a higher number of issues in the product backlog after each sprint, denoting that it is more difficult to estimate the duration of machine learning project related tasks in advance. After analyzing this data, we propose a few ways in which Agile machine learning projects can be better logged and executed, given their differences with normal software engineering projects.",scrum;machine learning project;software engineering;agile methodology,K. Singla; J. Bose; C. Naik,"Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India",2018.0,2018 15th IEEE India Council International Conference (INDICON),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987154,10.1109/INDICON45594.2018.8987154,20230520-160000,20230521-044735,"['analysis', 'of', 'software', 'engineering', 'for', 'agile', 'machine', 'learning', 'projects']",False,20230521-205332,,,,
31,ieeex,When Edge Computing Meets Agile Software Development,"Agile development has been a common methodology in software development. In response to the covid-19, most software development teams choose to work remotely. As a result of the different network environments, the company cloud center network load cannot meet the requirements of remote development and fault tolerance requirements of the agile development process. We designed a mixed-method called the Edge Development approach for improving Agile software development during the decision-making process. The extensive literature review provided us with three categories of challenges as well as solutions to support Edge Development's decision-support process. In the light of the survey, Five main software development decision-making challenges were identified in this study. In addition, we made a series of recommendations to improve the decision-making process of Edge Development from a variety of perspectives.",Agile development;Edge computing;Edge development;Decision-making,L. Zhu; S. Song; Z. Xu; W. Wang; S. Peng; S. Hu,"Institute of Software Chinese Academy of Sciences, Beijing, China; Alibaba Cloud Big Data Application College, Zhuhai College of Science and Technology, Zhuhai, China; Academy of Management, Guangdong University of Science and Technology, Dongguan, China; Alibaba Cloud Big Data Application College, Zhuhai College of Science and Technology, Zhuhai, China; Zhuhai Yingying Technology Co., Ltd., Zhuhai, China; Institute of Data Science, City University of Macau, Macau, China",2022.0,"2022 4th International Conference on Communications, Information System and Computer Engineering (CISCE)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851104,10.1109/CISCE55963.2022.9851104,20230520-160000,20230521-044735,"['when', 'edge', 'computing', 'meets', 'agile', 'software', 'development']",False,20230521-205332,,,,
32,ieeex,A survey study of success factors in data science projects,"In recent years, the data science community has pursued excellence and made significant research efforts to develop advanced analytics, focusing on solving technical problems at the expense of organizational and socio-technical challenges. According to previous surveys on the state of data science project management, there is a significant gap between technical and organizational processes. In this article we present new empirical data from a survey to 237 data science professionals on the use of project management methodologies for data science. We provide additional profiling of the survey respondents’ roles and their priorities when executing data science projects. Based on this survey study, the main findings are: (1) Agile data science lifecycle is the most widely used framework, but only 25% of the survey participants state to follow a data science project methodology. (2) The most important success factors are precisely describing stakeholders’ needs, communicating the results to end-users, and team collaboration and coordination. (3) Professionals who adhere to a project methodology place greater emphasis on the project’s potential risks and pitfalls, version control, the deployment pipeline to production, and data security and privacy.",data science;survey;project management;factor analysis;success factors,I. Martinez; E. Viles; I. G. Olaizola,"Vicomtech Foundation, Basque Research and Technology Alliance, Donostia-San Sebastián, Spain; TECNUN School of Engineering, University of Navarra, Donostia-San Sebastián, Spain; Vicomtech Foundation, Basque Research and Technology Alliance, Donostia-San Sebastián, Spain",2021.0,2021 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671588,10.1109/BigData52589.2021.9671588,20230520-160000,20230521-044735,"['a', 'survey', 'study', 'of', 'success', 'factors', 'in', 'data', 'science', 'projects']",False,20230521-205332,,,,
33,ieeex,Using Big Data Analytics to Create a Predictive Model for Joint Strike Fighter,"The amount of information needed to acquire knowledge on today's acquisition systems is growing exponentially due to more complex, higher resolution, software-intensive acquisition systems that need to operate in System-of-Systems (SoS), Family-of-Systems (FoS), Joint, and Coalition environments. Unfortunately, the tools and methods necessary to rapidly collect, aggregate, and analyze this information have not evolved as a whole in conjunction with this increased system complexity and, therefore, has made analysis and evaluation increasingly deficient and ineffective. The Test Resource Management Center's (TRMC's) vision is to build a DoD test and evaluation (T&E) knowledge management (KM) and analysis capability that leverages commercial big data analysis and cloud computing technologies to improve evaluation quality and reduce decision-making time. An evaluation revolution, starting with the Joint Strike Fighter (JSF) program, is underway to ensure the T&E community can support the demands of next-generation weapon systems.The true product of T&E is knowledge ascertained through the collection of information about a system or item under test. However, the T&E community's ability to provide this knowledge is hampered by more complex systems, more complex environments, and the need to be more agile in support of strategic initiatives, such as agile acquisition and the 3rd Offset Strategy. This increased complexity and need for speed cause delayed analysis and problems that go undetected during T&E. The primary reason for these shortfalls is antiquated tools and processes that make data hard to locate, aggregate, and convert into knowledge. In short, DoD has not evolved its evaluation infrastructure as its weapon systems have evolved.Conversely, commercial entities, such as medical observation and diagnosis, electric power distribution, retail, and industrial manufacturing, have embraced agility in their methodologies while modernizing analytics capabilities to keep up with the massive influx of data. Raw physical sensors could provide data, higher-quality image or video cameras, radio frequency identification (RFID) devices, faster data collectors, more detailed point-of-sale information or digitized records, and ultimately is providing more data to analysts in size and complexity than ever before. As more data has become available, an interrelated phenomenon is the desire of analysts to ask more detailed questions about their consumers and their business infrastructure. To drive the process of implementing big data analytics, businesses have begun establishing analytics centers which either take pre-defined business cases and apply methods to address them or implement existing knowledge within the data architecture to create a higher level of awareness to business groups or the company at-large. To meet these demands, data storage and computation architectures have become more sophisticated, dozens of technologies were developed for large-scale processing (such as Apache Hadoop or GreenPlum), and streaming architectures which allow data to be processed and actioned on in real-time as it is collected have become commonplace. The net result of these commercial best practices is a solid foundation for the DoD to transform how it uses data to achieve faster, better, and smarter decisions throughout the acquisition lifecycle.",Big Data;Data Analytics;Knowledge Management;Data Management;Virtualization;Cloud Computing;Predictive Maintainance;Department of Defense;Test and Evaluation,R. Norman; J. Bolin; E. T. Powell; S. Amin; J. Nacker,"Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA",2018.0,2018 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622388,10.1109/BigData.2018.8622388,20230520-160000,20230521-044735,"['using', 'big', 'data', 'analytics', 'to', 'create', 'a', 'predictive', 'model', 'for', 'joint', 'strike', 'fighter']",False,20230521-205332,,,,
34,ieeex,Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure,"Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a Big Data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP?In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better.The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI.",,C. J. Wang; B. Kim,"R&D InfoTech Labs, Toyota Motor North America (TMNA), U.S.A; R&D InfoTech Labs, Toyota Motor North America (TMNA), U.S.A",2020.0,2020 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378045,10.1109/BigData50022.2020.9378045,20230520-160000,20230521-044735,"['automotive', 'big', 'data', 'pipeline:', 'disaggregated', 'hyper-converged', 'infrastructure', 'vs', 'hyper-converged', 'infrastructure']",False,20230521-205332,,,,
35,ieeex,An Improved Agile Framework For Implementing Data Science Initiatives in the Government,"Implementing data mining projects in governmental organizations is emerging in the Middle East. The literature has been showing that there is a significant gap between the problems defined by the research in data mining and the problems in real world projects. The gap is to the level of semantics between the data scientists and the business users. Trying to fill this gap, we have developed an improved Agile data mining framework to fulfill the government business objectives and needs. The previous works had been claiming that handling such project is not yet mature in the region. For this an Agile implementation framework is required. We are also proposing a systematic way for identifying business problems as part of the framework. The process is Agile, so it would start from investigating the data set dimensions to identify business problems. It also allows early Business people cooperation with data scientist. We've applied the proposed framework in one of the Middle East government organizations. The business team and the data scientists have been showing their satisfaction regarding the results of using the proposed framework. The proposed framework have helped both business and data scientist to implement their first initiative in data mining. The proposed framework also helped in efficiently mapping the project with the core business objectives and problems using real world dataset.","data mining, data science, agile framework, business problems, business objectives",W. Qadadeh; S. Abdallah,"Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, UAE; Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, UAE",2020.0,2020 3rd International Conference on Information and Computer Technologies (ICICT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092078,10.1109/ICICT50521.2020.00012,20230520-160000,20230521-044735,"['an', 'improved', 'agile', 'framework', 'for', 'implementing', 'data', 'science', 'initiatives', 'in', 'the', 'government']",False,20230521-205332,,,,
36,ieeex,Building the federation of cloud service for big data,"The demand for agile and flexible business application for big data has sparked interest in using cloud computing technology. Due to the limitation of provider's capability and the magnanimity of task quantity for big data, a single cloud provider may not offer enough service resources. However, a service federation among multiple providers can effectively solve this problem. This paper proposes the framework of cloud federation and introduces the basic processes of building service federation among multiple cloud providers. Moreover, we propose a multi-objectives task assigning model in the federation. A genetic algorithm based heuristic approach is developed as the optimization method. Eventually, some simulation experiments are conducted to illustrate the effectiveness of the model.",cloud service;cloud federation;multiple objectives optimization;task assignment;genetic algorithm,J. Shu; C. Liang; B. Wang; J. Xu,"School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Statistics and Applied Mathematics, Anhui University of Finance and Economics, Bengbu, Anhui, China",2018.0,2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367670,10.1109/ICBDA.2018.8367670,20230520-160000,20230521-044735,"['building', 'the', 'federation', 'of', 'cloud', 'service', 'for', 'big', 'data']",False,20230521-205332,,,,
37,ieeex,Improving Agile Development from Perspective of Design-Informing Model,"Agile development is usually used to solve the problem of inflexibility which the other project management models, like the Waterfall model and the V model, may meet. However, conventional agile development still faces many problems under rapid iterations. Frequent iteration lacks efficient communication a large community, resources to share information, and quality of product. For better project management, this article describes a method, called the design-informing model (DIM), to improve the agile development. The design-informing model consists of four parts, user mental mode, developer mental model, system model, and environmental model. At the end of the paper, some discussions will be conducted to evaluate DIM in practice.",project management;agile development;software engineering;model optimization,Z. Zhang,"University of Toronto, Toronto, Canada",2020.0,2020 International Conference on Computing and Data Science (CDS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275950,10.1109/CDS49703.2020.00011,20230520-160000,20230521-044735,"['improving', 'agile', 'development', 'from', 'perspective', 'of', 'design-informing', 'model']",False,20230521-205332,,,,
38,ieeex,What is Good Feedback in Big Data Projects for Cyberinfrastructure Diffusion in e-Science?,"This paper investigates the role of feedback in big data projects for cyberinfrastructure (CI) diffusion in e-science. For many of these projects, large-scale and heterogeneous datasets, multidisciplinary and dispersed experts, and advanced technologies are brought together to harness analytic insights. However, without effective CI and computational tools, the accuracy and meaningfulness of analytics results are compromised. In fact, without CI tools, raw data remain raw with hidden insights, as data analytics cannot be executed at all. In order to improve such tools for meaningful results, we argue to conceptualize the communication mechanism of `feedback' in agile software development, with the goal of producing CI tools that are responsive to users. Based on a grounded analysis of interview data, we concluded that feedback helps developers in big data projects understand users' needs, makes tools user-friendly, prevents emergencies, and is better for developers than no feedback. Furthermore, good feedback is often structured, specific, actionable, timely, generalizable, and delivered in a tactful way. Despite the limitation of the findings being exploratory and yet to be evaluated experimentally, we argued that they still can motivate developers to be proactive seekers of feedback for their tools, productively guide developers' communication with users, and ultimately promote further adoption and diffusion of CI tools in e-science.",feedback;agile software development;e-science;cyberinfrastructure;technology adoption;diffusion of innovations,K. F. Kee; J. C. McCain,"School of Communication, Chapman University, Orange, CA, USA; School of Communication, Chapman University, Orange, CA, USA",2018.0,2018 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622573,10.1109/BigData.2018.8622573,20230520-160000,20230521-044735,"['what', 'is', 'good', 'feedback', 'in', 'big', 'data', 'projects', 'for', 'cyberinfrastructure', 'diffusion', 'in', 'e-science?']",False,20230521-205332,,,,
39,ieeex,A Framework to Data Delivery Security for Big Data Annotation Delivery System,"Big data annotation plays an important role in Artificial Intelligence model training. The proliferation of data annotation tasks has brought the issue of security of the big data delivery. This work identifies the security framework associated with encryption and compression procedures that support data delivery safety. In this paper, we propose an agile framework that caters to various types of data under RESTful web services. All the procedures are automatically operated by the server without human intervention. This work assists the company delivers the tagged data products to users with a high-security level avoiding the risk of information disclosure.",Big data;compression;encryption;lightweight framework;data delivery,Y. Yang; H. He; D. Wang; Z. Ding,"Information School, Beijing Institute of Graphic Communication, Beijing, China; Datatang (Beijing) Technology Company, Limited, Beijing, China; Datatang (Beijing) Technology Company, Limited, Beijing, China; Information School, Beijing Institute of Graphic Communication, Beijing, China",2018.0,2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567604,10.1109/MASS.2018.00082,20230520-160000,20230521-044735,"['a', 'framework', 'to', 'data', 'delivery', 'security', 'for', 'big', 'data', 'annotation', 'delivery', 'system']",False,20230521-205332,,,,
40,ieeex,Designing Knowledge Management System with Big Data for Hospital Inpatient Services : (Case Study at Islamic Hospital XYZ Pekanbaru),"The quality of health services is an important indicator in the health business and industry, especially for the XYZ ISLAMIC HOSPITAL in Pekanbaru. The need for performance improvements that can directly improve the quality of inpatient health services is a major problem. The role of doctors and nurses' knowledge becomes a benchmark in determining the performance and quality of services, in this case the Knowledge Management System (KMS) can be a solution in supporting the knowledge management process. However, the growth of innovation in knowledge management is also needed in practice. So Big Data as a large data processing technology and various types of data will be a supporter in the process of increasing and accelerating the growth of knowledge of doctors and nurses at the XYZ ISLAMIC HOSPITAL by providing relevant information as needed. Then it is necessary to design a KMS that uses Big data as one of the enablers in the process of creating knowledge for doctors and nurses and then can be stored and shared. This design is done by using the Knowledge Management System Agile Implementation Methodology (KMSAIM) which prioritizes the initiation process in each problem domain so that each component has the right and relevant solutions. The KMS design results are in the form of site-based applications that have file sharing features, discussion forums for sharing medical experiences and there are search features needed by doctors and nurses for inpatient services at XYZ ISLAMIC HOSPITAL.",Inpatient Medical Service;Knowledge Management;Knowledge Management System;Big Data.,T. R. Perdana; S. Mujiatun; S. Sfenrianto; E. R. Kaburuan,"Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia",2019.0,2019 International Conference on Information and Communications Technology (ICOIACT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938469,10.1109/ICOIACT46704.2019.8938469,20230520-160000,20230521-044735,"['designing', 'knowledge', 'management', 'system', 'with', 'big', 'data', 'for', 'hospital', 'inpatient', 'services', ':', '(case', 'study', 'at', 'islamic', 'hospital', 'xyz', 'pekanbaru)']",False,20230521-205332,,,,
41,ieeex,On the Appropriate Methodologies for Data Science Projects,"Data science is an emerging discipline with a particular research focus on improving the available techniques for data analysis. While the number of data science projects is growing, unfortunately, there is a slight consideration of how a team performs a data science project. Although the existence of a repeatable well-defined process could deal with many challenges of data science projects, researches conducted in recent years indicate a convergence of the results to agile methodologies as the appropriate ones for the projects. In this paper, first, the tasks and roles of individuals in data science projects are addressed; then, some research conducted for the methodologies used in the projects are studied. The study shows that agile methodologies could resolve many issues of data science projects by increasing the communications and cooperation of the team members and investors.",agile software methodologies;data science;big data;business intelligence,A. Karimi Dastgerdi; T. Javdani Gandomani,"Faculty of Business and Economics, Leuphana University of Luneburg, Luneburg, Germany; Department of Computer Science, Shahrekord University, Shahrekord, Iran",2021.0,2021 International Conference on Information Technology (ICIT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491712,10.1109/ICIT52682.2021.9491712,20230520-160000,20230521-044735,"['on', 'the', 'appropriate', 'methodologies', 'for', 'data', 'science', 'projects']",False,20230521-205332,,,,
42,ieeex,Big Data Analytics on Cyber Attack Graphs for Prioritizing Agile Security Requirements,"In enterprise environments, the amount of managed assets and vulnerabilities that can be exploited is staggering. Hackers' lateral movements between such assets generate a complex big data graph, that contains potential hacking paths. In this vision paper, we enumerate risk-reduction security requirements in large scale environments, then present the Agile Security methodology and technologies for detection, modeling, and constant prioritization of security requirements, agile style. Agile Security models different types of security requirements into the context of an attack graph, containing business process targets and critical assets identification, configuration items, and possible impacts of cyber-attacks. By simulating and analyzing virtual adversary attack paths toward cardinal assets, Agile Security examines the business impact on business processes and prioritizes surgical requirements. Thus, handling these requirements backlog that are constantly evaluated as an outcome of employing Agile Security, gradually increases system hardening, reduces business risks and informs the IT service desk or Security Operation Center what remediation action to perform next. Once remediated, Agile Security constantly recomputes residual risk, assessing risk increase by threat intelligence or infrastructure changes versus defender's remediation actions in order to drive overall attack surface reduction.",Security Requirements;Requirements Prioritization;Agile Security;Attack Graph;Graph Analytics;Attack Path;Remediation Requirements;Attack Surface;Cyber Digital Twin,E. Hadar; A. Hassanzadeh,"Accenture Labs, Accenture; Accenture Labs, Accenture",2019.0,2019 IEEE 27th International Requirements Engineering Conference (RE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920695,10.1109/RE.2019.00042,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'on', 'cyber', 'attack', 'graphs', 'for', 'prioritizing', 'agile', 'security', 'requirements']",False,20230521-205332,,,,
43,ieeex,Agility Measurement of Agile Supply Chain Network Based on Complex Network Theory,"With the development of information technology, the supply chain has developed into a new stage of intelligent supply chain which is deeply integrated with the Internet and the Internet of Objects. In order to give full play to the characteristics of innovation, collaboration, win-win, openness and greenness in supply chain, and to build a smart supply chain system with big data support, network sharing and intelligent collaboration, the agility measurement of supply chain has become an urgent and important topic. This paper presents an agile metric based on complex network theory for agile supply chain network. Firstly, the mathematical expression of agile supply chain network and its agility measurement method are defined, and the constraints of complex network theory are also defined. Secondly, to facilitate the calculation of agility metrics, complex network theory is introduced into agile supply chain network. In addition, a large number of experiments have been designed and implemented to verify the accuracy of the proposed complex network theory in agile supply chain network measurement. At the same time, the agility of the supply chain network is measured, and its changing rules and optimization methods are summarized. The experimental results show that the proposed complex network theory can accurately measure the agility of agile supply chain network. The purpose of this paper is to provide a method to turn agile supply chain system into intelligent information system through mathematical modeling.","complex network theory, agile supply chain network, estimated value, agility measurement, intelligent information system",Y. Yao; L. Li,"Anhui Finance & Trade Vocational College, Hefei, China; School of Management Hefei University of Technology, Anhui Finance & Trade Vocational College, Hefei, China",2019.0,"2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051272,10.1109/ICICAS48597.2019.00163,20230520-160000,20230521-044735,"['agility', 'measurement', 'of', 'agile', 'supply', 'chain', 'network', 'based', 'on', 'complex', 'network', 'theory']",False,20230521-205332,,,,
44,ieeex,Improving the Quality of Requirements Engineering Process in Software Development with Agile Methods: a Case Study Telemedicine Startup XYZ,"XYZ is a telemedicine startup company that uses Scrum, an Agile methodology, as a software development method. The company uses Scrum to deliver good products and services to customers on time, even with limited requirements. However, the company faced problems in product development, so the company could not release the product on time. Based on interviews with internal experts, the company has issues determining the priority scale of requirements and change requirement management, where both problems are part of requirement engineering. This study discusses the problems of the company XYZ regarding the requirement engineering process, especially the problem of determining the priority scale of requirements and change requirement management. This research uses the CMMI-Dev 1.3 specific process area to assess the requirement engineering process in the company using sub-specific practices in the Requirement Development (RD) and Requirement Management (REQM) process areas. Researchers conducted interviews with product managers to appraise sub-specific RD and REQM practices with current activities in the company. The results of this study are recommendations to improve the quality of the requirement engineering process by using Objective Key Result (OKR) and Action Priority Matrix (APM).",Action Priority Matrix;Agile;CMMI-Dev 1.3;Objective Key Result;Requirement Engineering;Scrum,A. S. Wibawa; E. K. Budiardjo; K. Mahatma,"Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia",2021.0,"2021 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701962,10.1109/ICADEIS52521.2021.9701962,20230520-160000,20230521-044735,"['improving', 'the', 'quality', 'of', 'requirements', 'engineering', 'process', 'in', 'software', 'development', 'with', 'agile', 'methods:', 'a', 'case', 'study', 'telemedicine', 'startup', 'xyz']",False,20230521-205332,,,,
45,ieeex,Smart Water Quality Analysis using IoT and Big Data Analytics: A Review,"In recent times, water quality monitoring, observing, and testing have become a significant research study with the advancement on the Internet of Things, and Big Data analytics research ideas. The relationship between water demand and supply is very crucial for every country and is likewise a complex challenge to satisfy this requirement around the world. Water is compulsory for human survival being on the earth. Therefore, for survival, the preservation and taking care of the existing water resource are also equally substantial. Moreover, for a healthier society, access to clean and safe water resources is also imperative. To recognize the water quality effects and provide an automated water quality mentoring and a testing system can support in guaranteeing the safety of the water. This paper presents a study on water quality analysis using IoT and Big Data analytics. This can help in developing an agile environment that can handle the massive flow of water big data generated by the smart sensors spread everywhere around us.",ater Quality;Internet of Things;Cloud Computing;and Big Data Analytics,E. E. -D. Hemdan; Y. M. Essa; A. El-Sayed; M. Shouman; A. N. Moustafa,"Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Principle Data and Knowledge. Bayer, Berlin, Germany; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt",2021.0,2021 International Conference on Electronic Engineering (ICEEM),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9480628,10.1109/ICEEM52022.2021.9480628,20230520-160000,20230521-044735,"['smart', 'water', 'quality', 'analysis', 'using', 'iot', 'and', 'big', 'data', 'analytics:', 'a', 'review']",False,20230521-205332,,,,
46,ieeex,Construction of a Social Security Monitoring and Early Warning Platform Driven by Big Data,"This article focuses on the existing sensitive information early warning mechanism and auxiliary decision-making is not sound, the emergency command and control is not agile, the application system business is solidified, and the existing monitoring and early warning service mode deals with multi-source, heterogeneous terrorism-related data, data utilization inefficiency and limited data processing service functions, the inability to achieve intelligent control of the process, and the inability to achieve precise monitoring, as well as the multi-dimensional and in-depth intelligent analysis of sensitive data. Research on distributed real-time transmission and distribution of big data based on multi-source and multi-channel adaptation, multi-source, heterogeneous big data distributed online real-time processing based on S4/Strom and distributed memory computing, position-based social security event monitoring, and semi-supervised system self-evolution and other key technologies, proposed to build a big data-driven social security monitoring and early warning platform system.",data-driven;early warning platform;big data;data mining,J. Yu; J. Guo; L. Globa; S. Li; M. Zhang; X. Li; J. Liu,"Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Institute of Telecommunication Systems of National Technical University of Ukraine, Igor Sikorsky Kyiv Polytechnic Institute, Kyiv, Ukraine; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Shandong Normal University, Jinan, China",2021.0,"2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482215,10.1109/IMCEC51613.2021.9482215,20230520-160000,20230521-044735,"['construction', 'of', 'a', 'social', 'security', 'monitoring', 'and', 'early', 'warning', 'platform', 'driven', 'by', 'big', 'data']",False,20230521-205332,,,,
47,ieeex,IoT Agile Framework Enhancement,"Internet of Things (IoT) is considered as a trend nowadays. Devices connected to the internet interact with surrounding; this poses strong challenges in handling big data with a certain level of security. In this paper IoT devices will be divided in to two categories high vulnerability devices and low vulnerability devices. The classification depends on the ease of attacks. In order to ensure the security of IoT devices, an agile approach is used to secure high vulnerability devices as first step and then low vulnerability devices by applying encryption algorithms.",Internet of Things;Agile approach;Encryption algorithms,B. Gabr; M. A. Azer,"Wireless intelligent networks centre (WINC), Nile University, Egypt; National Telecommunication Institute, Nile University, Egypt",2018.0,2018 1st International Conference on Computer Applications & Information Security (ICCAIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441993,10.1109/CAIS.2018.8441993,20230520-160000,20230521-044735,"['iot', 'agile', 'framework', 'enhancement']",False,20230521-205332,,,,
48,ieeex,Talent management in agile software development: The state of the art,"With increasing competition in the software market, software companies are using new management strategies to increase their competitiveness. In recent years, with the prevalence of agile methodologies in software development, paying attention to human resources, and selecting and managing talented human resources have become inevitable. This should be achieved by adopting appropriate talent management processes. However, in software engineering, talent management has not yet been seriously considered. Due to the critical role of agile methodologies in human resources, and the authority and freedom of individuals in agile teams, the benefit of talent management in these methodologies is vital. As a starting point, this article tries to provide a concise overview of talent management in agile software development and address the ambiguities and research gaps facing software researchers in this regard. The initial results of this study show that several ambiguities such as appropriate models of talent management applicable in agile methodologies, how to use them, effective factors in talent assessment, and the relationship between talent management and the quality of teamwork are some of the most noticeable research gaps in this area.",Agile software development;talent management;human capital;agile team management;research trends,T. J. Gandomani; A. Mashmool; M. Dashti; S. Khosravi; M. N. Sarpiri; M. Radnejad; M. Afshari; S. Mansouri,"Dept. of Computer Science, Shahrekord University, Shahrekord, Iran; Dept. of Computer Engineering, University of Birjand, Birjand, Iran; Data Science Research Center, Shahrekord University, shahrekord, Iran; Dept. of Computer Engineering, University of Birjand, Birjand, Iran; Dept. of Computer Engineering, Isfahan Branch, Islamic Azad University, Isfahan, Iran; Dept. of Computer Engineering, Isfahan Branch, Islamic Azad University, Isfahan, Iran; Data Science Research Center, Shahrekord University, shahrekord, Iran; Dept. of Computer Engineering, Dolatabad Branch, Islamic Azad University, Isfahan, Iran",2021.0,2021 3rd East Indonesia Conference on Computer and Information Technology (EIConCIT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431902,10.1109/EIConCIT50028.2021.9431902,20230520-160000,20230521-044735,"['talent', 'management', 'in', 'agile', 'software', 'development:', 'the', 'state', 'of', 'the', 'art']",False,20230521-205332,,,,
49,ieeex,Customizing and Deploying Data Science Roadmapping: A Case Study of an Oil and Gas Company,"Many organizations still face challenges leveraging data science in production and need strategic planning for organization-wide data science efforts and assets. Data Science Roadmapping (DSR) customizes the widely used Technology Roadmapping to facilitate such planning in organizations, aligning market, business, data, technology, and organization perspectives. This paper employs the action research method to customize and apply DSR in an oil and gas company. The approach mostly met the expectations regarding objectives and outcomes, the first step toward generalizability. The case study provides researchers and practitioners insights into roadmapping customization, remote and agile roadmap development process, and strategic planning for technology adoption in a large organization. Lastly, we identify the future research directions using the recent roadmapping literature.",technology roadmapping;data science;big data;high-performance computing;data strategy,K. Kayabay; M. O. Gökalp; E. Gökalp; S. M. Alagöz; P. E. Eren; A. Koçyiğit,"Department TÜBİTAK ULAKBİM, Data Informatics Middle East Technical University Network Technologies, Ankara, Türkiye; Data Analytics Center TÜPRAŞ, Ankara, Türkiye; Computer Engineering Department, Hacettepe University, Ankara, Türkiye; Data Analytics Center TÜPRAŞ, İstanbul, Türkiye; Information Systems Middle East Technical University, Ankara, Türkiye; Information Systems Middle East Technical University, Ankara, Türkiye",2022.0,"2022 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10082858,10.1109/ICTMOD55867.2022.10082858,20230520-160000,20230521-044735,"['customizing', 'and', 'deploying', 'data', 'science', 'roadmapping:', 'a', 'case', 'study', 'of', 'an', 'oil', 'and', 'gas', 'company']",False,20230521-205332,,,,
50,ieeex,ENIAD: A Reconfigurable Near-data Processing Architecture for Web-Scale AI-enriched Big Data Service,"To meet the surging demands required by AI-enriched Big Data services, cloud vendors are turning toward domain specific accelerators for improved efficiency, scalability and performance. ENIAD, the first end-to-end infrastructure for AI-enriched Big Data serving in real time, accelerates both deep neural network inferencing and billion-scale indexing at the data-center scale. Exploiting near- data computation, reconfigurable computing and rapid/agile hardware deployment flow, ENIAD serves state-of-the-art, online built indexing service with high efficiency at low batch sizes. A high-performance, index (data)-adaptable FPGA soft processor is at the heart of the system and able to serve 10x larger index size with 14x lower latency compared to state-of-the-art CPU and GPU architectures.",,J. Zhang; J. Li,"Department of Electrical and Systems Engineering, University of Pennsylvania, Hot Chips 33, August 22-24,2021; Department of Electrical and Systems Engineering, University of Pennsylvania, Hot Chips 33, August 22-24,2021",2021.0,2021 IEEE Hot Chips 33 Symposium (HCS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567229,10.1109/HCS52781.2021.9567229,20230520-160000,20230521-044735,"['eniad:', 'a', 'reconfigurable', 'near-data', 'processing', 'architecture', 'for', 'web-scale', 'ai-enriched', 'big', 'data', 'service']",False,20230521-205332,,,,
51,ieeex,Design and Research of Insurance Survey Claims System Based on Big Data Analysis,"In order to overcome the cumbersome procedures of insurance investigation and claim settlement and the difficulty of precise promotion of insurance services for specific customers, this paper proposes an insurance investigation and claim system based on big data analysis. This method is developed on the basis of agile model. It has case information management, investigation information management, claim settlement management, intelligent insurance recommendation, etc. Intelligent customer service and other core functions, relying on Web, mobile applications and social networks for data collection, filtering and real-time analysis of the collected large data information, using Hadoop framework to convert structured data into semi-structured or unstructured data, storage of data information, through advanced analysis, prediction model Type and visual query, mining and analyzing the extracted data, and finally displaying the results after analysis. The experimental results show that the insurance survey and claim system completes the business processing of one-click report, survey photos upload, efficient claim settlement and insurance recommendation, speeds up the claim processing speed, and realizes the personalized service and precise marketing of customer insurance.",Insurance;Claim Settlement;Intelligence,J. Wu; J. Wang; Y. Liu,"Dalian Neusoft University of Information, Dalian, China; Dalian Neusoft University of Information, Dalian, China; Dalian Neusoft University of Information, Dalian, China",2019.0,2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920755,10.1109/ICVRIS.2019.00059,20230520-160000,20230521-044735,"['design', 'and', 'research', 'of', 'insurance', 'survey', 'claims', 'system', 'based', 'on', 'big', 'data', 'analysis']",False,20230521-205332,,,,
52,ieeex,"Work-in-progress: Data Science Challenge-X: self-directed, competence-based, project-based learning","We discuss in this paper the implementation of a project-based self-direct learning competency-based project module in our Bachelor Data Science programme. The goal of the course is to integrate in a later stage all project modules, which are now divided in two: one with and one without external industry partners, treating different aspects of data science with a pre-defined goal and clear objectives for the project. Switching for a competency-based learner-based paradigm with agile aspects and intrinsic focus, we define the core project goals as secondary and develop core data science competences which are acquired by the students and reflected in a learning journal.",project-based learning;intrinsic motivation;self-directed learning,F. Benites; M. Schlatter; M. Messerli; R. Custer,"School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland",2022.0,2022 IEEE Global Engineering Education Conference (EDUCON),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766710,10.1109/EDUCON52537.2022.9766710,20230520-160000,20230521-044735,"['work-in-progress:', 'data', 'science', 'challenge-x:', 'self-directed,', 'competence-based,', 'project-based', 'learning']",False,20230521-205332,,,,
53,ieeex,An Optimization Model to Evaluate Dynamic Assignment Capability of Agile Organization,"Recently the planning under the uncertain and competitive environment is the hot topic in the agile organization. Many studies highlight how to rapidly make or change the plans with detecting advance information. One of the widely used solutions is to evaluate the agile organization's decision-making capability based the time-domain metrics. However, the dynamic assignment capability always changed during task operating within time-domain. It caused that the planning used the wrong organization capability in the most time. In this paper, we develop an improved simulated annealing algorithm to address this problem. In order to discretize the time-domain, we propose a horizon partition that is based on the task dynamic state. Finally, the optimization model is tested in a toy example. Compared with the traditional models, the results show the proposed model has better outcomes for accurately estimating dynamic agile organization capability.",Operational System of Systems (SoS);Agile organization;Adaptive Optimization;Simulated Annealing;Decision Making,Y. Feng; H. Huang; G. Cheng; C. Chen; J. Huang; Z. Liu; K. Huang,"National University of Defense Technology, Changsha, Hunan, CN; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China",2018.0,2018 4th International Conference on Big Data and Information Analytics (BigDIA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632798,10.1109/BigDIA.2018.8632798,20230520-160000,20230521-044735,"['an', 'optimization', 'model', 'to', 'evaluate', 'dynamic', 'assignment', 'capability', 'of', 'agile', 'organization']",False,20230521-205332,,,,
54,ieeex,Facilitating the Management of Agile and Devops Activities: Implementation of a Data Consolidator,"Organizations are confronted with a growing array of methodologies, tools and cloud offerings to address their business needs. On one hand, engineers and operations staff can leverage innovative DevOps oriented approaches for Continuous Delivery, Continuous Integration, containerization etc. On the other hand, project and operation leads are increasingly relying on agile methodologies to manage software development and release lifecycles. The number of tools available and used to run agile project tasks effectively is increasing and can yield an immense number of unmanageable information views for stakeholders. This paper focuses on the consolidation of these views through an information system built during a case study at South African SME, GZ Consulting Services. By designing an information system which is used as a central portal to aggregate data from internal systems used by the firm, we argue that an organization could better manage its agile and DevOps activities.",Agile;Dev-Ops;Project Management;Activity Theory;SME,G. A. K. Doukoure; E. Mnkandla,"School of Computing, University of South Africa(UNISA), Pretoria, South Africa; School of Computing, University of South Africa(UNISA), Johannesburg, South Africa",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465451,10.1109/ICABCD.2018.8465451,20230520-160000,20230521-044735,"['facilitating', 'the', 'management', 'of', 'agile', 'and', 'devops', 'activities:', 'implementation', 'of', 'a', 'data', 'consolidator']",False,20230521-205332,,,,
55,ieeex,Towards Prediction of Security Attacks on Software Defined Networks: A Big Data Analytic Approach,"Cyber-physical systems (CPS) tightly integrate physical and computing processes by monitoring and control data interacting between them via underlying networks. Software Defined Network (SDN) Technology has increasingly become essential in many advanced computer networks, including those in modern CPS, to provide flexible and agile network development. Despite many benefits that SDN offers, malicious attacks that can eventually prevent network services are unavoidable. Among the most predominant attacks on SDN controller layer, Link Discovery Attack and ARP (Address Resolution Protocol) Spoofing Attack are fundamental in that they are the gateways of many other SDN threats and attacks. To defend these attacks, most existing techniques either rely on relatively complex data validation techniques or use thresholds that can be subjective and unable to detect more than one type of attacks at a time if one deciding factor is used. While Big data technology, particularly machine learning, has been widely used for intrusion/anomaly detection, little has been done in SDN. This paper explores how well this technology can be used to predict these SDN attacks. By employing typical machine learning algorithms on simulated data of routing in SDN when attacks occur, preliminary results, obtained from four machine learning models, show the average area under ROC curve of over 96% and 92% for sample size 50,970 (12 switches) and 60,000 (20 switches), respectively. Further experiments show near-linear scaling in training time for the best performing algorithm when sample size grows up to 100,000.",Software-Defined Networking;SDN-specific security;Link Discovery attack;ARP Spoofing attack;Machine Learning;Data Analytic Applications,E. Unal; S. Sen-Baidya; R. Hewett,"Department of Computer Science, Texas Tech University, Lubbock, TX, USA; Department of Computer Science, Texas Tech University, Lubbock, TX, USA; Department of Computer Science, Texas Tech University, Lubbock, TX, USA",2018.0,2018 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622524,10.1109/BigData.2018.8622524,20230520-160000,20230521-044735,"['towards', 'prediction', 'of', 'security', 'attacks', 'on', 'software', 'defined', 'networks:', 'a', 'big', 'data', 'analytic', 'approach']",False,20230521-205332,,,,
56,ieeex,Counterfactual Regret Minimization for Anti-Jamming Game of Frequency Agile Radar,"The competition between radar and jammer is one important issue in modern electronic warfare, which in principle can be viewed as a non-cooperative game with two players. In this work, the competition between a frequency agile (FA) radar and a noise-modulated jammer is considered. As modern FA radar adopts coherent processing with several pulses, the competition is hence in a multiple-round way where each pulse can be modeled as one round interaction between the radar and jammer. To capture such multiple-round property as well as imperfect information inside the game, i.e., radar and jammer are unable to know the upcoming signal, we propose an extensive-form game formulation for such competition. Since the number of game information states grows exponentially with respect to number of pulses, finding Nash Equilibrium (NE) strategies may be a computationally intractable task. To effectively solve the game, a learning-based algorithm called deep Counterfactual Regret Minimization (CFR) is utilized. Numerical simulations demonstrates the effectiveness of deep CFR algorithm for approximately finding NE and obtaining the best response strategy.",Frequency agile radar;anti-jamming problem;extensive form game,H. Li; Z. Han; W. Pu; L. Liu; K. Li; B. Jiu,"Shenzhen Research Institute of Big Data, China; Shenzhen Research Institute of Big Data, China; Shenzhen Research Institute of Big Data, China; The Chinese University of Hong Kong, Shenzhen, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China",2022.0,2022 IEEE 12th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827883,10.1109/SAM53842.2022.9827883,20230520-160000,20230521-044735,"['counterfactual', 'regret', 'minimization', 'for', 'anti-jamming', 'game', 'of', 'frequency', 'agile', 'radar']",False,20230521-205332,,,,
57,ieeex,Understanding How the Ad Hoc use of Big Data Analytics Impacts Agility: A Sensemaking-Based Model,"As business environments become increasingly complex and turbulent, organizations are required to be more agile. Use of big data analytics (BDA) can be a differentiator for organizations seeking to improve agility to quickly sense and respond to novel and complex events. Usage of BDA comprises two types: the routine use and the ad hoc use. The latter is more associated with the unplanned analysis of big data to understand unexpected events, and its effects have not been studied in distinction to the former in the analytics literature. We draw on sensemaking, the organizational theory of the process of understanding novel and complex events, to investigate how the ad hoc use of BDA improves agility of organizations. Analysis of a survey of 107 business executives and senior managers demonstrated the positive effects of the ad hoc use of BDA on agility, through mediation by sensemaking.",big data;analytics;ad hoc use;sensemaking;agility,R. Hosoya; T. Kamioka,"Graduate School of Commerce and Management, Hitotsubashi University, Kunitachi, Tokyo, Japan; Graduate School of Commerce and Management, Hitotsubashi University, Kunitachi, Tokyo, Japan",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465446,10.1109/ICABCD.2018.8465446,20230520-160000,20230521-044735,"['understanding', 'how', 'the', 'ad', 'hoc', 'use', 'of', 'big', 'data', 'analytics', 'impacts', 'agility:', 'a', 'sensemaking-based', 'model']",False,20230521-205332,,,,
58,ieeex,"Big Data Hysteria, Cognizance and Scope","In real time scenario, every second man and machine have been generating a huge amount of data. Social networking sites like Facebook, tweeter, Instagram, search engine google, yahoo and video shearing websites like YouTube and many real time applications generates enormous quantity of data. These data-sets have different attributes (i.e. volume, velocity, complexity etc.) in it, known as `Big Data'. To manage, process and analyze big data, we require advance hardware platform, software stack and analytics techniques. Big data Analytics emerges as a major application for future data-sets, generating by parallel and distributes systems. This paper has discussed about hype on Big Data, its characteristics, different considerations (i.e. Hardware, Software, Platform, N oSql Data Base, Languages). It has summarized the Techniques of Big Data and light up on scope with other technologies (i.e. IoT, Agile, Lean Six Sigma).",Big Data;Volume;Inherent properties;Big Data Management;Analytics techniques,R. Harsh; G. Acharya; S. Chaudhary,"CSE Dept, M.E.C., Bikaner, Rajasthan, India; Industrial Engg & Management, Jaipur, Rajasthan, India; Industrial Engg & Management, Jaipur, Rajasthan, India",2018.0,2018 4th International Conference for Convergence in Technology (I2CT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057878,10.1109/I2CT42659.2018.9057878,20230520-160000,20230521-044735,"['big', 'data', 'hysteria,', 'cognizance', 'and', 'scope']",False,20230521-205332,,,,
59,ieeex,To Offload or Not? An Analysis of Big Data Offloading Strategies from Edge to Cloud,"Large reductions in completion times can result from transfer of Big Data tasks from edge nodes to cloud resources, which can reduce the completion times by up to 97 % and meet client deadlines for computational tasks with responsive and agile solutions. Using scientific programs of varying computational complexity to model resource-intensive tasks, we demonstrate that the task complexity of the computational jobs, the Wide Area Network (WAN) speed and the potential overload of edge servers (as reflected by CPU workloads) are crucial for achieving total reductions in task completion time edge-cloud orchestrators are situated in edge nodes. With continuous access to the parameters of Wireless Local Area Network (WLAN) speed (for data exchanges between client and edge resources), WAN speed (for data exchanges between edge and cloud resources) edge server CPU workload and the complexities in Big Data analytics requirements, accurate edge-to-cloud offloading decisions can be made to minimise total task completion time by the use of cloud computing resources. This work supports the major research efforts have been recently made to develop novel resource orchestration solutions to flexibly link edge nodes with centralised cloud resources so as to maximise the efficiency with which such a continuum of resources can be accessed by users.",Application-level orchestration;Cloud-to-Edge con-tinuum;Big Data analytics;WLAN;WAN;Computational complexity;Server workload,R. Singh; J. Kovacs; T. Kiss,"Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK; Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK; Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK",2022.0,2022 IEEE World AI IoT Congress (AIIoT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817276,10.1109/AIIoT54504.2022.9817276,20230520-160000,20230521-044735,"['to', 'offload', 'or', 'not?', 'an', 'analysis', 'of', 'big', 'data', 'offloading', 'strategies', 'from', 'edge', 'to', 'cloud']",False,20230521-205332,,,,
60,ieeex,Open Data Lake to Support Machine Learning on Arctic Big Data,"The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data.",big data;data management;data lake;open data;reusability;FAIR principle;CARE principle;Arctic data;Arctic expedition;machine learning;data mining,A. M. Olawoyin; C. K. Leung; A. Cuzzocrea,"Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; iDEA Lab University of Calabria, Rende, Italy",2021.0,2021 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671453,10.1109/BigData52589.2021.9671453,20230520-160000,20230521-044735,"['open', 'data', 'lake', 'to', 'support', 'machine', 'learning', 'on', 'arctic', 'big', 'data']",False,20230521-205332,,,,
61,ieeex,Machine Learning Experiments with Artificially Generated Big Data from Small Immunotherapy Datasets,"Big data and machine learning result in agile and robust healthcare by expanding raw data into useful patterns for data-enhanced decision support. The available datasets are mostly small and unbalanced, resulting in non-optimal classification when the algorithms are implemented. In this study, five novel machine learning experiments are conducted to address the challenges of small datasets by expanding these into big data and then utilising Random Forests. The experiments are based on personalised adaptable strategies for both balanced and unbalanced datasets. Multiple datasets from cryotherapy and immunotherapy are considered, however, hereby only immunotherapy is used. In the first experiment, artificially generated data is presented by increasing the observations of the dataset, each new data is four-time larger than the previous one, resulting in better classification. In the second experiment, the effect of volume on classification is considered based on the number of attributes. The attributes of each new dataset are built based on conditional probabilities. It did not make any difference, in obtained classification, when the number of attributes is increased to more than 879. In the third simulation experiment, classes of data are classified manually by dividing the data into a two-dimensional plane. This experiment is first performed on small data and then on expanded big data: by increasing observations, an accuracy of 73.68% is attained. In the fourth experiment, the visualisation of the enlarged data did not provide better insights. In the fifth experiment, the impact of correlations among datasets’ attributes on classification is observed, however, no improvements in performance are achieved. The experiments generally improved performance by comparing the classification results using the original and artificial data.",Immunotherapy;Big data;Machine learning;Classification;Random Forests;Warts;Cryotherapy;Health-care,A. Yunas Mahmoud; D. Neagu; D. Scrimieri; A. Rashad Ahmed Abdullatif,"Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England",2022.0,2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10069649,10.1109/ICMLA55696.2022.00165,20230520-160000,20230521-044735,"['machine', 'learning', 'experiments', 'with', 'artificially', 'generated', 'big', 'data', 'from', 'small', 'immunotherapy', 'datasets']",False,20230521-205332,,,,
62,ieeex,An Agile Sample Maintenance Approach for Agile Analytics,"Agile analytics can help organizations to gain and sustain a competitive advantage by making timely decisions. Approximate query processing (AQP) is one of the useful approaches in agile analytics, which facilitates fast queries on big data by leveraging a pre-computed sample. One problem such a sample faces is that when new data is being imported, re-sampling is most likely needed to keep the sample fresh and AQP results accurate enough. Re-sampling from scratch for every batch of new data, called the full re-sampling method and adopted by many existing AQP works, is obviously a very costly process, and a much quicker incremental sampling process, such as reservoir sampling, may be used to cover the newly arrived data. However, incremental update methods suffer from the fact that the sample size cannot be increased, which is a problem when the underlying data distribution dramatically changes and the sample needs to be enlarged to maintain the AQP accuracy. This paper proposes an adaptive sample update (ASU) approach that avoids re-sampling from scratch as much as possible by monitoring the data distribution, and uses instead an incremental update method before a re-sampling becomes necessary. The paper also proposes an enhanced approach (T-ASU), which tries to enlarge the sample size without re-sampling from scratch when a bit of query inaccuracy is tolerable to further reduce the sample update cost. These two approaches are integrated into a state-of-the-art AQP engine for an extensive experimental study. Experimental results on both real-world and synthetic datasets show that the two approaches are faster than the full re-sampling method while achieving almost the same AQP accuracy when the underlying data distribution continuously changes.",,H. Zhang; Y. Zhang; Z. He; Y. Jing; K. Zhang; X. S. Wang,"School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2020.0,2020 IEEE 36th International Conference on Data Engineering (ICDE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101582,10.1109/ICDE48307.2020.00071,20230520-160000,20230521-044735,"['an', 'agile', 'sample', 'maintenance', 'approach', 'for', 'agile', 'analytics']",False,20230521-205332,,,,
63,ieeex,Research and Implementation of Intelligent Platform for Targeted Employment Poverty Alleviation Based On Cloud Computing and Big Data,"With the development of Internet technology, big data technology provides technical support for China’s targeted poverty alleviation. The key to targeted poverty alleviation lies in providing employment. Employment poverty alleviation is the most direct, realistic and effective way for poor workers to get rid of poverty. How to establish an information communication platform between the poor and enterprises is a key problem to be solved urgently. This paper uses cloud computing, big data and intelligent decision making technology to develop the big data “Internet plus” platform for precision employment and poverty alleviation. It has solved the problems of asymmetric information among enterprises, the poor and government departments, lack of effective supply and demand docking platform, unbalanced regional distribution of employment posts and labor force, inaccurate employment services, long employment chain and difficult tracking services. This paper describes in detail the architecture design, targeted employment framework process, deployment and implementation for the platform adopting scrum and continuous integration development method. The platform has been successfully online, exploring employment poverty alleviation for about one year, successfully solved the employment of nearly 2,000 poor labor forces and 5,000 needy students in secondary vocational and higher vocational education, cooperated with more than 100 large-scale well-known enterprises in manufacturing, logistics and service industry, formed a systematic targeted employment poverty alleviation model, scheme and experience. Compared with the existing systems in the literature, the advantages and transformation effect of this platform are remarkable. The platform construction experience of this paper can provide reference for the application of big data, cloud computing and other technologies in other fields of national construction.",Targeted Employment;Big Data;Targeted Poverty Alleviation;Platform;Cloud Computing,C. Jiang,"School of Library, Shandong University of Political Science and Law, Jinan, China",2021.0,2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719060,10.1109/CISAI54367.2021.00102,20230520-160000,20230521-044735,"['research', 'and', 'implementation', 'of', 'intelligent', 'platform', 'for', 'targeted', 'employment', 'poverty', 'alleviation', 'based', 'on', 'cloud', 'computing', 'and', 'big', 'data']",False,20230521-205332,,,,
64,ieeex,Harnessing The Power of the Internet of Things (IoT) to Achieve an Agile Business Education Model: A Visionary Paper,"The emergence of artificial intelligence, big data, and the Internet of Things (IoT) has shifted human-human, human-machine, and machine-machine interaction to a new level. This shift is affecting all aspects of society’s behavior toward the adoption of technology. One important pillar of society that is especially impacted by this radical change is that of education. The advancement of new technologies as well as the occurrence of unexpected global events has forced education systems in many countries to look differently at traditional educational issues and work toward becoming a more agile education system. This means being responsive to any unpredicted changes that may occur in the education environment. Indeed, the agility of business schools and technological adaptability is one of the standards required by program accreditation organizations (i.e., AACSB). This paper discusses the application of IoT in business education, focusing on the opportunities, challenges, and paths forward this presents.",IoT;Business Education;Education Agility;Higher Education,A. Qasim; G. A. E. Refae; S. Eletter; A. R. Al-Chahadah,"College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Alzaytoonah University, Amman, Jordan",2021.0,"2021 8th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9704939,10.1109/IOTSMS53705.2021.9704939,20230520-160000,20230521-044735,"['harnessing', 'the', 'power', 'of', 'the', 'internet', 'of', 'things', '(iot)', 'to', 'achieve', 'an', 'agile', 'business', 'education', 'model:', 'a', 'visionary', 'paper']",False,20230521-205332,,,,
65,ieeex,A Service Driver Based Application Execution and Development Method in Multi-cloud Context,"To reduce the cost of cloud tenants and avoid the phenomenon of vendor lock-in, multi-cloud technique is proposed and competent for this goal. However, it leads to another difficultly on supporting application development and runtime update process in the multi-cloud context. The key points for this problem are: (i) implementing application runtime switch among cloud services for varied service requirements and status; (ii) supporting runtime agile and low-cost update, and redevelopment for emerging new cloud services. To overcome this problem and advance multi-cloud applications execution, we present a support technique based on service driver concept. Service driver can help applications shield the heterogeneity and switch among cloud services. To support the implementation of service driver, we have finished the following three areas: (i) proposing a multi-cloud application service access model which is implemented through multi-agent system technique; (ii) presenting a multi-cloud application runtime service update and invocation process; (iii) introducing a multi-cloud application development framework. Furthermore, to help and direct developers to design and implement multi-cloud application, we describe a multi-cloud application (re)development method. This method includes multi-cloud application development process and runtime multi-cloud application agile redevelopment process. Finally, we interpret the multi-cloud application development support techniques and methods via case study.",multi-cloud application;development method;service driver;service switch;agile redevelopment,S. Zhang; L. Ni; K. Han,"College of Information and Communication, National University of Defense Technology, Xi’an, China; College of Information and Communication, National University of Defense Technology, Xi’an, China; College of Information and Communication, National University of Defense Technology, Xi’an, China",2021.0,2021 IEEE International Conference on Data Science and Computer Application (ICDSCA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650251,10.1109/ICDSCA53499.2021.9650251,20230520-160000,20230521-044735,"['a', 'service', 'driver', 'based', 'application', 'execution', 'and', 'development', 'method', 'in', 'multi-cloud', 'context']",False,20230521-205332,,,,
66,ieeex,Big Data Analytics Role in Managing Complex Supplier Networks and Inventory Management,"In today's world, competition is not only restricted between the marketing aspects of two companies or big firms. The competition has expanded between the supply chain management perspectives of two firms. In order to sustain within the current competitive environment supply chain professionals of a firm are struggling hard to handle large-scale data, that is important to reach an integrated, efficient, effective as well as agile supply chain process within their business. As a result, explosive growth of data volume and amount of data within business, made it mandatory for the supply chain processionals to use an effective data analytic tool in order to manage these data. The main aim of this study is to identify use of various data analytic tools in order to manage large data of supply process and inventory management process with several advantages and disadvantages. As per the literature findings, it has been observed that use of data analytic tools within an organisation can be helpful to investigate new insights of the supply chain process, which can be able to detect different parts and elements of that process. A mixed method approach has been incorporated within this research paper by collecting primary and secondary both data collection process. Total 50 employees engaged with inventory and supply chain management of different firm are chosen to conduct a survey. Secondary data are collected from secondary sources. As per the findings, it can be stated that big data analytics plays a positive role in organization for managing large data.",Supply chain management;Inventory management;large-scale data;machine learning algorithm;Data processing. NoSQL;Regression;IoT;Cloud-computing;challenges,D. J. Anusha; M. Panga; A. Hadi Fauzi; A. Sreeram; A. Issabayev; N. Arailym,"Department of Computer Science & Engineering, Sri Padmavati Mahila Visvavidyalayam, Tirupati, India; Economic Prestige Institute of Management and Research Indore; Business Administration Department, Faculty of Political and Social Sciences, Universitas Padjadjaran, Indonesia; Operations & IT ICFAI Business School, (A Constituent of IFHE University), Hyderabad, India; Department of Architecture, International Education Corporation, Almaty, Kazakhstan; Department of Design, International Education Corporation, Almaty, Kazakhstan",2022.0,2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761008,10.1109/ICSCDS53736.2022.9761008,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'role', 'in', 'managing', 'complex', 'supplier', 'networks', 'and', 'inventory', 'management']",False,20230521-205332,,,,
67,ieeex,Web Development of Direct-to-consumer Genetics Testing,"As the cost of genetic testing becomes more affordable each year, direct-to-customer (DTC) genetic testing services witness rapid market growth. This has encouraged the development of an easy-to-use website application to optimize potential customers to obtain informed choice regarding the offered DTC genetic testing as well as purchasing information. We present a wireframing process as a part of the agile software development process to build a web portal prototype for an Indonesia-based genetic testing service called DNAku. The approach in building the prototype used in this case is a part of the Agile Software Development Method. In brief, the wireframing stage resulted in this work consists of three main important outcomes. The first one is the use case diagram as a blueprint of this web-based system. A site map is then proposed as an extended version of the use case diagram which visualizes the whole pages with the links. Finally, based on this site map a series of page mock-ups are designed using Hyper Text Marking Language (HTML) and Cascading Style Sheets (CSS). The result of the prototype can be used as the basis for the next development stage, which is the coding stage based on the collected feedback from users. Considering the continuous application development via the wireframing method by taking into account the cycle of feedbacks from involved parties, this approach can strengthen the infrastructure to sustain DTC genetic business model, which has a niche market in Indonesia.",agile;genetic testing;prototype;website development;wireframing,K. Azizatikarna; D. E. Parung; D. Amirullah; A. A. Hidayat; T. W. Cenggoro; A. Budiarto; Simon; B. Pardamean,"Genetics Indonesia, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia",2022.0,2022 4th International Conference on Cybernetics and Intelligent System (ICORIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031450,10.1109/ICORIS56080.2022.10031450,20230520-160000,20230521-044735,"['web', 'development', 'of', 'direct-to-consumer', 'genetics', 'testing']",False,20230521-205332,,,,
68,ieeex,Big Data Analytics APIs Architecture for Formative Assessors,"This Research to Practice Full Paper is driven by the question: Within limited time resources available to trainers in projects for Big Data Analytics (BDA) problems, how can they define project requirements for Formative Assessment (FA) actions? The paper suggests BDA APIs architecture as helping tool for formative assessors. It helps them effectively produce and adapt visual diagnostic reports for FA-actions in agile based requirements (i.e. features) definition. The paper presents two core architectures: Architecture for a parametrized feature-descriptor-system to define/refine a BDA API feature and its visual diagnostic reports, and an initial resources architecture for BDA API to initialize an analytics algorithm with its input big data sets. Clarifying visually the trainee's challenges (i.e. incremental features in a BDA API) is our main FA action. The FA action is designed based on Csikszentmihalyi's flow model to support a trainee in matching balance between his/her challenges and his/her skills. To test the architecture's functions, the paper has test setups for two formal projects (each has 1 to 6 trainees) and two informal projects (each has 1 to 3 trainees). The projects are to attack BDA problems in learning analytics and in image automatic classification. The test results show that the visual diagnostic reports produced by the trainers are very effective in clarifying visually incremental BDA API features not only for simple classifiers (i.e. classical data mining algorithms) but also for complex classifiers (i.e. deep learning algorithms). The results show also how visual diagnostic reports are easily produced for comparing the algorithm performances using different input big data sets, whereas other reports are produced for comparing performances between different algorithms, using one input data set. Related works are also discussed to show the architecture's differences and advantages. Its main advantages are: 1) it enables the trainers to use deep learning algorithms beside classical data mining algorithms in its BDA API parameterizable feature descriptors for visual diagnostic reports. 2) The descriptors can be extended, reused, shared, and scaled out to help trainers in other universities providing flow model based FA actions. 3) Finally, it has extensions to integrate other theoretical frameworks like Buckingham Shum and Deakin Crick's framework for dispositional learning analytics instead of the used flow model.",assessment in engineering education;planning for formative assessment;Big Data Analytics,W. Mahfouz; H. -D. Wuttke,"Faculty of Computer Science and Automation, Ilmenau University of Technology, Germany; Faculty of Computer Science and Automation, Ilmenau University of Technology, Germany",2021.0,2021 IEEE Frontiers in Education Conference (FIE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637431,10.1109/FIE49875.2021.9637431,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'apis', 'architecture', 'for', 'formative', 'assessors']",False,20230521-205332,,,,
69,ieeex,A reconciliation model of agile C2 organization based on converged networks,"With the promotion of information technology and big data technology, and the traction of new operational concepts such as Mosaic Warfare and Joint Global Operations, the research and practice of agile command & control(C2) organization has become a hot issue in the field of C2. One of the focal points of the debate is the contrast between the traditional hierarchy structure of C2 organizations and the edge structure. Is the traditional hierarchy structure of C2 necessarily in conflict with the edge structure? Can these two organizational structure models be reconciled to achieve organizational agility transformation? How to reconcile these two models of organizational structure? In order to solve the above problem, we put forward a kind of suitable reconciliation model of agile C2 organization considering our actual situation. On this basis, we use ontology modeling method to form characteristics of adaptive and intelligent cross-domain integrated solutions, through the establishment of agile ontology and reasoning mechanism of C2 organization.",command & control;agility;organization mode;reconciliation model;converged networks,W. Zhou; W. Bao; X. Sun; J. Wan; Y. Xu; Y. Gao,"College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Information and Communication, National University of Defense Technology, Xi'an, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; International Studies College, National University of Defense Technology, Nanjing, China",2020.0,2020 6th International Conference on Big Data and Information Analytics (BigDIA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384531,10.1109/BigDIA51454.2020.00018,20230520-160000,20230521-044735,"['a', 'reconciliation', 'model', 'of', 'agile', 'c2', 'organization', 'based', 'on', 'converged', 'networks']",False,20230521-205332,,,,
70,ieeex,Literature Review on Big Data Analytics and Demand Modeling in Supply Chain,"New digital technologies have been introduced into our business and social environments, causing a major change that is recognized as the digital transformation in recent years. While environmental shifts suggest that most of the organization starts using advanced technologies such as Internet of Things(IoT), Mobile applications, Blackchain, Intelligence Things, catboats and many more in their supply chain planning to gain an early competitive advantage and these technologies generates enormous amount of data that the traditional business intelligence system difficult to handle processing of vast data in real-time or nearly real time causes abstraction to the insight discovery, demand modeling and supply chain optimization, Big Data initiatives for demand modeling and supply chain optimization promise to answer these challenges by incorporating various services, methods and tools for more agile and adaptably analytics and decision making, there by this paper focus on reviewing the level of analytics and the forecasting methods being used in the supply chain, understating the fundamentals of supply chain and role of demand modeling, there by proposing a high level framework for supply chain analytics in the context of big data with the knowledge of data science, artificial intelligence, big data echo system and supply chain.",Supply chain;Demand modeling;Big data Analytics;Forecasting methods;supply chain framework,P. K. T; M. T. N; R. S. Hegadi,"BMS Institute of Technology and Management, Bengaluru, India; Dept. of ISE, BMS Institute of Technology and Management, Bengaluru, India; Dept. of Computer Science, Solapur University, Maharashtra, India",2018.0,"2018 International Conference on Electrical, Electronics, Communication, Computer, and Optimization Techniques (ICEECCOT)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001513,10.1109/ICEECCOT43722.2018.9001513,20230520-160000,20230521-044735,"['literature', 'review', 'on', 'big', 'data', 'analytics', 'and', 'demand', 'modeling', 'in', 'supply', 'chain']",False,20230521-205332,,,,
71,ieeex,Nexus of Internet of Things (IoT) and Big Data: Roadmap for Smart Management Systems (SMgS),"Disruptive technologies are emerging at a breakneck speed and changing the characteristics of businesses by making them smart. The aim of this paper is to show how industries can use Smart Management System (SMgS) to be competitive in the 21st century. Internet of Things (IoT) will be the key to connecting and communicating among different parts of the smart industries using sensor-like devices, and big data will be continuously collected and analyzed to improve performance. The SMgS will generate new possibilities for better product design, improved qualities, agile supply chain, and enhanced customer satisfaction. It will also help industries to achieve lean and sustainable systems with fewer efforts than traditional approaches. We demonstrate how early adopters have already implemented IoT and are currently generating big data. These efforts have resulted in significant improvements in streamlining their operations. The advantages of IoT and big data applications in different sectors are discussed here with several examples from the industry leaders. The reasons behind why many companies are still waiting to adopt IoT despite being enthusiastic about it are also suggested. Embracing SMgS is crucial for companies to gain a differential competitive advantage in the era of Industry 4.0.",IoT;smart management system;big data;lean;sustainability,M. Roy; A. Roy,"Management and Engineering for Manufacturing, University of Connecticut, Storrs, CT, USA; Management, Marketing and Entrepreneurship, University of Scranton, Scranton, PA, USA",2019.0,IEEE Engineering Management Review,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712560,10.1109/EMR.2019.2915961,20230520-160000,20230521-044735,"['nexus', 'of', 'internet', 'of', 'things', '(iot)', 'and', 'big', 'data:', 'roadmap', 'for', 'smart', 'management', 'systems', '(smgs)']",False,20230521-205332,,,,
72,ieeex,Structured Data for Product Performance Improvement,"SUMMARY & CONCLUSIONSAftermarket reliability data is a cornerstone to understand the performance of one's products against requirements. A successful aftermarket data system goes beyond the basics of supplying reliability figures. Its attributes also include additional metrics for an effective alerting and reporting system to enable proactive response to aftermarket issues. While these system features are key, the implementation and maintenance methodology of the system is crucial to its success. This is because these systems involve big data. In the case presented, it is data which spans several years, for a variety of model numbers on a variety of aircraft platforms or applications. Each set of circumstances yields different reliability figures and associated metrics. With this big data, it is equally crucial to its success to have a methodology to address data integrity, the speed of data, and the portability of data. Our solution with this successful methodology of these features is called Structured Data.A good aftermarket data system is a backbone for any successful organization. A good system in the aerospace industry goes beyond ATA Spec 2000 [1] formatted data and standard reliability figures such as MTBUR (Mean Time Between Unscheduled Removal) and MTBF (Mean Time Between Failure). It is also beyond implementing a Failure Reporting and Corrective Action System (FRACAS). A comprehensive system in the aerospace industry includes several additional measures (i.e. frequency, severity, risk) to represent the Voice of the Customer. And with a built-in mechanism for proactive response to the data, the system can then be considered World-Class.While designing a system with these features is important, its success also hinges upon the methodology of implementation and maintenance. As stated earlier, aftermarket data is considered big data due to the volume of highly specific data. With this big data, it is critical to success to address data integrity, the speed of data, and the portability of data all within a user-friendly experience. For data integrity, do we trust the data? This takes on many forms from cross referencing input and output data to determining an accurate mixed fleet factor. For speed of data, do we have a system in place to handle the cadence of data efficiently? For portability, do we structure our data in such a way where we can be agile to serve potential changes to our system or new systems as our company evolves? For a user-friendly experience, can we structure the data for intuitive analysis for all stakeholders? Thus in the proposed system, all of these aspects of data integrity, the speed of data, the portability of data, and formatting the data per stakeholders are addressed. Our solution with this successful methodology of these features is called Structured Data.The benefits of this newly developed Structured Data extend beyond ATA Spec 2000 in which it is based. The data is structured in a dynamic and interactive environment. This environment includes intuitive analysis and a system of prioritization for corrective action. The key benefit of this Structured Data system is proactive response to aftermarket data analysis.",Product performance;Reliability metrics;MTBUR / MTBF;FRACAS;Voice of Customer;Big data;Data integrity Speed of data;Portability of data;Natural Language Programming (NLP),P. Peter; C. Parendo,Collins Aerospace; Collins Aerospace,2021.0,2021 Annual Reliability and Maintainability Symposium (RAMS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605770,10.1109/RAMS48097.2021.9605770,20230520-160000,20230521-044735,"['structured', 'data', 'for', 'product', 'performance', 'improvement']",False,20230521-205332,,,,
73,ieeex,Design Method Of Frequency-Agile Radar Frequency Hopping Sequence Based On CNN Network And Chaotic Sequence,"With the development of modern radar anti-jamming technology, frequency-agile radar has developed rapidly. To counter jamming signals, the operating frequency of the frequency-agile radar transmitting pulse has strong random performance. The chaotic sequence has great random performance, and the sequence generated by the chaotic sequence also has great randomness. Therefore, this paper first generates data through the chaotic sequence and binary quantization method and uses the autocorrelation performance as the criterion, The optimal threshold corresponding to the optimal frequency hopping sequence of the same chaotic sequence is screened out. The selected random Frequency hopping point sequence with better performance has great ambiguity function performance, that is, target detection performance. First, divide the value range of the optimal threshold, use the chaotic sequence and the optimal threshold as the standard data, turn the threshold optimization problem into a pattern recognition classification problem, and use the standard data as the training set to train the neural network. In the end, the CNN network has a great classification ability can better realize the Frequency hopping point sequence generation.",CNN network;chaotic sequence;binary quantization;autocorrelation;target detection,P. An; Z. Shang; S. Yan; D. Wang,"The Second Research Institute of China Aerospace Science and Industry Corporation, Beijing Institute of Remote Sensing Equipment, Beijing, China; The Second Research Institute of China Aerospace Science and Industry Corporation, Beijing Institute of Remote Sensing Equipment, Beijing, China; Science and Technology on Optional Radiation Laboratory, Beijing Institute of Environment Features, Beijing, China; Science and Technology on Optional Radiation Laboratory, Beijing Institute of Environment Features, Beijing, China",2022.0,"2022 International Conference on Big Data, Information and Computer Network (BDICN)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758437,10.1109/BDICN55575.2022.00136,20230520-160000,20230521-044735,"['design', 'method', 'of', 'frequency-agile', 'radar', 'frequency', 'hopping', 'sequence', 'based', 'on', 'cnn', 'network', 'and', 'chaotic', 'sequence']",False,20230521-205332,,,,
74,ieeex,A Design of Childhood Stunting Assessment Feature with Agile UX Approach,"multidisciplinary collaboration between public health, system engineering, and UX is able to generate a solution in healthcare problem like stunting. The principle of Agile UX gathers requirements to generate an application design. Currently, various website and mobile applications are available to be utilized for stunting research. StuntingDB is one of many web-based applications that specialized in stunting data management. The application required several types of users to operate hierarchically. This research focused on Public Health Officers’ workflow that require a solution to in the form of assessment module for stunting DBMS by using Agile UX principle. The method collaborates agile team and UX team to solve Public Health Officer's difficulty in changing stunting status at pre-saved child patient's profile. Collaboration of both agile team and UX team successfully proposed an application design that system design.",information technology;usage index;shariah- compliant companies,R. Rahutomo; A. S. Perbangsa; F. Asadi; R. Nirwantono; B. Pardamean,"Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program – Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia",2022.0,2022 8th International HCI and UX Conference in Indonesia (CHIuXiD),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009800,10.1109/CHIuXiD57244.2022.10009800,20230520-160000,20230521-044735,"['a', 'design', 'of', 'childhood', 'stunting', 'assessment', 'feature', 'with', 'agile', 'ux', 'approach']",False,20230521-205332,,,,
75,ieeex,Advanced Data Analytics in Logistics Demand Forecasting,"The logistics demand forecasting is increasingly influenced by digitalization processes in logistics business. Traditional approach to logistics demand forecasting based on human expertise and statistical assessment is still very present, but the use of Big Data, Artificial Intelligence and Machine Learning becomes more prominent. By using these technologies, logistics demand forecasting becomes not only more reliable but also more agile and self-adjusting, with better insight into changing market conditions in the real-time perspective. In this paper, the Authors research the evolution of Data Analytics in logistics demand forecasting. and provide an insight to the features of Big Data, Artificial Intelligence and Machine Learning used for Advanced Data Analytics in logistics demand forecasting.",logistics demand forecasting;Advanced Data Analytics;Big Data;Artificial Intelligence;Machine Learning,A. Agatić; E. Tijan; S. Hess; T. P. Jugović,"Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime Logistics and Management, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia",2021.0,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596820,10.23919/MIPRO52101.2021.9596820,20230520-160000,20230521-044735,"['advanced', 'data', 'analytics', 'in', 'logistics', 'demand', 'forecasting']",False,20230521-205332,,,,
76,ieeex,Role of Joint 5G-IoT Framework for Smart Grid Interoperability Enhancement,"The ever-growing development in communication technology and very fast advances in data science are transferring the power systems in a new era. The level of autonomy is improving by means of Internet-of-Things (IoT), while the level of intelligence is improving through artificial intelligence. The applications of big data analytics and cloud computing techniques in smart grids are also new topics, which have been paid particular attention recently. These paradigms can be used in both grid-scale and local-scale, while the central grid operation center has interoperability with an abundant number of sub-controllers, and aggregators in a wide variety of scales. On the one hand, the system operator must deal with multiple parameters with different kinds of uncertainties. On the other hand, the new structures are evolving toward transactive energy trading models in microgrids. In such a circumstance, a myriad of elements is producing critical data, which should be acquired, transferred, stored, analyzed, and finally, proper controlling actions must be sent. These data are producing at different intervals, even in a fraction of a second. This matter makes it possible to maintain grid security and better real-time operation as well as to get better demand responsiveness. A smart grid consists of many embedded or interconnected systems that are linked to each other through various communication platforms in the cyber layer. A flexible, highly-autonomous, and intelligent smart grid entails an agile communication system, whether wired or wireless. However, cellular networks have prominent benefits. Hence, 5G technology, which is state-of-the-art technology in this field, can be deployed. The communication infrastructure links many components to each other in cyber-physical smart grids. The velocity of data exchange has a profound importance for some purposes, while 5G technology can be the best solution. The joint integration of IoT and 5G procures more reliability, resiliency, security, and economy.",Smart Grids;5G;Internet of things (IoT);Communication infrastructure;Blockchain;Big data analytics,H. Shahinzadeh; A. -s. Mirhedayati; M. Shaneh; H. Nafisi; G. B. Gharehpetian; J. Moradi,"Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Najafabad Branch, Islamic Azad University, Najafabad, Iran; Smart Microgrid Research Center, Najafabad Branch, Islamic Azad Universityy, Najafabad, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Young Researchers and Elite Club, Khomeinishahr Branch, Islamic Azad University, Esfahan, Iran",2020.0,2020 15th International Conference on Protection and Automation of Power Systems (IPAPS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9375539,10.1109/IPAPS52181.2020.9375539,20230520-160000,20230521-044735,"['role', 'of', 'joint', '5g-iot', 'framework', 'for', 'smart', 'grid', 'interoperability', 'enhancement']",False,20230521-205332,,,,
77,ieeex,"MAP: Design, Development, Deployment, and Maintenance of Industrie 4.0 AI Applications","This paper presents a proven process and method to design, develop, deploy, and maintain Industrie 4.0 Big Data Artificial Intelligence (AI) scalable solutions at ABB called modular adaptive process (MAP). The method follows a hybrid DevOps-Agile-Waterfall approach that takes advantage of different elements of all three methodologies to bring to fruition Artificial Intelligence (AI) and Machine Learning (ML) solutions. The described methodology has three phases that include Definition, Development, and Deployment. An important and novel concept that will be discussed is the development of a Value-based Work Breakdown Structure (VWBS) that facilitates DevOps development. Another important discussion is related to the re-training of AI/ML models once the application is deployed.",Artificial Intelligence;Machine Learning;DevOps;Agile;Industrie 4.0;value-based WBS;Model re-training;UX,A. Dagnino; M. Kolomycki; A. Kucheria,"GBS IS Innovation and Emerging Services ABB Inc, Cary, USA; GBS IS Innovation and Emerging Services ABB Ltd, Krakow, Poland; GBS IS Innovation and Emerging Services ABB Inc, Cary, USA",2022.0,2022 IEEE Eighth International Conference on Big Data Computing Service and Applications (BigDataService),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898260,10.1109/BigDataService55688.2022.00024,20230520-160000,20230521-044735,"['map:', 'design,', 'development,', 'deployment,', 'and', 'maintenance', 'of', 'industrie', '4.0', 'ai', 'applications']",False,20230521-205332,,,,
78,ieeex,"The adoption of Design Thinking, Agile Software Development and Co-creation concepts A case study of Digital Banking innovation","Acceleration of technology, especially the mobile internet, causes changes all aspects of human life, including in the banking sector. New emerging technology such as Artificial Intelligence, Blockchain, Big Data, and Cloud computing change the business and operation of the bank. The bank's services have become more personalized, furthermore change customers' lifestyles. Banks are competing to create innovations and breakthroughs to create added value and building a digital ecosystem with fintech and big tech companies in the era of sharing economy. This case study explores the process of creating digital innovation in banking institutions by focusing on adopting design thinking (DT), agile software development (ASD), and co-creation concepts for building digital banking platforms. The case study involved IT executives from four banks in Indonesia. Data were taken through semi-structured interviews and analyzed using NVIVO12. The implication of this research is to accelerate the process of digital banking innovation and produce high-quality digital banking platforms in terms of features and technology.",Digital Innovation;Digital Banking;Agile Software Development;Design Thinking;Co-creation,E. Indriasari; H. Prabowo; F. L. Gaol; B. Purwandari,"Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science, Bina Nusantara University, Jakarta, Indonesia; Universitas Indonesia, Jakarta, Indonesia",2021.0,2021 International Conference on Platform Technology and Service (PlatCon),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680763,10.1109/PlatCon53246.2021.9680763,20230520-160000,20230521-044735,"['the', 'adoption', 'of', 'design', 'thinking,', 'agile', 'software', 'development', 'and', 'co-creation', 'concepts', 'a', 'case', 'study', 'of', 'digital', 'banking', 'innovation']",False,20230521-205332,,,,
79,ieeex,The Effect of Big Data Analytics in Enhancing Agility in Cybersecurity Incident Response,"The ongoing automation of business operations is putting enterprises at risk of cyber attacks more than ever before. Incident response teams are employed by the enterprises for the identification, management, and elimination of cybersecurity attacks along with for the recovery of business operations timely and effectively. In this paper, we argue that to effectively react to the cybersecurity attacks enterprises should build agility in their incident response method and big data analytics performs an effective role in developing agility in incident response. Grounded on twenty-one in depth expert interviews, we develop a framework that explains the salient features and effect of big data analytics in the incident response method at three stages, i.e., manual analysis, basic analysis, and advanced analysis. The agile properties of flexibility, innovation and swiftness are instilled in the incident response method by practicing big data analytics at higher stages of analysis. The results informed that the key features of big data analytics can be firstly utilize to estimate the existing analytical capability and secondly as an assisting tool to enhance incident response method capability.",Big data analytics;incident response;cybersecurity;agility;analytical capability,A. Naseer; A. M. Siddiqui,"Department of Computer Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Department of Electrical Engineering, National University of Sciences and Technology, Islamabad, Pakistan",2022.0,2022 16th International Conference on Open Source Systems and Technologies (ICOSST),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016853,10.1109/ICOSST57195.2022.10016853,20230520-160000,20230521-044735,"['the', 'effect', 'of', 'big', 'data', 'analytics', 'in', 'enhancing', 'agility', 'in', 'cybersecurity', 'incident', 'response']",False,20230521-205332,,,,
80,ieeex,Machine Learning-based Estimation of Story Points in Agile Development: Industrial Experience and Lessons Learned,"Estimating story points is an important activity in agile software engineering. Story-point estimation enables software development teams to, among other things, better scope products, prioritize requirements, allocate resources and measure progress. Several machine learning techniques have been proposed for automated story-point estimation. However, most of these techniques use open-source projects for evaluation. There are important differences between open-source and commercial projects with respect to story authoring. The goal of this paper is to evaluate a state-of-the-art machine learning technique, known as Deep-SE [3], for estimating story points in a commercial project. Our dataset is comprised of 4,727 stories for a data anonymization product developed by a 27-member agile team at a healthcare data science company, IQVIA. Over this dataset, Deep-SE achieved a mean absolute error of 1.46, significantly better than three different baselines. Model performance nonetheless varied across stories, with the estimation error being larger for stories that had higher points. Our results further indicate that model performance is correlated with certain story characteristics such as the level of detail and the frequency of vague terms in the stories. An important take-away from our study is that, before organizations attempt to introduce machine learning-based estimation into agile development, they need to better embrace agile best practices, particularly in relation to story authoring and expert-based estimation.",Agile Development;Story-point Estimation;Machine Learning,M. Abadeer; M. Sabetzadeh,"Privacy Analytics Inc., an IQVIA company Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada",2021.0,2021 IEEE 29th International Requirements Engineering Conference Workshops (REW),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582288,10.1109/REW53955.2021.00022,20230520-160000,20230521-044735,"['machine', 'learning-based', 'estimation', 'of', 'story', 'points', 'in', 'agile', 'development:', 'industrial', 'experience', 'and', 'lessons', 'learned']",False,20230521-205332,,,,
81,ieeex,Automated Guided Vehicles Challenges for Artificial Intelligence,"The use of Artificial Intelligence (AI) to support the Automated Guided Vehicles (AGV) that are used by industry poses a number of challenges that are specific to smart internal logistics systems that are necessary for agile manufacturing. On the one hand, it might seem that experience with the autonomous navigation system that are used in autonomous vehicles can be easily transferred to AGV. However, in this paper, the authors highlight specific problems that are associated with the navigation system of AGV, which has to reflect its operation in an industrial environment with high level of interaction with other production systems and human staff. On the other hand, it may seem that the wealth of experience from using AI in smart manufacturing can be easily transferred to the use of AGV. However, the authors show that although AGV are production tools, the challenges that are associated with the use of AI can significantly differ from other smart manufacturing areas. The number of challenges that are specific to use of AI for AGV is also discussed. This paper systematizes these challenges and discusses the most promising AI methods that can be used for the internal logistics systems that are based on AGV.",Artificial Intelligence (AI);Automated Guided Vehicles (AGV);Smart Manufacturing;Internal Logistics;Explainable AI (XAI),R. Cupek; J. C. -W. Lin; J. H. Syu,"Silesian University of Technology, Gliwice, Poland; Western Norway University of Applied Sciences, Bergen, Norway; National Taiwan University, Taipei, Taiwan",2022.0,2022 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021117,10.1109/BigData55660.2022.10021117,20230520-160000,20230521-044735,"['automated', 'guided', 'vehicles', 'challenges', 'for', 'artificial', 'intelligence']",False,20230521-205332,,,,
82,ieeex,Interactive Visualization for Statistical Modelling through a Shiny App in R,"The importance of analytics and visualization tools has been growing over the last decades to handle big data which steamed from all aspects of life. The focus of this paper was on visualization as a crucial tool in presenting complex raw data and modelling results to provide easy-to-understand actionable information that facilitate decision-making. However, limited research distinguished between “data visualization” and “model visualization”, which has been clearly made in this paper. Furthermore, this paper aimed to shed light on the importance of interactive visualizations to compliment statistical data modelling using R and Shiny for its advanced capabilities. Specifically, a methodology has been proposed based on a hybrid development lifecycle that adopts the Agile Software Development Lifecycle and the Data Analytics Lifecycle. Finally, by presenting a case study to model the dynamics of COVID-19, it was found that R and Shiny alongside the proposed hybrid development lifecycle significantly reduced the amount of time required to build visually interactive applications. The reported results highlighted the effectiveness of the adopted approach in assisting and guiding researchers and developers in building interactive applications that leverage Big Data Analytics.",Data Analytics;Interactive Applications;R;Shiny;Visualization,A. Khedr; S. Hilal,"MSc. in Big Data Science and Analytics, University of Bahrain, Sakhir, Kingdom of Bahrain; College of Science, University of Bahrain, Sakhir, Kingdom of Bahrain",2021.0,2021 International Conference on Data Analytics for Business and Industry (ICDABI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9655841,10.1109/ICDABI53623.2021.9655841,20230520-160000,20230521-044735,"['interactive', 'visualization', 'for', 'statistical', 'modelling', 'through', 'a', 'shiny', 'app', 'in', 'r']",False,20230521-205332,,,,
83,ieeex,The Review for Visual Analytics Methodology,"Big data usage evolves from previously looking into the capacity of big data's descriptive and diagnostic perspectives into currently feeding the demands for predictive big data analytics. The needs come about due to organizations that crave predictive analytics capabilities to reduce risk, make intelligent decisions, and generate different customer experiences. Similarly, visual analytics play an essential role in understanding and fitting the analytics prediction in their business decision. Hence, the combination of descriptive, diagnostics and predictive within Visual Analytics emerges as a balanced field to provide understandable predictive insight. Due to the organizational demand and multi-discipline area, the approach to developing visual analytics is still uncertain in the Big Data Project Lifecycle from methodological perspectives. While there are a few potential methodological approaches that could be used for visual analytics, they are scattered across numerous academic research and industrial practice. To date, there is no coherent review and analysis of the work that has been explored specifically for Visual Analytics methodology. This paper reports on a review of previous literature concerning how Visual Analytics has been executed in the big data life cycle to address the gap. The review is organized in this study from three perspectives: i) general ICT -related methodology (e.g. SDLC, Agile, DevOps), ii) Data Science-related methodology (e.g. CRISP-DM, SEMMA, KDD) and iii) Visual Analytics-related methodologies in which each method will be benchmarked based on the Visual Analytics major part of reality, computer and human, in terms of its width, depth, and flows. This study found insufficiencies, non-specific and vague conditions in handling the Visual Analytics when using current methodological approaches based on the review conducted. The paper also highlights the Visual Analytics-related methodological review, which can shed some light on the approaches and ways of implementing analytics in the big data lifecycle, which can be beneficial for future studies in proposing a more comprehensive methodology for Visual Analytics in the big data lifecycle.",process;methodology;visual analytics;big data analytics,Z. Ahmad; S. Yaacob; R. Ibrahim; W. F. Wan Fakhruddin,"Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Social Science and Humanity Faculty, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia",2022.0,"2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800100,10.1109/HORA55278.2022.9800100,20230520-160000,20230521-044735,"['the', 'review', 'for', 'visual', 'analytics', 'methodology']",False,20230521-205332,,,,
84,ieeex,SLA-Based Agile VM Management in Cloud & Datacenter,"Cloud Computing is the main root technology to provide various services over the internet in the current scenario, which is basically powered via virtual machines (VMs) over commodity hardware. As soon as a task arrives in the cloud or data center that task is assigned to a VM as per the task scheduler and resource allocation policy. Whenever cloud or data center do not have sufficient spare resources over VM to assign a task, a new VM is created over host machine which have spare resource capacity in the cloud and/or data center. The VM creation should be in such a manner that will follow the Service Level Agreement (SLA) to maintain the Quality of Service (QoS) for the client. We have proposed SLA-based agile VM management algorithm to minimize the VM creation time and VM response time. We use ghost VM to increase the efficiency of cloud, allocation of new VM is from the ghost VM, and using the average creation time is reduced up to 11.98%. We propose two algorithms first for Admission control and second for Rescheduling of VM's. Our aim is to reduce the time taken in the rescheduling of the VM. Currently, we are assuming excess VM which are eligible to Garbage Collection do not put overhead over the cloud and they can be handled via background service, and with do not affect foreground services directly and they are handled via the separate management service.",Cloud computing;VM management;cloud efficiency;data-center,N. Sharma; S. Maurya,"Govt. Women Engineering College, Ajmer, India; Govt. Women Engineering College, Ajmer, India",2019.0,"2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862260,10.1109/COMITCon.2019.8862260,20230520-160000,20230521-044735,"['sla-based', 'agile', 'vm', 'management', 'in', 'cloud', '&', 'datacenter']",False,20230521-205332,,,,
85,ieeex,SMARTD Web-Based Monitoring and Evaluation System,"Sustainable Management of Agricultural Research and Technology Dissemination (SMARTD) is a national program organized by Indonesian Agency for Agricultural Research and Development (IAARD), The Ministry of Agriculture of the Republic of Indonesia. It provides funding to increase research capacity in all units under IAARD. Because of the large scope of this program, a good monitoring and evaluation system is needed to ensure its effectiveness. A web-based application is proposed to complement the existing manual monitoring system. Design Thinking method and SCRUM are used as the approach to develop system. This system was developed using PHP 5 with Code Igniter framework and the database was developed using MySQL. This system has successfully implemented to all units under IAARD and are running smoothly for daily reporting system.",Information System;Monitoring;Evaluation;Web Application;Reporting System,A. Budiarto; M. F. Kacamarga; T. Suparyanto; S. Purnamasari; R. E. Caraka; H. H. Muljo; B. Pardamean,"Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; School of Mathematical Sciences, The National University of Malaysia, Kuala Lumpur, Malaysia; Accounting Information Systems Program, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia",2018.0,2018 Indonesian Association for Pattern Recognition International Conference (INAPR),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627034,10.1109/INAPR.2018.8627034,20230520-160000,20230521-044735,"['smartd', 'web-based', 'monitoring', 'and', 'evaluation', 'system']",False,20230521-205332,,,,
86,ieeex,All-Fiber Laser With Agile Mode-Switching Capability Through Intra-Cavity Conversion,"Agile mode switching between LP01 and LP11 modes in an all-fiber laser is demonstrated by exploiting an acoustically induced fiber grating within the laser cavity. The laser exploits a cladding pump configuration and can deliver up to 5.85 W of stable output power in LP11 mode at 1070.07 nm and 6.06 W in LP01 mode at 1070.48 nm, with a slope efficiency near 50%. Complete mode-switching speed with 250 Hz and partial mode-switching speed with 1 kHz are demonstrated. Based on the obtained switching time between LP11 and LP01 mode, the maximum complete mode-switching speed is calculated to be ~555.56 Hz. Moreover, variable output beam profiles could be obtained by adjusting the frequency of the modulation signal applied on the acoustically induced fiber grating. This paper could provide an example of realizing a high-power, mode-switchable fiber laser source for practical use.",Mode switching;agile;acoustically-induced fiber grating;high order mode,H. Wu; J. Lu; L. Huang; X. Zeng; P. Zhou,"College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai University, Shanghai, China; College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai University, Shanghai, China; College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China",2020.0,IEEE Photonics Journal,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691732,10.1109/JPHOT.2019.2911270,20230520-160000,20230521-044735,"['all-fiber', 'laser', 'with', 'agile', 'mode-switching', 'capability', 'through', 'intra-cavity', 'conversion']",False,20230521-205332,,,,
87,ieeex,SMVS: A Web-based Application for Graphical Visualization of Malay Text Corpus,"Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur'an corpus.",Big data;data visualization;knowledge representation;Qur'an knowledge;natural language processing,N. B. Ahmat Baseri; J. A. Bakar; A. Ahmad; H. Jafferi; M. F. Zamri,"School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia",2020.0,2020 IEEE 10th Symposium on Computer Applications & Industrial Electronics (ISCAIE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108705,10.1109/ISCAIE47305.2020.9108705,20230520-160000,20230521-044735,"['smvs:', 'a', 'web-based', 'application', 'for', 'graphical', 'visualization', 'of', 'malay', 'text', 'corpus']",False,20230521-205332,,,,
88,ieeex,HerdMonitor: Monitoring Live Migrating Containers in Cloud Environments,"Cloud computing uses pools of virtual machines to provide shared computing resources. Provisioning and management of these resources are generally done using statistical algorithms to help decide how to better utilize available compute power; recently, this has been performed mostly by using live migration of virtual machines. Nowadays containers deliver the flexibility to handle many software environments and tasks in a lighter-weight virtualization scheme, providing a more agile alternative to virtual machines for certain applications. Application checkpointing coupled with a container manager allows the live migration of a container. In this work, we present Herd-Monitor, a resource monitoring system to gather performance metrics of containers and their respective compute hosts. This data can be used to analyze the utilization of available resources, characterize workloads, and develop forecast models. With the analysis of the data provided by the monitoring system, we can fine-tune resource provisioning policies, with the end goal of constructing a cloud resource provisioning platform that enables an improvement in usage and execution of container workloads through the use of live migration. The design, development, performance evaluation and characterization of our lightweight resource monitoring tool that enables offline and real-time resource utilization analysis of live migration workloads as well as the performance impact on their hosts are presented.",Cloud computing;Containers;Live Migration;Big Data Infrastructure;Software Systems to Support Big Data Computing;Performance Monitoring;Data Streaming;Cloud Architecture;Realtime Monitoring,A. E. González; E. Arzuaga,"Department of Electrical and Computer Engineering, University of Puerto Rico, Mayagüez, PR; Department of Computer Science and Engineering, University of Puerto Rico, Mayagüez, PR",2020.0,2020 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378473,10.1109/BigData50022.2020.9378473,20230520-160000,20230521-044735,"['herdmonitor:', 'monitoring', 'live', 'migrating', 'containers', 'in', 'cloud', 'environments']",False,20230521-205332,,,,
89,ieeex,Nanoservice Infrastructure Notation (NINo) and the ASPIRE Interns,"NINo is a future DevOps / Data Science pipeline tool that is being developed by JHU APL and two ASPIRE interns. The goal of this capability is to expose function-level capabilities, via either a simple application or configuration file, for use in Docker [1], Serverless Architectures [2], or data science/analytic pipelines. The goal is similar to efforts such as Metaparticle [3] and Source-to-Image[4] that aim to lower the barrier to horizontal scaling of data processing and analysis capabilities. In previous years ASPIRE interns have developed tools to ease the acceptance of DevOps principles in JHU APL. They have created a web application, Harmonia, that asked users a few simple questions and supplied the scaffolding for a software project with artifacts to support sound software engineering processes. The lack of user interest has driven us to a more focused objective. NINo will focus on easing deployment to cloud environments. Ideally, any person could develop cloud-based data science services. The team and its work has been organized in an asynchronous and agile manner. There have been three members working on three subsystems: configuration, framework/integration, and artifact generation. An incremental and prototype-driven approach has allowed for creation of increasingly more functional software as internship has proceeded. Interns have been given extensive control over their development processes and have investigated the programming frameworks used. While the initial stages have not resulted in a complete system, the interns have improved their programming skills and complete common coding challenges. The team is close to integration testing and initial demonstration. As the academic year closes, team members will work on design improvement, refactoring, and generation of future feature requests from prospective users. One summer intern will focus on developing a user interface for configuring and observing results.",,C. T. Pascale; M. Rice; S. Sharma,NA; NA; NA,2020.0,2020 IEEE Integrated STEM Education Conference (ISEC),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397808,10.1109/ISEC49744.2020.9397808,20230520-160000,20230521-044735,"['nanoservice', 'infrastructure', 'notation', '(nino)', 'and', 'the', 'aspire', 'interns']",False,20230521-205332,,,,
90,ieeex,Agile approach to a CS2-based course using the Jupyter notebook in lab classes,"In introductory programming courses, there is a need for a change in teaching strategies for practicing programming, which must be influenced by productive learning experiences connected with real world scenarios and methodologies. The abundance of data from different sources, online experimentation, and simulators and virtual/remote labs should also play a fundamental role when we think in new teaching strategies for these courses. In this paper, we show how agile methodologies, widely used in industry and manufacturing, combined with online experimentation, can be both applied to a CS2-based course in the era of data engineering. And, then, a new approach of teaching lab classes in CS2-based course is introduced, benefiting from the Scrum framework, to student-centered learning activities on lab classes, and from the concept of Jupyter notebook to online experimentation.",online experimentation;data engineering;agile methodologies;Jupyter;CS2-based course;programming labs,H. Guerra; L. M. Gomes; A. Cardoso,"NIDeS, Faculty of Sciences and Technology, University of the Azores Centro Algoritmi, University of Minho, Ponta Delgada, Portugal; NIDeS, Faculty of Sciences and Technology, University of the Azores Centro Algoritmi, University of Minho, Ponta Delgada, Portugal; CISUC, University of Coimbra, Coimbra, Portugal",2019.0,2019 5th Experiment International Conference (exp.at'19),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876536,10.1109/EXPAT.2019.8876536,20230520-160000,20230521-044735,"['agile', 'approach', 'to', 'a', 'cs2-based', 'course', 'using', 'the', 'jupyter', 'notebook', 'in', 'lab', 'classes']",False,20230521-205332,,,,
91,ieeex,Case study: Factors that hinder and support the adoption of Pair Programming in an agile software development company,"Pair programming is the XP practice that is the least adopted in software development departments or companies; although previous research suggests there are numerous benefits that can be realised from its use. It is suggested that this practice, which involves two programmers working collaboratively on the same task and following a prescribed approach, produces high quality code, in shorter timeframes, with increased knowledge-sharing and improved developer productivity. This paper investigates the factors that support, and deter, pair programming adoption in a case study at a software development company in the eThekwini (Durban) region, South Africa. The survey and interviews indicate that the most positive influences are the support from senior and peer staff and the company's willingness to provide the necessary hardware, software and physical layout to enable the use of pair programming. The biggest challenge was the personality mix in a pair, for example introvert/extrovert pairs, where extroverts can dominate pair collaboration. This company has specific managerial guidelines and practices which are used to mitigate the challenges and provide support to, not only make pair programming a more operationally feasible option, but also reap its benefits.",pair programming;XP (extreme programming);software developer,P. Dhoodhanath; R. Quilling,"School of Management, Information Technology and Governance, University of KwaZulu-Natal (eThekwini), Durban, South Africa; School of Management, Information Technology and Governance, University of KwaZulu-Natal (eThekwini), Durban, South Africa",2020.0,"2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183869,10.1109/icABCD49160.2020.9183869,20230520-160000,20230521-044735,"['case', 'study:', 'factors', 'that', 'hinder', 'and', 'support', 'the', 'adoption', 'of', 'pair', 'programming', 'in', 'an', 'agile', 'software', 'development', 'company']",False,20230521-205332,,,,
92,ieeex,"Electrically Small, Planar, Frequency-Agile, Beam-Switchable Huygens Dipole Antenna","An electrically small, planar, frequency-agile, beam-switchable Huygens dipole antenna is investigated in this article. The near-field resonant parasitic (NFRP) design incorporates an Egyptian axe dipole (EAD) and a capacitively loaded loop (CLL) that function as the electric and magnetic NFRP elements, respectively. A varactor diode is integrated into each of these NFRP elements to facilitate simultaneous tuning of its operating frequency and switching its main beam direction. By changing the capacitance values of these two varactor diodes, the antenna realizes two independent, antipodal, unidirectional endfire radiating states with similar realized gain (RG) and front-to-back ratio (FTBR) values within virtually the same frequency-agile ranges. The experimental results demonstrate that the developed antenna exhibits a 5% frequency-agile fractional impedance bandwidth in both of its two oppositely directed endfire states. The antenna is electrically small at the highest frequency of this bandwidth ( ${ka}_{high} < 0.86$ ) and has measured relatively high radiation efficiency (RE >67.7%), peak RG (2.1–3.19 dBi), and FTBR (5.61–13.4 dB) values, together with stable and uniform radiation patterns, over this frequency-agile range.",Beam-switchable antennas;electrically small antennas (ESAs);frequency-agile antennas;Huygens dipole antennas (HDAs);planar antennas,Z. Wu; M. -C. Tang; R. W. Ziolkowski,"Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, College of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, College of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia",2021.0,IEEE Transactions on Antennas and Propagation,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464275,10.1109/TAP.2021.3090580,20230520-160000,20230521-044735,"['electrically', 'small,', 'planar,', 'frequency-agile,', 'beam-switchable', 'huygens', 'dipole', 'antenna']",False,20230521-205332,,,,
93,ieeex,"Frequency Agile, Sub-wavelength, Metamaterial-inspired Huygens Dipole Antenna","Near-field resonant parasitic based Huygens sources have been of special interest in many antenna applications recently. Unidirectional patterns with high directivity, high radiation efficiencies and large front-to-back-ratio values, as well as compact dimensions, have made them an attractive choice for space-limited wireless platforms. It is demonstrated with CST simulations that the frequency of operation of a sub-wavelength, metamaterial-inspired Huygens dipole antenna and, hence, its cardioid pattern, can be easily adjusted across a broad bandwidth using tunable lumped reactive elements.",,L. Vincelj; S. Hrabar; R. W. Ziolkowski,"Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia",2022.0,2022 Sixteenth International Congress on Artificial Materials for Novel Wave Phenomena (Metamaterials),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920708,10.1109/Metamaterials54993.2022.9920708,20230520-160000,20230521-044735,"['frequency', 'agile,', 'sub-wavelength,', 'metamaterial-inspired', 'huygens', 'dipole', 'antenna']",False,20230521-205332,,,,
94,ieeex,Model of Learning Management System Based on Artificial Intelligence in Team-Based Learning Framework,"The presence of various innovations and technology of Artificial Intelligence (AI) has now begun to be adopted by Indonesia in many aspects including in the industrial sector. The utilization of AI also can offer a new paradigm in learning and teaching strategies. The development of learning strategies continues also performed to obtain the variations of learning that involve student activity. Team-Based Learning (TBL) is one of the teaching strategies that can improve the quality of the learning process and student activity in groups. By starting to integrate digital-based learning resources in the learning and teaching process, the TBL strategy can potentially be an alternative to new learning strategies that are relevant to be applied in the era of the educational revolution 4.0. The main focus of this research is to develop and evaluate the application of AI in a digital-based TBL strategy that will be implemented in the form of personalized learning about student learning styles. This research was developed based on the learning strategy development of the research method. However, this article more focuses on developing the AI application design that will be applied. The application design was developed based on the agile development method, especially SCRUM. The result of this study is an additional feature that was implemented on a Learning Management System (LMS) based on the Modular Object-Oriented Dynamic Learning Environment (MOODLE).",artificial intelligence;team-based learning;personalized learning;moodle,B. Pardamean; T. Suparyanto; T. W. Cenggoro; D. Sudigyo; A. Anugrahana; I. Anugraheni,"Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Elementary School Teacher Education, Sanata Dharma University, Yogyakarta, Indonesia; Elementary School Teacher Education, Satya Wacana Christian University, Salatiga, Indonesia",2021.0,2021 International Conference on Information Management and Technology (ICIMTech),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535088,10.1109/ICIMTech53080.2021.9535088,20230520-160000,20230521-044735,"['model', 'of', 'learning', 'management', 'system', 'based', 'on', 'artificial', 'intelligence', 'in', 'team-based', 'learning', 'framework']",False,20230521-205332,,,,
95,ieeex,"Drone Swarm ""Agile Suppression"" Tactics","Unmanned aerial vehicle (UAV) swarm, as a new quality power growth point of electronic warfare, has been widely paid attention to all over the world. This article will open innovative uav swarm combined with operational concept of ""agile suppression"", from the principle of methods, the implementation method, grasp the key points, four aspects such as the core, for example, elaborated the uav swarm ""agile suppression methods and value, the advantages of uav swarm fighting for the future research laid the theoretical basis of related, as our system of battlefield electromagnetic power advantage added.",,Y. Feng; B. Wang; Z. Li; X. Xiong,NA; NA; NA; NA,2022.0,CIBDA 2022; 3rd International Conference on Computer Information and Big Data Applications,VDE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9899058,,20230520-160000,20230521-044735,"['drone', 'swarm', '""agile', 'suppression""', 'tactics']",False,20230521-205332,,,,
96,ieeex,Drone Application Model for Image Acquisition of Plantation Areas and Oil Palm Trees Counting,"The area of oil palm plantations in Indonesia increased by 7% from 14 million ha in 2017 to 15 million ha in 2021. The vast land requires the support of effective and efficient management techniques to maintain sustainable productivity. The high-performance computing technologies, Internet of Things (IoT), Big Data, Artificial Intelligence, spatial modeling, and drones are the answers to these needs. This study aims to design an application that can obtain plantation image data and analyze the calculation of the number of oil palm trees. The image of oil palm plantations is obtained from processing photo data from drones through a mosaic and composite process. This study also employed Scrum and UML as a system model development method. The image of the oil palm plantation area is used to build a tree counting model using the Viola-Jones algorithm. The oil palm tree count information generated by this system can then be used by management for fertilizing, harvesting, and monitoring the condition of oil palm trees.",drone;oil palm;Viola-Jones;tree counting;Scrum;UML,H. Sastrohartono; A. P. Suryotomo; S. Saifullah; T. Suparyanto; A. S. Perbangsa; B. Pardamean,"Department of Agricultural Engineering, Faculty of Agricultural Technology, Instiper Yogyakarta, Yogyakarta, Indonesia; Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta, Yogyakarta, Indonesia; Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta, Yogyakarta, Indonesia; Bioinformatics and Data Science Research Center Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, School of Information Systems Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Master of Computer Science Bina Nusantara University, Jakarta, Indonesia",2022.0,2022 International Conference on Information Management and Technology (ICIMTech),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915223,10.1109/ICIMTech55957.2022.9915223,20230520-160000,20230521-044735,"['drone', 'application', 'model', 'for', 'image', 'acquisition', 'of', 'plantation', 'areas', 'and', 'oil', 'palm', 'trees', 'counting']",False,20230521-205332,,,,
97,ieeex,A Way of Students' Ability Cultivation of ”Five-one” for Software Engineering Major under Background of New Engineering,"Based on the individualized development of students for software engineering major under background of new engineering education, a possible way of students' ability cultivation of “Five-one” is put forward. As a case study of Anhui Sanlian University, from the three levels of interest and hobby, practical ability, and scientific research expansion to construct of the framework of “Five-one” on students' ability cultivation, and good results on implementation are achieved. Finally, further work is expected in the future. Firstly, a sustainable agile curriculum selecting system should be developed soon. Secondly, a platform for innovative practice should be established based on Outcomes-Based Education (OBE) by the form of school-enterprise cooperation.",new engineering;software engineering;ability cultivatio;Five-one;agile;Outcomes-Based Education(OBE),J. Yu; Y. Mei; J. Zhang; D. Zhang; Y. Chen; C. Zhu; N. Wu; L. Zhu,"College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China",2020.0,2020 International Conference on Big Data and Informatization Education (ICBDIE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150172,10.1109/ICBDIE50010.2020.00047,20230520-160000,20230521-044735,"['a', 'way', 'of', ""students'"", 'ability', 'cultivation', 'of', '”five-one”', 'for', 'software', 'engineering', 'major', 'under', 'background', 'of', 'new', 'engineering']",False,20230521-205332,,,,
98,ieeex,Towards Agile Integration: Specification-based Data Alignment,"Utilizing data sets from multiple domains is a common procedure in scientific research. For example, research on the performance of buildings may require data from multiple sources that lack a singular standard for data reporting. The Building Management System might report data at regular 5minute intervals, whereas an air-quality sensor might capture values only when there has been significant change from the previous value. Many systems exist to help integrate multiple data sources into a single system or interface. However, such systems do not necessarily make it easy to modify an integration plan, for example, to accommodate data exploration, new and changing data sets or shifts in the questions of interest. We propose an agile data-integration system to enable quick and adaptive analysis across many data sets, concentrating initially on the data alignment step: combining data values from multiple time-series based data sets whose time schedules. To this end, we adopt a Domain Specific Language approach where we construct a domain model for alignment, provide a specification language for describing alignments in the model and implement an interpreter for specification in that language. Our implementation exploits a rank-based join in SQL that produces faster alignment times than the commonly suggested method of aligning data sets in a database. We present experiments to demonstrate the advantage of our method and exploit data properties for optimization.",data integration;time series;data alignment,C. Giossi; D. Maier; K. Tufte; E. Gall; M. Barnes,"Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Mechanical Engineering, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR",2020.0,2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191394,10.1109/IRI49571.2020.00055,20230520-160000,20230521-044735,"['towards', 'agile', 'integration:', 'specification-based', 'data', 'alignment']",False,20230521-205332,,,,
99,ieeex,On the Relationship Between Organizational Structure Patterns and Architecture in Agile Teams,"Forming members of an organisation into coherent groups or teams is an important issue in any large-scale software engineering endeavour, especially so in agile software development where teams rely heavily on self-organisation and organisational flexibility. But is there a recurrent organisational structure pattern in agile software engineering teams? and if so what does that pattern imply, in terms of software architecture quality? We address these questions using mixed-methods research in industry featuring interviews, surveys, and Delphi studies of real agile teams. In our study of 30 agile software teams we found that, out of seven organisational structure patterns that recur across our dataset, a single organisational pattern occurs over 37% of the time. This pattern: (a) reflects young communities (1-12 months old); (b) disappears in established ones (13+ months); and (c) reflects the highest number of architecture smells reported. Finally, we observe a negative correlation between a proposed organisational measure and architecture smells. On the one hand, these insights may serve to aid architects in designing not only their architectures but also their communities to best support their co-evolution. On the other hand, we observe that organisational structures in software engineering influence much more than simply software architectures, and we expect our results to lay the foundations of more structured and rigorous approaches to organisational structure studies and use in software engineering research and practice.",Software organisational structures;human aspects in software engineering;social software engineering;empirical software engineering;industrial mixed-methods research,D. A. Tamburri; R. Kazman; H. Fahimi,"Jheronimus Academy of Data Science, Eindhoven University of Technology, Eindhoven, The Netherlands; SEI-CMU, Hawaii University, Honolulu, HI, USA; CGI Corp., Rotterdam, The Netherlands",2023.0,IEEE Transactions on Software Engineering,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712241,10.1109/TSE.2022.3150415,20230520-160000,20230521-044735,"['on', 'the', 'relationship', 'between', 'organizational', 'structure', 'patterns', 'and', 'architecture', 'in', 'agile', 'teams']",False,20230521-205332,,,,
100,ieeex,Developing a Virtual Smart Total Learning Environment for Future Teaching-Learning System,"The world of education system after this COVID19 pandemic will have to change its dimension to map the needs of learners. The proposed framework is focused on transforming the learning experience into two possible ways like online and on-campus learning through groundbreaking & agile methodologies. The new interfaces for learners will be included like Gamification, animated tutorial etc. The framework designed here is the outcome of the e-learning experiences of the authors and it tries to add all relevant technologies with cutting-edge research to provide inspirational and transformative knowledge to learners of all ages, social status, communities who form worldwide communities of special-learners. It will rise to the occasion to use its open source technology along with the emerged technologies like IoT, 5G etc, to transcend physical and social borders. This framework is a total learning environment as it will incorporate all possible latest technologies like big data and machine learning. The e-learning system possesses features like personalized e-learning, anomaly detection, student performance monitoring, dynamic content preparations, students' satisfaction monitoring etc. The new framework will include big data, cloud applications, machine learning and artificial intelligence to make the system faster, efficient and smart. The new features will make the e-learning system based on Virtual Smart Total Learning Environment (VSTLE) more technologically sound and efficient in processing, predicting, evaluating and making storage backup. This framework is designed in such a way that the minimum human intervention will be needed for its functioning. As a result, the final output will be more accurate as compared to other e-learning systems available.",smart;virtual;learning-environment;machine learning;big data;adaptive learning,M. A. Akour; A. Das,"A’Sharqiyah University, Sultanate, Oman; Cotton University, India",2020.0,"2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9368373,10.1109/TALE48869.2020.9368373,20230520-160000,20230521-044735,"['developing', 'a', 'virtual', 'smart', 'total', 'learning', 'environment', 'for', 'future', 'teaching-learning', 'system']",False,20230521-205332,,,,
101,ieeex,"Design-Computational Thinking, Transfer and Flavors of Reuse: Scaffolds to Information and Data Science for Sustainable Systems in Smart Cities","This paper investigates how to increase understanding of design and sustainable systems by scaffolding cognitive access and transfer of learning using eclectic approaches to experiment with networks of design potentials. Cognitive access simulates multi-criteria case indexing, refined from knowledge induction derived from analyses of random but related cases based on search strategies. Randomization of the search space encourages emergence of heuristic solutions, fuzzy though informed transfers and further refinement of schema. We investigate the type of navigational structures/design resulting from creative reuse/refactoring and lean management; and whether there will be evidences of knowledge induction from randomized search scaffolded by Case-based Reasoning (CBR), which leads to heuristic transfer and learning. Examples from two courses carried out August-December 2017 within the participatory design-agile framework for engagement in Smart Cities are assessed for creative reuse regarding: a) people, process and tools; b) domain engineering; c) component mining and d) open source vs. systematic reuse. Findings confirm longitudinal insights: CBR-informed but emergent search leading to more efficient and higher quality heuristic transfer and learning is scaffolded by systemic modelling and design dependent on four factors.","Technology and Engineering Management;design centering;Project management;creativity;reuse, integration",C. -S. Lee; K. D. Wong,"Sunway University, Universiti Tunku Abdul Rahman, Malaysia; Daniel Wireless Software Pte. Ltd., Singapore, Singapore",2018.0,2018 IEEE International Conference on Information Reuse and Integration (IRI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424711,10.1109/IRI.2018.00040,20230520-160000,20230521-044735,"['design-computational', 'thinking,', 'transfer', 'and', 'flavors', 'of', 'reuse:', 'scaffolds', 'to', 'information', 'and', 'data', 'science', 'for', 'sustainable', 'systems', 'in', 'smart', 'cities']",False,20230521-205332,,,,
102,ieeex,Toward Automatized Handling of Future Agile Networks Employing Various Optical Switching Functionalities,Various optical switch systems will be required to support future wide application network areas having different requirements. A bottom-up modeling approach which will realize a common platform for automatized operation of physical layer is discussed.,Photonic Networking/Switching System Designs and Architectures for Computing and Big Data;Software defined networking (SDN) for computing and big data control,K. Ishii; S. Namiki,"National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan",2019.0,2019 24th OptoElectronics and Communications Conference (OECC) and 2019 International Conference on Photonics in Switching and Computing (PSC),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818061,10.23919/PS.2019.8818061,20230520-160000,20230521-044735,"['toward', 'automatized', 'handling', 'of', 'future', 'agile', 'networks', 'employing', 'various', 'optical', 'switching', 'functionalities']",False,20230521-205332,,,,
103,ieeex,Comparative Analysis of Machine Learning Techniques in Effort Estimation,"In Software engineering effort estimation provides an important role for software development and managing project cost, quality, and time. Since last decades, software estimation has been receiving significant attention from researchers and substantial research has been performed using various techniques and algorithms of machine learning. This paper suggests different machine learning techniques such as Naïve Bayes, Random Forests Logistic Regression, stochastic gradient boosting, decision tree, and story point for estimation to assess prediction more efficiently. Nowadays uses of these approaches by software development industries for software estimation aim to tackle deficiencies of parametric and traditional estimation techniques, rise project. A comparative study of the mentioned techniques is presented and examined in this paper to critically evaluate the performance of these techniques.",Effort;efficiency;software;estimation;techniques,Ritu; Y. Garg,"Guru Nanak Dev Engineering College, Ludhiana, Punjab, India; Department of Computer Science & Engineering, APEX Institute of Technology, Chandigarh University, Mohali, Punjab, India",2022.0,"2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850592,10.1109/COM-IT-CON54601.2022.9850592,20230520-160000,20230521-044735,"['comparative', 'analysis', 'of', 'machine', 'learning', 'techniques', 'in', 'effort', 'estimation']",False,20230521-205332,,,,
104,ieeex,Integration of Machine Learning in Agile Supply Chain Management,"One essential component of any manufacturing industry's success is a successful supply chain. Customer expectations have increased due to the quick growth of information and communication technologies, which has also made the world more competitive. Global production and manufacturing have now transitioned to Industry 4.0. The ""Internet of Things,"" ""Big Data,"" and ""Artificial Intelligence"" are the dominant digital technologies in this. Consequently, in the near future, supply chain management (SCM) will manage not only the flow of raw materials, semi-finished goods, finished goods, and services from the manufacturer to the customer, but also the flow of the most recent data for current and future supply chain visibility & sustainability. For this many companies around the world have tapped one of the advanced technique - Machin Learning (ML) for early risk identification & management, material planning & forecasting, raw material price forecasting etc. As a result, purpose of this paper is to explain a conceptual framework which illuminates factors influencing integration of Machin learning (ML) in Agile Supply chain management, its benefits, and challenges to implement.",machine learning;agile supply chain management;industry 4.0;supply chain risk management;advanced technologies,V. Ghabak; A. Seetharaman,"Business Administration, SP Jain School of Global Management, Mumbai, India; Business Administration, SP Jain School of Global Management, Singapore",2023.0,2023 15th International Conference on Computer and Automation Engineering (ICCAE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10111340,10.1109/ICCAE56788.2023.10111340,20230520-160000,20230521-044735,"['integration', 'of', 'machine', 'learning', 'in', 'agile', 'supply', 'chain', 'management']",False,20230521-205332,,,,
105,ieeex,Smart Factory Production and Operation Management Methods based on HCPS,"The human-cyber-physical system (HCPS) is a composite intelligent system comprising humans, cyber systems, and physical systems with the aim of achieving specific manufacturing goals at an optimized level. Smart factory is an important carrier of a new-generation intelligent manufacturing. In order to achieve the comprehensive collaboration of human-machine-thing and other elements in the smart factory, the HCPS is introduced to the smart factory in this paper. Firstly, a smart factory model is constructed based on human-cyber-physical (HCPS). Then, according to the characteristics of big data, Internet-of-Things(IoT) and artificial intelligence(AI), the management methods of smart factory is proposed, including production design, resource intelligent management and knowledge discovery. Finally, a guiding technology architecture of human-centered smart factory production and operation management is given. The smart factory based on HCPS is of great significance to realize the full use of various resources, and agile management.",Human-cyber-physical system;Smart Factory;Production and Operation;Management Methods,J. Yu; Y. Sun; W. Zheng; X. Zhou,"School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Research Center for Novel Technology of Intelligent Equipment, Nanjing University, Nanjing, China",2020.0,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238110,10.1109/ICNSC48988.2020.9238110,20230520-160000,20230521-044735,"['smart', 'factory', 'production', 'and', 'operation', 'management', 'methods', 'based', 'on', 'hcps']",False,20230521-205332,,,,
106,ieeex,AGV Congestion Avoidance using Threshold-modulating Oscillator in Cellular Manufacturing,"Control of automated guided vehicles (AGVs) for avoiding congestion must be stable and adaptive in agile production such as cellular manufacturing. In this study, we propose a flexible AGV-dispatch algorithm based on the synchronization phenomenon of a coupled oscillators. The dynamics of a production system is formulated as that of relaxation oscillators. Through controlling the threshold of the relaxation oscillators, the proposed algorithm can synchronize AGV-dispatch timing even with fluctuating production speeds. Phase-plane analysis is applied to investigate the qualitative behavior of the dynamical system the algorithm. In addition, through numerical simulation, we demonstrate that our AGV-dispatch algorithm can improve the congestion index of AGVs by 30%.",,T. Itou; H. Wakayama; K. Konishi; K. Tadano; Y. Maenol; M. Ogawa,"Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Dept. of Electrical and Information Systems, Osaka Prefecture University, Osaka, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan",2018.0,2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502643,10.1109/ETFA.2018.8502643,20230520-160000,20230521-044735,"['agv', 'congestion', 'avoidance', 'using', 'threshold-modulating', 'oscillator', 'in', 'cellular', 'manufacturing']",False,20230521-205332,,,,
107,ieeex,CRISIS: Integrating AIS and Ocean Data Streams Using Semantic Web Standards for Event Detection,"Information deluge is still an issue in the maritime environment, creating situations where data are sometimes underutilized or in more extreme cases, not utilized, in the decision-making process. In part, this is due to the high volume of incoming data that are available to the operational community. However, better exploitation of these data streams can be accomplished through techniques that focus on the semantics of the incoming stream, to discover information-based alerts that generate knowledge that is only obtainable when considering the totality of the streams. In this paper, we present an agile data architecture for real-time data representation, integration, and querying situations over heterogeneous data streams using Semantic Web Technologies, with the goal of improved knowledge interoperability. We apply the framework to the maritime ship traffic domain to discover real-time traffic alerts by querying and reasoning across multiple streams.",,A. Soares; R. Dividino; F. Abreu; M. Brousseau; A. W. Isenor; S. Webb; S. Matwin,"Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia",2019.0,2019 International Conference on Military Communications and Information Systems (ICMCIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842749,10.1109/ICMCIS.2019.8842749,20230520-160000,20230521-044735,"['crisis:', 'integrating', 'ais', 'and', 'ocean', 'data', 'streams', 'using', 'semantic', 'web', 'standards', 'for', 'event', 'detection']",False,20230521-205332,,,,
108,ieeex,IndustEdge: A Time-Sensitive Networking Enabled Edge-Cloud Collaborative Intelligent Platform for Smart Industry,"An edge-cloud collaborative intelligent (ECCI) platform is of great significance for the agile development and rapid deployment of ECCI applications, which are essential for realizing smart industry in the era of Industry 4.0. However, the existing platforms lack considering the high real-time latency demand of industrial operations, which severely hinders the development of smart industry and may even lead to severe industrial accidents. To effectively reduce the response latency of industrial applications, in this article, we propose an ECCI platform IndustEdge. It takes time-sensitive networking as the deterministic transport for the link layer, and provides an extensible ECCI orchestration component to reduce the system level latency. Furthermore, IndustEdge has an ECCI algorithm library for different collaborative modes and provides the complete life cycle management for ECCI applications. We implement platforms for both the real-world prototype and emulated-world emulation, and conduct two case studies to evaluate the effectiveness of IndustEdge.",Edge cloud collaborative intelligence (ECCI);edge computing platform;Industry 4.0;smart industry;time -sensitive networking (TSN),Y. Wang; S. Yang; X. Ren; P. Zhao; C. Zhao; X. Yang,"National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Department of Computing, Imperial College London, London, U.K.; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",2022.0,IEEE Transactions on Industrial Informatics,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531530,10.1109/TII.2021.3104003,20230520-160000,20230521-044735,"['industedge:', 'a', 'time-sensitive', 'networking', 'enabled', 'edge-cloud', 'collaborative', 'intelligent', 'platform', 'for', 'smart', 'industry']",False,20230521-205332,,,,
109,ieeex,Exploiting Page Table Locality for Agile TLB Prefetching,"Frequent Translation Lookaside Buffer (TLB) misses incur high performance and energy costs due to page walks required for fetching the corresponding address translations. Prefetching page table entries (PTEs) ahead of demand TLB accesses can mitigate the address translation performance bottleneck, but each prefetch requires traversing the page table, triggering additional accesses to the memory hierarchy. Therefore, TLB prefetching is a costly technique that may undermine performance when the prefetches are not accurate.In this paper we exploit the locality in the last level of the page table to reduce the cost and enhance the effectiveness of TLB prefetching by fetching cache-line adjacent PTEs ""for free"". We propose Sampling-Based Free TLB Prefetching (SBFP), a dynamic scheme that predicts the usefulness of these ""free"" PTEs and prefetches only the ones most likely to prevent TLB misses. We demonstrate that combining SBFP with novel and state-of-the-art TLB prefetchers significantly improves miss coverage and reduces most memory accesses due to page walks.Moreover, we propose Agile TLB Prefetcher (ATP), a novel composite TLB prefetcher particularly designed to maximize the benefits of SBFP. ATP efficiently combines three low-cost TLB prefetchers and disables TLB prefetching for those execution phases that do not benefit from it. Unlike state-of-the-art TLB prefetchers that correlate patterns with only one feature (e.g., strides, PC, distances), ATP correlates patterns with multiple features and dynamically enables the most appropriate TLB prefetcher per TLB miss.To alleviate the address translation performance bottleneck, we propose a unified solution that combines ATP and SBFP. Across an extensive set of industrial workloads provided by Qualcomm, ATP coupled with SBFP improves geometric speedup by 16.2%, and eliminates on average 37% of the memory references due to page walks. Considering the SPEC CPU 2006 and SPEC CPU 2017 benchmark suites, ATP with SBFP increases geometric speedup by 11.1%, and eliminates page walk memory references by 26%. Applied to big data workloads (GAP suite, XSBench), ATP with SBFP yields a geometric speedup of 11.8% while reducing page walk memory references by 5%. Over the best state-of-the-art TLB prefetcher for each benchmark suite, ATP with SBFP achieves speedups of 8.7%, 3.4%, and 4.2% for the Qualcomm, SPEC, and GAP+XSBench workloads, respectively.",virtual memory;address translation;translation lookaside buffer;page table locality;prefetching,G. Vavouliotis; L. Alvarez; V. Karakostas; K. Nikas; N. Koziris; D. A. Jiménez; M. Casas,"Barcelona Supercomputing Center, Universitat Politecnica de Catalunya; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya; National Technical University of Athens; National Technical University of Athens; National Technical University of Athens; Texas A&M University; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya",2021.0,2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499825,10.1109/ISCA52012.2021.00016,20230520-160000,20230521-044735,"['exploiting', 'page', 'table', 'locality', 'for', 'agile', 'tlb', 'prefetching']",True,20230521-205332,,,,
110,ieeex,A Method of Verification in Chisel Based Deep Learning Accelerator Design,"Chisel is a new generation of hardware construction language (HCL) for agile development. More and more developers have developed their project in agile design. At the same time, a considerable part of Verilog-based design has also been released in agile design versions. However, there is no comprehensive verification flow for Chisel based design. Due to the difficulties of verification in Chisel based design, it is a tough task to attach Chisel based design on Verilog based design. We purpose a feasible verification flow in chisel-based deep learning accelerator (DLA) design, which is composed by performance equivalence check at module-level and function equivalence check at pin-level. Compared to Universe Verification Method in RTL level codes that cost considerable time and funds, this verification flow improves the verification efficiency and reduce the difficulty of debug.",deep learning accelerator;verification;Chisel,Z. Li; Y. Chen; D. Zhao,"Beijing University of Post and Telecommunications, Beijing, China; Beijing University of Post and Telecommunications, Beijing, China; The Institute of Computing Technology of the Chinese Academy of Sciences, Beijing",2020.0,"2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277284,10.1109/ICIBA50161.2020.9277284,20230520-160000,20230521-044735,"['a', 'method', 'of', 'verification', 'in', 'chisel', 'based', 'deep', 'learning', 'accelerator', 'design']",False,20230521-205332,,,,
111,ieeex,DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud,"Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.",Container;microservice;moving target defense;cloud computing,H. Jin; Z. Li; D. Zou; B. Yuan,"National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China",2021.0,IEEE Transactions on Dependable and Secure Computing,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726136,10.1109/TDSC.2019.2916666,20230520-160000,20230521-044735,"['dseom:', 'a', 'framework', 'for', 'dynamic', 'security', 'evaluation', 'and', 'optimization', 'of', 'mtd', 'in', 'container-based', 'cloud']",False,20230521-205332,,,,
112,ieeex,APCC: Agile and Precise Congestion Control in Datacenters,"Modern datacenter networks exhibit complicated and time-varying traffic patterns, from long-running flows to burst short-lived flows. Recently in-network-telemetry (INT) is employed by datacenter transports to perform precise congestion control (CC). Current INT-based CC works well for long flows, however, suffers from serious performance downgrades when BDP-level small flows burst in the first RTT, due to the reason that current INT information from the receivers (host-based INT) needs at least one RTT to respond. In this paper, we make the first attempt to propose an agile and precise congestion control, called APCC, in datacenter networks, working for traffic patterns that is a mix of BDP-level short flows and long flows. APCC explores INT information from switches (switch-based INT) to feedback the congestion information eagerly, and effectively manage BDP-level flows. APCC utilizes the switch-based INT to schedule the complicated and time-varying traffic stably and precisely, and achieve low latency, high bandwidth and network stability simultaneously. We conduct extensive experiments to evaluate the performance of APCC. The experiment results show that with data centers load containing many BDP-level flows such as Cache Follower and Web Server, switch-based INT shows huge potential of improving the long tail effect on completion time (FCT). APCC reduces tail delay by 21.7%-28.9% under normal circumstances, and can still reduce tail delay by 9.1% under more severe conditions comparing with HPCC. Moreover, APCC shows better convergence.",datacenter networks;congestion control;in-network telemetry (INT);switch-based INT;host-based INT,R. Zhou; G. Yuan; D. Dong; S. Huang,"National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China",2020.0,"2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443722,10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00107,20230520-160000,20230521-044735,"['apcc:', 'agile', 'and', 'precise', 'congestion', 'control', 'in', 'datacenters']",False,20230521-205332,,,,
113,ieeex,Frequency-Hopping MIMO Radar-Based Communications: An Overview,"Enabled by the advancement in radio frequency technologies, the convergence of radar and communication systems becomes increasingly promising and is envisioned as a key feature of future sixth-generation networks. Recently, the frequency-hopping (FH) MIMO radar has been introduced to underlay dual-function radar-communication (DFRC) systems. Superior to many previous radar-centric DFRC designs, the symbol rate of FH-MIMO radar-based DFRC (FH-MIMO DFRC) can exceed the radar pulse repetition frequency. However, many practical issues, particularly those crucial to achieving effective data communications, are unexplored or unsolved. To promote the awareness and general understanding of the novel DFRC, this article is devoted to providing a timely introduction of FH-MIMO DFRC. We comprehensively review many essential aspects of the novel DFRC: channel/signal models, signaling strategies, modulation/demodulation processing, and channel estimation methods, to name a few. We also highlight major remaining issues in FH-MIMO DFRC and suggest potential solutions to shed light on future research directions.",Multi-Functional RF Systems (MFRFS);joint communication and radar/radio sensing (JCAS);dual-function radar-communication (DFRC);frequency hopping (FH);MIMO radar;frequency-agile radar (FAR);timing offset and channel estimation,K. Wu; J. A. Zhang; X. Huang; Y. J. Guo,"Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia",2022.0,IEEE Aerospace and Electronic Systems Magazine,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656537,10.1109/MAES.2021.3081176,20230520-160000,20230521-044735,"['frequency-hopping', 'mimo', 'radar-based', 'communications:', 'an', 'overview']",False,20230521-205332,,,,
114,ieeex,Research on the application of service choreography in the intelligent customer service system,"The background of this paper is to study the situation that the intelligent customer service system needs different response processes in different scenarios, including the high cost of developing and managing these processes. This paper applies the process engine framework Zeebe, which configures the sequence of various question-and-answer processes and other automatically triggered external processes through flexible scheduling. This application enables the system to respond flexibly to business process changes and achieve rapid and agile responses to new requirements. This system can be customized for different scenarios. The advantages of this system are that it reduces development costs and improves system scalability.",Intelligent customer service;business process;service choreography;Zeebe,Z. Shuo; Y. Rui; X. Yin; Z. Yan; Z. Wei; A. Yeteng; H. Wei; C. Long; K. Na; X. Liyang,"State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China",2023.0,"2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10090735,10.1109/EEBDA56825.2023.10090735,20230520-160000,20230521-044735,"['research', 'on', 'the', 'application', 'of', 'service', 'choreography', 'in', 'the', 'intelligent', 'customer', 'service', 'system']",False,20230521-205332,,,,
115,ieeex,A Microservices Platform for Monitoring and Analysis of IoT Traffic Data in Smart Cities,"The ongoing digitization of cities, enabled by the diffusion of interconnected sensors and devices, makes it possible to continuously collect and analyze huge streams of data at extremely large spatio-temporal scales and fine resolutions. These data can be used to monitor, detect and anticipate different kinds of infrastructure vulnerabilities and anomalies, as well as to implement more personalized services that could improve citizens' life. In this new context, full of opportunities, it is difficult to foresee and develop, in advance, the set of applications and services that can be potentially useful for administrators and citizens to solve the manifold compelling needs a city may have to face. Novel ICT paradigms and technologies can help designing agile, general-purpose smart city platforms aimed at supporting the collection and treatment of large-scale, multi-source (streams of) data and the development of novel applications that could fulfill diverse functional requirements under strict non-functional constraints. This paper presents the reference architecture, a prototype implementation and a city-scale case-study evaluation of PROMENADE, a platform that exploits IoT/Fog/Cloud paradigms, microservices and DevOps infrastructures to guarantee continuous development of robust and reliable applications for real-time monitoring and analysis of traffic data generated by IoT devices in large smart cities. The prototype has been evaluated in a case study concerning the quasi real-time detection of road networks vulnerabilities via centrality measures from on-line traffic conditions, emulated from off-line real datasets available for the city of Lyon, France.",IoT Platform;Microservices;Smart cities;Traffic monitoring;Resilience,A. De Iasio; A. Furno; L. Goglia; E. Zimeo,"University of Sannio, Benevento, Italy; ENTPE, IFSTTAR LICIT UMR T9401, Univ. of Lyon, Lyon, France; University of Sannio, Benevento, Italy; CINI Smart City Lab, University of Sannio, Benevento, Italy",2019.0,2019 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006025,10.1109/BigData47090.2019.9006025,20230520-160000,20230521-044735,"['a', 'microservices', 'platform', 'for', 'monitoring', 'and', 'analysis', 'of', 'iot', 'traffic', 'data', 'in', 'smart', 'cities']",False,20230521-205332,,,,
116,ieeex,Collaborative Cloud-Edge-End Task Offloading in Mobile-Edge Computing Networks With Limited Communication Capability,"Mobile edge computing (MEC) is an emerging computing paradigm for enabling low-latency, high-bandwidth and agile mobile services by deploying computing platform at the edge of network. In order to improve the cloud-edge-end processing efficiency of the tasks within the limited computation and communication capabilities, in this article, we investigate the collaborative computation offloading, computation and communication resource allocation scheme, and develop a collaborative computing framework that the tasks of mobile devices (MDs) can be partially processed at the terminals, edge nodes (EN) and cloud center (CC). Then, we propose the pipeline-based offloading scheme, where both MDs and ENs can offload computation-intensive tasks to a particular EN and CC, according to their computation and communication capacities, respectively. Based on the proposed pipeline offloading strategy, a sum latency of all MDs minimization problem is formulated with the consideration of the offloading strategy, computation resource, delivery rate and power allocation, which is a non-convex problem and difficult to deal with. To solve the optimization problem, by using the classic successive convex approximation (SCA) approach, we transform the non-convex optimization problem into the convex one. Finally, simulation results indicate that the proposed collaboration offloading scheme with the pipeline strategy is efficient and outperforms other offloading schemes.",Mobile edge computing;collaborative offloading;delivery rate,C. Kai; H. Zhou; Y. Yi; W. Huang,"Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China",2021.0,IEEE Transactions on Cognitive Communications and Networking,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171865,10.1109/TCCN.2020.3018159,20230520-160000,20230521-044735,"['collaborative', 'cloud-edge-end', 'task', 'offloading', 'in', 'mobile-edge', 'computing', 'networks', 'with', 'limited', 'communication', 'capability']",False,20230521-205332,,,,
117,ieeex,Mission Replanning for Multiple Agile Earth Observation Satellites Based on Cloud Coverage Forecasting,"Recent decades have witnessed a tremendous growth in the number of Earth observation satellites (EOSs), which presents a huge challenge for mission planning. For the EOSs with optical sensors particularly, the observation mission is significantly influenced by the uncertainty of cloud coverage, which has been identified as the most dominant factor for the invalidation of remote sensing images. To overcome this uncertainty, uncertainty programming methods, namely, chance constraint programming (CCP), stochastic expectation model, and robust optimization, are put forth. Despite their success, these approaches are limited in that they simplified the complex cloud coverage uncertainty, which may be different from the true cloud conditions, and they did not take the true cloud information into consideration. Motivated by these recent trends toward Big Data of satellite cloud images and machine learning for spatiotemporal prediction, this article explores a dynamic replanning scheme for multiple EOSs based on cloud forecasting. Specifically, we propose a new approach mainly in the following three steps: first, proactive scheduling based on a CCP is implemented and uploaded via ground control; second, cloud forecasting can be continuously conducted relying on the predictive recurrent neural network and the latest satellite cloud image; and third, mission replanning can be conducted according to the initial schedule and relatively accurate cloud information. Simulation results show that the cloud forecasting method is effective, and the replanning approach presents highly efficient and accurate scheduling results.",Agile Earth observation satellite (AEOS);artificial neural network;cloud forecasting;mission replanning;uncertainty programming,Y. Gu; C. Han; Y. Chen; W. W. Xing,"School of Astronautics, Beihang University, Beijing, China; School of Astronautics, Beihang University, Beijing, China; School of Astronautics, Beihang University, Beijing, China; School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China",2022.0,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652077,10.1109/JSTARS.2021.3135529,20230520-160000,20230521-044735,"['mission', 'replanning', 'for', 'multiple', 'agile', 'earth', 'observation', 'satellites', 'based', 'on', 'cloud', 'coverage', 'forecasting']",False,20230521-205332,,,,
118,ieeex,Gear: Enable Efficient Container Storage and Deployment with a New Image Format,"Containers have been widely used in various cloud platforms as they enable agile and elastic application deployment through their process-based virtualization and layered image system. However, different layers of a container image may contain substantial duplicate and unnecessary data, which slows down its deployment due to long image downloading time and increased burden on the image registry. To accelerate the deployment and reduce the size of the registry, we propose a new image format, named Gear image, that consists of two parts: a Gear index describing the structure of the image's file system and a set of files that are required when running an application. The Gear index is represented as a single-layer image compatible with the existing deployment framework. Containers can be launched by pulling a Gear index and on demand retrieving files pointed to by the index. Furthermore, the Gear image enables a file-level sharing mechanism, which helps remove duplicate data in the registry and avoid repeated downloading of identical files by a client. We implement a prototype of the container framework, named Gear, supporting the new image format. Evaluation shows that Gear saves 54 % storage capacity in the registry, speeds up container startup by up to ${5\times}$, and reduces 84 % bandwidth demands.",container;image format;deployment time;registry,H. Fan; S. Bian; S. Wu; S. Jiang; S. Ibrahim; H. Jin,"National Engineering Research Center for Big Data Technology and System; National Engineering Research Center for Big Data Technology and System; National Engineering Research Center for Big Data Technology and System; Department of Computer Science and Engineering, University of Texas at Arlington, U.S; Inria, Univ. Rennes, CNRS, IRISA, France; National Engineering Research Center for Big Data Technology and System",2021.0,2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546503,10.1109/ICDCS51616.2021.00020,20230520-160000,20230521-044735,"['gear:', 'enable', 'efficient', 'container', 'storage', 'and', 'deployment', 'with', 'a', 'new', 'image', 'format']",False,20230521-205332,,,,
119,ieeex,A Simulator and Compiler Framework for Agile Hardware-Software Co-design Evaluation and Exploration,"As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and hardware-software co-design. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support heterogeneous combinations of general-purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we describe our compiler and simulator pair: DEC++ and MosaicSim. Together, they provide a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. The simulator and corresponding compiler were developed as part of the DECADES project, a multi-team effort to design and tape out a new heterogeneous architecture. We will present two case-studies in important data-science applications where DEC++ and MosaicSim enable straightforward design space explorations for emerging full-stack systems.",performance modeling;heterogeneous systems;hardware-software co-design. LLVM simulation,T. Sorensen; A. Manocha; E. Tureci; M. Orenes-Vera; J. L. Aragón; M. Martonosi,"UC, Santa Cruz; Princeton University; Princeton University; Princeton University; Universidad de Murcia; Princeton University",2020.0,2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256600,,20230520-160000,20230521-044735,"['a', 'simulator', 'and', 'compiler', 'framework', 'for', 'agile', 'hardware-software', 'co-design', 'evaluation', 'and', 'exploration']",False,20230521-205332,,,,
120,ieeex,Reinforcement Learning-Based and Parametric Production-Maintenance Control Policies for a Deteriorating Manufacturing System,"The model of a stochastic production/inventory system that is subject to deterioration failures is developed and examined in this paper. Customer interarrival times are assumed to be random and backorders are allowed. The system experiences a number of deterioration stages before it ultimately fails and is rendered inoperable. Repair and maintenance activities restore the system to its initial and previous deterioration state, respectively. The duration of both repair and maintenance is assumed to be stochastic. We address the problem of minimizing the expected sum of two conflicting objective functions: the average inventory level and the average number of backorders. The solution to this problem consists of finding the optimal tradeoff between maintaining a high service level and carrying as low inventory as possible. The primary goal of this research is to obtain optimal or near-optimal joint production/maintenance control policies, by means of a novel reinforcement learning-based approach. Furthermore, we examine parametric production and maintenance policies that are often used in practical situations, namely, Kanban, (s, S), threshold-type condition based maintenance and periodic maintenance. The proposed approach is compared with the parametric policies in an extensive series of simulation experiments and it is found to clearly outperform them in all cases. Based on the numerical results obtained by the experiments, the behavior of the parametric policies as well as the structure of the control policies derived by the Reinforcement Learning-based approach is investigated.",Inventory control;preventive maintenance;reinforcement learning;intelligent manufacturing systems,A. S. Xanthopoulos; A. Kiatipis; D. E. Koulouriotis; S. Stieger,"Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; Fujitsu Technology Solutions GmbH, Munich, Germany; Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; Fujitsu Technology Solutions GmbH, Munich, Germany",2018.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114172,10.1109/ACCESS.2017.2771827,20230520-160000,20230521-044735,"['reinforcement', 'learning-based', 'and', 'parametric', 'production-maintenance', 'control', 'policies', 'for', 'a', 'deteriorating', 'manufacturing', 'system']",False,20230521-205332,,,,
121,ieeex,Energy-Efficient Resource Allocation with Flexible Frame Structure for Heterogeneous Services,"The key objective of the fifth generation (5G) wireless technology is to support services with vastly variable requirements, which necessitates the flexible numerology and frame structure for radio resource allocation. In this paper, flexible 2-dimensional resource allocation is investigated to maximize the energy efficiency (EE) for service transmissions with heterogeneous latency requirements. Exploiting the frequency and time diversities of the resource grid, frequency-selective resource allocation, together with an agile ""on-off"" operation of the power amplifier (PA) are performed by the proposed sliding window-based (SW) algorithm with scalability. Simulation results further demonstrate that the SW algorithm can achieve similar EE performance as the exhaustive method with a substantially lower complexity.","Flexible numerology, flexible frame structure, heterogeneous services, energy efficiency, resource allocation",W. Sui; X. Chen; S. Zhang; Z. Jiang; S. Xu,"Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science",2019.0,"2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8875273,10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00139,20230520-160000,20230521-044735,"['energy-efficient', 'resource', 'allocation', 'with', 'flexible', 'frame', 'structure', 'for', 'heterogeneous', 'services']",False,20230521-205332,,,,
122,ieeex,Evaluation of stochastic bounds on the remaining completion time of products in a buffered sequential workflow,"Agile production systems face major issues in satisfying fickle market needs in highly demand-driven industry sectors, such as electronics and mechatronics. In this context, the time needed to complete the production of an item tends to be highly variable, and online estimation of the remaining completion time may suffer the lack of adequate sensor data, especially in existing manufacturing systems. To solve this issue, we propose a new analytical technique for the evaluation of an upper and a lower stochastic bound on the remaining completion time of a product, considering an assembly line made of sequential workstations with transfer blocking and buffer capacity. The approach notably encompasses service times with non-Markovian distribution, and avoids the limitation of existing works requiring the system to be at steady state at the inspection time. The technique is experimented on a case study and validated through simulation, providing an empirical analysis of its complexity.",Assembly lines;inspection;stochastic bounds;remaining completion time;non-Markovian durations,M. Biagi; L. Carnevali; K. Tadano; E. Vicario,"Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering, University of Florence, Florence, Italy; Data Science Research Labs NEC Corporation, Kawasaki, Japan; Department of Information Engineering, University of Florence, Florence, Italy",2018.0,2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502542,10.1109/ETFA.2018.8502542,20230520-160000,20230521-044735,"['evaluation', 'of', 'stochastic', 'bounds', 'on', 'the', 'remaining', 'completion', 'time', 'of', 'products', 'in', 'a', 'buffered', 'sequential', 'workflow']",False,20230521-205332,,,,
123,ieeex,Agile Approach on the Performance Prediction of ARM TrustZone-based Mandatory Access Control Security Enhancement,"Mandatory Access Control (MAC) is one of the most important security mechanisms of Linux, but it may be threatened by vulnerabilities in kernel space. Currently, the ARM TrustZone-based MAC (TZ-MAC) security enhancement method has been proposed to protect the key security function of MAC with the hardware-based trusted execution environment. However, given that each call to the hook set of the TZ-MAC security modules will cause switching between the normal and secure worlds of ARM TrustZone, the specific design of the TZ-MAC framework will substantially affect system performance, and may even be considerably slow to prevent the security module from being applied. Therefore, when researchers design a security module, they need an agile method to predict the performance cost brought by the hook set realized, to assist the optimization of the design scheme and improve system performance. This study presents a performance prediction method of TZ-MAC based on the statistical analysis of the Linux Security Modules (LSM) hook calls. This method is universal for different TZ-MAC frameworks, security modules, and benchmarks. Moreover, the proposed method can predict only the performance based on the security module design of TZ-MAC, and the implementation of the module is not needed. An agile approach of performance prediction for TZ-MAC is conducted based on the performance prediction method. For two different TZ-MAC implementation ideas, we constructed prediction data sets based on the classic benchmarks, namely, LMbench and UnixBench, and verified the effectiveness of our method. The tests based on the security module SELinux show that over 50% of the overhead is caused by 3% of the LSM hook functions, which indicates the direction for future optimization.",Performance Evaluation;TrustZone;Mandatory Access Control,Z. Li; Y. Ding; X. Chen; P. Dong; C. Huang; L. Song; P. Wang,"School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China",2021.0,"2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644816,10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00150,20230520-160000,20230521-044735,"['agile', 'approach', 'on', 'the', 'performance', 'prediction', 'of', 'arm', 'trustzone-based', 'mandatory', 'access', 'control', 'security', 'enhancement']",False,20230521-205332,,,,
124,ieeex,Sidelobe Coherency Recovery Technique of Interpulse Diversity based on Inverse Filtering,"Transmitting the pulse-to-pulse agile waveforms will break up the sidelobe coherency of impulse responses, which makes the static clutter fail to be completely suppressed, and has a negative impact on radar detection. In this paper, inspired by inverse filtering, we propose an effective method for designing pulse-compression filters that recover the sidelobe coherency of the agile waveforms. By selecting an appropriate window function in the frequency-domain, the impulse responses can be all identical while achieving marked sidelobe level improvement. Furthermore, we analyse the echoes of targets with different speeds and point out the situation which would happen in modern radar application. Simulations are conducted to verify the effectiveness of this method.",interpulse diversity;inverse filtering;sidelobe coherency recovery;low sidelobe level;clutter suppression,Q. Ge; D. Zhao; Y. Yao; G. Wu,"Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China",2020.0,"2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277065,10.1109/ICIBA50161.2020.9277065,20230520-160000,20230521-044735,"['sidelobe', 'coherency', 'recovery', 'technique', 'of', 'interpulse', 'diversity', 'based', 'on', 'inverse', 'filtering']",False,20230521-205332,,,,
125,ieeex,SymPlot: A Web-Tool to Visualise Symbolic Musical Data,"Some complex musical parameters might be especially difficult to understand for someone with no theoretical expertise in music. Musicians and music scholars alike normally evaluate such parameters visually by departing from scores, which present the musical events at once. Yet for the under-standing of such symbolic representations, musical training is essential, making scores mostly incomprehensible for amateurs. Data visualisation has been applied to meaningfully represent complex musical parameters, thus enabling music amateurs to grasp concepts such as texture or structure. Although scores are one of the ""primary"" sources to understand music, previous work shows a strong bias towards the visualisation of acoustic data, in detriment of the visualisation of symbolic information. To bridge the gap, we present SymPlot, a web-based open source tool to automatically visualise textural density, scoring, and structure from MusicXML files. Due to the multidisciplinary nature of the topic, in this project we have applied the Scrum's agile methodology, an iterative incremental approach specifically tailored for interdisciplinary projects. The tool, aimed at enhancing musical understanding in amateurs and students, as well as in scholars of other disciplines who need to incorporate music into their discourses, i.e., historians, philologists, etc., enables visualisation of local features at various hierarchical levels, highlighting similarities both within and across scores. Our evaluation of SymPlot-based on a five-level rating-scale test performed by 50 participants-suggests that colours increase users' understanding of complex musical parameters.",visualisation;music;data science;digital humanities;score;computational musicology;symbolic music data,P. Muñoz-Lago; A. Llorens; E. Parada-Cabaleiro; Á. Torrente,"Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain",2020.0,2020 24th International Conference Information Visualisation (IV),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373167,10.1109/IV51561.2020.00092,20230520-160000,20230521-044735,"['symplot:', 'a', 'web-tool', 'to', 'visualise', 'symbolic', 'musical', 'data']",False,20230521-205332,,,,
126,ieeex,Design and Implementation of Operating Management Platform of Dispatching and Control Cloud Application based on Container Technology,"With the development of dispatching and control cloud platform, the existing virtual resource management mechanism has been unable to meet the requirements of rapid construction, agile delivery and convenient management of applications. The emergence of container technology provides a good solution. Combined with the Docker technology and the requirements of application lifecycle management, this paper proposes an operating management platform of dispatching and control cloud application based on container technology, introduces the overall architecture of the platform, designs and implements function modules including image management, application management and resource scheduling. With the platform designed in this paper, applications can realize the rapid construction, efficient deployment and convenient management, meet the requirements of flexible elastic expansion and directional scheduling, generally provide strong support for the development and use of the dispatching and control cloud platform.",Docker technology;application management;resource scheduling;dispatching and control cloud,X. Ma; Q. Yang; L. Tao; Y. Huang; P. Zhang; Z. Zhang,"Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; State Grid Jibei Electric Power Company, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China",2020.0,"2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276832,10.1109/ICIBA50161.2020.9276832,20230520-160000,20230521-044735,"['design', 'and', 'implementation', 'of', 'operating', 'management', 'platform', 'of', 'dispatching', 'and', 'control', 'cloud', 'application', 'based', 'on', 'container', 'technology']",False,20230521-205332,,,,
127,ieeex,Development of Ship Detection Using OPENCV YOLO Method on Unmanned Prototype Boat for Monitoring National Sea,"Indonesia is a vast archipelago and a large sea area. Quoting from the Preamble of the 1945 Constitution states that the purpose of the Government of the Republic of Indonesia is to protect the entire Indonesian nation and its homeland. Therefore, defensive aspects need to be taken into special account. The Sea Defense System requires an agile unmanned mini-sea boat maneuvering capability which is able to secure the sea area according to its function and detect foreign ships. Indonesia needs to be more vigilant and detect its underwater defenses so that intruders do not attempt to violate the sovereignty of the Republic of Indonesia. This research is intended as a solution by designing a mini marine prototype to protect and strengthen Indonesian sea border. The system is developed using OpenCV and YOLO (You Only Look Once) method to detect ship. It is developed on an laptop which run on Linux. This research yields the results of the ship detection system by percentage of precision confidence level range 54–96% and several factors of undetectable condition, namely camouflaged ship, half body of ship image, and sunset condition.",unmanned;mini sea-boat;prototype;detection;sea,A. P. W. Aldryani; H. Tjahjadi; I. A. Dahlan; I. Kholis; R. Istoni; A. F. Bangun; A. C. Tambunan; J. K. S. Pigome,"Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Electrical Engineering, University of Indonesia, Depok, Indonesia; Electrical Engineering, Technical University of Malaysia Melaka, Melaka, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia",2022.0,2022 7th International Workshop on Big Data and Information Security (IWBIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924891,10.1109/IWBIS56557.2022.9924891,20230520-160000,20230521-044735,"['development', 'of', 'ship', 'detection', 'using', 'opencv', 'yolo', 'method', 'on', 'unmanned', 'prototype', 'boat', 'for', 'monitoring', 'national', 'sea']",False,20230521-205332,,,,
128,ieeex,Interplay of Machine Learning and Software Engineering for Quality Estimations,"In this era, the agile mindset has innovated the traditional software engineering (SE) process through the integration of DevOps flow engines, scrum iterations, and automation of continuous integration (CI) and continuous deployment (CD) cycles. However, the CI/CD integration requires manual code-revisions and refactoring at large scales. Recently, machine-learning (ML) is employed in SE that allows legacy codes to be highly dynamic, less coupling in related modules, automatic code versioning, and refactoring, with less coupling among related modules. However, over time, ML models tend to become bulky, with increasing monotonic losses during model training. To address this, SE techniques like code revisions are employed over ML codes to allow low-order training losses, that enables seamless and precise workflow structures. Motivated from the aforementioned discussions, the paper presents a systematic review of the close interplay of SE and ML and possible interactions in different applications. Suitable research questions and case studies are presented for possible adoption scenarios that depict the close ML-SE interplay share with each other, with the concluding remarks. The paper forms useful insights for ML engineers, data science practitioners, and SE quality estimators towards the building of efficient and scalable software solutions.",Machine learning;Software Engineering;Effort estimation;Quality estimation,H. Abubakar; M. S. Obaidat; A. Gupta; P. Bhattacharya; S. Tanwar,"Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; College of Computing and Informatics, University of Sharjah, Sharjah 27272, UAE, King Abdullah II School of Information Technology, University of Jordan, Amman 11942, Jordan, University of Science and Technology Beijing, Beijing, China; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India",2020.0,"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256507,10.1109/CCCI49893.2020.9256507,20230520-160000,20230521-044735,"['interplay', 'of', 'machine', 'learning', 'and', 'software', 'engineering', 'for', 'quality', 'estimations']",False,20230521-205332,,,,
129,ieeex,Management Consulting Business Models: Operations through and for Digital Transformation,"Management consulting as a service has become part of almost every company’s daily business. The growth is being exponential, even with all the non-consensual issues and controversies in the industry. However, the market is increasingly competitive, with new competitors coming from everywhere. At the same time, the world is changing at a speed never seen before, and the challenges are several: automatization, scarcity of resources, democratization of the information, big data, and regulation are some examples. Thus, it’s not possible for consulting firms to keep providing the market needs without adapting continuously their own business models. The companies that can outperform these challenges more efficiently will win against the competitors. Investigate which strategies and mechanisms adopt to be agile and flexible enough, in which sectors invest the most, and how reinvent their business model in order to be resilient in a fast changing and technological world are the main objectives of this research. Several interviews with the top management of fifteen of the biggest consulting companies in Portugal were conducted. The results suggested that companies are now trying to differentiate by the services delivered, and these business models’ adaptation to the digital transformation is rather than a reality, a need.",Management Consulting;Digital Transformation;Business Models,C. Jerónimo; L. Pereira; H. Sousa,"BRU-IUL, ISCTE Business School, Lisboa, Portugal; BRU-IUL, ISCTE Business School, Lisboa, Portugal; BRU-IUL, ISCTE Business School, Lisboa, Portugal",2019.0,"2019 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792592,10.1109/ICE.2019.8792592,20230520-160000,20230521-044735,"['management', 'consulting', 'business', 'models:', 'operations', 'through', 'and', 'for', 'digital', 'transformation']",False,20230521-205332,,,,
130,ieeex,Energy Efficient Double Critic Deep Deterministic Policy Gradient Framework for Fog Computing,"-Nowadays the data is growing at a faster pace and the big data applications are required to be more agile and flexible. There is a need for a decentralized model to carry out the required substantial amount of computation across edge devices as they has led to the innovation of fog computing. Energy consumption among the edge devices is one of the potential threatening issues in fog computing. Their high energy demand also contributes to higher computation cost. In this paper Double Critic (DC) approach is enforced over the Deep Deterministic Policy Gradient (DDPG) technique to design the DC-DDPG framework which formulates high quality energy efficiency policies for fog computing. The performance of the proposed framework is outstanding compared to existing works based on the metrics like energy consumption, response time, total cost, and throughput. They are measured under two different fog computing scenarios i.e., fog layer with multiple entities in a region and fog layer with multiple entities in multiple regions. Mathematical modeling reveals that the energy efficiency policies formulated are of high quality as they satisfy the quality assurance metrics, such as empirical correctness, robustness, model relevance, and data privacy.",Deterministic Policy Gradient;Fog computing;Energy;Q-learning;Double Critic,B. Krishnamurthy; S. G. Shiva,"Department of Computer Science, Siddaganga Institute of Technology, Tumakuru, Karnataka, India; Department of Computer Science, University of Memphis, Memphis, Tennessee, USA",2022.0,2022 IEEE World AI IoT Congress (AIIoT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817157,10.1109/AIIoT54504.2022.9817157,20230520-160000,20230521-044735,"['energy', 'efficient', 'double', 'critic', 'deep', 'deterministic', 'policy', 'gradient', 'framework', 'for', 'fog', 'computing']",False,20230521-205332,,,,
131,ieeex,ACT Testbot and 4S Quality Metrics in XAAS Framework,"The purpose of this paper is to analyze all Cloud based Service Models, Continuous Integration, Deployment and Delivery process and propose an Automated Continuous Testing and testing as a service based TestBot and metrics dashboard which will be integrated with all existing automation, bug logging, build management, configuration and test management tools. Recently cloud is being used by organizations to save time, money and efforts required to setup and maintain infrastructure and platform. Continuous Integration and Delivery is in practice nowadays within Agile methodology to give capability of multiple software releases on daily basis and ensuring all the development, test and Production environments could be synched up quickly. In such an agile environment there is need to ramp up testing tools and processes so that overall regression testing including functional, performance and security testing could be done along with build deployments at real time. To support this phenomenon, we researched on Continuous Testing and worked with industry professionals who are involved in architecting, developing and testing the software products. A lot of research has been done towards automating software testing so that testing of software product could be done quickly and overall testing process could be optimized. As part of this paper we have proposed ACT TestBot tool, metrics dashboard and coined 4S quality metrics term to quantify quality of the software product. ACT testbot and metrics dashboard will be integrated with Continuous Integration tools, Bug reporting tools, test management tools and Data Analytics tools to trigger automation scripts, continuously analyze application logs, open defects automatically and generate metrics reports. Defect pattern report will be created to support root cause analysis and to take preventive action.",Cloud;ACT (Automated Continuous Testing);TestBot;Continuous Testing;Continuous Integration;Continuous Delivery;Continuous Deployment;XaaS (Everything as a Service);T-Model;Auto Bug Logging and Tracking;4S Quality Metrics,D. Chhillar; K. Sharma,"Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India; Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India",2019.0,"2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862212,10.1109/COMITCon.2019.8862212,20230520-160000,20230521-044735,"['act', 'testbot', 'and', '4s', 'quality', 'metrics', 'in', 'xaas', 'framework']",False,20230521-205332,,,,
132,ieeex,Best Practices for Engineering AI-Infused Applications: Lessons Learned from Microsoft Teams,"Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML.","AI, Machine Learning, Industry Practice",A. Begel,"Microsoft Research, Redmond, WA, USA",2019.0,2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836177,10.1109/CESSER-IP.2019.00008,20230520-160000,20230521-044735,"['best', 'practices', 'for', 'engineering', 'ai-infused', 'applications:', 'lessons', 'learned', 'from', 'microsoft', 'teams']",True,20230521-205332,,,,
133,ieeex,"Transitioning from Legacy Air Traffic Management to Airspace Management through Secure, Cloud-Native Automation Solutions","Advancements in Cloud-native services, Machine-Learning (ML), Artificial Intelligence (AI), and Rapid Application Development (RAD) using the Agile methodology has led countless industries to achieving desirable levels of automation while reducing cost and improving quality software deployments, timely / iterative delivery, and accountability. Coupling this framework with the principle of security as a shared responsibility further enhances the efficacy of an integrated Development, Security, and Operations (DevSecOps) Team within organizations to deliver secured digital solutions. Air Navigation Service Providers (ANSPs) around the world are currently exploring and embracing the digital evolution shifting from monolithic, legacy automation platforms to an application framework of microservices to allow for flexible operations as capabilities and airspace operations evolve. Specific to the US, the ATM automation system of today is comprised of both safety and non-safety critical systems, with mission-essential, efficiency-critical, and mission-support services that are predominately maintained and evolved through multi-year, one contractor-led programs. Although the system has proven resilient, it has not proven to be agile and flexible to allow for advances in capabilities on-board aircraft or in the data integration and sharing with other NAS automation systems. This creates significant overhead in development, sustainability, and operations of the current automation system, and leaves modernization efforts—in terms of new capabilities—in constant investment decision planning cycles, costing agencies not just money, but more time to innovate. To advance aviation into a new generation of interoperability leveraging collaborative frameworks and application specific capabilities, ANSPs must adapt to innovative methods to collect, process, and deliver critical and essential aeronautical, weather, and flight information to air traffic control operators and ultimately to airspace users. Doing so can not only lead to sustaining NAS automation systems while reducing the costs to develop and operate these systems, but it also provides an opportunity to present strategies on how to dramatically reduce the time and integration efforts needed to deploy new capabilities. Leveraging cloud-native technologies and services is a way to realize this automation evolution vision for ANSPs.This paper examines the migration from today’s systems to secure, cloud-native platforms to prove that Mission Services and Mission Applications can be rapidly available / deployable to operators who provide separation and flow management services, using a cyber-secured cloud-native environment. Aeronautical data typically used for tactical decision making is now seen as crucial to the decision-making process in Air Traffic Management (ATM). Integrating global and localized datasets into a digital aviation data platform enhances the capabilities of the solutions and opens the possibilities of leveraging big data analytics and microservices to compute trajectory predictions (TP), demand capacity balancing (DCB), arrival and departure sequencing, airspace delay, among others, in real-time to achieve operator-driven mission objectives. Technology has reached a state of maturity, especially in cloud and hybrid cloud solutions, to support safety of life operations, like ATM. This paper identifies approaches that are being considered for that migration to support the integration of new airspace entrants, the use of application services to provide a dynamic, evolutionary ATM platform, and addresses some of the safety and security strategies that must be considered for this evolution.",Automation;ATM;Cloud-native;Microservices,A. Solomon; Z. Crawford,"Digital Aviation Solutions Thales, Arlington, VA, USA; Digital Aviation Solutions Thales, Arlington, VA, USA",2021.0,2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594313,10.1109/DASC52595.2021.9594313,20230520-160000,20230521-044735,"['transitioning', 'from', 'legacy', 'air', 'traffic', 'management', 'to', 'airspace', 'management', 'through', 'secure,', 'cloud-native', 'automation', 'solutions']",False,20230521-205332,,,,
134,ieeex,Generalized Linear Optical Sampling Technique Realized by Using Non-Pulse Electro-Optic Frequency Comb Sampling Source,"We propose a novel generalized linear optical sampling (GLOS) technique realized by using an electro-optic frequency comb (EOFC) as the sampling signal. GLOS technique is demonstrated as a bandwidth compression process in frequency domain instead of gating effect in time domain. An EOFC without the limitation to be ultra-short pulse serves as sampling signal is pre-measured. In experiments, the waveforms are sampled by an EOFC with agile repetition rates and bandwidths. After a demodulation process with pre-measured information, the original signal under test in both intensity and phase fields can be recovered. The results obtained from the proposed method are consistent with those from traditional linear optical sampling technique. Besides, with a high average mode power, EOFC-based GLOS technique realizes more than 10 dB SNR improvement and has ability to detect weak signal with a power of -47.3 dBm. Our demonstration opens the way for cost-effective comb sources to be used in optical sampling fields.",Linear optical sampling;electro-optic frequency comb;repetition rate agility;SNR improvement,B. Xu; X. Fan; S. Wang; Z. He,"Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China",2020.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121264,10.1109/ACCESS.2020.3003780,20230520-160000,20230521-044735,"['generalized', 'linear', 'optical', 'sampling', 'technique', 'realized', 'by', 'using', 'non-pulse', 'electro-optic', 'frequency', 'comb', 'sampling', 'source']",False,20230521-205332,,,,
135,ieeex,Diaspore: Diagnosing Performance Interference in Apache Spark,"Apache Spark is being increasingly used to execute big data applications on cluster computing platforms. To increase system utilization, cluster operators often configure their clusters such that multiple co-located applications can simultaneously share the resources of a cluster node. With resource sharing, applications can compete with each other for shared node resources thereby interfering with each other's performance. Many Spark applications take a long time to execute. Performance interference from other applications can thus cause a Spark application to fail or take even longer time to execute thereby wasting cluster resources and frustrating users. This motivates the need for an automated technique that can detect interference quickly and also diagnose the root cause of the interference to facilitate mitigation of the problem. Most existing approaches are not designed to offer quick interference detection and diagnosis. For example, they typically require extensive training data for every application of interest under various possible input data sizes and resource allocations. In this paper, we systematically investigate the design of a Machine Learning (ML) based technique that addresses this open problem. We implement a tool called Diaspore that integrates our findings. We evaluate the tool with a diverse set of 13 Spark applications executing on a real cluster. Experimental results show that Diaspore requires only small scale training data, i.e., executions under small input sizes and resource allocations. Furthermore, our results show that the tool can offer accurate predictions for applications not present in the training data. Consequently, Diaspore reduces the training time needed to offer predictions. Finally, the feature engineering underlying Diaspore ensures that the tool can detect and diagnose interference quickly in an online manner by sampling only a small fraction of a long running application's execution. This can allow cluster operators to mitigate interference in an agile manner.",Interference detection;big data;machine learning,S. Shah; Y. Amannejad; D. Krishnamurthy,"Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada; Mathematics and Computing Department, Mount Royal University, Calgary, AB, Canada; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada",2021.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490641,10.1109/ACCESS.2021.3098426,20230520-160000,20230521-044735,"['diaspore:', 'diagnosing', 'performance', 'interference', 'in', 'apache', 'spark']",False,20230521-205332,,,,
136,ieeex,DeepCP: Deep Learning Driven Cascade Prediction-Based Autonomous Content Placement in Closed Social Network,"Online social networks (OSNs) are emerging as the most popular mainstream platform for content cascade diffusion. In order to provide satisfactory quality of experience (QoE) for users in OSNs, much research dedicates to proactive content placement by using the propagation pattern, user's personal profiles and social relationships in open social network scenarios (e.g., Twitter and Weibo). In this paper, we take a new direction of popularity-aware content placement in a closed social network (e.g., WeChat Moment) where user's privacy is highly enhanced. We propose a novel data-driven holistic deep learning framework, namely DeepCP, for joint diffusion-aware cascade prediction and autonomous content placement without utilizing users' personal and social information. We first devise a time-window LSTM model for content popularity prediction and cascade geo-distribution estimation. Accordingly, we further propose a novel autonomous content placement mechanism CP-GAN which adopts the generative adversarial network (GAN) for agile placement decision making to reduce the content access latency and enhance users' QoE. We conduct extensive experiments using cascade diffusion traces in WeChat Moment (WM). Evaluation results corroborate that the proposed DeepCP framework can predict the content popularity with a high accuracy, generate efficient placement decision in a real-time manner, and achieve significant content access latency reduction over existing schemes.",Social network analysis;cascade prediction;autonomous content placement,Q. Wu; M. Wu; X. Chen; Z. Zhou; K. He; L. Chen,"School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Financial Technology, Tencent Inc., Shenzhen, China",2020.0,IEEE Journal on Selected Areas in Communications,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107092,10.1109/JSAC.2020.2999687,20230520-160000,20230521-044735,"['deepcp:', 'deep', 'learning', 'driven', 'cascade', 'prediction-based', 'autonomous', 'content', 'placement', 'in', 'closed', 'social', 'network']",False,20230521-205332,,,,
137,ieeex,Digital Inclusion in Nothern England: Training Women from Underrepresented Communities in Tech: A Data Analytics Case Study,"The TechUPWomen programme takes 100 women from the Midlands and North of England, particularly from underrepresented communities, with degrees or experience in any subject area, retrains them in technology and upon graduation guarantees an interview with a company. The retraining programme, developed by the Partner Universities in conjunction with the Industrial Partners, has modules at level 6/7 including: Technology: coding, data science, cyber security, machine learning, agile project management; Workplace readiness skills: public speaking, clear communication, working as a team. In this paper, we introduce, for the first time, the TechUPWomen programme, and we analyse its temporal evolution and special features via a data analytics nowcasting approach. Deepening these women’s experience with applied upskilling includes one-to-one mentoring (100-100), strong networking, residentials, close industry connection with two directions (non-technical & technical) and four job-focussed final tracks: business analyst, agile project manager, data scientist, developer. TechUPWomen also has significant representation of traditionally underrepresented communities, with focus on enabling instead of teaching approach. Beside the originality of the unique combination of features of the programme, this is, to the best of our knowledge, the first analysis based on data analytics of a women in tech(nology) retraining programme, based on nowcasting. Results show that the approach is effective; topic analysis shows that frequent topics include joy, BAME, networking, residential, industry, learning.",TechUPWomen;Underrepresented Communities;Digital Inclusion;Data Analytics;Computer Science Education,O. T. Aduragba; J. Yu; A. I. Cristea; M. Hardey; S. Black,"Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK",2020.0,2020 15th International Conference on Computer Science & Education (ICCSE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201693,10.1109/ICCSE49874.2020.9201693,20230520-160000,20230521-044735,"['digital', 'inclusion', 'in', 'nothern', 'england:', 'training', 'women', 'from', 'underrepresented', 'communities', 'in', 'tech:', 'a', 'data', 'analytics', 'case', 'study']",False,20230521-205332,,,,
138,ieeex,Automated Robot (Car) using Artificial Intelligence,"This paper discusses about researching an automated robot car using artificial intelligence; training its neural network using AlexNet model, using YOLO (you only look once algorithm) for object detection phase and for practical deduction and judging component we have used Open Neural Network Exchange (ONNX) format. Our Robot Car model is agile and cost efficient. It detects objects efficiently in front of it and movement of it is smooth. It moves through sensors in motors which makes it different than other models in the world.",Deep learning;NVIDIA Jetson Nano;ISBot;AlexNet;YOLO (You Only Look Once);Open Neural Network Exchange (ONNX);Convolutional Neural Network (CNN);Stochastic Gradient Descent (SGD);Intersection over Union (IoU),S. Mishra; C. S. Minh; H. Thi Chuc; T. V. Long; T. T. Nguyen,"Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Management and Information System, International School, Vietnam National University, Hanoi, Vietnam; Head, Department of Science and Technology, International School, Vietnam National University, Hanoi, Vietnam",2022.0,"2021 International Seminar on Machine Learning, Optimization, and Data Science (ISMODE)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743130,10.1109/ISMODE53584.2022.9743130,20230520-160000,20230521-044735,"['automated', 'robot', '(car)', 'using', 'artificial', 'intelligence']",False,20230521-205332,,,,
139,ieeex,Data security compliance management and control technology based on scene orchestration,"The digital economy has entered the fast lane, and data has become a core production factor and a key strategic resource. Data flows to create value, and it also brings various security compliance risks. How to balance the relationship between data “protection” and “utilization” is a difficult problem. This topic is oriented to the security and compliance needs of data used in different business scenarios, and proposes a data process compliance management and control and data security capability agile invocation mechanism based on scenario orchestration technology, and is used in scenarios such as power data analysis, testing, and outsourcing. Application verification has been carried out to effectively realize the integration of business and security capabilities, management and technology integration, and online and offline integration.",scenario orchestration;agile invocation;compliance management and control;integration of business and security,D. Wang; R. Yang; X. Gao,"State Grid Big Data Center, Beijing, China; State Grid Key Laboratory of Information & Network Security, Nanjing, China; State Grid Key Laboratory of Information & Network Security, Nanjing, China",2021.0,2021 13th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410067,10.1109/ICMTMA52658.2021.00093,20230520-160000,20230521-044735,"['data', 'security', 'compliance', 'management', 'and', 'control', 'technology', 'based', 'on', 'scene', 'orchestration']",False,20230521-205332,,,,
140,ieeex,BotCensor: Detecting DGA-Based Botnet Using Two-Stage Anomaly Detection,"Nowadays, most botnets utilize domain generation algorithms (DGAs) to build resilient and agile command and control (C&C) channels. Specifically, botmasters employ DGAs to dynamically produce a large number of random domains and only register a small subset for their actual C&C servers with the purpose to defend them from takeovers and blacklisting attempts. While many approaches and models have been developed to detect DGA-based botnets, they suffer from several limitations, such as difficulties of DNS traffic collection, low feasibility and scalability, and so forth. In this paper, we present BotCensor, a new system that can determine if a host is infected with certain DGA malware with two-stage anomaly detection. In the first stage, we preliminarily attempt to identify malicious domains using a Markov model, and in the second stage, we re-examine the hosts that requested aforementioned malicious domains using novelty detection algorithms. Our experimental results show that our approach performs very well on identifying previously unknown DGA-generated domains and detects DGA bots with high efficiency and efficacy. Our approach not only can be regarded as security forensics tools, but also can be used to prevent malware infections and spread.","DGA-based botnet detection, Two-stage anomaly detection, Markov model, Novelty detection algorithms, DNS traffic",B. Qi; J. Jiang; Z. Shi; R. Mao; Q. Wang,"Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN",2018.0,"2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8455977,10.1109/TrustCom/BigDataSE.2018.00109,20230520-160000,20230521-044735,"['botcensor:', 'detecting', 'dga-based', 'botnet', 'using', 'two-stage', 'anomaly', 'detection']",False,20230521-205332,,,,
141,ieeex,RTA: an Efficient SIMD Architecture for Ray Tracing,"In recent years, real-time ray tracing has attracted considerable attention with the increasing demand for photo-realistic graphics and rapid advances in CPUs/GPUs. However, efficient hardware architecture is challenging due to branches and high computation intensity for ray tracing. In this paper, we present a novel ray tracing hardware architecture called RTA (Ray Tracing Accelerator) to improve hardware efficiency. RTA has two key features: 1) an area-efficient T&I pipeline adopts three optimization strategies; 2) the configuration of two Ray Traversal units has the highest ray tracing efficiency. Combined with these, we implement our system at RTL level with agile chip development. Experimental results demonstrate that RTA's performance achieves $2.83\times$ higher than other academic and commercial architectures in a similar area.",computer graphics;hardware architecture;ren-dering;ray tracing,R. Yan; L. Huang; H. Guo; Y. Lü; L. Yang; N. Xiao; L. Shen; Y. Wang,"School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; Huawei 2012 Labs, Beijing, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China",2022.0,"2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074637,10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00040,20230520-160000,20230521-044735,"['rta:', 'an', 'efficient', 'simd', 'architecture', 'for', 'ray', 'tracing']",False,20230521-205332,,,,
142,ieeex,A Framework for Partitioning Support Vector Machine Models on Edge Architectures,"Current IoT applications generate huge volumes of complex data that requires agile analysis in order to obtain deep insights, often by applying Machine Learning (ML) techniques. Support vector machine (SVM) is one such ML technique that has been used in object detection, image classification, text categorization and Pattern Recognition. However, training even a simple SVM model on big data takes a significant amount of computational time. Due to this, the model is unable to react and adapt in real-time. There is an urgent need to speedup the training process. Since organizations typically use the cloud for this data processing, accelerating the training process has the advantage of bringing down costs. In this paper, we propose a model partitioning approach that partitions the tasks of Stochastic Gradient Descent based Support Vector Machines (SGD-SVM) on various edge devices for concurrent computation, thus reducing the training time significantly. The proposed partitioning mechanism not only brings down the training time but also maintains the approximate accuracy over the centralized cloud approach. With a goal of developing a smart objection detection system, we conduct experiments to evaluate the performance of the proposed method using SGD-SVM on an edge based architecture. The results illustrate that the proposed approach significantly reduces the training time by 47%, while decreasing the accuracy by 2%, and offering an optimal number of partitions.",partitioning;edge computing;SGD-SVM,M. Sahi; M. A. Maruf; A. Azim; N. Auluck,"Department of Computer Science and Engineering, Indian Institute of Technology, Ropar, India; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Ontario, Canada; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Ontario, Canada; Department of Computer Science and Engineering, Indian Institute of Technology, Ropar, India",2021.0,2021 IEEE International Conference on Smart Computing (SMARTCOMP),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556256,10.1109/SMARTCOMP52413.2021.00062,20230520-160000,20230521-044735,"['a', 'framework', 'for', 'partitioning', 'support', 'vector', 'machine', 'models', 'on', 'edge', 'architectures']",False,20230521-205332,,,,
143,ieeex,"The Design of a Compact, Wide Bandwidth, Non-Foster-Based Substrate Integrated Waveguide Filter","A compact, wideband, half-mode substrate integrated waveguide (HM-SIW) filter with internal non-Foster element is demonstrated. First, its passive version is simulated and measured. Next, by integrating an ideal tunable capacitor at the end of the central stub of the HM-SIW resonator, the frequency-agile characteristic of the tunable HM-SIW filter is investigated. Finally, a negative impedance converter (NIC) is developed to replace this tunable capacitor to design a new nonFoster filter. The non-Foster-based HM-SIW filter was realized. Its measured results indicate that it has an operational fractional bandwidth of 10.8% and an electrical size 0.118×0.292 λg2, which is a 3.93 times bandwidth increase and a ~12% electrical size reduction compared to its passive, fixed capacitance version.",Half-mode substrate integrated waveguide filter;negative impedance converter;non-Foster element;wide bandwidth,T. Shi; M. -C. Tang; R. W. Ziolkowski,"College of Communication Engineering, Chongqing University, Chongqing, China; College of Communication Engineering, Chongqing University, Chongqing, China; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia",2018.0,2018 IEEE Asia-Pacific Conference on Antennas and Propagation (APCAP),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538271,10.1109/APCAP.2018.8538271,20230520-160000,20230521-044735,"['the', 'design', 'of', 'a', 'compact,', 'wide', 'bandwidth,', 'non-foster-based', 'substrate', 'integrated', 'waveguide', 'filter']",False,20230521-205332,,,,
144,ieeex,Research and Practice of Container System,"Container technology has been widely used in various real-world situations, like cloud platforms, CI/CD, and DevOps. By enabling a layered image system and OS-level virtualization, container technology can provide agile deployment and isolate execution environment for applications. However, existing container systems fail to support containers efficiently and securely. On the one hand, coarse-grained image management makes the deployment and update of applications time-consuming when the corresponding images need to be delivered in network. On the other hand, shared OS kernel may arise resource contention and security issues. This talk shows our research and practice of container systems. Specifically, I will introduce approaches of image management for fast container deployment, OS kernel isolation for secure and high-performance container execution environment, and container live migration for mitigating resource contention.",,H. Jin,"National Engineering Research Center for Big Data Technology and System Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",2021.0,2021 International Symposium on Theoretical Aspects of Software Engineering (TASE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546738,10.1109/TASE52547.2021.00013,20230520-160000,20230521-044735,"['research', 'and', 'practice', 'of', 'container', 'system']",False,20230521-205332,,,,
145,ieeex,Determining Viability of Deep Learning on Cybersecurity Log Analytics,"The Department of Defense currently maintains a network known as the Defense Research Engineering Network (DREN), which provides various Department of Defense (DoD) sites across the nation connectivity to HPC resource centers. To ensure the security of the DREN system, a defense system known as the Cybersecurity Environment for Detection, Analysis, and Reporting (CEDAR) was created. CEDAR contains a variety of cybersecurity sensors, which constantly monitor and record real time network activity on the DREN. Over time, CEDAR has accumulated massive quantities of valuable cybersecurity data, which necessitates a form of automation in the process of reviewing this data. We propose the application of deep learning techniques to CEDAR data in an attempt to automatically detect potentially malicious activity in a more agile and adaptable manner. These deep learning techniques can be carried out in a high performance computing (HPC) environment, allowing for the rapid utilization of large amounts of data. Our most effective model is able to classify CEDAR alerts as malicious with an accuracy sufficient to greatly reduce human analyst workloads.",Deep Learning;Cybersecurity;High Performance Computing,C. Lorenzen; R. Agrawal; J. King,"Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS; Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS; Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS",2018.0,2018 IEEE International Conference on Big Data (Big Data),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622165,10.1109/BigData.2018.8622165,20230520-160000,20230521-044735,"['determining', 'viability', 'of', 'deep', 'learning', 'on', 'cybersecurity', 'log', 'analytics']",False,20230521-205332,,,,
146,ieeex,Investment in Research & Development or Size Expansion? The Case of Internet of Things Companies,"The Internet of Things (IoT) is at the height of its hype cycle and one can argue that the IoT construct will subsume housing, infrastructures, industrial plants, and other systems in the near future. Big data that is associated with IoT could control systems, affect automation and the process industries require R&D support to shape the concept into a functional asset that resolves the problems of users. Hence, investment in research and development (R&D) as an integral part of any IoT project could be the first step towards project success. The objective of this study is to examine the effects of an investment in R&D and size expansion on the firm value of the top Internet of Things companies. This study examines the top 20 Internet of Things companies in the world spanning the period from 2012 to 2019. By using the panel regression random effect model, this study yields two main conclusions. First, the expansion of size by the companies has a significant impact on promoting the firm value. Second, investment in R&D is negatively associated with the firm value of the IoT companies at the initial stage but the lag effect of investment in R&D is associated positively with the firm value. The significant size expansion impact on the firm value in the IoT firms suggests that the agile size could lead to more efficient use of resources and easy identification of growth opportunities. The second conclusion demonstrates the need for a budget allocation for the investment in R&D for the technological progression and scientific advancement in the IoT companies. Although it takes a few years to observe the significant impacts of investment in R&D on IoT firms, in the long term, it could improve the performance of IoT companies in driving the proliferation of connected devices to enhance human productivity and efficiency.",Research and development;internet of things;size expansion;return on invested capital,H. S. LEE; B. K. SIA; S. C. CHONG; C. W. LOW,"Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia; Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia; Faculty of Accountancy, Management and Economics New Era University College, Kajang, Malaysia; Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia",2020.0,"2020 IEEE 8th Conference on Systems, Process and Control (ICSPC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305758,10.1109/ICSPC50992.2020.9305758,20230520-160000,20230521-044735,"['investment', 'in', 'research', '&', 'development', 'or', 'size', 'expansion?', 'the', 'case', 'of', 'internet', 'of', 'things', 'companies']",False,20230521-205332,,,,
147,ieeex,An Adaptive Multi-objective Memetic Algorithm: a Case of Observation Scheduling for Active-imaging AEOS,"Observation scheduling problem for agile earth observation satellites (OSPFAS) plays a critical role in management of agile earth observation satellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call the novel problem as observation scheduling problem for AEOS with variable image duration (OSWVID). A cumulative image quality and a detailed energy consumption is proposed to build OSWVID as a bi-objective optimization model. A multi-objective memetic algorithm, $\text{ALNS}+\text{NSGA}-\text{II}$, is designed to solve OSWVID. Considering the heuristic knowledges summarized in our previous research, several operators are designed for improving it. Based on existing instances, we analyze the critical parameters optimization, operators evolution, and efficiency of the algorithm according to extensive simulation experiments.",Scheduling;Active imaging;Cumulative image quality;Multi-objective optimization;Memetic algorithm,S. Lu; Z. Chang; Z. Zhou; F. Yao,"Technology Department, Zhongke Tianzhi operation control (Shenzhen) Technology Co., Ltd, Shenzhen, China; School of Business Administration, Hunan University, Changsha, China; School of Business Administration, Hunan University, Changsha, China; School of System Engineering, National University of Defense Technology, Changsha, China",2021.0,2021 7th International Conference on Big Data and Information Analytics (BigDIA),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619648,10.1109/BigDIA53151.2021.9619648,20230520-160000,20230521-044735,"['an', 'adaptive', 'multi-objective', 'memetic', 'algorithm:', 'a', 'case', 'of', 'observation', 'scheduling', 'for', 'active-imaging', 'aeos']",False,20230521-205332,,,,
148,ieeex,Science Autonomy and Planetary Missions: ML and Data Science Applied to the ExoMars Mission,"Future planetary science instruments will be capable of producing far more data than can be transmitted back to Earth, potentially leaving valuable scientific data on a planet's surface. Instruments will need to carefully identify the subset of total data to be prioritized for return, as transmission of the full data volume, even after compression, will not be feasible. The concept of science autonomy, where instruments collect measurement data, perform selected science data analyses onboard, and then autonomously act upon those analyses through self-adjustment and tuning of instrument parameters, can be used to identify and produce an optimal and compact data set for return, maximizing the value of each bit returned to Earth. Furthermore, the selection of the next operation(s) to be run following preliminary measurements, without requiring ground-in-the-loop communication, increases mission efficiency and enables successful yet shorter duration missions to hazardous planetary environments. This capability allows missions to prioritize the most compelling or time-critical data, yielding a more efficient and productive scientific investigation overall. In this paper, we present our implementation using different machine learning (ML) techniques (i.e., clustering, classification) for analyzing science data from the Mars Organic Molecule Analyzer (MOMA) instrument onboard the ExoMars rover Rosalind Franklin. MOMA is a dual-source (laser desorption and gas chromatography) mass spectrometer that will search for past or present life on the Martian surface and subsurface through analysis of soil samples. We use data collected from the MOMA flight-like engineering model to develop mass-spectrometry-focused ML techniques. This effort, in preparation for operating on Mars, is aimed at 1) helping the ExoMars science and operations team quickly analyze new data and support them in their decision-making process regarding subsequent operations and, 2) getting a better understanding of the challenges to enable science autonomy in future missions. We also present two significant challenges we faced in this development that are particular to space missions and will be common to most, if not all, robotic planetary missions. First, the lack of sufficient data volume from these unique and highly optimized instruments to train neural networks, and second the lack of sufficient results from the system to fully trust its output. To tackle the first challenge, we analyze the performance of ML algorithms after adding augmented data. We discuss adopting transfer learning techniques to fine-tune a NN trained on large amounts of commercial instrument data so that it can operate on our limited MOMA dataset. For the ‘trust’ challenge—as it is not always clear what we are looking for in planetary science—we must consider agile ML applications and demonstrate that these will not filter out potentially critical data. We will discuss our concept of a Trust Readiness Level for science autonomy akin to the NASA Technology Readiness Level. This initial project for advanced autonomy illustrates some key first steps of a longer-term objective to enable the spacecraft and instruments themselves to make real-time adjustments during operations as direct human oversight will not be possible for missions going further away in our solar system and beyond.",,V. Da Poian; E. Lyness; R. Danell; B. Theiling; W. Brinckerhoff,"NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD; NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD; Danell Consulting, Winterville, NC; NASA Goddard Space Flight Center, Greenbelt, MD; NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD",2023.0,2023 IEEE Aerospace Conference,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115830,10.1109/AERO55745.2023.10115830,20230520-160000,20230521-044735,"['science', 'autonomy', 'and', 'planetary', 'missions:', 'ml', 'and', 'data', 'science', 'applied', 'to', 'the', 'exomars', 'mission']",False,20230521-205332,,,,
149,ieeex,HCOBASAA: Countermeasure Against Sinkhole Attacks in Software-Defined Wireless Sensor Cognitive Radio Networks,"Software-defined wireless sensor cognitive radio network is one of the emerging technologies which is simple, agile, and flexible. The sensor network comprises of a sink node with high processing power. The sensed data is transferred to the sink node in a hop-by-hop basis by sensor nodes. The network is programmable, automated, agile, and flexible. The sensor nodes are equipped with cognitive radios, which sense available spectrum bands and transmit sensed data on available bands, which improves spectrum utilization. Unfortunately, the Software-defined wireless sensor cognitive radio network is prone to security issues. The sinkhole attack is the most common attack which can also be used to launch other attacks. We propose and evaluate the performance of Hop Count-Based Sinkhole Attack detection Algorithm (HCOBASAA) using probability of detection, probability of false negative, and probability of false positive as the performance metrics. On average HCOBASAA managed to yield 100%, 75%, and 70% probability of detection.",sinkhole attack;software-defined wireless sensor cognitive radio network;change in position,L. Sejaphala; M. Velempini; S. V. Dlamini,"Department of Computer Science, University of Limpopo, Limpopo, South Africa; Department of Computer Science, University of Limpopo, Limpopo, South Africa; Mareka Institute, Council for Scientific & Industrial Research, CSIR, Pretoria, South Africa",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465449,10.1109/ICABCD.2018.8465449,20230520-160000,20230521-044735,"['hcobasaa:', 'countermeasure', 'against', 'sinkhole', 'attacks', 'in', 'software-defined', 'wireless', 'sensor', 'cognitive', 'radio', 'networks']",False,20230521-205332,,,,
150,ieeex,"Prevalence of GitOps, DevOps in Fast CI/CD Cycles","Today, when we are surrounded by technology, software and applications are making our lives more efficient and easy because of the operations and processes controlled by them. Since the technology is constantly changing at a very high pace, improving and modifying with each development, there is a constant need of is faster and more frequent delivery of the software and applications. Today, most software and applications are built in such a way that they could run across multiple operating environments. Software development is performed using agile principles and the most critical part of it is Continuous Delivery and Continuous Integration (CI/CD). CI/CD aims at automating the process of testing, building, and deploying the commitments made by the developer to the code repository. The use of Container-based applications solves a number of complex problems that are found on CI/CD such as portability, elasticity, visibility, and version control. This modular approach enables a simpler, faster, more secure, and more efficient way of development by more focused teams responsible for specific containers. In this context, a new point of interest in the development process, GitOps, which is more agile, reliable, fast, and efficient in its approach towards better performance levels with cloud-native. The main objective of this paper is to understand the Kubernetes GitOps process by day 2 operations, to access the benefits of implementing GitOps in the Kubernetes environment, and to implement Kubernetes GitOps on AWS.",GitOps;DevOps;CI/CD;Continuous Delivery;Continuous Integration;AWS,S. Gupta; M. Bhatia; M. Memoria; P. Manani,"Computer Science & Engineering, Amity School of Engineering & Technology, Amity University, Noida, India; Computer Science & Engineering, Amity School of Engineering & Technology, Amity University, Noida, India; Department of Computer Science & Engineering, Uttaranchal University, Dehradun, Uttarakhand, India; Department of Computer Science & Engineering, Uttaranchal University, Dehradun, Uttarakhand, India",2022.0,"2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850786,10.1109/COM-IT-CON54601.2022.9850786,20230520-160000,20230521-044735,"['prevalence', 'of', 'gitops,', 'devops', 'in', 'fast', 'ci/cd', 'cycles']",False,20230521-205332,,,,
151,ieeex,Towards privacy-aware software design in small and medium enterprises,"The legal definition of privacy regulations, like GDPR in the European Union, significantly impacted on the way in which software, systems and organizations should be designed or maintained to be compliant to rules. While the privacy community stated proper risk assessment and mitigation approaches to be applied, literature seems to suggest that the software engineering community, with special reference to companies, did actually concentrate on the specification phase, with less attention for the test phase of products. In coherence with the privacy-by-design approach, we believe that a bigger methodological effort must be put in the systematic adaptation of software development cycles to privacy regulations, and that this effort might be promoted in the industrial community by focusing on the relation between organizational costs vs technical features, also leveraging the benefits of targeted testing as a mean to lower operational privacy enforcement costs.",Software design;Privacy;GDPR;Risk analysis;Software development life cycle (SDLC);Agile methodology;Nonfunctional requirements;Privacy-by-design,L. Campanile; M. Iacono; M. Mastroianni,"Dipartimento di Matematica e Fisica, Università Degli Studi Della Campania Luigi Vanvitelli, Caserta, Italy; Dipartimento di Matematica e Fisica, Università Degli Studi Della Campania Luigi Vanvitelli, Caserta, Italy; Dipartimento di Informatica, Università Degli Studi di Salerno, Fisciano (SA), Italy",2022.0,"2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927958,10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927958,20230520-160000,20230521-044735,"['towards', 'privacy-aware', 'software', 'design', 'in', 'small', 'and', 'medium', 'enterprises']",False,20230521-205332,,,,
152,ieeex,The Making of Continuous Colormaps,"Continuous colormaps are integral parts of many visualization techniques, such as heat-maps, surface plots, and flow visualization. Despite that the critiques of rainbow colormaps have been around and well-acknowledged for three decades, rainbow colormaps are still widely used today. One reason behind the resilience of rainbow colormaps is the lack of tools for users to create a continuous colormap that encodes semantics specific to the application concerned. In this paper, we present a web-based software system, CCC-Tool (short for Charting Continuous Colormaps) under the URL https://ccctool.com, for creating, editing, and analyzing such application-specific colormaps. We introduce the notion of “colormap specification (CMS)” that maintains the essential semantics required for defining a color mapping scheme. We provide users with a set of advanced utilities for constructing CMS's with various levels of complexity, examining their quality attributes using different plots, and exporting them to external application software. We present two case studies, demonstrating that the CCC-Tool can help domain scientists as well as visualization experts in designing semantically-rich colormaps.",CCC-Tool;charting continuous colormaps;colormap specification;perceptual uniformity;colormap analysis,P. Nardini; M. Chen; F. Samsel; R. Bujack; M. Böttinger; G. Scheuermann,"Institute of Computer Science, University of Leipzig, Leipzig, Germany; Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Center for Agile Technology, University of Texas at Austin, Austin, TX, USA; Data Science at Scale Team, Los Alamos National Laboratory, Los Alamos, NM, USA; German Climate Computing Center (DKRZ), Hamburg, Germany; Institute of Computer Science, University of Leipzig, Leipzig, Germany",2021.0,IEEE Transactions on Visualization and Computer Graphics,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939459,10.1109/TVCG.2019.2961674,20230520-160000,20230521-044735,"['the', 'making', 'of', 'continuous', 'colormaps']",False,20230521-205332,,,,
153,ieeex,How to Efficiently Predict Dengue Incidence in Kuala Lumpur,"Mosquito-borne diseases are rapidly spreading in all regions of the world with an estimation of 2.5 billion people globally are at risk. The recent surge in dengue outbreaks has caused severe affliction to Malaysian society. Hence, the ability to predict a dengue outbreak and mitigate its damage and loss proactively is very critical. In this paper, we study the possibility of applying machine learning (ML) and deep learning (DL) approaches to predict the number of confirmed dengue fever (DF) cases in Kuala Lumpur. We identified several contribution factors correlate to a dengue outbreak. In addition to the two frequently used factors (daily mean temperature and daily rainfall), we also took into account the enhanced vegetation index (EVI), humidity and wind speed as input factors to our prediction engines. We collected and cleansed data on these factors and the daily DF incidents in Kuala Lumpur from 2002 to 2012. We then used these data to train and evaluate our 3 ML/DL models. Among the three models, GA_RNN was the best performer and achieved a MAE of 10.95 for DF incidence prediction.",dengue outbreak prediction;machine learning;deep learning,D. N. Pham; T. Aziz; A. Kohan; S. Nellis; J. b. A. Jamil; J. J. Khoo; D. Lukose; S. AbuBakar; A. Sattar; H. H. Ong,"Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; Data Science, GCS Agile Pty Ltd, Victoria, Australia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; IIIS, Griffith University, Queensland, Australia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia",2018.0,"2018 Fourth International Conference on Advances in Computing, Communication & Automation (ICACCA)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776790,10.1109/ICACCAF.2018.8776790,20230520-160000,20230521-044735,"['how', 'to', 'efficiently', 'predict', 'dengue', 'incidence', 'in', 'kuala', 'lumpur']",False,20230521-205332,,,,
154,ieeex,Let's DO - Automotive Platform for Interoperability,"Developing automotive software applications is one of the most challenging and time-consuming activities in the automotive product development cycle. As of today, classical automotive software applications communicate exclusively using vehicle-specific communication protocols such as Controller Area Network (CAN) and FlexRay communication buses. Automotive applications communicate using transport layer messages that are defined and configured for each vehicle system (car model). This hard-wired design makes out-of-the box integrations between heterogeneous automotive products virtually impossible. It also renders automotive integration projects to digital world (smart devices, cloud, big data, IoT gadgets) hard to develop and maintain. We present in this paper Let's DO, a novel platform for interoperability and data exchange between different noncoherent products, systems and devices (both automotive and nonautomotive). Let's DO platform abstracts automotive communication protocol messages in a unified message standard transported over IP-based Ethernet networks enabling interoperability, quick prototyping, code reuse, and allowing more agile and efficient automotive software development cycles.",Automotive Software;Prototyping;Digital Transformation,R. ElHakim; A. Elqadi; M. Torky; M. Zayed; I. Farag; M. Agamawi,"Innovation Department, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Driving Systems and Functions, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Smart Service Center Valeo, Cairo, Egypt",2021.0,2021 4th International Conference on Information and Computer Technologies (ICICT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476917,10.1109/ICICT52872.2021.00054,20230520-160000,20230521-044735,"[""let's"", 'do', '-', 'automotive', 'platform', 'for', 'interoperability']",False,20230521-205332,,,,
155,ieeex,Deep Learning in Mobile and Wireless Networking: A Survey,"The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.",Deep learning;machine learning;mobile networking;wireless networking;mobile big data;5G systems;network management,C. Zhang; P. Patras; H. Haddadi,"Institute for Computing Systems Architecture, School of Informatics, University of Edinburgh, Edinburgh, U.K.; Institute for Computing Systems Architecture, School of Informatics, University of Edinburgh, Edinburgh, U.K.; Dyson School of Design Engineering, Imperial College London, London, U.K.",2019.0,IEEE Communications Surveys & Tutorials,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666641,10.1109/COMST.2019.2904897,20230520-160000,20230521-044735,"['deep', 'learning', 'in', 'mobile', 'and', 'wireless', 'networking:', 'a', 'survey']",False,20230521-205332,,,,
156,ieeex,Chatbot Driven Web-based Platform for Online Safety and Sexual Exploitation Awareness and Reporting in Namibia,"Technological devices have become a commodity, access to information can be achieved within seconds, connecting people across the globe is easy and possible. Where there is growth, exploitation lurks too. Online sex offenders have taken this opportunity to seduce, groom and make contact with children online. The objective of the research was to design an interactive website with a reporting mechanism that serves as a safe haven where children can find awareness materials and report online incidences of abuse. The use of chatbots on such a website can be beneficial, as queries reported can be attended to. The research used the Software Development Life Cycle (SDLC) focusing on Agile Method to develop the interactive website prototype and chatbot. Qualitative primary data was collected from 42 pre-teens and teens selected from 2 private and 1 public schools in Windhoek, Namibia. The schools were purposefully selected to reflect the extent of the challenge as they offer Computer Studies or Computer Science subject, the children mostly have access to digital technologies daily. Results from the study yielded opinions that teens and pre-teens would make use of the chatbot and reporting portal, and also supported it by sharing innovative ideas for a platform that they would want to utilise. The prototype was evaluated for Usability by five participants using the unmonitored remote usability testing and the feedback was used to further refine the design.",Online Safety;Online Sex Offender;Children;Awareness;Interactive Website,M. N. Rita; F. B. Shava,"Department of Computer Science, Namibia University of Science and Technology, Windhoek, Namibia; Department of Computer Science, Namibia University of Science and Technology, Windhoek, Namibia",2021.0,"2021 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519375,10.1109/icABCD51485.2021.9519375,20230520-160000,20230521-044735,"['chatbot', 'driven', 'web-based', 'platform', 'for', 'online', 'safety', 'and', 'sexual', 'exploitation', 'awareness', 'and', 'reporting', 'in', 'namibia']",False,20230521-205332,,,,
157,ieeex,Securing Distributed SDN Controller Network from Induced DoS Attacks,"With the escalation in security breaches on organizations and institutions that store, maintain and work with critical data, there is a need for a security-enhancing and risk-mitigating solution that works on the fly and is feasible to implement. Software Defined Networks is a networking paradigm that makes the network agile by disaggregating hardware and software. SDN helps enhance security with the help of micro-segmentation. The controller maintains a central view of the network, and its ability to monitor and store network information helps optimize routing. The centralization nature of the controller makes it vulnerable to DoS attacks which can be catastrophic for network functioning. The objective of this paper is to secure the distributed SDN controller architecture against DoS attacks. The proposed architecture is robust, scalable, and uses Big Data techniques to process streams of network traffic in real-time and Machine Learning to detect and mitigate DoS attacks.","Software Defined Networks, DoS Attack, RyuController, Zodiac FX, Kafka, Storm",S. G.; S. N. H.; R. P. Rustagi; O. Sharma,"PES University; PES University; Department of Computer, Science and Engineering, KS Institute of Technology, Bengaluru, India; Department of Computer, Science and Engineering PES University, Bengaluru, India",2019.0,2019 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051954,10.1109/CCEM48484.2019.000-4,20230520-160000,20230521-044735,"['securing', 'distributed', 'sdn', 'controller', 'network', 'from', 'induced', 'dos', 'attacks']",False,20230521-205332,,,,
158,ieeex,Advancing Design and Runtime Management of AI Applications with AI-SPRINT (Position Paper),"The adoption of Artificial intelligence (AI) technologies is steadily increasing. However, to become fully pervasive, AI needs resources at the edge of the network. The cloud can provide the processing power needed for big data, but edge computing is close to where data are produced and therefore crucial to their timely, flexible, and secure management. In this paper, we introduce the AI-SPRINT project, which will provide solutions to seamlessly design, partition, and run AI applications in computing continuum environments. AI-SPRINT will offer novel tools for AI applications development, secure execution, easy deployment, as well as runtime management and optimization: AI-SPRINT design tools will allow trading-off application performance (in terms of end-to-end latency or throughput), energy efficiency, and AI models accuracy while providing security and privacy guarantees. The runtime environment will support live data protection, architecture enhancement, agile delivery, runtime optimization, and continuous adaptation.",Cloud computing;fog computing;edge computing;AI and machine learning;Cloud trust security & privacy,H. Sedghani; D. Ardagna; M. Matteucci; G. A. Fontana; G. Verticale; F. Amarilli; R. Badia; D. Lezzi; I. Blanquer; A. Martin; K. Wawruch,Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Barcelona Super Computing Center; Barcelona Super Computing Center; Universitat Politècnica de València; Dresden University of Technology; 7Bulls,2021.0,"2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529477,10.1109/COMPSAC51774.2021.00216,20230520-160000,20230521-044735,"['advancing', 'design', 'and', 'runtime', 'management', 'of', 'ai', 'applications', 'with', 'ai-sprint', '(position', 'paper)']",False,20230521-205332,,,,
159,ieeex,Infoxication in the Genomic Data Era and Implications in the Development of Information Systems,"We live in an age where data acquisition is no longer a problem and the real challenge is how to determine which information is the right one to take important and sometimes difficult decisions. Infoxication (also known as Infobesity or Information Overload) is a term used to describe the difficulty of adapting to new situations and effectively making decisions when there is too much information to manage. With the advent of the Big Data, infoxication is affecting critical domains such as Health Sciences, where tough decisions for patient's health is being taken every day based on heterogeneous, unconnected and sometimes conflicting information. In order to understand the magnitude of the challenge, based on the information publicly available about the genetic causes of the disease and using data quality assessment techniques, we performed an exhaustive analysis of the DNA variations that have been associated to the risk of suffering migraine headache. The same analysis has been repeated 8 months after, and the results have allowed us to exemplify i) how fragile is the information in this domain, ii) the difficulty of finding repositories of contrasted and reliable data, and iii) the need to have information systems that, far from integrating and storing huge volumes of data, are able to support the decision-making process by providing mechanisms agile and flexible enough to be able to adapt to the changing user needs.",Infoxication;Genomics;Information Systems;SILE method,A. L. Palacio; Ó. P. López,"Universitat Politècnica de València, Valencia, Spain; Universitat Politècnica de València, Valencia, Spain",2019.0,2019 13th International Conference on Research Challenges in Information Science (RCIS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877003,10.1109/RCIS.2019.8877003,20230520-160000,20230521-044735,"['infoxication', 'in', 'the', 'genomic', 'data', 'era', 'and', 'implications', 'in', 'the', 'development', 'of', 'information', 'systems']",False,20230521-205332,,,,
160,ieeex,Smart Services Maturity Level in Germany,"Digitization of business processes is changing the industry. Enterprises using data as efficiently and smart as possible, can often create a clear competitive advantage and be more responsive to their customer needs. Through the smart use of data, new business models can be created. The most well-known changes of digitization are taking place in the B2C market. The B2B market is affected by this change too. Enterprises recognize the ongoing shift to a service-oriented society and therefore should be able to react directly to the customer needs. Service based business models, such as implementing Smart Services, are developed and intergarted in existing enterprise offerings. This paper reports upon a study of the maturity level regarding Smart Services of three selected German enterprises. The aim is to highlight the the impact of the ongoing digital transformation and map the maturity levels with regards to digitization and Smart Services. The case studies offer a first assessment about the current situation of Smart Services, using sub-categories to pinpoint developments, in manufacturing enterprises. The analysis shows that the maturity levels of these enterprises depend on their technology management, financial resources and corporate culture. The three cases have a high maturity level and already implemented Smart Services in their business model strategy. Nevertheless, there is still potential for improvement, especially regarding `Simultaneous Engineering' and `Automation Level'. It can be stated that within these enterprises financial resources, critical awareness as well as know-how of digitization and Smart Services are available. The cases were organizationally rather set in rigid structures. In order to reach an even higher degree of maturity and thus to remain competitive in the future, the enterprises should fundamentally rethink their corporate culture. These case studies may be considered as a pilot study into this topic, with refinements and improvements to further studies possible.",digitization;agile culture;internet of things;intelligent services;industry 4.0,F. Kaltenbach; P. Marber; C. Gosemann; T. Bölts; A. Kühn,"Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany",2018.0,"2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8436329,10.1109/ICE.2018.8436329,20230520-160000,20230521-044735,"['smart', 'services', 'maturity', 'level', 'in', 'germany']",False,20230521-205332,,,,
161,ieeex,A Fast Self-Jamming Cancellation Architecture and Algorithm for Passive RFID Sensor System,"In this letter, we propose a fast self-jamming cancellation (SJC) architecture for Ultra High Frequency (UHF) radio-frequency identification (RFID) interrogators. The core SJC architecture includes a Field Programmable Gate Array (FPGA) as the RFID baseband processor, a radio frequency (RF) agile transceiver which has two transmitting ports as the RF front-end, and a combiner. By detecting the amplitude and phase of the interference carrier, the SJC algorithm transmits a suppression carrier through the second transmitting port of the agile RF transceiver. The suppression carrier could effectively suppress the self-jamming carrier without designing complex circuits. Our test results showed the isolation between the transmitting and receiving port achieves 100dB at UHF band, and the cancellation processes can be finished within 0.4ms.",UHF RFID interrogator;interference cancellation;self-jamming;carrier leakage canceler;passive sensor system,C. Shen; H. Xiong; X. Wang; F. Mei; T. T. Ye,"School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science, Memorial University of Newfoundland, St. John’s, NL, Canada; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China",2021.0,IEEE Communications Letters,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380725,10.1109/LCOMM.2021.3066177,20230520-160000,20230521-044735,"['a', 'fast', 'self-jamming', 'cancellation', 'architecture', 'and', 'algorithm', 'for', 'passive', 'rfid', 'sensor', 'system']",False,20230521-205332,,,,
162,ieeex,Software Engineering for Machine Learning: A Case Study,"Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",artifical intelligence;machine learning;software engineering;process;data,S. Amershi; A. Begel; C. Bird; R. DeLine; H. Gall; E. Kamar; N. Nagappan; B. Nushi; T. Zimmermann,"Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; University of Zurich, Zurich, Switzerland; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",2019.0,2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804457,10.1109/ICSE-SEIP.2019.00042,20230520-160000,20230521-044735,"['software', 'engineering', 'for', 'machine', 'learning:', 'a', 'case', 'study']",True,20230521-205332,,,,
163,ieeex,GELAB – The Cutting Edge of Grammatical Evolution,"The advent of cloud-based super-computing platforms has given rise to a Data Science (DS) boom. Many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration. Machine Learning (ML) tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike. Coupled with modern-day computing power, ML tools can be looked at as hammers that can deal with even the most stubborn nails. ML tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly. In order to keep pace with these requirements, a new enterprise, referred to as MLOps has blossomed in recent years. MLOps combines the process of ML and DS with an agile software engineering technique to develop and deliver solutions in a fast and iterative way. One of the key challenges to this is that ML and DS tools should be efficient and have better usability characteristics than were traditionally offered. In this paper, we present a novel software for Grammatical Evolution (GE) that meets both of these expectations. Our tool, GELAB, is a toolbox for GE in Matlab which has numerous features that distinguish it from existing contemporary GE software. Firstly, it is user-friendly and its development was aimed for use by non-specialists. Secondly, it is capable of hybrid optimization, in which standard numerical optimization techniques can be added to GE. We have shown experimentally that when hybridized with meta-heuristics GELAB has an overall better performance as compared with standard GE.",Grammatical evolution;diversity;hybrid optimization,K. K. Gupt; M. A. Raja; A. Murphy; A. Youssef; C. Ryan,"Department of Electrical and Electronic Engineering, Technological University of the Shannon: Midlands Midwest, Limerick, Ireland; Regulated Software Research Center (RSRC), Dundalk Institute of Technology (DkIT), Dundalk, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland",2022.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751757,10.1109/ACCESS.2022.3166115,20230520-160000,20230521-044735,"['gelab', '–', 'the', 'cutting', 'edge', 'of', 'grammatical', 'evolution']",False,20230521-205332,,,,
164,ieeex,Artificial Intelligence Aided Next-Generation Networks Relying on UAVs,"In this article, we propose artificial intelligence (AI) enabled unmanned aerial vehicle (UAV) aided wireless networks (UAWN) for overcoming the challenges imposed by the random fluctuation of wireless channels, blocking and user mobility effects. In UAWN, multiple UAVs are employed as aerial base stations, which are capable of promptly adapting to the randomly fluctuating environment by collecting information about the users' position and tele-traffic demands, learning from the environment and acting upon the satisfaction level feedback received from the users. Moreover, AI enables the interaction among a swarm of UAVs for cooperative optimization of the system. As a benefit of the AI framework, several challenges of conventional UAWN may be circumvented, leading to enhanced network performance, improved reliability and agile adaptivity. As a further benefit, dynamic trajectory design and resource allocation are demonstrated. Finally, potential research challenges and opportunities are discussed.",,X. Liu; M. Chen; Y. Liu; Y. Chen; S. Cui; L. Hanzo,"Queen Mary University of London; Princeton University; Queen Mary University of London; Queen Mary University of London; The Chinese University of Hong Kong, Shenzhen; University of Southampton",2021.0,IEEE Wireless Communications,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9267780,10.1109/MWC.001.2000174,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'aided', 'next-generation', 'networks', 'relying', 'on', 'uavs']",False,20230521-205332,,,,
165,ieeex,Key Technologies of Large Power Grid Security and Stability Intelligent Sand Table Deduction,"Existing power system simulation systems focus on calculations and lack effective analysis and display capabilities, which limits the application level of simulation calculation results. Aiming at the problem of power grid simulation data analysis and display combined with simulation calculation and artificial intelligence, this paper proposes the new connotation of large power grid safety and stability sand table deduction technology, and the corresponding data analysis model and agile analysis model. The work in this paper provides the necessary ideas and technical foundation for the establishment of a new grid simulation analysis environment combining human, artificial intelligence and simulation calculation.",Sand Table Deduction;Grid Simulation Analysis;Artificial Intelligence;Visual Analysis,W. Li; Y. Huang; X. Chen; W. Li; S. Zhang,"State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Grid Zhejiang Electric Power CO. LTD, Hangzhou, China",2020.0,2020 IEEE Sustainable Power and Energy Conference (iSPEC),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351210,10.1109/iSPEC50848.2020.9351210,20230520-160000,20230521-044735,"['key', 'technologies', 'of', 'large', 'power', 'grid', 'security', 'and', 'stability', 'intelligent', 'sand', 'table', 'deduction']",False,20230521-205332,,,,
166,ieeex,Learning Service Semantics for Self-Organization in Distributed Environments: Concepts and Research Directions,"A key challenge in performing analytics in distributed environments is to automatically compose services to dynamically match operational tasks to information requirements, accounting for impact, in a many-to-many temporally and spatially complicated and complex situations. In dynamic and agile environments, such as coalition environments, the state of the network and resources cannot be completely known in advance nor controlled due to the evolving nature of the network and constraints that may preclude partners from accessing complete state information about different parts of the system. In addition, there may be requests made to the system that have not been made before, requiring services to be created on the fly. Motivated by these observations, in this paper, we present a critical analysis of gaps in the state-of-the-art and our vision to address those through novel theoretical contributions. We envision that such formalized and theorized fundamentals will enable service elements to automatically configure themselves to perform analytic tasks based on user specified goals by taking account of context-be it system or user context.",,G. Bent; G. de Mel; R. Ganti; T. La Porta; G. Pearson; T. Pham; S. Stein; L. Tassiulas; I. Taylor,"ETS, IBM Research, Hursley, UK; IBM Research, Hartree Centre, Warrington, UK; IBM TJ Watson Research Center, NY, USA; The Pennsylvania State University, University Park, PA, USA; Defence Science and Technology Laboratory, UK; US Army Research Laboratory, Adelphi, MD, USA; University of Southampton, Southampton, UK; Yale University, New Haven, CT, USA; Cardiff University, Cardiff, UK",2018.0,MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8599809,10.1109/MILCOM.2018.8599809,20230520-160000,20230521-044735,"['learning', 'service', 'semantics', 'for', 'self-organization', 'in', 'distributed', 'environments:', 'concepts', 'and', 'research', 'directions']",False,20230521-205332,,,,
167,ieeex,Dynamic allocation of traffic light plans as a traffic reduction strategy,"The city of Medellin, like other cities in the world, is facing major mobility issues caused by the accelerated growth of the vehicle fleet in the last decade. The efficient operation of the traffic light network plays a fundamental role in the search for solutions to achieve an agile, comfortable, safe and sustainable mobility. For this reason, the Municipal Administration has made important investments in its updating and technological modernization that allows actions for a better performance. Currently the traffic lights of the city are operated by classic programming models, mostly at fixed times in different time zones and others in modes actuated and semi-actuated as scheduled, without responding to changing traffic conditions, making it necessary to search for autonomous traffic regulation systems that adapt their behavior according to the conditions. While adaptive systems based on a wide sensorisation for obtaining information online are an alternative, their current costs of implementation, maintenance and operation, has led to evaluate the new global trends in terms of information capture, storage, processing and use in the optimization of the operation of the traffic signal network. This is how the city of Medellin has been consolidating a Big Data storage system and has developed a technological platform capable of receiving it and executing actions on the traffic light system when it identifies that there are events that generate traffic variations different from normal or daily conditions, which has allowed to improve mobility conditions according to the results obtained, which will be detailed later. This first part of this document is an introduction of the different modes of operation of a traffic light network commonly used; the second part contains a brief description of the city's traffic light network; in the third part, the collaborative data systems are studied; the fourth part develops the solution scheme adopted by Medellin based on the collaborative data system; subsequently the results of the implementation of the system in a specific crossroads of the city are presented; and it ends with some brief conclusions in this regard.",Traffic light;Jams Optimization;Collaborative;WAZE;Big Data,M. L. Suarez; L. E. Alvarez; P. A. Camacho; L. C. Marin; B. Vasquez; G. Gutierrez; R. A. Aranzazu; M. Carranza; F. G. Montoya; A. Valdes; C. Gonzalez; M. Jaramillo; S. Henao,"Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223",2018.0,MOVICI-MOYCOT 2018: Joint Conference for Urban Mobility in the Smart City,IET,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643139,10.1049/ic.2018.0012,20230520-160000,20230521-044735,"['dynamic', 'allocation', 'of', 'traffic', 'light', 'plans', 'as', 'a', 'traffic', 'reduction', 'strategy']",False,20230521-205332,,,,
168,ieeex,lunule: An Agile and Judicious Metadata Load Balancer for CephFS,"For a decade, the Ceph distributed file system (CephFS) has been widely used to serve the ever-growing big data in many key fields ranging from Internet services to AI computing. To scale out the massive metadata access, CephFS adopts a dynamic subtree partitioning method, splitting the hierarchical namespace and distributing subtrees across multiple metadata servers. However, this method suffers from a severe imbalance problem that may result in poor performance due to its inaccurate imbalance prediction, ignorance of workload characteristics, and unnecessary/invalid migration ac-tivities. To eliminate these inefficiencies, we propose Lunule, a novel CephFS metadata load balancer, which employs an imbalance fac-tor model for accurately determining when to trigger re-balance and tolerate benign imbalanced situations. Lunule further adopts a workload-aware migration planner to appropriately select sub-tree migration candidates. Compared to baselines, Lunule achieves better load balance, increases the metadata throughput by up to 315.8%, and shortens the tail job completion time by up to 64.6% for five real-world workloads and their mixture, respectively. Be-sides, Lunule is capable of handling the metadata cluster expansion and the client workload growth, and scales linearly on a cluster of 16 MDSs.",,Y. Wang; C. Li; X. Shao; Y. Chen; F. Yan; Y. Xu,"University of Science and Technology of China, Hefei, Anhui, China; Anhui Province Key Laboratory of High Performance Computing, USTC, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Nevada, Reno, Reno, Nevada, USA; Anhui Province Key Laboratory of High Performance Computing, USTC, Hefei, Anhui, China",2021.0,"SC21: International Conference for High Performance Computing, Networking, Storage and Analysis",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910055,10.1145/3458817.3476196,20230520-160000,20230521-044735,"['lunule:', 'an', 'agile', 'and', 'judicious', 'metadata', 'load', 'balancer', 'for', 'cephfs']",False,20230521-205332,,,,
169,ieeex,Knowledge-Based Digital Twin for Predicting Interactions in Human-Robot Collaboration,"Semantic representation of motions in a human-robot collaborative environment is essential for agile design and development of digital twins (DT) towards ensuring efficient collaboration between humans and robots in hybrid work systems, e.g., in assembly operations. Dividing activities into actions helps to further conceptualize motion models for predicting what a human intends to do in a hybrid work system. However, it is not straightforward to identify human intentions in collaborative operations for robots to understand and collaborate. This paper presents a concept for semantic representation of human actions and intention prediction using a flexible task ontology interface in the semantic data hub stored in a domain knowledge base. This semantic data hub enables the construction of a DT with corresponding reasoning and simulation algorithms. Furthermore, a knowledge-based DT concept is used to analyze and verify the presented use-case of Human-Robot Collaboration in assembly operations. The preliminary evaluation showed a promising reduction of time for assembly tasks, which identifies the potential to i) improve efficiency reflected by reducing costs and errors and ultimately ii) assist human workers in improving decision making. Thus the contribution of the current work involves a marriage of machine learning, robotics, and ontology engineering into DT to improve human-robot interaction and productivity in a collaborative production environment.",human-robot interaction;digital twin;human action models;ontology;machine learning,T. B. Tuli; L. Kohl; S. A. Chala; M. Manns; F. Ansari,"Chair for Manufacturing Automation and Assembly (FAMS), PROTECH-Institute for Production Technology, University of Siegen, Siegen, Germany; Research Group of Smart and Knowledge-Based Maintenance, Institute of Management Science TU Wien, Vienna, Austria; Data Science and AI, Fraunhofer FIT, Sankt Augustin, Germany; Chair for Manufacturing Automation and Assembly (FAMS), PROTECH-Institute for Production Technology, University of Siegen, Siegen, Germany; Research Group of Smart and Knowledge-Based Maintenance, Institute of Management Science TU Wien, Vienna, Austria",2021.0,2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA ),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613342,10.1109/ETFA45728.2021.9613342,20230520-160000,20230521-044735,"['knowledge-based', 'digital', 'twin', 'for', 'predicting', 'interactions', 'in', 'human-robot', 'collaboration']",False,20230521-205332,,,,
170,ieeex,Automated Risk Management Based Software Security Vulnerabilities Management,An automated risk assessment approach is explored in this work. The focus is to optimize the conventional threat modeling approach to explore software system vulnerabilities. Data produced in the software development processes are better leveraged using Machine Learning approaches. A large amount of industry knowledge around security vulnerabilities can be leveraged to enhance current threat modeling approaches. Work done here is in the ecosystem of software development processes that use Agile methodology. Insurance business domain data are explored as a target for this study. The focus is to enhance the traditional threat modeling approach with a better quantitative approach and reduce the biases introduced by the people who are part of software development processes. This effort will help bridge multiple data sources prevalent across the software development ecosystem. Bringing these various data sources together will assist in understanding patterns associated with security aspects of the software systems. This perspective further helps to understand and devise better controls. Approaches explored so far have considered individual areas of software development and their influence on improving security. There is a need to build an integrated approach for a total security solution for the software systems. A wide variety of machine learning approaches and ensemble approaches will be explored. The insurance business domain is considered for the research here. CWE (Common Weaknesses Enumeration) mapping from industry knowledge are leveraged to validate the security needs from the industry perspective. This combination of industry and company data will help get a holistic picture of the software system’s security. Combining the industry and company data helps lay down the path for an integrated security management system in software development. The risk management framework with the quantitative threat modeling process is the work’s uniqueness. This work contributes toward making the software systems secure and robust with time.,Quantitative threat modeling;software security;machine learning;quantitative risk assessment;integrated security management system,R. R. Althar; D. Samanta; M. Kaur; D. Singh; H. -N. Lee,"Data Science Department, CHRIST University, Bangalore, Karnataka, India; Department of Computer Science, CHRIST University, Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India",2022.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802103,10.1109/ACCESS.2022.3185069,20230520-160000,20230521-044735,"['automated', 'risk', 'management', 'based', 'software', 'security', 'vulnerabilities', 'management']",False,20230521-205332,,,,
171,ieeex,Neural Fictitious Self-Play for Radar Antijamming Dynamic Game With Imperfect Information,"One emerging issue in modern electronic warfare is the competition between the radar and jammer, which in principle can be viewed as a noncooperative game with two players. In practice, the interaction between the radar and jammer involves multiple rounds as well as partial observation. This makes the competition become a dynamic game with imperfect information. Antijamming strategy design for such kind of a game is still unclear. In this work, the competition between a frequency agile radar and a transmit/receive time-sharing jammer is considered. We utilize an extensive-form game (EFG) with imperfect information to model the multiple rounds interaction between the radar and jammer. For the established EFG, finding Nash equilibrium (NE) strategies is a computationally-intractable task since the number of information states grows exponentially with respect to game stages. Instead, a sampled-based learning method called neural fictitious self play algorithm is used to find approximate NE strategies (ANES). Simulation results show that ANES can be obtained and outperform the common elementary and advanced strategies from the perspective of detection performance.",Antijamming strategies design;approximate Nash equilibrium (NE);dynamic games;electronic warfare;extensive-form game (EFG);imperfect information,K. Li; B. Jiu; W. Pu; H. Liu; X. Peng,"National Laboratory of Radar Signal Processing, Xidian University, Xian, China; National Laboratory of Radar Signal Processing, Xidian University, Xian, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; National Laboratory of Radar Signal Processing, Xidian University, Xian, China; Research Academy of Rocket, Beijing, China",2022.0,IEEE Transactions on Aerospace and Electronic Systems,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775208,10.1109/TAES.2022.3175186,20230520-160000,20230521-044735,"['neural', 'fictitious', 'self-play', 'for', 'radar', 'antijamming', 'dynamic', 'game', 'with', 'imperfect', 'information']",False,20230521-205332,,,,
172,ieeex,Data vault modelling as alternative to dimensional modelling to embrace complexity in data driven decision systems: a critical systems perspective,We live in a complex world where uncertainty is the only certainty. Today's compelling business problem is replaced tomorrow with a problem which was not even imagined yesterday. Data driven decision systems are used by managers in support of their strategic decisions and should be agile and flexibility to survive in our ever change world of complex decisions. The argument presented in this conceptual paper is that data vault modeling is inherently better equipped than dimensional modelling to handle the turbulations of our complex world. The paper investigates the underlying assumptions of dimensional modelling and data vault modelling in terms of requirements collection and the resulting data modelling techniques. It uses critical systems thinking as guiding philosophy to reflect on the benefits of understanding and modelling a variety of perspectives in a problem situation. Critical systems thinking also promotes equal opportunity and accountability. It is argued that both these aspirations can better be achieved by using dimensional modeling as alternative to dimensional modelling. We hope to promote the development of sustainable data driven decision systems which can stand the test of our turbulent times.,data driven decision systems;data vault modelling;dimensional modelling;critical systems thinking,R. Goede,"Unit for Data Science and Computing, North-West University, Potchefstroom, South Africa",2022.0,2022 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10089249,10.1109/CSDE56538.2022.10089249,20230520-160000,20230521-044735,"['data', 'vault', 'modelling', 'as', 'alternative', 'to', 'dimensional', 'modelling', 'to', 'embrace', 'complexity', 'in', 'data', 'driven', 'decision', 'systems:', 'a', 'critical', 'systems', 'perspective']",False,20230521-205332,,,,
173,ieeex,AD4ML: Axiomatic Design to Specify Machine Learning Solutions for Manufacturing,"Machine learning is increasingly adopted in manufacturing use cases, e.g., for fault detection in a production line. Each new use case requires developing its own machine learning (ML) solution. A ML solution integrates different software components to read, process, and analyze all use case data, as well as to finally generate the output that domain experts need for their decision-making. The process to design a system specification for a ML solution is not straight-forward. It entails two types of complexity: (1) The technical complexity of selecting combinations of ML algorithms and software components that suit a use case; (2) the organizational complexity of integrating different requirements from a multidisciplinary team of, e.g., domain experts, data scientists, and IT specialists. In this paper, we propose several adaptations to Axiomatic Design in order to design ML solution specifications that handle these complexities. We call this Axiomatic Design for Machine Learning (AD4ML). We apply AD4ML to specify a ML solution for a fault detection use case and discuss to what extent our approach conquers the above-mentioned complexities. We also discuss how AD4ML facilitates the agile design of ML solutions.",manufacturing;machine-learning;design,A. G. V. Zacarias; R. Ghabri; P. Reimann,"University of Stuttgart, GSaME, Stuttgart, Germany; University of Stuttgart, IPVS, Stuttgart, Germany; University of Stuttgart, GSaME, Stuttgart, Germany",2020.0,2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191629,10.1109/IRI49571.2020.00029,20230520-160000,20230521-044735,"['ad4ml:', 'axiomatic', 'design', 'to', 'specify', 'machine', 'learning', 'solutions', 'for', 'manufacturing']",False,20230521-205332,,,,
174,ieeex,Digital Transformation Impact Analysis towards Transition in the Role of Information Technology for Organization in New Digital Bank,"The role of Information Technology in the banking industry has been playing an important role in providing better services to customers and open new opportunities. Bank XYZ is a conventional bank that is transforming into a digital bank to improve bank XYZ's position in financial services sector, specifically in the banking industry. In the process of transforming into digital banking, Information Technology leadership in the organization is important. However, publications regarding the impact of digital transformation in Information Technology role and leadership, especially in the banking industry are scarce, so this research is importance. The benefit of this research is to be organization consideration for designing corporate information strategy & management and can be a reference and contribution of ideas that can enrich knowledge and further research about corporate information strategy & management. This study aims to identify digital transformation impact in IT role and leadership specifically in new digital bank. Qualitative approach with data collection from semi-structured interviews and document was used to identify the impact of digital transformation towards transition in the role of information technology and do benchmarking Bank XYZ's case with a few new digital banks in the world. Based on the comparison and benchmarking, learned lesson as an input for Bank XYZ to improve the digital transformation process into a digital bank. Integrated big data, agile team, automation process, cloud computing, machine learning, and artificial intelligence was the common capability of a digital bank.",Digital Bank;Digital Transformation;Leadership;Role of Information Technology;Strategic,Y. P. Sagala; M. A. Juniawan; V. A. Effendy; R. Putrianasari; W. Nuraini; V. A. Rahmatika; M. R. Shihab; B. Ranti,"Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia",2022.0,2022 Seventh International Conference on Informatics and Computing (ICIC),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007003,10.1109/ICIC56845.2022.10007003,20230520-160000,20230521-044735,"['digital', 'transformation', 'impact', 'analysis', 'towards', 'transition', 'in', 'the', 'role', 'of', 'information', 'technology', 'for', 'organization', 'in', 'new', 'digital', 'bank']",False,20230521-205332,,,,
175,ieeex,Blockchain as a Service for Software Defined Networks: A Denial of Service Attack Perspective,"Software defined networking (SDN) is one of the most popular network technologies which provides an adaptive, agile and flexible network management and visibility. Although SDN architecture provides manifold benefits but on the same time its dependence on a logically centralized controller lead to the single point of failure. An attacker can easily capture the any forwarding device and restrict the availability of the controller using different prevalent attacks. Distributed denial of service (DDoS) is one of the most popular attack of this category which is quiet prevalent in SDN. Here, the aim of the attackers is to inject false script in the open flow tables through malicious switches which multiply exponentially. Therefore, in this paper, a blockchain as a service framework has been presented wherein BlockSDSec model is designed to provide security as a separate service for the SDN architecture. This work provides a mechanism to prevent the threats of DDoS at the switch level by embedding an security using blockchain onto the interaction channels of data and control planes. The load balancing at the controller level is achieved using a virtual controller. The proposed scheme is simulated using MiniNet Emulator to analyze the delay originating from usage of blockchain.","Blockchain, Distributed Denial of Service, Malicious Switch, Software Defined Networks, MiniNet",A. Bose; G. S. Aujla; M. Singh; N. Kumar; H. Cao,"Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Thapar Institute of Engineering and Technology, Patiala, India; Key Lab of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Nanjing, China",2019.0,"2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890267,10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00166,20230520-160000,20230521-044735,"['blockchain', 'as', 'a', 'service', 'for', 'software', 'defined', 'networks:', 'a', 'denial', 'of', 'service', 'attack', 'perspective']",False,20230521-205332,,,,
176,ieeex,Predicting Visitor Distribution for Large Events in Smart Cities,"The prediction of the distribution of visitors in large events is a valuable piece of information in the context of smart cities. The organizers of large events leverage it for safety and coordination purposes and the Fog computing infrastructures for cost effective, agile and reliable allocation of the mobile apps and festival services workload along the continuum from edge devices to cloud. In this research we examine two sets of supervised Machine Learning techniques in order to predict the visitors' distribution in the next timesteps and evaluate them using real data from a large music event that took place in 2017 and 2018. To enrich the feature space of the predictive models we use and evaluate open data such as the weather and the popularity of artists. A further added value of the examined Machine Learning techniques, in comparison with the current state of the art in mobility prediction, is that they look into the phenomenon of visitors coming and going from the area of interest.",Smart Cities;Large Events;Fog Computing;Open Data;Points of Interest;Classification;Regression,J. Violos; S. Pelekis; A. Berdelis; S. Tsanakas; K. Tserpes; T. Varvarigou,"Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Informatics and Telematics, Harokopio University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece",2019.0,2019 IEEE International Conference on Big Data and Smart Computing (BigComp),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8679181,10.1109/BIGCOMP.2019.8679181,20230520-160000,20230521-044735,"['predicting', 'visitor', 'distribution', 'for', 'large', 'events', 'in', 'smart', 'cities']",False,20230521-205332,,,,
177,ieeex,Neighbor Library-Aware Graph Neural Network for Third Party Library Recommendation,"Modern software development has moved toward agile growth and rapid delivery, where developers must meet the changing needs of users instantaneously. In such a situation, plug-and-play Third-Party Libraries (TPLs) introduce a considerable amount of convenience to developers. However, selecting the exact candidate that meets the project requirements from the countless TPLs is challenging for developers. Previous works have considered setting up a personalized recommender system to suggest TPLs for developers. Unfortunately, these approaches rarely consider the complex relationships between applications and TPLs, and are unsatisfactory in accuracy, training speed, and convergence speed. In this paper, we propose a new end-to-end recommendation model called Neighbor Library-Aware Graph Neural Network (NLA-GNN). Unlike previous works, we only initialize one type of node embedding, and construct and update all types of node representations using Graph Neural Networks (GNN). We use a simplified graph convolution operation to alternate the information propagation process to increase the training efficiency and eliminate the heterogeneity of the app-library bipartite graph, thus efficiently modeling the complex high-order relationships between the app and the library. Extensive experiments on large-scale real-world datasets demonstrate that NLA-GNN achieves consistent and remarkable improvements over state-of-the-art baselines for TPL recommendation tasks.",Third-Party Library (TPL);TPL recommendation;Graph Neural Network (GNN);bipartite graph,Y. Jin; Y. Zhang; Y. Zhang,"School of Artificial Intelligence and Big Data, Hefei University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China",2023.0,Tsinghua Science and Technology,TUP,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011160,10.26599/TST.2022.9010042,20230520-160000,20230521-044735,"['neighbor', 'library-aware', 'graph', 'neural', 'network', 'for', 'third', 'party', 'library', 'recommendation']",False,20230521-205332,,,,
178,ieeex,Human as a Service: Towards Resilient Parking Search System With Sensorless Sensing,"The high demand for ubiquitous availability of reliable parking spaces in cities faces challenges on timely information sharing and low-cost infrastructure deployment. In this paper, we propose a mobile crowdsensing system, namely ParkHop, to aggregate on-street and roadside parking space information through sensorless sensing, and disseminate this information to urban drivers in a resilient manner. ParkHop targets special social groups that have stable work routines to serve as crowd workers. We propose a crowdsensing algorithm employing a joint estimator to process crowdsensed data, and evaluate the reliability of crowd workers based on the veracity of their answers to a series of control questions. In addition, the specific worker selection method to speed up the crowdsensing process and incentive scheme to achieve fair reward distribution have been carefully designed in ParkHop. Our system disseminates the availability of parking spaces and their up-to-date price information to drivers with on-demand needs via a publish-subscribe messaging pattern. The efficacy of ParkHop for aggregation and dissemination of parking space information has been evaluated in both real-world tests and simulations. Our results show the system is robust and agile enough to cope with different crowdsensing scenarios.",Sensorless sensing;mobile crowdsensing;resilient system;user reliability;smart parking,D. Wu; Z. Zeng; F. Shi; W. Yu; T. Wu; Q. Liu,"Key Laboratory for Embedded and Network Computing of Hunan Province, Hunan University, Changsha, China; Key Laboratory for Embedded and Network Computing of Hunan Province, Hunan University, Changsha, China; Department of Computing, Imperial College London, London, U.K.; Department of Computer Science, University of Warwick, Coventry, U.K.; Hunan Key Laboratory of Geospatial Big Data Mining and Application, Hunan Normal University, Changsha, China; Department of Computer Science, The University of Texas at Austin, Austin, TX, USA",2022.0,IEEE Transactions on Intelligent Transportation Systems,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658308,10.1109/TITS.2021.3133713,20230520-160000,20230521-044735,"['human', 'as', 'a', 'service:', 'towards', 'resilient', 'parking', 'search', 'system', 'with', 'sensorless', 'sensing']",False,20230521-205332,,,,
179,ieeex,An End-to-End Recommendation System for Urban Traffic Controls and Management Under a Parallel Learning Framework,"A paradigm shift towards agile and adaptive traffic signal control empowered with the massive growth of Big Data and Internet of Things (IoT) technologies is emerging rapidly for Intelligent Transportation Systems. Generally, an adaptive signal control system fine-tunes signal timing parameters based on pre-defined control hyperparameters using instantaneous traffic detection information. Once traffic pattern changes, those hyperparameters (e.g., maximum and minimum green times) need to be adjusted according to the evolution of traffic dynamics over a very short-term period. Such adjustment processes are usually conducted by professional and experienced traffic engineers. Here we present a human-in-the-loop parallel learning framework and its utilization in an end-to-end recommendation system that mimics and enhances professional signal control engineers' behaviors. The system has been deployed into a real-world application for an extended period in Hangzhou, China, where signal control hyperparameters are recommended based on large-scale multidimensional traffic datasets. Experimental evaluations demonstrate significant improvements in traffic efficiency through the use of our signal recommendation system.",Intelligent traffic control;traffic signal control;parallel learning;recommendation systems;deep neural networks,J. Jin; H. Guo; J. Xu; X. Wang; F. -Y. Wang,"Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",2021.0,IEEE Transactions on Intelligent Transportation Systems,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005386,10.1109/TITS.2020.2973736,20230520-160000,20230521-044735,"['an', 'end-to-end', 'recommendation', 'system', 'for', 'urban', 'traffic', 'controls', 'and', 'management', 'under', 'a', 'parallel', 'learning', 'framework']",False,20230521-205332,,,,
180,ieeex,Contexts Enhance Accuracy: On Modeling Context Aware Deep Factorization Machine for Web API QoS Prediction,"Service-oriented computing (SOC) promises a world of cooperating services loosely connected, constructing agile Web applications in heterogeneous environments conveniently. Web application interface (API) as an emerging technique attracts more and more enterprises and organizations to publish their deep computing functionalities and big data on the Internet, Web API has become the backbone to promote the development of SOC, thus forming the prosperous Web API economy. However, the number of available Web APIs on the Internet is massive and growing constantly, which causes the Web API overload problem. Quality of service (QoS) as an indicator is able to well differentiate the quality of Web APIs and has been widely applied for high quality Web API selection. Since testing QoS for massive Web APIs is resource-consuming, and the QoS performance depends on contextual information such as network and location, hence accurate QoS prediction has become very crucial for personalized Web API recommendation and high quality Web application construction. To address the above issue, this paper presents a context aware deep factorization machine model (CADFM for short) for accurate Web API QoS prediction. Specifically, we first carry out detailed data analysis using real-world QoS dataset and discover a positive relationship between QoS and contextual information, which motivates us to incorporate beneficial contexts for enhancing QoS prediction accuracy. Then, we treat QoS prediction as a regression problem and propose a context aware CADFM framework that integrates the contextual information via embedding technique. Particularly, we adopt MF and MLP for high-order and nonlinear interaction modeling, so as to learn the complex interaction between users and Web APIs accurately. Finally, the experimental results on real-world QoS dataset demonstrate that CADFM outperforms the classic and the state-of-the-art baselines, thereby generating the most accurate QoS predictions and increasing the revenue of Web APIs recommendation.",Service-oriented computing;Web API;quality of service prediction;context aware;deep factorization machine,L. Shen; M. Pan; L. Liu; D. You; F. Li; Z. Chen,"Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; National Science Library, Chinese Academy of Sciences, Beijing, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; College of Computer and Communication Engineering, Northeastern University, Shenyang, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China",2020.0,IEEE Access,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189762,10.1109/ACCESS.2020.3022891,20230520-160000,20230521-044735,"['contexts', 'enhance', 'accuracy:', 'on', 'modeling', 'context', 'aware', 'deep', 'factorization', 'machine', 'for', 'web', 'api', 'qos', 'prediction']",False,20230521-205332,,,,
181,ieeex,Artificial Intelligence For Media Operations Why AI algorithms will become a must for every network management system,"Artificial intelligence already has a big impact on a lot of different segments in the media industry. With the broadcast industry moving to all-IP and data center deployments those environments are more agile and complex than ever before. With fast-evolving technologies and cycles, ever more mission critical systems and constantly changing operational practices and devops style operations, traditional network management systems (NMS) and their paradigms don't fit the bill anymore. This paper explores why machine-learning algorithms must find their way into network monitoring and management solutions to orchestrate a modern media data center dynamically and in a proactive way. The foundation for an AI-driven NMS platform is a solid big data storage architecture; a lack of profound data and data hygiene is often one of the biggest obstacles to successfully deploy big data projects. As in today's all-IP environments nothing is static anymore, an AI entity must be highly intelligent. Unsupervised learning is key to automatically adapt to changing environments. Augmented operation and a zero-configuration and zero-maintenance approach will be crucial to successfully deploy the right management strategy.",NMS;artificial intelligence;machine learning;augmented operation;forecasting;intelligent fault detection;incident detection;deep root cause analysis;advanced analytics,T. Gunkel; B. Vandenberghe,Skyline Communications; Skyline Communications,2018.0,SMPTE 2018,SMPTE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8609872,10.5594/M001813,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'for', 'media', 'operations', 'why', 'ai', 'algorithms', 'will', 'become', 'a', 'must', 'for', 'every', 'network', 'management', 'system']",False,20230521-205332,,,,
182,ieeex,Competency Model for Programming Courses in Information Technology Education (ITE) Programs from Industry Perspective: A Delphi Method,"This study aimed to develop a competency model for software development courses in ITE programs as perceived by the IT industry in the Philippines in the new normal. A review of previous studies revealed existing software engineering competency models being referenced by the IT industry along with the Commission on Higher Education (CHED) General Education Curriculum (GEC) being referenced by the academe. However, things drastically changed during this global pandemic which may have affected these current standards. Thus, this study aimed to determine the current competency needs in the IT industry in the new normal in relation to the programming courses being offered by the ITE programs in the Philippines; A mixed method three-round Delphi technique was used to solicit a unified expert opinion from the point of view of nine (9) IT industry experts in the Philippines. Twenty-three (23) technical skills and eleven (11) soft skills were extracted from online interviews using thematic analysis. Out of 23 technical skills, nineteen (19) have consensus. The findings produced a competency model for software development courses in the new normal consisting of must-have technical skills, game-changer technical skills, and must-have soft skills. The must-have technical skills include Web Development, Cyber Security, Cloud Computing, Agile Project Management, Mobile Development, and DevOps. The game changer technical skills include Data Science and Data Analytics, Artificial Intelligence and Machine Learning, the Internet of Things, and Research and Development. And the must-have soft skills include Communication skills, Results-Oriented, and Collaboration skills.",competency model;Delphi method;Information Technology Education (ITE);programming courses;software development,J. E. E. Goh; C. V. Mojado; H. J. T. Manaligod,"Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines; Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines; Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines",2022.0,"2022 IEEE 14th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)",IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109471,10.1109/HNICEM57413.2022.10109471,20230520-160000,20230521-044735,"['competency', 'model', 'for', 'programming', 'courses', 'in', 'information', 'technology', 'education', '(ite)', 'programs', 'from', 'industry', 'perspective:', 'a', 'delphi', 'method']",False,20230521-205332,,,,
183,ieeex,"MosaicSim: A Lightweight, Modular Simulator for Heterogeneous Systems","As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and domain-specific hardware-software co-designs. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support rich heterogeneous combinations of general purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we introduce MosaicSim, a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. By integrating the LLVM toolchain, MosaicSim enables efficient modeling of instruction dependencies and flexible additions across the stack. Its modularity also allows the composition and integration of different hardware components. We first demonstrate that MosaicSim captures architectural bottlenecks in applications, and accurately models both scaling trends in a multicore setting and accelerator behavior. We then present two case-studies where MosaicSim enables straightforward design space explorations for emerging systems, i.e. data science application acceleration and heterogeneous parallel architectures.",heterogeneity;hardware-software co design;performance modeling;multi-core architectures;accelerators,O. Matthews; A. Manocha; D. Giri; M. Orenes-Vera; E. Tureci; T. Sorensen; T. J. Ham; J. L. Aragon; L. P. Carloni; M. Martonosi,"Princeton University; Princeton University; Columbia University; Princeton University; Princeton University; Princeton University; Seoul National University; University of Murcia, Murcia, Spain; Columbia University; Princeton University",2020.0,2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238641,10.1109/ISPASS48437.2020.00029,20230520-160000,20230521-044735,"['mosaicsim:', 'a', 'lightweight,', 'modular', 'simulator', 'for', 'heterogeneous', 'systems']",False,20230521-205332,,,,
184,ieeex,IBM Z development transformation,"This article discusses how the product development cycle is being transformed with “Artificial Intelligence” (AI) for the first time in zSeries history. This new era of AI, under the project name IBM Z Development Transformation (zDT), has allowed the team to grow and learn new skills in data science. This transformation forces change structurally in how data is prepared and stored. In z14, there were incremental productivity gains with enhancements to automation with eServer Automation Test Solution and a technology data analysis engine called zDataAssist. However, in z15, AI will significantly accelerate our efficiency. This article explains how Design Thinking and Agile principles were used to identify areas that are of high impact and feasible to implement: 1) what and how data is collected via System Test Event Logging and Analysis engine, Problem ticket management system (Jupitr), and Processor data analysis engine (Xrings); 2) problem identification, analysis, and management (AutoJup) along with Intelligent Recovery Verification Assistant; 3) product design documentation search engine (AskTheMachine); and 4) prototype microprocessor allocation processes Intelligent Commodity Fulfillment System using Machine Learning. This article details the approach of these areas for z15, the implementation of these solutions under the zDT project, as well as the results and future work.",,E. C. McCain; P. Bastien; B. F. Belmar; B. Bhattacharya; K. K. Cheruiyot; M. Coq; R. Dartey; K. Deekaram; K. Ghadai; L. D. Lalima; J. Nettey; A. W. Owolabi; K. Phillips; T. M. Shiling; D. T. Schroeder; C. Slegel; B. Steen; D. A. Thorne; E. Venuto; J. D. Willoughby; D. Yaniv; N. Ziemis,NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,2020.0,IBM Journal of Research and Development,IBM,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138677,10.1147/JRD.2020.3008122,20230520-160000,20230521-044735,"['ibm', 'z', 'development', 'transformation']",False,20230521-205332,,,,
185,ieeex,Strategic Information System Planning in the Industry 4.0 Era: A Systematic Literature Review,"Information systems and technology have an important role in building the Company's competitive advantage in facing the Industrial Era 4.0. Strategic Information System Planning (SISP) helps companies formulate reliable information systems that are aligned with business strategies. The academic world should contribute in this regard, but currently, the amount of research related to SISP is very limited. This research is a systematic literature review, which aims to find out more about SISP research trends, research motivations and backgrounds, industries that have been handled, and the methods used in developing SISP. This research is expected to be a trigger for the emergence of new research to support the successful development of SISP in companies in various industries. The results of this research show that several topics are widely researched and need to be improved in the future, namely the alignment of IS strategies with business strategies, the development of specific SISPs in various industries, and the reliability of IS strategies by considering the application of the latest information technology, such as blockchain, artificial intelligence, big data, augmented reality, Internet of Things, and cloud computing. In addition, it is also necessary to develop a SISP framework that is more accommodating to changes in the business environment that is increasingly fast, agile, and collaborative, which includes aspects of business architecture, data/information architecture, technology architecture, information system security, governance, and human resources.",Strategic Information System Planning;SISP;IS Strategic Planning;Systematic literature review,I. Mahendra; A. Ramadhan; A. Trisetyarso; E. Abdurachman; M. Zarlis,"Computer Science Program, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia",2022.0,2022 IEEE Creative Communication and Innovative Technology (ICCIT),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10119002,10.1109/ICCIT55355.2022.10119002,20230520-160000,20230521-044735,"['strategic', 'information', 'system', 'planning', 'in', 'the', 'industry', '4.0', 'era:', 'a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
186,ieeex,Guest Editorial Special Issue on Big Data and Computational Intelligence for Agile Wireless IoT,"The papers in this special section focus on Big Data and computational intelligence for agile Internet of Things (IOT) wireless networking technology. This technology is one of the main components that could empower a wide range of Internet-of-Things (IoT) applications including smart city, smart home, smart grid, e-health, smart transportation, etc. While providing an easily extensible solution for information exchange, wireless networks also have brought some crucial challenges due to the unstable characteristics of wireless communications. ",,,,2020.0,IEEE Transactions on Emerging Topics in Computational Intelligence,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099340,10.1109/TETCI.2020.2990757,20230520-160000,20230521-044735,"['guest', 'editorial', 'special', 'issue', 'on', 'big', 'data', 'and', 'computational', 'intelligence', 'for', 'agile', 'wireless', 'iot']",False,20230521-205332,,,,
187,ieeex,Panel: Addressing the Shortage of Big Data Skills with Inter-Disciplinary Big Data Curriculum,"One major challenge faced by enterprises in contemporary era is the shortage of big data and analytics (BDA) professionals. These professionals possess skills to analyze and derive intelligence from big data generated by enterprises. Currently, universities and colleges have not been able to produce sufficient professionals to meet the ever-growing demand for data analytics skill sets. A possible reason for this may be the narrow focus and lack of interdisciplinary approach to big data analytics education. To address this challenge, this panel brings together practitioners, researchers and educators in big data and analytics; to explore the potentials for developing an interdisciplinary curriculum that will deliver data analytics skills to students across all other academic majors. This might help to produce more agile data analytics professionals and close the gap between demand and supply of those professionals.",Analytics;Big Data;Education;Curriculum,J. C. Nwokeji; R. Stachel; T. Holmes; F. Aqlan; E. C. Udenze; R. Orji,"Compt. & Infor. Sci. Dept, Gannon University, Erie PA, USA; School of Business, Gannon University, Erie PA, USA; School of Business, Gannon University, Erie PA, USA; Industrial Engr. Dept, Penn. State Uni, Erie PA, USA; Physical Sciences Dept, Yakima Valley College, Yakima WA, USA; Computer Science Dept, Dalhousie University, Halifax, Canada",2019.0,2019 IEEE Frontiers in Education Conference (FIE),IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9028350,10.1109/FIE43999.2019.9028350,20230520-160000,20230521-044735,"['panel:', 'addressing', 'the', 'shortage', 'of', 'big', 'data', 'skills', 'with', 'inter-disciplinary', 'big', 'data', 'curriculum']",False,20230521-205332,,,,
188,ieeex,Actionable Analytics for Software Engineering,"Although intensive research on software analytics has been going on for nearly a decade, a repeated complaint in software analytics is that industrial practitioners find it hard to apply the results generated from data science. This theme issue aims to reflect on actionable analytics for software engineering and to document a catalog of success stories in which analytics has been proven actionable and useful, in some significant way, in an organization. This issue features five articles covering promising analytical methods for improving change triage, strategic maintenance, and team robustness, as well as the success stories of applying analytical tools during an organizational transformation.",actionable analytics;context-driven software engineering;software analytics;change triage;agile development;DevOps;software engineering;software development,Y. Yang; D. Falessi; T. Menzies; J. Hihn,"Stevens Institute of Technology; California Polytechnic State University, San Luis Obispo; North Carolina State University; Jet Propulsion Laboratory",2018.0,IEEE Software,IEEE,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239931,10.1109/MS.2017.4541039,20230520-160000,20230521-044735,"['actionable', 'analytics', 'for', 'software', 'engineering']",False,20230521-205332,,,,
189,scopus,Achieving Agile Big Data Science: The Evolution of a Team's Agile Process Methodology,"While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams. © 2019 IEEE.",Agile; Big Data Science; Process Methodology,"Saltz J.S., Shamshurin I.","School of Information Studies Syracuse University, Syracuse, NY, United States",2019.0,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081303461&doi=10.1109%2fBigData47090.2019.9005493&partnerID=40&md5=bf4c216dcc15cbc568a6a16d3f41c9e3,10.1109/BigData47090.2019.9005493,20230520-160000,20230521-044735,"['achieving', 'agile', 'big', 'data', 'science:', 'the', 'evolution', 'of', 'a', ""team's"", 'agile', 'process', 'methodology']",True,20230521-205332,,,,
190,scopus,SKI: An Agile Framework for Data Science,"This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrumlike time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus, SKI implements the Kanban process, but with a more repeatable and structured approach. © 2019 IEEE.",Agile; Big Data; Data Science; Process Methodology,"Saltz J., Suthrland A.","Syracuse University, United States; Scrum Inc.",2019.0,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081330216&doi=10.1109%2fBigData47090.2019.9005591&partnerID=40&md5=40117a3d48d67e091f50df7e54ab659e,10.1109/BigData47090.2019.9005591,20230520-160000,20230521-044735,"['ski:', 'an', 'agile', 'framework', 'for', 'data', 'science']",True,20230521-205332,,,,
191,scopus,Agile projects and big data,"In this paper, we explore the Agile approach to IT and big data project management and explain the benefit of agile methodologies for Big Data projects. The primary benefit of adopting an Agile methodology is its fluidity, this enables projects to adapt to changing assumptions, hypotheses, and requirements in a transparent way. Organizations are modernizing by using big data to power important decisions. They are refining agile approaches to Big Data problems and develop new techniques. An Agile approach is beneficial for big data projects because it allows analysts to gain valuable insights quickly, even from large data sets. This is possible by the way Agile projects break data sets down into smaller increments and is assisted by the continuous testing process. The paper reviews benefits of agile methodologies and explain how applying Agile IT methodology to Data Science Projects and Big Data Projects and why does Data Science need Agile methodologies. © 2019 Academic Conferences and Publishing International Limited. All rights reserved.",Agile project; Big data; Big data project management; Data science,Demigha S.,"CRI University of Paris 1, Sorbonne, France",2019.0,"Proceedings of the International Conference on Intellectual Capital, Knowledge Management and Organisational Learning, ICICKM",Academic Conferences and Publishing International Limited,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100802246&doi=10.34190%2fIKM.19.025&partnerID=40&md5=a1f7b70e866c95e9180392b8801167fa,10.34190/IKM.19.025,20230520-160000,20230521-044735,"['agile', 'projects', 'and', 'big', 'data']",False,20230521-205332,,,,
192,scopus,Adopting Agile Software Development Methodologies in Big Data Projects - A Systematic Literature Review of Experience Reports,"During the last decade, agile software development methodologies have been widely adopted in various project contexts. Big data projects are different from software engineering projects in all three aspects - people, processes and technologies. Recent research has shown that agile approaches are suitable and beneficial when applied in big data projects. The aim of the current study is to investigate which of the agile software development methodologies are currently applied in big data projects and what are the key considerations for their application. As a first step towards achieving this aim, the paper presents a systematic literature review of research articles reporting real-world experience of adopting agile methodologies in different big data science contexts. The findings of the study are beneficial to both practitioners and researchers to define and adopt agile approaches which are well suited for their big data projects. © 2020 IEEE.",agile software development; big data science; methodology adoption; real-world experience; systematic literature review,"Krasteva I., Ilieva S.","Software University St. Kliment Ohridski, Gate Institute, Sofia, Bulgaria",2020.0,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103840307&doi=10.1109%2fBigData50022.2020.9378118&partnerID=40&md5=160b4937181f9294ddbfa76504622c99,10.1109/BigData50022.2020.9378118,20230520-160000,20230521-044735,"['adopting', 'agile', 'software', 'development', 'methodologies', 'in', 'big', 'data', 'projects', '-', 'a', 'systematic', 'literature', 'review', 'of', 'experience', 'reports']",True,20230521-205332,,,,
193,scopus,Current approaches for executing big data science projects—a systematic literature review,"There is an increasing number of big data science projects aiming to create value for organizations by improving decision making, streamlining costs or enhancing business processes. However, many of these projects fail to deliver the expected value. It has been observed that a key reason many data science projects don’t succeed is not technical in nature, but rather, the process aspect of the project. The lack of established and mature methodologies for executing data science projects has been frequently noted as a reason for these project failures. To help move the field forward, this study presents a systematic review of research focused on the adoption of big data science process frameworks. The goal of the review was to identify (1) the key themes, with respect to current research on how teams execute data science projects, (2) the most common approaches regarding how data science projects are organized, managed and coordinated, (3) the activities involved in a data science projects life cycle, and (4) the implications for future research in this field. In short, the review identified 68 primary studies thematically classified in six categories. Two of the themes (workflow and agility) accounted for approximately 80% of the identified studies. The findings regarding workflow approaches consist mainly of adaptations to CRISP-DM (vs entirely new proposed methodologies). With respect to agile approaches, most of the studies only explored the conceptual benefits of using an agile approach in a data science project (vs actually evaluating an agile framework being used in a data science context). Hence, one finding from this research is that future research should explore how to best achieve the theorized benefits of agility. Another finding is the need to explore how to efficiently combine workflow and agile frameworks within a data science context to achieve a more comprehensive approach for project execution © 2022 Saltz and Krasteva",Agile data science; Big data science; Big data science workflows; Process frameworks; Project execution,"Saltz J.S., Krasteva I.","Syracuse University, Syracuse, NY, United States; GATE Institute, Sofia University, Sofia, Bulgaria",2022.0,PeerJ Computer Science,PeerJ Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125838568&doi=10.7717%2fPEERJ-CS.862&partnerID=40&md5=a8f281fbcb4ed8938f0aab5a2680a3fd,10.7717/PEERJ-CS.862,20230520-160000,20230521-044735,"['current', 'approaches', 'for', 'executing', 'big', 'data', 'science', 'projects—a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
194,scopus,Identifying the most Common Frameworks Data Science Teams Use to Structure and Coordinate their Projects,"This paper presents the results of a study focused on exploring which framework, if any, teams use to execute data science projects. The study consisted of a survey of 109 industry professionals, as well as an evaluation of relevant framework terms searched at Google. Overall, CRISP-DM was the most commonly used framework, with Scrum and Kanban being the second and third most frequently used. We note that CRISP-DM is a life cycle framework, whereas Scrum and Kanban are team coordination frameworks. Hence, this research also notes the potential demand for a framework that integrates both life cycle and team coordination aspects of leading a data science project. © 2020 IEEE.",Big Data; Data Science; Process Methodology,"Saltz J.S., Hotz N.","Syracuse University; Indiana University, United States",2020.0,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103847302&doi=10.1109%2fBigData50022.2020.9377813&partnerID=40&md5=0f5b16f2d44788e39f672855f4ebf0dc,10.1109/BigData50022.2020.9377813,20230520-160000,20230521-044735,"['identifying', 'the', 'most', 'common', 'frameworks', 'data', 'science', 'teams', 'use', 'to', 'structure', 'and', 'coordinate', 'their', 'projects']",True,20230521-205332,,,,
195,scopus,Applying Scrum in Data Science Projects,"The rise of big data has led to an increase in data science projects conducted by organizations. Such projects aim to create valuable insights by improving decision making or enhancing an organization's service offering through data-driven services. However, the majority of data science projects still fail to deliver the expected value. To increase the success rate of projects, the use of process models or methodologies is recommended in the literature. Nevertheless, organizations are hardly using them because they are considered too rigid and they do not support the typical iterative and open nature of data science projects. To overcome this problem, this research suggests applying Agile methodologies to data science projects. Agile methodologies were originally developed in the software engineering domain and are characterised by their iterative approach towards software development. In this study, we selected the Scrum approach and integrated it into the CRISP-DM methodology for data science projects using a Design Science Research approach. This new methodology was then evaluated in three different case organizations using expert interviews. Analysis of the expert interviews resulted in a further refinement of the Agile data science methodology proposed by this research. © 2020 IEEE.",Agile; Data Science; Scrum,"Baijens J., Helms R., Iren D.","Open University, Department of Information Science, Heerlen, Netherlands",2020.0,"Proceedings - 2020 IEEE 22nd Conference on Business Informatics, CBI 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089284821&doi=10.1109%2fCBI49978.2020.00011&partnerID=40&md5=c8d4cc95ac6249f5cc098e412ffa4b23,10.1109/CBI49978.2020.00011,20230520-160000,20230521-044735,"['applying', 'scrum', 'in', 'data', 'science', 'projects']",True,20230521-205332,,,,
196,scopus,On the Appropriate Methodologies for Data Science Projects,"Data science is an emerging discipline with a particular research focus on improving the available techniques for data analysis. While the number of data science projects is growing, unfortunately, there is a slight consideration of how a team performs a data science project. Although the existence of a repeatable well-defined process could deal with many challenges of data science projects, researches conducted in recent years indicate a convergence of the results to agile methodologies as the appropriate ones for the projects. In this paper, first, the tasks and roles of individuals in data science projects are addressed; then, some research conducted for the methodologies used in the projects are studied. The study shows that agile methodologies could resolve many issues of data science projects by increasing the communications and cooperation of the team members and investors. © 2021 IEEE.",agile software methodologies; big data; business intelligence; data science,"Dastgerdi A.K., Gandomani T.J.","Leuphana University of Luneburg, Faculty of Business and Economics, Luneburg, Germany; Shahrekord University, Department of Computer Science, Shahrekord, Iran",2021.0,"2021 International Conference on Information Technology, ICIT 2021 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112190039&doi=10.1109%2fICIT52682.2021.9491712&partnerID=40&md5=6a6082ddf5e3c4be550a417d9ee2f340,10.1109/ICIT52682.2021.9491712,20230520-160000,20230521-044735,"['on', 'the', 'appropriate', 'methodologies', 'for', 'data', 'science', 'projects']",True,20230521-205332,,,,
197,scopus,Towards the Automation of Industrial Data Science: A Meta-learning based Approach,"In context of the fourth industrial revolution (industry 4.0), the industrial big data is subject to grow rapidly to respond the agile industrial computing and manufacturing technologies. This data evolution can be captured using ubiquitous integrated sensors and multiple smart machines. We believe the use of data science methodologies, for the selection of models and configuration of hyper-parameters, may help to better control such data evolution. But, at the same time, the industrial practitioners and researchers often lack machine-learning expertise to directly retrieve the benefit from valuable manufacturing big data. Such a lack poses the major obstacle to yield value from even-though familiar data. In this case, a collaboration with data scientists may become an exigence along with the extensive machine learning knowledge which presumably may result to pursue further delays and effort. Multiple approaches for automating machine learning (AutoML) have been proposed for the past recent years in order to alleviate this deficiency. These approaches are expected to perform better along with accomplishment of computing resources which are mostly not readily accessible. To address this research challenge, in this paper, we propose a meta-learning based approach that may serve an effective decision support system for the AutoML process. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Automated Machine Learning; Industrial Data Science; Industry 4.0; Manufacturing Big Data; Meta-learning,"Garouani M., Ahmad A., Bouneffa M., Lewandowski A., Bourguin G., Hamlich M.","Univ. Littoral Côte d’Opale, UR 4491, LISIC, Laboratoire d’Informatique Signal et Image de la Côte d’Opale, Calais, F-62100, France; ISSIEE Laboratory, ENSAM, University of Hassan II, Casablanca, Morocco; Study and Research Center for Engineering and Management(CERIM), HESTIM, Casablanca, Morocco",2021.0,"International Conference on Enterprise Information Systems, ICEIS - Proceedings","Science and Technology Publications, Lda",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130939416&partnerID=40&md5=250835e33056711f0f351e5d28013e12,,20230520-160000,20230521-044735,"['towards', 'the', 'automation', 'of', 'industrial', 'data', 'science:', 'a', 'meta-learning', 'based', 'approach']",False,20230521-205332,,,,
198,scopus,On the Application of SCRUM in Data Science Projects,"The emerging discipline of Data Science poses several challenges for teams conducting projects in the field as notably, the majority of Data Science teams fail to deliver the expected outcomes. To improve the results, researchers tried to adapt agile project methodologies like Scrum for Data Science projects. Scrum in particular is often implemented due its success in software engineering. However, the basic Scrum framework has proven itself to be too strict for Data Science, due to frequent unpredictabilities of Data Science tasks. Consequently, adaptions were made to traditional Scrum to make it more suitable for the new challenges. This article discusses further adaptations and suggests that Scrum in itself is usable in Data Science, however, additional adaptations of the core concepts need to be envisioned. © 2022 IEEE.",data science; project management; SCRUM,"Kraut N., Transchel F.","Harz University of Applied Sciences, Faculty of Business Studies, Wernigerode, Germany; Harz University of Applied Sciences, Faculty of Automation Computer Science, Wernigerode, Germany",2022.0,"2022 7th International Conference on Big Data Analytics, ICBDA 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129474110&doi=10.1109%2fICBDA55095.2022.9760341&partnerID=40&md5=677417fa61bb17bfdb2b45060cf1848d,10.1109/ICBDA55095.2022.9760341,20230520-160000,20230521-044735,"['on', 'the', 'application', 'of', 'scrum', 'in', 'data', 'science', 'projects']",True,20230521-205332,,,,
199,scopus,Evaluating Data Science Project Agility by Exploring Process Frameworks Used by Data Science Teams,"The lack of effective team process is often noted as one of the key drivers of data science project inefficiencies and failures. To help address this challenge, this research reports on semi-structured interviews, across 16 organizations, which explored data science agile framework usage. While 62% of the organizations reported using an agile framework, none actually followed the Scrum Guide (or any other published framework), but rather, each organization had defined their own process that incorporated one or more aspects of Scrum. The other organizations used a proprietary/ad-hoc approach, often based on a proprietary data science life cycle. In short, while many data science teams are trying to be agile, they are adapting existing frameworks to work within a data science context. Future research could explore how data science teams can best achieve agility, perhaps via new agile frameworks that address the unique data science project management challenges. © 2023 IEEE Computer Society. All rights reserved.",Agile; Data Science; Team Process,"Lahiri S., Saltz J.","Syracuse University, United States",2023.0,Proceedings of the Annual Hawaii International Conference on System Sciences,IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152142973&partnerID=40&md5=903d518d32151177c40c952810cface2,,20230520-160000,20230521-044735,"['evaluating', 'data', 'science', 'project', 'agility', 'by', 'exploring', 'process', 'frameworks', 'used', 'by', 'data', 'science', 'teams']",False,20230521-205332,,,,
200,scopus,Data science roadmapping: An architectural framework for facilitating transformation towards a data-driven organization,"Leveraging data science can enable businesses to exploit data for competitive advantage by generating valuable insights. However, many industries cannot effectively incorporate data science into their business processes, as there is no comprehensive approach that allows strategic planning for organization-wide data science efforts and data assets. Accordingly, this study explores the Data Science Roadmapping (DSR) to guide organizations in aligning their business strategies with data-related, technological, and organizational resources. The proposed approach is built on the widely adopted technology roadmapping framework and customizes its context, architecture, and process by synthesizing data science, big data, and data-driven organization literature. Based on industry collaborations, the framework provides a hybrid and agile methodology comprising the recommended steps. We applied DSR with a research group with sector experience to create a comprehensive data science roadmap to validate and refine the framework. The results indicate that the framework facilitates DSR initiatives by creating a comprehensive roadmap capturing strategy, data, technology, and organizational perspectives. The contemporary literature illustrates prebuilt roadmaps to help businesses become data-driven. However, becoming data-driven also necessitates significant social change toward openness and trust. The DSR initiative can facilitate this social change by opening communication channels, aligning perspectives, and generating consensus among stakeholders. © 2021",Big data; Data science; Data-driven organization; Digital transformation; Technology management; Technology roadmapping,"Kayabay K., Gökalp M.O., Gökalp E., Erhan Eren P., Koçyiğit A.","Middle East Technical University, Informatics Institute, Ankara, Turkey; TÜBİTAK ULAKBİM, Network Technologies Department, Ankara, Turkey; University of Cambridge, Institute for Manufacturing, Cambridge, United Kingdom; Hacettepe University, Computer Engineering Department, Ankara, Turkey",2022.0,Technological Forecasting and Social Change,Elsevier Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116906475&doi=10.1016%2fj.techfore.2021.121264&partnerID=40&md5=141893bcc136762b0bdb79fe1b0467a5,10.1016/j.techfore.2021.121264,20230520-160000,20230521-044735,"['data', 'science', 'roadmapping:', 'an', 'architectural', 'framework', 'for', 'facilitating', 'transformation', 'towards', 'a', 'data-driven', 'organization']",False,20230521-205332,,,,
201,scopus,Managing and Composing Teams in Data Science: An Empirical Study,"Data science projects have become commonplace over the last decade. During this time, the practices of running such projects, together with the tools used to run them, have evolved considerably. Furthermore, there are various studies on data science workflows and data science project teams. However, studies looking into both workflows and teams are still scarce and comprehensive works to build a holistic view do not exist. This study bases on a prior case study on roles and processes in data science. The goal here is to create a deeper understanding of data science projects and development processes. We conducted a survey targeted at experts working in the field of data science (n=50) to understand data science projects' team structure, roles in the teams, utilized project management practices and the challenges in data science work. Results show little difference between big data projects and other data science. The found differences, however, give pointers for future research on how agile data science projects are, and how important is the role of supporting project management personnel. The current study is work in progress and attempts to spark discussion and new research directions. © 2021 IEEE.",agile practices; Data science; project management; teamwork,"Aho T., Kilamo T., Lwakatare L., Mikkonen T., Sievi-Korte O., Yaman S.","Tieto Evry, Tampere, Finland; Computing Sciences, Tampere University, Tampere, Finland; Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland; KPMG Finland, Helsinki, Finland",2021.0,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125358489&doi=10.1109%2fBigData52589.2021.9671737&partnerID=40&md5=f8525ec802c682aa292feb05a5d74dd0,10.1109/BigData52589.2021.9671737,20230520-160000,20230521-044735,"['managing', 'and', 'composing', 'teams', 'in', 'data', 'science:', 'an', 'empirical', 'study']",True,20230521-205332,,,,
202,scopus,Story and Task Issue Analysis for Agile Machine Learning Projects,"The usage of Agile methodology in planning and executing machine learning (ML) and data science related software engineering projects is increasing. However, there are very few studies using real data on how effective such planning is or guidelines on how to plan such projects. In this paper, we analyze data taken from several software projects using Scrum tools. We compare the data for data science/ML and non-ML projects, in an attempt to understand if data science and ML projects are planned or executed any differently compared to normal software engineering projects. We also perform a story classification task using machine learning to analyze story logs for agile tasks for several teams. We find there are differences in what makes a good ML story as opposed to a non ML story. After analyzing this data, we propose a few ways in which software projects, whether machine learning related or not, can be better logged and executed using Scrum tools like Jira. © 2020 IEEE.",agile methodology; machine learning project; scrum; software engineering,"Singla K., Vinayak T.M., Arpitha A.S., Naik C., Bose J.","Samsung Rd Institute, Bangalore, India",2020.0,"Proceedings of 2020 IEEE-HYDCON International Conference on Engineering in the 4th Industrial Revolution, HYDCON 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096881966&doi=10.1109%2fHYDCON48903.2020.9242803&partnerID=40&md5=5b9053eaf110d1456a4fb9e7476e048a,10.1109/HYDCON48903.2020.9242803,20230520-160000,20230521-044735,"['story', 'and', 'task', 'issue', 'analysis', 'for', 'agile', 'machine', 'learning', 'projects']",True,20230521-205332,,,,
203,scopus,Customizing and Deploying Data Science Roadmapping: A Case Study of an Oil and Gas Company,"Many organizations still face challenges leveraging data science in production and need strategic planning for organization-wide data science efforts and assets. Data Science Roadmapping (DSR) customizes the widely used Technology Roadmapping to facilitate such planning in organizations, aligning market, business, data, technology, and organization perspectives. This paper employs the action research method to customize and apply DSR in an oil and gas company. The approach mostly met the expectations regarding objectives and outcomes, the first step toward generalizability. The case study provides researchers and practitioners insights into roadmapping customization, remote and agile roadmap development process, and strategic planning for technology adoption in a large organization. Lastly, we identify the future research directions using the recent roadmapping literature. © 2022 IEEE.",big data; data science; data strategy; high-performance computing; technology roadmapping,"Kayabay K., Gokalp M.O., Gokalp E., Alagoz S.M., Eren P.E., Kocyigit A.","Data Informatics Middle East Technical University Network Technologies, Department TÜBITAK ULAKBIM, Ankara, Turkey; Data Analytics Center TÜPRAŞ, Ankara, Turkey; Hacettepe University, Computer Engineering Department, Ankara, Turkey; Information Systems Middle East Technical University, Ankara, Turkey",2022.0,"2022 IEEE International Conference on Technology Management, Operations and Decisions, ICTMOD 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152129611&doi=10.1109%2fICTMOD55867.2022.10082858&partnerID=40&md5=39f520f9702d3cb2fb2f677492f4ad7a,10.1109/ICTMOD55867.2022.10082858,20230520-160000,20230521-044735,"['customizing', 'and', 'deploying', 'data', 'science', 'roadmapping:', 'a', 'case', 'study', 'of', 'an', 'oil', 'and', 'gas', 'company']",True,20230521-205332,,,,
204,scopus,Application of methodologies and process models in big data projects,"The concept of Big Data is being used in different business sectors; however, it is not certain which methodologies and process models have been used for the development of these kind of projects. This paper presents a systematic literature review of studies reported between 2012 and 2017 related to agile and non-agile methodologies applied in Big Data projects. For validating our review process, a text mining method was used. The results reveal that since 2016 the number of articles that integrate the agile manifesto in Big Data project has increased, being Scrum the agile framework most commonly applied. We also found that 44% of articles obtained from a manual systematic literature review were automatically identified by applying text mining. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Agile Methodologies; Big Data; Systematic Literature Review; Text Mining,"Quelal R., Mendoza L.E., Villavicencio M.","ESPOL Polytechnic University, Escuela Superior Politécnica del Litoral, ESPOL, Facultad de Ingeniería en Electricidad y Computación, Campus Gustavo Galindo Km., 30.5 Vía Perimetral, Guayaquil, 01-5863, Ecuador; Processes and Systems Department, Simón Bolívar University, Valle de Sartenejas,, Caracas, Venezuela",2019.0,ICEIS 2019 - Proceedings of the 21st International Conference on Enterprise Information Systems,SciTePress,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067451936&doi=10.5220%2f0007729602770284&partnerID=40&md5=4e8341268184f09670b6e2536e4cbd16,10.5220/0007729602770284,20230520-160000,20230521-044735,"['application', 'of', 'methodologies', 'and', 'process', 'models', 'in', 'big', 'data', 'projects']",False,20230521-205332,,,,
205,scopus,"Agile testing quadrants on problem-based learning involving agile development, big data, and cloud computing","This paper describes the use of Agile Testing Quadrants, using Scrum Agile Method in a collaborative software project named Big Data, Internet of Things, and Agile for Accidents and Crises (BD-ITAC). It applies the Scrum agile method and its best practices, the Hadoop ecosystem, and cloud computing for the management of emergencies, involving monitoring, warning, and prevention. It reports the experience of students, during the first semester of 2016, from three different courses on the graduate program in Electronics and Computer Engineering at the Brazilian Aeronautics Institute of Technology (Instituto Tecnologico de Aeronautica-ITA). The major contribution of this work is the academic application of Agile Testing Quadrants for Problem-Based Learning. The students worked asynchronous and geographically dispersed to deliver valuable increments. This work was performed during four project Sprints on just sixteen academic weeks. The main project output was a working, developed, and tested software. © Springer International Publishing AG 2018.",Agile testing quadrants; Big data; Cloud computing; Management of emergencies; Scrum agile method,"de Castro Martins J., Pinto A.F.M., Goncalves G.S., Shigemura R.A.L., Neto W.C., da Cunha A.M., Dias L.A.V.","Computer Science Department, Brazilian Aeronautics Institute of Technology, Instituto Tecnologico de Aeronautica – ITA, Sao Jose dos Campos, Sao Paulo, Brazil",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048493999&doi=10.1007%2f978-3-319-54978-1_56&partnerID=40&md5=16c75746455b18f561f7e6f31d039ffc,10.1007/978-3-319-54978-1_56,20230520-160000,20230521-044735,"['agile', 'testing', 'quadrants', 'on', 'problem-based', 'learning', 'involving', 'agile', 'development,', 'big', 'data,', 'and', 'cloud', 'computing']",False,20230521-205332,,,,
206,scopus,Big data project management by agile approach: In the case of the Seoul Metropolitan City Owl Bus,"Big data has proven to be a good source in analysing complicated situations and designing complex systems. With big data analysis, solutions have become more accurate. However, due to a lack of experience with big data, projects that generally handle big data have a higher failure rate in terms of time, money and user satisfaction. Therefore, projects involving big data should differ from a typical project. Using the case of the Seoul Metropolitan City Owl Bus, the authors have setup project procedures and raised several issues developers would do well to consider when dealing with big data. When the Seoul City Government in South Korea planned the night bus lines and its schedules, it made use of big data to do so. We expect that this case analysis will guide the further usage of big data in the service sector project management. Copyright © 2021 Inderscience Enterprises Ltd.",Agile project management; Big data; Data analysis; DevOps project management; Extreme project management; Public policy; Scrum project management; Service management; Simulation,"Kim S.H., Song C.I., Yang K.H.","K-ICT Big Data Center, National Information Society Agency, 53, Cheomdan-ro, Dong-gu, Daegu, 41068, South Korea; Korea Telecom (KT), 33, Jong-ro 3-gil, Jongno-gu, Seoul, 03155, South Korea; IS Department, University of Wisconsin La Crosse, 1725 State Street, La Crosse, WI  54601, United States",2021.0,International Journal of Services and Operations Management,Inderscience Publishers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109934615&doi=10.1504%2fIJSOM.2021.116103&partnerID=40&md5=714eac2a211b2dbe0c19a6f8b6f7b726,10.1504/IJSOM.2021.116103,20230520-160000,20230521-044735,"['big', 'data', 'project', 'management', 'by', 'agile', 'approach:', 'in', 'the', 'case', 'of', 'the', 'seoul', 'metropolitan', 'city', 'owl', 'bus']",False,20230521-205332,,,,
207,scopus,Linking data science to lean production: a model to support lean practices,"The literature discusses data science (DS) as a very promising set of techniques and tools to support lean production (LP) practices. DS could aid manufacturing companies in transforming massive real-time data into meaningful knowledge, increasing process transparency and product quality information and supporting improvement activities through data-driven decision-making. However, no attempt has been made in the literature to formalise the links between DS and LP practices. Thus, this study aims to overcome this gap by clarifying the DS techniques and tools that can support LP practices and how to apply them. This study employs a quantitative bibliometric method–specifically, a keyword co-occurrence network analysis–on a set of papers extracted from Scopus. The results obtained allowed the researchers to identify a set of DS techniques and tools that can support LP practices and to develop a model to guide their implementation based on the typical improvement implementation stages of the plan-do-check-act cycle. The model shows how to use DS techniques and tools in LP for: identifying areas for improvement and subsequent implementation (plan); enabling a better knowledge and process management (do); identifying/predicting potential problems and employing statistical process control (check); providing remedial actions and effectively applying process improvement (act). © 2021 Informa UK Limited, trading as Taylor & Francis Group.",big data analytics; Data science; keyword co-occurrence network; lean production; plan-do-check-act,"Pozzi R., Cannas V.G., Ciano M.P.","School of Industrial Engineering, LIUC University, Castellanza, Italy",2022.0,International Journal of Production Research,Taylor and Francis Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109906680&doi=10.1080%2f00207543.2021.1946192&partnerID=40&md5=61e3d75ca1611e2a214905e6e4ff9f7f,10.1080/00207543.2021.1946192,20230520-160000,20230521-044735,"['linking', 'data', 'science', 'to', 'lean', 'production:', 'a', 'model', 'to', 'support', 'lean', 'practices']",False,20230521-205332,,,,
208,scopus,A scalable methodology to guide student teams executing computing projects,"This article reports on a sequential mixed-methods research study, which compared different approaches on how to guide students through a semester-long data science project. Four different methodologies, ranging from a traditional “just assign some intermediate milestones” to other more Agile methodologies, were first compared via a controlled experiment. The results of this initial experiment showed that the project methodology used made a significant difference in student outcomes. Surprisingly, the Agile Kanban approach was found to be much more effective than the Agile Scrum methodology. Based on these initial results, in the second semester, we focused on use of the Kanban methodology. The findings in the second, more qualitative phase, confirmed the methodology’s usefulness and scalability. A key issue when using the scrum methodology was that the students had a very difficult time estimating what could be completed in each of their two-week sprints. The Kanban board, which visually shows and limits work-in-progress, was found to be an effective way for students to communicate with each other as well as with their instructor. In addition, Agile Kanban also streamlined the work required for instructors to efficiently provide guidance to student teams and to understand each team’s status. In summary, a scalable Kanban methodology, which can be applied to a wide variety of student computing projects, was found to an effective methodology to guide and manage student projects, improving student outcomes and minimizing instructor workload. © 2018 ACM.",Project methodologies; Project-based learning; Scalable methodologies,"Saltz J.S., Heckman R.R.","Hinds Hall, Syracuse, NY  13244, United States",2018.0,ACM Transactions on Computing Education,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064535263&doi=10.1145%2f3145477&partnerID=40&md5=b2169dc4372126e7d5dcdf264d450bfa,10.1145/3145477,20230520-160000,20230521-044735,"['a', 'scalable', 'methodology', 'to', 'guide', 'student', 'teams', 'executing', 'computing', 'projects']",True,20230521-205332,,,,
209,scopus,A predictive model to identify Kanban teams at risk,"Kanban, which is an agile process methodology as well as a means to implement lean principles, has been growing as a project management framework across a range of domains, including manufacturing, software development and data science. This paper explores, for teams using Kanban, the ability to predict low team performance. The prediction is based on an analytical model that uses specific project metrics that can be collected via the team's visual Kanban board. Specifically, data from 80 teams was used to build and test machine learning models that predict teams at risk for delivering low quality results. The model developed was significantly better than the baseline situation of thinking that all teams were at risk. While this analysis was done within a data science project context, the results are likely applicable across a range of information system projects. © 2019-IOS Press and the authors. All rights reserved.",data science project management; Kanban; metrics; project management; team performance,"Shamshurin I., Saltz J.S.","School of Information Studies, Syracuse University, Hinds Hall, Syracuse, NY  13210, United States",2019.0,Model Assisted Statistics and Applications,IOS Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077866301&doi=10.3233%2fMAS-190471&partnerID=40&md5=1255e8fdfcbe529f5d9ba6408694172d,10.3233/MAS-190471,20230520-160000,20230521-044735,"['a', 'predictive', 'model', 'to', 'identify', 'kanban', 'teams', 'at', 'risk']",False,20230521-205332,,,,
210,scopus,Literature Review on Big Data Analytics and Demand Modeling in Supply Chain,"New digital technologies have been introduced into our business and social environments, causing a major change that is recognized as the digital transformation in recent years. While environmental shifts suggest that most of the organization starts using advanced technologies such as Internet of Things(IoT), Mobile applications, Blackchain, Intelligence Things, catboats and many more in their supply chain planning to gain an early competitive advantage and these technologies generates enormous amount of data that the traditional business intelligence system difficult to handle processing of vast data in real-Time or nearly real time causes abstraction to the insight discovery, demand modeling and supply chain optimization, Big Data initiatives for demand modeling and supply chain optimization promise to answer these challenges by incorporating various services, methods and tools for more agile and adaptably analytics and decision making, there by this paper focus on reviewing the level of analytics and the forecasting methods being used in the supply chain, understating the fundamentals of supply chain and role of demand modeling, there by proposing a high level framework for supply chain analytics in the context of big data with the knowledge of data science, artificial intelligence, big data echo system and supply chain. © 2018 IEEE.",Big data Analytics; Demand modeling; Forecasting methods; Supply chain; supply chain framework,"Puneeth Kumar K., Manjunath T.N., Hegadi R.S.","BMS Institute of Technology and Management, Bengaluru, India; BMS Institute of Technology and Management, Dept. of ISE, Bengaluru, India; Solapur University, Dept. of Computer Science, Maharashtra, India",2018.0,"3rd International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques, ICEECCOT 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081123785&doi=10.1109%2fICEECCOT43722.2018.9001513&partnerID=40&md5=11bdb42ed5c68072df66908d6c53b824,10.1109/ICEECCOT43722.2018.9001513,20230520-160000,20230521-044735,"['literature', 'review', 'on', 'big', 'data', 'analytics', 'and', 'demand', 'modeling', 'in', 'supply', 'chain']",True,20230521-205332,,,,
211,scopus,"Using big data, internet of things, and agile for crises management","This paper describes the use of Scrum Agile Method in a collaborative software project named Big Data, Internet of Things, and Agile for Accidents and Crises (BD-ITAC). It applies the Scrum agile method and its best practices, the Hadoop ecosystem, and cloud computing for the management of emergencies, involving monitoring, warning, and prevention. It reports the experience of students from three different courses on the graduate program in Electronics and Computer Engineering at the Brazilian Aeronautics Institute of Technology (Instituto Tecnologico de Aeronautica – ITA), during the first semester of 2016. The major contribution of this work is the application of an interdisciplinary Problem-Based Learning, where students have worked asynchronously and geographically dispersed to deliver valuable increments. This work was performed during four project sprints on just sixteen academic weeks. The main project output was a working, developed, and tested software. During all project, a big data environment was used, as a transparent way to fulfill the needs for alerts and crises management. © Springer International Publishing AG 2018.",Alerts and crisis; Big data; Cloud computing; Hadoop ecosystem; Internet of things,"de Castro Martins J., Mancilha Pinto A.F., Junior E.E.B., Goncalves G.S., Louro H.D.B., Gomes J.M., Filho L.A.L., da Silva L.H.R.C., Rodrigues R.A., Neto W.C., da Cunha A.M., Dias L.A.V.","Computer Science Department, Brazilian Aeronautics Institute of Technology, Instituto Tecnologico de Aeronautica – ITA, Sao Jose dos Campos, SP, Brazil",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048507081&doi=10.1007%2f978-3-319-54978-1_50&partnerID=40&md5=aba860966fd420306d50edd5b1af23f7,10.1007/978-3-319-54978-1_50,20230520-160000,20230521-044735,"['using', 'big', 'data,', 'internet', 'of', 'things,', 'and', 'agile', 'for', 'crises', 'management']",False,20230521-205332,,,,
212,scopus,Enhanced Framework For Big Data Requirement Elicitation,"Requirement engineering is one of the software development life cycle phases; it has been recognized as an important phase for collecting and analyzing a system’s goals. However, despite its importance, requirement engineering has several limitations such as incomplete requirements, vague requirements, lack of prioritization, and less user involvement, all of which affect requirement quality. With the emergence of big data technology, the complexity of big data, which is defined by large data volume, high velocity, and large data variety, has gradually increased, affecting the quality of big data software requirements. This study proposes a framework with four sequential phases to improve requirement engineering quality through big data software development. By integrating the proposed framework’s phases in which user requirements are collected in a complete vision using traditional requirement elicitation techniques with agile methodology and mind mapping, the collected requirements are displayed via a graphical representation using mind maps to achieve high requirement accuracy with connectivity and modifiability, enabling the accurate prioritization of requirements implemented using agile SCRUM methodology. The proposed framework improves requirement quality in big data software development, which is represented by accuracy, completeness, connectivity, and modifiability to understand the value of the collected requirements and effectively affect the quality of the implementation phase. © 2021. International Journal of Advanced Computer Science and Applications.All Rights Reserved",agile methodology; big data requirement; mind mapping; Requirement engineering,"Hesham A., Emam O.E., Salah M.","Department of Information Systems, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Faculty of Informatics and Computer Science, British University in Egypt, Cairo, Egypt",2021.0,International Journal of Advanced Computer Science and Applications,Science and Information Organization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119017355&doi=10.14569%2fIJACSA.2021.0120816&partnerID=40&md5=14cfd8a84aafec714dd88a57ca94b0dc,10.14569/IJACSA.2021.0120816,20230520-160000,20230521-044735,"['enhanced', 'framework', 'for', 'big', 'data', 'requirement', 'elicitation']",False,20230521-205332,,,,
213,scopus,The Review for Visual Analytics Methodology,"Big data usage evolves from previously looking into the capacity of big data's descriptive and diagnostic perspectives into currently feeding the demands for predictive big data analytics. The needs come about due to organizations that crave predictive analytics capabilities to reduce risk, make intelligent decisions, and generate different customer experiences. Similarly, visual analytics play an essential role in understanding and fitting the analytics prediction in their business decision. Hence, the combination of descriptive, diagnostics and predictive within Visual Analytics emerges as a balanced field to provide understandable predictive insight. Due to the organizational demand and multi-discipline area, the approach to developing visual analytics is still uncertain in the Big Data Project Lifecycle from methodological perspectives. While there are a few potential methodological approaches that could be used for visual analytics, they are scattered across numerous academic research and industrial practice. To date, there is no coherent review and analysis of the work that has been explored specifically for Visual Analytics methodology. This paper reports on a review of previous literature concerning how Visual Analytics has been executed in the big data life cycle to address the gap. The review is organized in this study from three perspectives: i) general ICT -related methodology (e.g. SDLC, Agile, DevOps), ii) Data Science-related methodology (e.g. CRISP-DM, SEMMA, KDD) and iii) Visual Analytics-related methodologies in which each method will be benchmarked based on the Visual Analytics major part of reality, computer and human, in terms of its width, Depth, and flows. This study found insufficiencies, non-specific and vague conditions in handling the Visual Analytics when using current methodological approaches based on the review conducted. The paper also highlights the Visual Analytics-related methodological review, which can shed some light on the approaches and ways of implementing analytics in the big data lifecycle, which can be beneficial for future studies in proposing a more comprehensive methodology for Visual Analytics in the big data lifecycle. © 2022 IEEE.",big data analytics; methodology; process; visual analytics,"Ahmad Z., Yaacob S., Ibrahim R., Wan Fakhruddin W.F.","Universiti Teknologi Malaysia, Advanced Informatics Department, Kuala Lumpur, Malaysia; Universiti Teknologi Malaysia, Social Science and Humanity Faculty, Kuala Lumpur, Malaysia",2022.0,"HORA 2022 - 4th International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133962611&doi=10.1109%2fHORA55278.2022.9800100&partnerID=40&md5=07c01f4726fa16fd8faa6ab350683ed8,10.1109/HORA55278.2022.9800100,20230520-160000,20230521-044735,"['the', 'review', 'for', 'visual', 'analytics', 'methodology']",True,20230521-205332,,,,
214,scopus,A big data on private cloud agile provisioning framework based on OpenStack,"On the bases of the OpenStack private cloud delivery big data platform, numerous entities yearn for attaining agile and standardized big data delivery platform, reclaiming the resources, managing the total cost of ownership (TCO) and adapting to multiple big data open source or commercial off-The-shelf (COTS) solutions. Nevertheless, as regards the big data platform running on cloud computing, the big data platform is disintegrated from the cloud computing system by virtual machines since neither being based on OpenStack private cloud nor on big data platform can achieve end-To-end resource delivery, together with ensuring that it is quite convenient for the long-Term operations. Accordingly, establishing an across framework between private cloud and big data platform is quite essential. The big data on cloud agile provision framework could realize fast resource delivery based on predefined orchestration template of private cloud, operating system, big data platform, monitor, inspection system, etc. Through the deployment of this framework, it is capable of attaining the delivery of agile, low cost, standardized and high adaptability the big data on cloud, as well as the high-quality operation of the big data on cloud with the help of integration configuration management database (CMDB) with the automatic inspection system. © 2018 IEEE.",agile resource provisioning; big data platform orchestration; cloud computing; inspection and rule engine,"Lu M., Zhou X.","University of Chinese Academy of Sciences, Infrastructure As A Service, BT/IT, Lenovo, Beijing, China; Infrastructure As A Service, BT/IT, Lenovo, Beijing, China",2018.0,"2018 3rd IEEE International Conference on Cloud Computing and Big Data Analysis, ICCCBDA 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050164019&doi=10.1109%2fICCCBDA.2018.8386522&partnerID=40&md5=fa47e7c460a840cc26a692c81df522b3,10.1109/ICCCBDA.2018.8386522,20230520-160000,20230521-044735,"['a', 'big', 'data', 'on', 'private', 'cloud', 'agile', 'provisioning', 'framework', 'based', 'on', 'openstack']",True,20230521-205332,,,,
215,scopus,Agile elastic desktop corporate architecture for big data,"New challenges in the dynamically changing business environment require companies to experience digital transformation and more effective use of Big Data generated in their expanding online business activities. A possible solution for solving real business problems concerning Big Data resources is proposed in this paper. The defined Agile Elastic Desktop Corporate Architecture for Big Data is based on virtualizing the unused desktop resources and organizing them in order to serve the needs of Big Data processing, thus saving resources needed for additional infrastructure in an organization. The specific corporate business needs are analyzed within the developed R&D environment and, based on that, the unused desktop resources are customized and configured into required Big Data tools. The R&D environment of the proposed Agile Elastic Desktop Corporate Architecture for Big Data could be implemented on the available unused resources of hundreds desktops. © 2020 Sciendo. All rights reserved.",Agile Elastic Desktop Corporate Architecture; Big Data; Desktop Virtualization; Digital Transformation,"Kisimov V., Kabakchieva D., Naydenov A., Stefanova K.","University of National and World Economy, Sofia, 1700, Bulgaria",2020.0,Cybernetics and Information Technologies,Sciendo,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092904304&doi=10.2478%2fcait-2020-0025&partnerID=40&md5=3601ffd7b005a27afcb983617761210e,10.2478/cait-2020-0025,20230520-160000,20230521-044735,"['agile', 'elastic', 'desktop', 'corporate', 'architecture', 'for', 'big', 'data']",False,20230521-205332,,,,
216,scopus,Using a coach to improve team performance when the team uses a kanban process methodology,"Teams are increasing their use of the Kanban process methodology across a range of information system projects, including software development and data science projects. While the use of Kanban is growing, little has been done to explore how to improve team performance for teams that use Kanban. One possibility is to introduce a Kanban Coach (KC). This work reports on exploring the use of a Kanban Coach, with respect to both how the coach could interact with the team as well as how the use of a coach impacts team results. Specifically, this paper reports on an experiment where teams either had, or did not have, a Kanban Coach. A quantitative and qualitative analysis of the data collected during the experiment found that introducing KC led to significant improvement of team performance. Coordination Theory and Shared Mental Models were then employed to provide an explanation as to why a KC leads to better project results. While this experiment was done within a data science project context, the results are likely applicable across a range of information system projects. © 2019, SciKA.",Agile; Kanban; Kanban process methodology; Process methodology; Project management; Team performance,"Shamshurin I., Saltz J.S.","Syracuse University, 343 Hinds Hall, Syracuse, NY  13210, United States",2019.0,International Journal of Information Systems and Project Management,SciKA,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070779562&doi=10.12821%2fijispm070204&partnerID=40&md5=a6d9b3209ad94393b6de99c5b1d5e201,10.12821/ijispm070204,20230520-160000,20230521-044735,"['using', 'a', 'coach', 'to', 'improve', 'team', 'performance', 'when', 'the', 'team', 'uses', 'a', 'kanban', 'process', 'methodology']",False,20230521-205332,,,,
217,scopus,Identifying and Addressing 6 Key Questions when Using Data Driven Scrum,"Data Driven Scrum (DDS) enables lean data science project agility and addresses the key challenges that have been identified when using Scrum in a data science context. However, little has been written with respect to the questions or challenges teams might encounter when trying to use DDS. Based on a survey of 18 team leads trying to use DDS, this paper describes six common questions teams might encounter when trying to implement DDS, as well as how to address these challenges. © 2021 IEEE.",,"Saltz J.S., Sutherland A., Jombart T.","Syracuse University, United States; Scrum Inc; London School of Hygiene Tropical Medicine",2021.0,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125360830&doi=10.1109%2fBigData52589.2021.9671930&partnerID=40&md5=def43fef3385d19c33704c2c595b0100,10.1109/BigData52589.2021.9671930,20230520-160000,20230521-044735,"['identifying', 'and', 'addressing', '6', 'key', 'questions', 'when', 'using', 'data', 'driven', 'scrum']",True,20230521-205332,,,,
218,scopus,Lessons learned to improve the UX practices in agile projects involving data science and process automation,"Context: User-Centered Design (UCD) and Agile methodologies focus on human issues. Nevertheless, agile methodologies focus on contact with contracting customers and generating value for them. Usually, the communication between end users (they use the software and have low decision power) and the agile team is mediated by customers (they have high decision power but do not use the software). However, they do not know the actual problems that end users (may) face in their routine, and they may not be directly affected by software shortcomings. In this context, UX issues are typically identified only after the implementation, during user testing and validation. Objective: Aiming to improve the understanding and definition of the problem in agile projects, this research investigates the practices and difficulties experienced by agile teams during the development of data science and process automation projects. Also, we analyze the benefits and the teams’ perceptions regarding user participation in these projects. Method: We collected data from four agile teams, in the context of an academia and industry collaboration focusing on delivering data science and process automation solutions. Therefore, we applied a carefully designed questionnaire answered by developers, scrum masters, and UX designers. In total, 18 subjects answered the questionnaire. Results: From the results, we identify practices used by the teams to define and understand the problem and to represent the solution. The practices most often used are prototypes and meetings with stakeholders. Another practice that helped the team to understand the problem was using Lean Inception (LI) ideation workshops. Also, our results present some specific issues regarding data science projects. Conclusion: We observed that end-user participation can be critical to understanding and defining the problem. They help to define elements of the domain and barriers in the implementation. We identified a need for approaches that facilitate user-team communication in data science projects to understand the data and its value to the users’ routine. We also identified insights about the need of more detailed requirements representations to support the development of data science solutions. © 2022 Elsevier B.V.",Agile; Data science; Lean inception; User experience; User involvement; User participation; User-centered design,"Ferreira B., Marques S., Kalinowski M., Lopes H., Barbosa S.D.J.","Departament of Informatics, Pontifical Catholic University of Rio de Janeiro, Rua Marques de Sao Vicente, 225/410, RDC, Gavea, Rio de Janeiro, Rio de Janeiro, 22451-900, Brazil",2023.0,Information and Software Technology,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145568139&doi=10.1016%2fj.infsof.2022.107106&partnerID=40&md5=e1f34b13a26ed1d8c5db7eb024963f24,10.1016/j.infsof.2022.107106,20230520-160000,20230521-044735,"['lessons', 'learned', 'to', 'improve', 'the', 'ux', 'practices', 'in', 'agile', 'projects', 'involving', 'data', 'science', 'and', 'process', 'automation']",False,20230521-205332,,,,
219,scopus,Exploring the challenges of integrating data science roles in agile autonomous teams,"The notion of autonomous teams is core to agile software development. However, autonomy in agile teams is challenged by increasingly complex software projects, large-scale agile and perhaps increasingly multidisciplinary teams. At the same time, data science roles are making their way into agile teams as companies seek to reap the potential advantages of using data to develop better and more competitive services and products. The consequences of implementing such roles in traditional agile teams are largely unknown. In this paper, we take an exploratory approach to the topic of data science roles in agile teams by a set of interviews with five data scientists as well as three members of an agile software development team. Based on the interviews we identify a set of challenges associated with incorporating the role in agile autonomous teams. Based on these challenges we discuss preliminary recommendations for companies seeking to integrate data science roles in agile teams. © The Author(s) 2019.",Agile; Autonomy; Data science; Software development; Teams,"Hukkelberg I., Berntzen M.","Department of Informatics, University of Oslo, Gaustadalléen 23B, Oslo, 0730, Norway",2019.0,Lecture Notes in Business Information Processing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072843077&doi=10.1007%2f978-3-030-30126-2_5&partnerID=40&md5=58b9cef0fe1330087bed95a07ae893b1,10.1007/978-3-030-30126-2_5,20230520-160000,20230521-044735,"['exploring', 'the', 'challenges', 'of', 'integrating', 'data', 'science', 'roles', 'in', 'agile', 'autonomous', 'teams']",False,20230521-205332,,,,
220,scopus,Rethinking data-driven decision support in flood risk management for a big data age,"Decision-making in flood risk management is increasingly dependent on access to data, with the availability of data increasing dramatically in recent years. We are therefore moving towards an era of big data, with the added challenges that, in this area, data sources are highly heterogeneous, at a variety of scales, and include a mix of structured and unstructured data. The key requirement is therefore one of integration and subsequent analyses of this complex web of data. This paper examines the potential of a data-driven approach to support decision-making in flood risk management, with the goal of investigating a suitable software architecture and associated set of techniques to support a more data-centric approach. The key contribution of the paper is a cloud-based data hypercube that achieves the desired level of integration of highly complex data. This hypercube builds on innovations in cloud services for data storage, semantic enrichment and querying, and also features the use of notebook technologies to support open and collaborative scenario analyses in support of decision making. The paper also highlights the success of our agile methodology in weaving together cross-disciplinary perspectives and in engaging a wide range of stakeholders in exploring possible technological futures for flood risk management. © 2020 The Authors. Journal of Flood Risk Management published by Chartered Institution of Water and Environmental Management and John Wiley & Sons Ltd.",big data; cloud computing; data hypercube; data science; flexible querying; semantic web; uncertainty,"Towe R., Dean G., Edwards L., Nundloll V., Blair G., Lamb R., Hankin B., Manson S.","School of Computing and Communications, Lancaster University, Lancaster, United Kingdom; Shell Research Ltd., London, United Kingdom; Environmental Data Science, UK Centre for Ecology & Hydrology, Lancaster, United Kingdom; JBA Trust, Skipton, United Kingdom; Lancaster Environment Centre, Lancaster University, Lancaster, United Kingdom; JBA Consulting, Warrington, United Kingdom; Flood & Coastal Risk Management Research, Environment Agency, Beverley, United Kingdom",2020.0,Journal of Flood Risk Management,Blackwell Publishing Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089290674&doi=10.1111%2fjfr3.12652&partnerID=40&md5=fa8e88e1f299ca8c1b2c1366b233b85e,10.1111/jfr3.12652,20230520-160000,20230521-044735,"['rethinking', 'data-driven', 'decision', 'support', 'in', 'flood', 'risk', 'management', 'for', 'a', 'big', 'data', 'age']",False,20230521-205332,,,,
221,scopus,The agile learning model: Using big data to personalise the acquisition of accounting skills,"Big data mirrors the accounting process to the extent that it deals with how we capture, categorise, summarise and report information so that users can make informed decisions. By modelling this process, we can both demonstrate the future of accounting to our students, and build an agile learning environment that identifies for a student their 'next crucial action' in the learning process. Presented in this paper is a pilot study. © ASCILITE 2015 - Australasian Society for Computers in Learning and Tertiary Education, Conference Proceedings.All right reserved.",Agile learning; Automated intervention; Education big data; Personalised learning,"Gregory B., Wysel M., Gregory S.","UNE Business School, University of New England, Australia; School of Education, University of New England, Australia",2019.0,"ASCILITE 2015 - Australasian Society for Computers in Learning and Tertiary Education, Conference Proceedings",Australasian Society for Computers in Learning in Tertiary Education (ASCILITE),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071727825&partnerID=40&md5=6c8f621714d688b0d9861b8659a184ac,,20230520-160000,20230521-044735,"['the', 'agile', 'learning', 'model:', 'using', 'big', 'data', 'to', 'personalise', 'the', 'acquisition', 'of', 'accounting', 'skills']",False,20230521-205332,,,,
222,scopus,Web services-based report generation system from big data in the manufacturing industry based on agile software development,"In the manufacturing industry, there are many information technology (IT) systems and machines connected to different databases with complex big data. In this study, the web service system is developed by using different programming languages consisting of C#, Javascript, HTML, CSS, Ext JS and structured query language (SQL). In addition to these programming languages, model view controller (MVC), a software design pattern is also used for developing a database interface. The development of this system allows the web service system to search for reports that meet the user needs and also has the user interface (UI) for convenience and speed. In this study, agile software development method is used in accordance with scrum framework, which consist of 4 steps: 1) product backlog creation, 2) sprint backlog creation, 3) sprint or the system development and testing and test case writing and 4) daily scrum. Sprint review is held to report the results of unit test, functional test, integration test and user acceptance test (UAT). This sprint review enables the development of an appropriate and comprehensive system and results in collaboration and understanding among stakeholders, including technology adoption among users. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Agile; Big Data; Web Services,"Kattiyawong P., Tangprasert S.","Department of Mathematics, Faculty of Applied Science, King Mongkut's University of Technology North Bangkok, 1518 Pracharat 1 Road, Wongsawang, Bangsue, Bangkok, 10800, Thailand",2020.0,ICEIS 2020 - Proceedings of the 22nd International Conference on Enterprise Information Systems,SciTePress,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090792650&partnerID=40&md5=6e97096fff6df9366c550c54e346da88,,20230520-160000,20230521-044735,"['web', 'services-based', 'report', 'generation', 'system', 'from', 'big', 'data', 'in', 'the', 'manufacturing', 'industry', 'based', 'on', 'agile', 'software', 'development']",False,20230521-205332,,,,
223,scopus,Using Agile Frameworks in Big Data projects,"Considering the main problems of Big Data projects-huge amounts of data, uncertainty and the need to take into account constant changes, the study decided to investigate the process of managing Big Data projects using Agile. The problem of choosing Agile techniques is complicated by the fact that each of the known frameworks has its own advantages and disadvantages. Depending on the type of project, a particular tool can influence various criteria for the success of the project. In addition, research has shown that some enterprises use separate elements of a particular framework. Therefore, the scientific novelty of the article lies in the study of the influence of individual elements of Agile techniques on the success of the project and its course. With the help of expert assessment in the work, a quantity of separate elements of Agile were formed. These techniques are the most common among practicing managers of Big Data project. The data were prepared to create a regression model. © 2021 IEEE.",Agile; Big Data; expert assessment; project management; questionnaire; statistics,"Kolesnikova K., Mezentseva O., Kolesnikov O., Obenewaa D.J.","Taras Shevchenko National University of Kyiv, Kyiv, Ukraine",2021.0,International Scientific and Technical Conference on Computer Sciences and Information Technologies,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124313416&doi=10.1109%2fCSIT52700.2021.9648622&partnerID=40&md5=da19e9d1303ccd2b13e22d47052ed46b,10.1109/CSIT52700.2021.9648622,20230520-160000,20230521-044735,"['using', 'agile', 'frameworks', 'in', 'big', 'data', 'projects']",True,20230521-205332,,,,
224,scopus,Agile manufacturing practices: the role of big data and business analytics with multiple case studies,"The purpose of this study was to examine the role of big data and business analytics (BDBA) in agile manufacturing practices. Literature has discussed the benefits and challenges related to the deployment of big data within operations and supply chains, but there has not been a study of the facilitating roles of BDBA in achieving an enhanced level of agile manufacturing practices. As a response to this gap, and drawing upon multiple qualitative case studies undertaken among four UK organisations, we present and validate a framework for the role of BDBA within agile manufacturing. The findings show that market turbulence has negative universal effects and that agile manufacturing enablers are being progressively deployed and aided by BDBA to yield better competitive and business performance objectives. Further, the level of intervention was found to differ across companies depending on the extent of deployment of BDBA, which accounts for variations in outcomes. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",agile manufacturing; big data and business analytics; competitive advantage; enablers; performance,"Gunasekaran A., Yusuf Y.Y., Adeleye E.O., Papadopoulos T.","School of Business and Public Administration, California State University, Bakersfield, CA, United States; School of Management, University of Central Lancashire, Preston, United Kingdom; Department of Business Administration, Elizade University, Ilara-Mokin, Nigeria; Kent Business School, University of Kent, Sail and Colour Loft, The Historic Dockyard, Chatham, United Kingdom",2018.0,International Journal of Production Research,Taylor and Francis Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032702646&doi=10.1080%2f00207543.2017.1395488&partnerID=40&md5=144587db68aae868013ae027cb8a540b,10.1080/00207543.2017.1395488,20230520-160000,20230521-044735,"['agile', 'manufacturing', 'practices:', 'the', 'role', 'of', 'big', 'data', 'and', 'business', 'analytics', 'with', 'multiple', 'case', 'studies']",False,20230521-205332,,,,
225,scopus,"CRISP-DM for Data Science: Strengths, Weaknesses and Potential Next Steps","This paper explores the strengths and weaknesses of CRISP-DM when used for data science projects. The paper then explores what key actions data science teams using CRISP-DM should consider that addresses CRISP-DM's weaknesses. In brief, CRISP-DM, which is the most popular framework teams use to execute data science projects, provides an easy to understand description of the data science project workflow (i.e., the data science life cycle). However, CRISP-DM's project phases miss some key aspects of the data science project life cycle. In addition, CRISP-DM's task-focused approach fails to address how a team should prioritize tasks, and in general, collaborate and communicate. Hence, this paper also describes how CRISP-DM could be combined with a team coordination framework, such as Scrum or Data Driven Scrum, which is a newer collaboration framework developed to address the unique data science coordination challenges. © 2021 IEEE.",,Saltz J.S.,"Syracuse University, United States",2021.0,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125312919&doi=10.1109%2fBigData52589.2021.9671634&partnerID=40&md5=10caae94486062574507f50ec5d6db53,10.1109/BigData52589.2021.9671634,20230520-160000,20230521-044735,"['crisp-dm', 'for', 'data', 'science:', 'strengths,', 'weaknesses', 'and', 'potential', 'next', 'steps']",True,20230521-205332,,,,
226,scopus,Big data analytics capability and co-innovation: An empirical study,"Business; Economics; Information science; Big data analytics capabilities; Co-innovation; Big data; Co-creation © 2019 The Author(s)There are numerous emerging studies addressing big data and its application in different organizational aspects, especially regarding its impact on the business innovation process. This study in particular aims at analyzing the existing relationship between Big Data Analytics Capabilities and Co-innovation. To test the hypothesis model, structural equations by the partial least squares method were used in a sample of 112 Colombian firms. The main findings allow to positively relate Big Data Analytics Capabilities with better and more agile processes of product and service co-creation and with more robust collaboration networks with stakeholders internal and external to the firm. © 2019 The Author(s)",Big data; Big data analytics capabilities; Business; Co-creation; Co-innovation; Economics; Information science,"Lozada N., Arias-Pérez J., Perdomo-Charry G.","Department of Administrative Sciences, University of Antioquia, Medellín, Colombia; Business School, CEIPA University, Medellín, Colombia",2019.0,Heliyon,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072856547&doi=10.1016%2fj.heliyon.2019.e02541&partnerID=40&md5=f1c8232de5dbd4d4ca195f3e14768fc8,10.1016/j.heliyon.2019.e02541,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'capability', 'and', 'co-innovation:', 'an', 'empirical', 'study']",False,20230521-205332,,,,
227,scopus,Agile Project Management Based on Data Analysis for Information Management Systems,"Nowadays, many projects and product managers, industry, and portfolio leads understand that data from the project or portfolio can be valuable for increasing their activities. There are many different types of project and portfolio lifecycle processes of managers daily duties: pre-sales and sales, mobilization, delivery, and closure phases. Definitely, in research, we focus on the processes, staffing, governance, and reporting activities. The day-by-day tasks are quite regulated and clearly described using templates and techniques as a company standard. Our literature review shows that Data Science methods can increase the level of project management and project success in several business problems. This study gives new opportunities to improve project management evaluation and results for managers, industry, and delivery leads. The proposed approach allows doing a project, portfolio management, and agile development more accurately, considering best practices and project performance data. Moreover, our results can provide more efficient benefits for different internal and external stakeholders. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Agile development; Data analysis; Data science; Lean; Machine learning; Project management; Safe; Scrum,"Haidabrus B., Grabis J., Protsenko S.","Riga Technical University, 1, Kalku Street, Riga, 1658, Latvia; Riseba University of Applied Science, 3, Meza Street, Riga, 1056, Latvia; Sumy State University, 2, Rymskogo-Korsakova Street, Sumy, 40007, Ukraine",2021.0,Lecture Notes in Mechanical Engineering,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110642204&doi=10.1007%2f978-3-030-77719-7_18&partnerID=40&md5=472c3196cd9d5f4a82bb0f612cbf7a63,10.1007/978-3-030-77719-7_18,20230520-160000,20230521-044735,"['agile', 'project', 'management', 'based', 'on', 'data', 'analysis', 'for', 'information', 'management', 'systems']",False,20230521-205332,,,,
228,scopus,Why we need a small data paradigm,"Background: There is great interest in and excitement about the concept of personalized or precision medicine and, in particular, advancing this vision via various 'big data' efforts. While these methods are necessary, they are insufficient to achieve the full personalized medicine promise. A rigorous, complementary 'small data' paradigm that can function both autonomously from and in collaboration with big data is also needed. By 'small data' we build on Estrin's formulation and refer to the rigorous use of data by and for a specific N-of-1 unit (i.e., a single person, clinic, hospital, healthcare system, community, city, etc.) to facilitate improved individual-level description, prediction and, ultimately, control for that specific unit. Main body: The purpose of this piece is to articulate why a small data paradigm is needed and is valuable in itself, and to provide initial directions for future work that can advance study designs and data analytic techniques for a small data approach to precision health. Scientifically, the central value of a small data approach is that it can uniquely manage complex, dynamic, multi-causal, idiosyncratically manifesting phenomena, such as chronic diseases, in comparison to big data. Beyond this, a small data approach better aligns the goals of science and practice, which can result in more rapid agile learning with less data. There is also, feasibly, a unique pathway towards transportable knowledge from a small data approach, which is complementary to a big data approach. Future work should (1) further refine appropriate methods for a small data approach; (2) advance strategies for better integrating a small data approach into real-world practices; and (3) advance ways of actively integrating the strengths and limitations from both small and big data approaches into a unified scientific knowledge base that is linked via a robust science of causality. Conclusion: Small data is valuable in its own right. That said, small and big data paradigms can and should be combined via a foundational science of causality. With these approaches combined, the vision of precision health can be achieved. © 2019 The Author(s).",Artificial intelligence; Data science; Personalized medicine; Precision health; Precision medicine; Small data,"Hekler E.B., Klasnja P., Chevance G., Golaszewski N.M., Lewis D., Sim I.","Center for Wireless and Population Health Systems, Department of Family Medicine and Public Health, Design Lab and Qualcomm Institute Faculty Member, UC San Diego, 9500 Gilman Ave, San Diego, CA  92093, United States; School of Information, University of Michigan, Ann Arbor, MI, United States; OpenAPS, Seattle, WA, United States; School of Medicine, UC San Francisco, San Francisco, CA, United States",2019.0,BMC Medicine,BioMed Central Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069510980&doi=10.1186%2fs12916-019-1366-x&partnerID=40&md5=61517534a35a607709742572a7c1fbef,10.1186/s12916-019-1366-x,20230520-160000,20230521-044735,"['why', 'we', 'need', 'a', 'small', 'data', 'paradigm']",False,20230521-205332,,,,
229,scopus,Research on Enterprise Agile High Potential Talent Identification System Based on Big Data Technology,"In the era of VUCA, enterprises need to quickly and accurately identify high-potential talents to achieve enterprise development and transformation. This article will talent radar, data, image, big data technologies, such as tendency analysis and Merce post evaluation methods, behavioral event interview, evaluation center technology and so on to carry on the organic combination, build agile high latent talent identification system, to establish high latent talent ability quality model, establish other agile high dive into the well path and the specification, as to provide theoretical basis for enterprise agile high latent talent identification. © 2021 IEEE.",competency model; high potential talents; talent recognition system; VUCA agile,"Yang M., Wang W.","Shanghai Sanda University, School of Management, Shanghai, China; Harbin University of Science and Technology, School of Economics and Management, Harbin, China",2021.0,"2021 9th International Conference on Orange Technology, ICOT 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126228254&doi=10.1109%2fICOT54518.2021.9680668&partnerID=40&md5=09368d941932ab72ffa4370224cd6d83,10.1109/ICOT54518.2021.9680668,20230520-160000,20230521-044735,"['research', 'on', 'enterprise', 'agile', 'high', 'potential', 'talent', 'identification', 'system', 'based', 'on', 'big', 'data', 'technology']",True,20230521-205332,,,,
230,scopus,"The application framework of big data technology in the COVID-19 epidemic emergency management in local government—a case study of Hainan Province, China","Background: As COVID-19 continues to spread globally, traditional emergency management measures are facing many practical limitations. The application of big data analysis technology provides an opportunity for local governments to conduct the COVID-19 epidemic emergency management more scientifically. The present study, based on emergency management lifecycle theory, includes a comprehensive analysis of the application framework of China’s SARS epidemic emergency management lacked the support of big data technology in 2003. In contrast, this study first proposes a more agile and efficient application framework, supported by big data technology, for the COVID-19 epidemic emergency management and then analyses the differences between the two frameworks. Methods: This study takes Hainan Province, China as its case study by using a file content analysis and semistructured interviews to systematically comprehend the strategy and mechanism of Hainan’s application of big data technology in its COVID-19 epidemic emergency management. Results: Hainan Province adopted big data technology during the four stages, i.e., migration, preparedness, response, and recovery, of its COVID-19 epidemic emergency management. Hainan Province developed advanced big data management mechanisms and technologies for practical epidemic emergency management, thereby verifying the feasibility and value of the big data technology application framework we propose. Conclusions: This study provides empirical evidence for certain aspects of the theory, mechanism, and technology for local governments in different countries and regions to apply, in a precise, agile, and evidence-based manner, big data technology in their formulations of comprehensive COVID-19 epidemic emergency management strategies. © 2021, The Author(s).",Application framework; Big data technology; China; COVID-19; Emergency management; Hainan Province; Local government,"Mao Z., Zou Q., Yao H., Wu J.","College of Public Administration, Huazhong University of Science and Technology, No 1037 Luau Road, Hongshan District, Wuhan, Hubei  430074, China; Non-traditional Security Institute, Huazhong University of Science and Technology, Wuhan, Hubei  430074, China",2021.0,BMC Public Health,BioMed Central Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118708006&doi=10.1186%2fs12889-021-12065-0&partnerID=40&md5=973914ab141b9d64b6a79243c62d24ea,10.1186/s12889-021-12065-0,20230520-160000,20230521-044735,"['the', 'application', 'framework', 'of', 'big', 'data', 'technology', 'in', 'the', 'covid-19', 'epidemic', 'emergency', 'management', 'in', 'local', 'government—a', 'case', 'study', 'of', 'hainan', 'province,', 'china']",False,20230521-205332,,,,
231,scopus,Toward an Understanding of Big Data Analytics and Competitive Performance,"The most significant enterprise system topic over the last decade is business intelligence and analytics. Big data analytics is now viewed as a disruptive technology that will significantly transform business intelligence and analytics. Therefore, big data technology, as a way to analyze and comprehend turbulent environments, has attracted huge interest from researchers and practitioners. Such environments are highly challenging for enterpris-es; how can they deal with such turbulence and stay competitive? The valuable information that this technology can offer seems almost limitless. Can big data help organizations deal with turbulent environments, and if so, how? We address this question by closely examining the relations between (1) big data analytics capabilities and dynamic capabilities, (2) dynamic capabilities and competitive performance, (3) big data analytics capabilities and operational capabilities, and (4) operational capabilities and competitive performance. Big data analytics capabilities are necessary to use big data effectively. We developed a model with four hypotheses to investigate these relations. We conducted a survey among 107 respondents from the largest companies in the Nordic countries. All but one of our hypotheses were supported. This research contributes to a better understanding of how big data analytic investments support agile capabilities, in turn promoting competitive performance. © Scandinavian Journal of Information Systems,.",big data analytics; big data analytics capabilities; competitive performance; dynamic capabilities; operational capabilities,"Danielsen F., Olsen D., Framnes V.A.","Department of Information Systems, University of Agder, Kristiansand, Norway; TietoEVRY, Kristiansand, Norway",2021.0,Scandinavian Journal of Information Systems,IRIS Association,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126451031&partnerID=40&md5=979377e5180e85604c23b96dfe46c4fa,,20230520-160000,20230521-044735,"['toward', 'an', 'understanding', 'of', 'big', 'data', 'analytics', 'and', 'competitive', 'performance']",False,20230521-205332,,,,
232,scopus,"Big Data Hysteria, Cognizance and Scope","In real time scenario, every second man and machine have been generating a huge amount of data. Social networking sites like Facebook, tweeter, Instagram, search engine google, yahoo and video shearing websites like YouTube and many real time applications generates enormous quantity of data. These data-sets have different attributes (i.e. volume, velocity, complexity etc.) in it, known as 'Big Data'. To manage, process and analyze big data, we require advance hardware platform, software stack and analytics techniques. Big data Analytics emerges as a major application for future data-sets, generating by parallel and distributes systems. This paper has discussed about hype on Big Data, its characteristics, different considerations (i.e. Hardware, Software, Platform, N oSql Data Base, Languages). It has summarized the Techniques of Big Data and light up on scope with other technologies (i.e. IoT, Agile, Lean Six Sigma). © 2018 IEEE.",Analytics techniques; Big Data; Big Data Management; Inherent properties; Volume,"Harsh R., Acharya G., Chaudhary S.","CSE Dept, Bikaner, Rajasthan, India; Industrial Engg Management, Jaipur, Rajasthan, India",2018.0,"2018 4th International Conference for Convergence in Technology, I2CT 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084130212&doi=10.1109%2fI2CT42659.2018.9057878&partnerID=40&md5=fc3db82fb60caff8e153423294930679,10.1109/I2CT42659.2018.9057878,20230520-160000,20230521-044735,"['big', 'data', 'hysteria,', 'cognizance', 'and', 'scope']",True,20230521-205332,,,,
233,scopus,Analysis of Software Engineering for Agile Machine Learning Projects,"The number of machine learning, artificial intelligence or data science related software engineering projects using Agile methodology is increasing. However, there are very few studies on how such projects work in practice. In this paper, we analyze project issues tracking data taken from Scrum (a popular tool for Agile) for several machine learning projects. We compare this data with corresponding data from non-machine learning projects, in an attempt to analyze how machine learning projects are executed differently from normal software engineering projects. On analysis, we find that machine learning project issues use different kinds of words to describe issues, have higher number of exploratory or research oriented tasks as compared to implementation tasks, and have a higher number of issues in the product backlog after each sprint, denoting that it is more difficult to estimate the duration of machine learning project related tasks in advance. After analyzing this data, we propose a few ways in which Agile machine learning projects can be better logged and executed, given their differences with normal software engineering projects. © 2018 IEEE.",agile methodology; machine learning project; scrum; software engineering,"Singla K., Bose J., Naik C.","Samsung R and D Institute, Bangalore, India",2018.0,INDICON 2018 - 15th IEEE India Council International Conference,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082604564&doi=10.1109%2fINDICON45594.2018.8987154&partnerID=40&md5=7d124c646dfce11a36e539d325f690af,10.1109/INDICON45594.2018.8987154,20230520-160000,20230521-044735,"['analysis', 'of', 'software', 'engineering', 'for', 'agile', 'machine', 'learning', 'projects']",True,20230521-205332,,,,
234,scopus,Panel: Addressing the Shortage of Big Data Skills with Inter-Disciplinary Big Data Curriculum,"One major challenge faced by enterprises in contemporary era is the shortage of big data and analytics (BDA) professionals. These professionals possess skills to analyze and derive intelligence from big data generated by enterprises. Currently, universities and colleges have not been able to produce sufficient professionals to meet the ever-growing demand for data analytics skill sets. A possible reason for this may be the narrow focus and lack of interdisciplinary approach to big data analytics education. To address this challenge, this panel brings together practitioners, researchers and educators in big data and analytics; to explore the potentials for developing an interdisciplinary curriculum that will deliver data analytics skills to students across all other academic majors. This might help to produce more agile data analytics professionals and close the gap between demand and supply of those professionals. © 2019 IEEE.",Analytics; Big Data; Curriculum; Education,"Nwokeji J.C., Stachel R., Holmes T., Aqlan F., Udenze E.C., Orji R.","Gannon University, Compt. Infor. Sci. Dept, Erie, PA, United States; Gannon University, School of Business, Erie, PA, United States; Penn. State Uni, Industrial Engr. Dept, Erie, PA, United States; Yakima Valley College, Physical Sciences Dept, Yakima, WA, United States; Dalhousie University, Computer Science Dept, Halifax, Canada",2019.0,"Proceedings - Frontiers in Education Conference, FIE",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082438137&doi=10.1109%2fFIE43999.2019.9028350&partnerID=40&md5=a044ddbf386ed06644e76d5d551de3fb,10.1109/FIE43999.2019.9028350,20230520-160000,20230521-044735,"['panel:', 'addressing', 'the', 'shortage', 'of', 'big', 'data', 'skills', 'with', 'inter-disciplinary', 'big', 'data', 'curriculum']",True,20230521-205332,,,,
235,scopus,"Big Data Analytics as a mediator in Lean, Agile, Resilient, and Green (LARG) practices effects on sustainable supply chains","The effect of big data on the lean, agile, resilient, and green (LARG) supply chain has not been explored much in the literature. This study investigates the role of ‘Big Data Analytics’ (BDA) as a mediator between ‘sustainable supply chain business performance’ and key factors, namely, lean practices, social practices, environmental practices, organisational practices, supply chain practices, financial practices, and total quality management. A sample of 297 responses from thirty-seven Indian manufacturing firms was collected. The paper is beneficial for managers and practitioners to understand supply chain analytics, and it addresses challenges in the management of LARG practices to contribute to a sustainable supply chain. © 2020 Elsevier Ltd",Big data analytics; Business performance and innovation; LARG; Manufacturing firms; Supply chain and logistics management; Sustainability,"Raut R.D., Mangla S.K., Narwane V.S., Dora M., Liu M.","Dept. of Operations and Supply Chain Management, National Institute of Industrial Engineering (NITIE), Vihar Lake, NITIE, Powai, Mumbai, Maharashtra  400087, India; Knowledge Management and Business Decision Making, Plymouth Business School, University of PlymouthPL4 8AA, United Kingdom; Dept. of Mechanical Engineering, K. J. Somaiya College of Engineering, Vidyanagar, Vidya Vihar East, Ghatkopar East, Mumbai, Maharashtra  400077, India; Operations and Supply Chain Management, Brunel Business School, Brunel University London, United Kingdom; Business School, Hunan University, Changsha, China",2021.0,Transportation Research Part E: Logistics and Transportation Review,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097784905&doi=10.1016%2fj.tre.2020.102170&partnerID=40&md5=d1de929113a08514566f4066b45daf61,10.1016/j.tre.2020.102170,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'as', 'a', 'mediator', 'in', 'lean,', 'agile,', 'resilient,', 'and', 'green', '(larg)', 'practices', 'effects', 'on', 'sustainable', 'supply', 'chains']",False,20230521-205332,,,,
236,scopus,Open Data Lake to Support Machine Learning on Arctic Big Data,"The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data. © 2021 IEEE.",Arctic data; Arctic expedition; big data; CARE principle; data lake; data management; data mining; FAIR principle; machine learning; open data; reusability,"Olawoyin A.M., Leung C.K., Cuzzocrea A.","University of Manitoba, Department of Computer Science, Winnipeg, MB, Canada; IDEA Lab, University of Calabria, Rende, Italy",2021.0,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125329937&doi=10.1109%2fBigData52589.2021.9671453&partnerID=40&md5=e7a99b9e1f98eb4ec73bc51f52d469ec,10.1109/BigData52589.2021.9671453,20230520-160000,20230521-044735,"['open', 'data', 'lake', 'to', 'support', 'machine', 'learning', 'on', 'arctic', 'big', 'data']",True,20230521-205332,,,,
237,scopus,A framework to data delivery security for big data annotation delivery system,"Big data annotation plays an important role in Artificial Intelligence model training. The proliferation of data annotation tasks has brought the issue of security of the big data delivery. This work identifies the security framework associated with encryption and compression procedures that support data delivery safety. In this paper, we propose an agile framework that caters to various types of data under RESTful web services. All the procedures are automatically operated by the server without human intervention. This work assists the company delivers the tagged data products to users with a high-security level avoiding the risk of information disclosure. © 2018 IEEE.",Compression; Data delivery; Encryption; Keywords—Big data; Lightweight framework,"Yang Y., He H., Wang D., Ding Z.","Information School, Beijing Institute of Graphic Communication, Beijing, China; Datatang (Beijing) Technology Company, Limited, Beijing, China",2018.0,"Proceedings - 15th IEEE International Conference on Mobile Ad Hoc and Sensor Systems, MASS 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060260827&doi=10.1109%2fMASS.2018.00082&partnerID=40&md5=7b06fc8091a2b0b9f339fb9bd08070d7,10.1109/MASS.2018.00082,20230520-160000,20230521-044735,"['a', 'framework', 'to', 'data', 'delivery', 'security', 'for', 'big', 'data', 'annotation', 'delivery', 'system']",True,20230521-205332,,,,
238,scopus,Agile business intelligence: Combining big data and business intelligence to responsive decision model,"Big data and instant information on the external environment of enterprises are critical for decisionmaking; however, little attention is paid to contemporary business intelligence (BI) theories and practices. This study proposes a new business decision model, agile BI (ABI), which integrates external big data and internal BI to facilitate decision-making for enterprises in a dynamic and rapidly changing environment. This novel model presents two contributions to research in this field: (1) it proposes a new architecture combining external and internal information and (2) it integrates external big data, such as hot searches, social media, news, popular issues, and competitors' information, to increase the accuracy of BI. This study takes international expansion as an example and simulates the international investment decisions of Taiwanese firms by importing data from a search engine, competitors, and firm-specific datasets. The results show that the proposed ABI model not only responds quickly to the external environment but also enhances decision-making efficiently. © 2018 Taiwan Academic Network Management Committee. All rights reserved.",Big data; Business intelligence; Decision making,Chang B.-J.,"Department of Business Administration, Feng Chia University, Taiwan",2018.0,Journal of Internet Technology,Taiwan Academic Network Management Committee,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060736035&doi=10.3966%2f160792642018111906007&partnerID=40&md5=a7b40da0ba354a23b17248a909106c04,10.3966/160792642018111906007,20230520-160000,20230521-044735,"['agile', 'business', 'intelligence:', 'combining', 'big', 'data', 'and', 'business', 'intelligence', 'to', 'responsive', 'decision', 'model']",False,20230521-205332,,,,
239,scopus,Nursing Value User Stories: A Value Measurement Method for Linking Nurse Contribution to Patient Outcomes,"The use of nursing big data sets for value-based measurement is novel. Nursing value measurement depends on the availability of essential data attributes in the electronic health record related to nursing care delivered (what happened, when, and the result seen). Key in measuring value is a standardized structure and format of these attributes for enabling uniform consistent analysis, along with data sets that are sharable and comparable across individuals and groups, time, organization, and practice focus. The foundation of such sharable and comparable data sets would represent at a minimum individual essential nurse care actions and the resulting patient outcome(s). While nurses generate an extraordinary amount of health-related data, healthcare information systems are not designed to collect structured data that reflect the unique attributes of nursing care or support nursing analytic activities that would measure value. More important, the multidimensional features of the nursing process are difficult to untangle and differentiate from other healthcare workers and nonnursing care activities. The complexity of nursing knowledge work has limited the development of nursing data science methods like value measurement and discouraged value versus cost discussions. This article sets out to describe nursing value measurement and an approach that nurse scientists are maximizing through methods adapted from agile project management, including user stories, and business analysis processes to recognize nurses as primary contributors to patient outcomes and value generation. Nursing Value User Story methods deconstruct complex nursing scenarios into user stories that capture nursing actions as standardized data that can be mapped to a common nursing data model. Methods described here are being used in pilot research at Los Angeles Children's Hospital, and results will be available in 2019. © 2019 Wolters Kluwer Health, Inc. All rights reserved.",Clinical data model; Hospital administration; Nurse cost models; Nurse value; Nursing administration; Nursing user stories; Risk-sharing arrangements; Value-based care,"Moon L.A., Clancy G., Welton J., Harper E.","School of Nursing, University of Minnesota, 308 Harvard St SE, Minneapolis, MN  55455, United States; Advocate Consulting, Apple ValleyMN, United States; School of Nursing, University of Colorado-Denver, United States; University of Kansas, School of Nursing, Kansas City, United States",2019.0,CIN - Computers Informatics Nursing,Lippincott Williams and Wilkins,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062422002&doi=10.1097%2fCIN.0000000000000520&partnerID=40&md5=c816a5fbe2da3ce5a430b3aa01a0ffa3,10.1097/CIN.0000000000000520,20230520-160000,20230521-044735,"['nursing', 'value', 'user', 'stories:', 'a', 'value', 'measurement', 'method', 'for', 'linking', 'nurse', 'contribution', 'to', 'patient', 'outcomes']",False,20230521-205332,,,,
240,scopus,Smart water quality analysis using IoT and big data analytics: A review,"In recent times, water quality monitoring, observing, and testing have become a significant research study with the advancement on the Internet of Things, and Big Data analytics research ideas. The relationship between water demand and supply is very crucial for every country and is likewise a complex challenge to satisfy this requirement around the world. Water is compulsory for human survival being on the earth. Therefore, for survival, the preservation and taking care of the existing water resource are also equally substantial. Moreover, for a healthier society, access to clean and safe water resources is also imperative. To recognize the water quality effects and provide an automated water quality mentoring and a testing system can support in guaranteeing the safety of the water. This paper presents a study on water quality analysis using IoT and Big Data analytics. This can help in developing an agile environment that can handle the massive flow of water big data generated by the smart sensors spread everywhere around us. © 2021 IEEE.",And Big Data Analytics; Ater Quality; Cloud Computing; Internet of Things,"Hemdan E.E.-D., Essa Y.M., El-Sayed A., Shouman M., Moustafa A.N.","Menofia University, Computer Science and Engineering Department, Faculty of Electronic Engineering, Menouf, Egypt; Principle Data and Knowledge. Bayer, Berlin, Germany",2021.0,ICEEM 2021 - 2nd IEEE International Conference on Electronic Engineering,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114214294&doi=10.1109%2fICEEM52022.2021.9480628&partnerID=40&md5=2c1cf46d2d48b7f9c57428e527d80d02,10.1109/ICEEM52022.2021.9480628,20230520-160000,20230521-044735,"['smart', 'water', 'quality', 'analysis', 'using', 'iot', 'and', 'big', 'data', 'analytics:', 'a', 'review']",True,20230521-205332,,,,
241,scopus,How big data analytics improve supply chain performance: Considering the roles of supply chain and is strategy,"This paper aims to examine the relationship between big data analytics (BDA) and supply chain (SC) performance. Drawing on the dynamic capabilities theory, we hypothesize that supply chain strategy (i.e., lean and agile supply chain strategy) will positively mediate the relationship between BDA and SC performance. Further, from the perspective of strategy alignment, we also hypothesize that the effect of supply chain strategy on SC performance will be moderated by IS strategy (i.e., IS innovator and IS conservative strategy). Our study uses 159 match-paired questionnaires collected from Chinese firms to empirically test the hypotheses. This paper explains how BDA can improve SC performance and reveals the interaction effect of IS strategy and supply chain strategy on SC performance, which contributes to theoretical and practical implications. © ICIS 2020. All rights reserved.",Agile supply chain strategy; Big data analytics; IS conservative strategy; IS innovator strategy; Lean supply chain strategy; Supply chain performance,"Chen W., Wei S., Yin J., Chen X.","School of Management, University of Science and Technology of China, 96 Jinzhai Road, Anhui, Hefei  230026, China; School of Management, Hefei University of Technology, Hefei, Anhui  230009, China",2020.0,"International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global",Association for Information Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103444769&partnerID=40&md5=b247dce725cb621b5e2b8a8776a11072,,20230520-160000,20230521-044735,"['how', 'big', 'data', 'analytics', 'improve', 'supply', 'chain', 'performance:', 'considering', 'the', 'roles', 'of', 'supply', 'chain', 'and', 'is', 'strategy']",False,20230521-205332,,,,
242,scopus,Development of human faces retrieval in a big photo database with SCRUM: A case study,"In this paper we present a case study of the use of SCRUM in an applied research scenario, consisting of the detection and identification of human faces in a large database of photos. The study shows how the adoption of agile methods was important to deal with uncertainty and unstable requirements, allowing adaptable development with opportunity to learn from the development process. The implementation of experiments reveals, as our research advances, the applicability of techniques to support the solution for the requirements. All sort of problems with illumination, pose, low quality of image and other type of noise were present as obstacles to accuracy in different approaches for detection and recognition. Fast retrieval of similar faces was also necessary. In the end, the requirements were successfully tackled by developing an efficient and short implementation of face alignment, feature extraction and search. © Springer International Publishing AG 2018.",Agile methodology; Big data; Face detection; Face recognition; SCRUM,"Pivetta T.A., Forster C.H.Q., Dias L.A.V., Guerra E.M.","Instituto Tecnologico de Aeronautica, ITA, Sao Jose dos Campos, Sao Paulo, Brazil; Instituto Nacional de Pesquisa Espacial, INPE, Sao Jose dos Campos, Sao Paulo, Brazil",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048501559&doi=10.1007%2f978-3-319-54978-1_122&partnerID=40&md5=f85fed6ecf0688c671a227619e9f3b6d,10.1007/978-3-319-54978-1_122,20230520-160000,20230521-044735,"['development', 'of', 'human', 'faces', 'retrieval', 'in', 'a', 'big', 'photo', 'database', 'with', 'scrum:', 'a', 'case', 'study']",False,20230521-205332,,,,
243,scopus,The Effect of Big Data Analytics in Enhancing Agility in Cybersecurity Incident Response,"The ongoing automation of business operations is putting enterprises at risk of cyber attacks more than ever before. Incident response teams are employed by the enterprises for the identification, management, and elimination of cybersecurity attacks along with for the recovery of business operations timely and effectively. In this paper, we argue that to effectively react to the cybersecurity attacks enterprises should build agility in their incident response method and big data analytics performs an effective role in developing agility in incident response. Grounded on twenty-one in depth expert interviews, we develop a framework that explains the salient features and effect of big data analytics in the incident response method at three stages, i.e., manual analysis, basic analysis, and advanced analysis. The agile properties of flexibility, innovation and swiftness are instilled in the incident response method by practicing big data analytics at higher stages of analysis. The results informed that the key features of big data analytics can be firstly utilize to estimate the existing analytical capability and secondly as an assisting tool to enhance incident response method capability. © 2022 IEEE.",agility; analytical capability; Big data analytics; cybersecurity; incident response,"Naseer A., Siddiqui A.M.","National University of Sciences and Technology, Department of Computer Software Engineering, Islamabad, Pakistan; National University of Sciences and Technology, Department of Electrical Engineering, Islamabad, Pakistan",2022.0,"2022 16th International Conference on Open Source Systems and Technologies, ICOSST 2022 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147664943&doi=10.1109%2fICOSST57195.2022.10016853&partnerID=40&md5=b1f9d4608413636b9f6b0bba461430ca,10.1109/ICOSST57195.2022.10016853,20230520-160000,20230521-044735,"['the', 'effect', 'of', 'big', 'data', 'analytics', 'in', 'enhancing', 'agility', 'in', 'cybersecurity', 'incident', 'response']",True,20230521-205332,,,,
244,scopus,The era of big data and path towards sustainability,"This paper is an attempt to throw light on the applications of big data analytics in nurturing sustainable develoment through a descriptive metadata study. Big data is widely used in many areas such as hospitality, transporataion, health, governance, e-commerce etc. Common applications of big data include consumer profiling, personalised pricing, marketing, advertising and predictive analysis. One of the formidable challanges confronted by the businesses in the contemporary period is to reconcile the conflicting interests of profit maximisation and fostering sustainability. The unprecedented magnitude of data generated within the organisations do have the potential to bring gainful insights for efficient resource utilisation and waste minimisation. The advent of big data aids in making these conflicting interests complementary by providing efficient and precise predicitions. A number of studies are going on to explore possible options avialable to leverage big data analytics to create social and environmental value. Novel analytical approaches, enormous amounts of data and new technology would help in gaining insights to frame more agile and efficient policies to protect the environment. This paper discusses how big data is applied in different areas to foster sustainability. © 2018 Elsevier Ltd. All rights reserved.",Big data; Gartner's model; Sustainability,"Victor V., Maria F.F.","Szent István University, Hungary; Gödöllő, Hungary",2018.0,"Proceedings of the 31st International Business Information Management Association Conference, IBIMA 2018: Innovation Management and Education Excellence through Vision 2020","International Business Information Management Association, IBIMA",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060782789&partnerID=40&md5=a8f0113ee7f3e7334ebab2bc78520c72,,20230520-160000,20230521-044735,"['the', 'era', 'of', 'big', 'data', 'and', 'path', 'towards', 'sustainability']",False,20230521-205332,,,,
245,scopus,Toward Automatized Handling of Future Agile Networks Employing Various Optical Switching Functionalities,"Various optical switch systems will be required to support future wide application network areas having different requirements. A bottom-up modeling approach which will realize a common platform for automatized operation of physical layer is discussed. © 2019 The Institute of Electronics, Information and Communication Engineers (IEICE).",Photonic Networking/Switching System Designs and Architectures for Computing and Big Data; Software defined networking (SDN) for computing and big data control,"Ishii K., Namiki S.","National Institute of Advanced Industrial Science and Technology (AIST), Umezono 1-1-1 Central 2, Tsukuba, 305-8568, Japan",2019.0,OECC/PSC 2019 - 24th OptoElectronics and Communications Conference/International Conference Photonics in Switching and Computing 2019,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072333232&doi=10.23919%2fPS.2019.8818061&partnerID=40&md5=c34f299f9fce2db41320d11fd465bbb9,10.23919/PS.2019.8818061,20230520-160000,20230521-044735,"['toward', 'automatized', 'handling', 'of', 'future', 'agile', 'networks', 'employing', 'various', 'optical', 'switching', 'functionalities']",True,20230521-205332,,,,
246,scopus,IoT Agile Framework Enhancement,"Internet of Things (IoT) is considered as a trend nowadays. Devices connected to the internet interact with surrounding; this poses strong challenges in handling big data with a certain level of security. In this paper IoT devices will be divided in to two categories high vulnerability devices and low vulnerability devices. The classification depends on the ease of attacks. In order to ensure the security of IoT devices, an agile approach is used to secure high vulnerability devices as first step and then low vulnerability devices by applying encryption algorithms. © 2018 IEEE.",Agile approach; Encryption algorithms; Internet of Things,"Gabr B., Azer M.A.","Wireless Intelligent Networks Centre (WINC), Nile University, Egypt; National Telecommunication Institute, Nile University, Egypt",2018.0,"1st International Conference on Computer Applications and Information Security, ICCAIS 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053551091&doi=10.1109%2fCAIS.2018.8441993&partnerID=40&md5=2a6097f6e8c81f2123ab4624d52130da,10.1109/CAIS.2018.8441993,20230520-160000,20230521-044735,"['iot', 'agile', 'framework', 'enhancement']",True,20230521-205332,,,,
247,scopus,Health Care Information Systems: A Crisis Approach,"During the 1st Semester of 2017, at the BrazilianAeronautics Institute of Technology (Instituto Tecnologico de Aeronautica, ITA), a successful Interdisciplinary Problem-Based Learning (IPBL) experience took place. At that time, almost 30 undergraduate and graduate students from three different courses within just 17 academic weeks had the opportunity of conceptualizing, modeling, and developing a Computer System based on Big Data, Internet of Things, and other emerging technologies for governmental organizations and private sectors. The purpose of this system was to aggregate data and integrate actors, such as Patients, Hospitals, Physicians, and Suppliers for decision making processes related to crises management involving events of health systems, such as epidemics, that needs to manage data and information. Differently from other existing products from Universities, Research Centers, Governmental Agencies, Public and/or Private companies, this product was developed and tested in just 17 academic weeks, applying the Scrum agile method and its best practices available in the market. This experience was stored in a Google site and implemented as a Proof of Concept (PoC). It represents just one example of how to address the old problems of teaching, learning, and developing complex intelligent academic computer projects to solve health system problems, by collaboratively using the Scrum agile method with Python or Java, Spark, NoSQL databases, Kafka, and other technologies. The major contribution of this paper is the use of agile testing to verify and validate an academic health system case study. © 2018, Springer International Publishing AG, part of Springer Nature.",Agile method; Agile testing; Big Data; Health system; Internet of Things (IoT); Predictive models; Problem-Based Learning (PBL),"da Silva D.A., Goncalves G.S., dos Santos S.C., Pugliese V.U., Navas J., de Barros Santana R.M., Queiroz F.S., Dias L.A.V., da Cunha A.M., Tasinaffo P.M.","Computer Science Department, Brazilian Aeronautics Institute of Technology (Instituto Tecnológico de Aeronáutica—ITA), Sao Jose dos Campos, Sao Paulo, Brazil",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045851932&doi=10.1007%2f978-3-319-77028-4_34&partnerID=40&md5=848c230639778cff543067bb0516f2c3,10.1007/978-3-319-77028-4_34,20230520-160000,20230521-044735,"['health', 'care', 'information', 'systems:', 'a', 'crisis', 'approach']",False,20230521-205332,,,,
248,scopus,How to conduct big data projects: Methods overview and industrial feedback [Synthèse des méthodes de conduite de projets big data et des retours collectés lors de pilotes industriels],"Companies are increasingly faced with the challenge of handling increasing and even massive amounts of digital data. Although Big Data technical solutions are available, many companies are struggling to deploy them because of a lack of maturity related to their management. This paper aims at improving guidance in this area based on a series of methodological brick documented in the literature from data mining projects to nowadays. It is complemented by lessons learned from pilots conducted in four key areas (IT, health, space, food industry). They give a concrete vision of how to implement the requirements gathering and data understanding steps with a focus on the identification of value, the definition of a relevant strategy and an agile follow-up to also manage the rise in maturity. c 2018 Lavoisier",Adoption process; Agile Methods; Big Data; Case study.; Projet management,"Ponsard C., Touzani M., Majchrowski A.","CETIC - Centre de recherche, Gosselies, Belgium; Docteur en Informatique, Toulouse, France",2018.0,Ingenierie des Systemes d'Information,Lavoisier,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056081990&doi=10.3166%2fISI.23.1.9-33&partnerID=40&md5=9b617b4f66290dd4665cb584f60081cf,10.3166/ISI.23.1.9-33,20230520-160000,20230521-044735,"['how', 'to', 'conduct', 'big', 'data', 'projects:', 'methods', 'overview', 'and', 'industrial', 'feedback', '[synthèse', 'des', 'méthodes', 'de', 'conduite', 'de', 'projets', 'big', 'data', 'et', 'des', 'retours', 'collectés', 'lors', 'de', 'pilotes', 'industriels]']",False,20230521-205332,,,,
249,scopus,Towards microservice identification approaches for architecting data science workflows,"In order to support fast development cycles and deploying software components in productive environments, there are three crucial trends in data science. These are agile process models, development of many technologies and increasing usage of cloud platforms. Therefore, effective architectures are needed to support this trend in data science context. This paper explores and evaluates first approaches for, why and how microservice architecture style can support fast development cycles for data science workflows. Microservices are becoming a popular architectural style for designing modern applications due to several advantages like scalability, reliability and maintainability. First, this paper points out the research gap on why microservices could be a suitable way to design data science workflows. Second, it defines relevant research questions for future research that addresses challenges of the microservice architectural style in the data science context. An essential prerequisite for this architecture style is to identify the “right context” of a microservice for data science workflows. © 2021 The Authors. Published by Elsevier B.V.",Data science workflows; Microservice; Microservice identification; Software architecture,Schröer C.,"Volkswagen Aktiengesellschaft, Berliner Ring 2, Wolfsburg, 38440, Germany; University of Oldenburg, Ammerländer Heerstr. 114-118, Oldenburg, 26129, Germany",2021.0,Procedia Computer Science,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105650172&doi=10.1016%2fj.procs.2021.01.198&partnerID=40&md5=9fe37879dd29efe88c6e8cbed6e5f4d6,10.1016/j.procs.2021.01.198,20230520-160000,20230521-044735,"['towards', 'microservice', 'identification', 'approaches', 'for', 'architecting', 'data', 'science', 'workflows']",False,20230521-205332,,,,
250,scopus,Drilling performance improvement through use of artificial intelligence in bit and bottom hole assembly selection in gulf of Thailand,"This paper describes a method of transforming legacy manual bit/BHA planning process into a digital solution to enhance drilling assembly selection efficiency and consistency. The solution presented improves overall capital stewardship thru an effective and semi-automated use of data to deliver high quality decisions and improve decision consistency across drilling applications and drive drilling performance. Data science and machine learning is applied to streamline the data preparation process and present to the user a statistically sound drilling assembly solution for the drilling environment input. A large +6000 well database is used to explore alternatives and rank potential solutions using performance and directional compatibility characteristics unique to the Gulf of Thailand. The digital project goal presented is two-fold. The first is to streamline all related data and decision processes in the office to improve work efficiency and information accessibility. The second goal is to improve field drilling performance by installation of a self-learning advisory tool. There is a requirement for multiple sub-processes to work in parallel. The population of data in the database and quality checks must be automated to handle hourly/daily data updates. A system for auto-loading drilling data from rigsite was created. A second system containing data science and machine learning was created to identify similar wells, rank their respective performance and directional compatibility to a future well of interest, and offer a statistically relevant solution recommendation. A benefit of such a system is a more efficient workflow with improved field drilling results while effectively capturing Chevron Thailand methods for many drilling engineers to use in the future. Adopting agile concept during development phase is one of the keys to success for this project. Additionally, utilization of digital transformation technology is a key enabler to handle big data, data science and data foundation. © 2021, IADC/SPE Asia Pacific Drilling Technology Conference",,"Tortrakul N., Pochan C., Southland S., Mala P., Pichaichanlert T., Tangsawanich Y.","Chevron Thailand Exploration and Production, LTD; Chevron Upstream Drilling and Completions",2021.0,"Proceedings of the IADC/SPE Asia Pacific Drilling Technology Conference, APDT",Society of Petroleum Engineers (SPE),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113921783&partnerID=40&md5=b05d3d624cb61741279baf8cc78205d5,,20230520-160000,20230521-044735,"['drilling', 'performance', 'improvement', 'through', 'use', 'of', 'artificial', 'intelligence', 'in', 'bit', 'and', 'bottom', 'hole', 'assembly', 'selection', 'in', 'gulf', 'of', 'thailand']",False,20230521-205332,,,,
251,scopus,Advanced Customer Analytics: Strategic Value Through Integration of Relationship-Oriented Big Data,"As more firms adopt big data analytics to better understand their customers and differentiate their offerings from competitors, it becomes increasingly difficult to generate strategic value from isolated and unfocused ad hoc initiatives. To attain sustainable competitive advantage from big data, firms must achieve agility in combining rich data across the organization to deploy analytics that sense and respond to customers in a dynamic environment. A key challenge in achieving this agility lies in the identification, collection, and integration of data across functional silos both within and outside the organization. Because it is infeasible to systematically integrate all available data, managers need guidance in finding which data can provide valuable and actionable insights about customers. Leveraging relationship marketing theory, we develop a framework for identifying and evaluating various sources of big data in order to create a value-justified data infrastructure that enables focused and agile deployment of advanced customer analytics. Such analytics move beyond siloed transactional customer analytics approaches of the past and incorporate a variety of rich, relationship-oriented constructs to provide actionable and valuable insights. We develop a customized kernel-based learning method to take advantage of these rich constructs and instantiate the framework in a novel prototype system that accurately predicts a variety of customer behaviors in a challenging environment, demonstrating the framework’s ability to drive significant value. Copyright © Taylor & Francis Group, LLC.",,"Kitchens B., Dobolyi D., Li J., Abbasi A.","University of Virginia, United States",2018.0,Journal of Management Information Systems,Routledge,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047254729&doi=10.1080%2f07421222.2018.1451957&partnerID=40&md5=153e6cfaf5ece007a16e737b5f669192,10.1080/07421222.2018.1451957,20230520-160000,20230521-044735,"['advanced', 'customer', 'analytics:', 'strategic', 'value', 'through', 'integration', 'of', 'relationship-oriented', 'big', 'data']",False,20230521-205332,,,,
252,scopus,Study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology,"In order to achieve the sustainable development, the predictive mechanism with big data-driven Lean Manufacturing and Six Sigma methodology is proposed in this paper. The sustainable development for serious competition is often studied, however, the predictive mechanism with big data-driven Lean Manufacturing and Six Sigma methodology is seldom mentioned in publications. This paper reports the predictive mechanism from the perspective of big data-driven Lean Manufacturing. The key techniques including PLC communication, DMAIC roadmap, SPC technique and Hypothesis Testing are utilized to eliminate the waste and obtain continuous improvement. The demonstration of calculator production indicates the predictive mechanism can effectively eliminate the waste and improve the output by 60% with the sufficient capability of Cp &gt; 1.33 and Cpk &gt; 1. © 2021, IFIP International Federation for Information Processing.",DMAIC; Hypothesis testing; Lean manufacturing; Predictive mechanism; Six sigma; Statistical process control,"Chen H., Wu J.D., Zhang W., Guo Q., Lu H.F.","College of Electrical Engineering, Zhejiang University, Hangzhou, 310027, China",2021.0,IFIP Advances in Information and Communication Technology,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115209896&doi=10.1007%2f978-3-030-85910-7_70&partnerID=40&md5=413925019808f744018aa54e67f05c5f,10.1007/978-3-030-85910-7_70,20230520-160000,20230521-044735,"['study', 'of', 'the', 'predictive', 'mechanism', 'with', 'big', 'data-driven', 'lean', 'manufacturing', 'and', 'six', 'sigma', 'methodology']",False,20230521-205332,,,,
253,scopus,"Work-in-progress: Data Science Challenge-X: self-directed, competence-based, project-based learning","We discuss in this paper the implementation of a project-based self-direct learning competency-based project module in our Bachelor Data Science programme. The goal of the course is to integrate in a later stage all project modules, which are now divided in two: one with and one without external industry partners, treating different aspects of data science with a pre-defined goal and clear objectives for the project. Switching for a competency-based learner-based paradigm with agile aspects and intrinsic focus, we define the core project goals as secondary and develop core data science competences which are acquired by the students and reflected in a learning journal. © 2022 IEEE.",intrinsic motivation; project-based learning; self-directed learning,"Benites F., Schlatter M., Messerli M., Custer R.","Fhnw, School of Engineering, Switzerland",2022.0,"IEEE Global Engineering Education Conference, EDUCON",IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130467107&doi=10.1109%2fEDUCON52537.2022.9766710&partnerID=40&md5=2d05870fd1e4513d85b294f26e3ca934,10.1109/EDUCON52537.2022.9766710,20230520-160000,20230521-044735,"['work-in-progress:', 'data', 'science', 'challenge-x:', 'self-directed,', 'competence-based,', 'project-based', 'learning']",True,20230521-205332,,,,
254,scopus,"Artificial intelligence, big data, strategic flexibility, agility, and organizational resilience: A conceptual framework based on existing literature","In today’s economically turbulent times, it is imperative that organizations remain flexible and resilient in order to adapt themselves to an ever-changing environment. To facilitate this, organizations should rely upon pliant structures of information, whilst simultaneously continuing to incorporate more rigid infrastructures in order to allow for the collection and analysis of large amounts of both internal and external data. This juxtaposition gives rise to the need for a trade-off. While academic literature has stressed that information systems may represent a burden for organizations pursuing strategic agility, flexibility, and organizational resilience, this paper highlights the ways in which Analytical, Automatic, Adaptive, and Agile information systems - or Big Data Analytics (BDA) capable information systems - may be helpful. In particular, this paper proposes BDA capable information systems, tied with artificial intelligence capabilities, as a trade-off solution. Alongside this, it also proposes some further implications of the topic for scholars and practitioners. © 2018 IADIS Press. All Rights Reserved.",Artificial Intelligence; Big Data Analytics; Information Systems; Organizational Resilience; Strategic Agility; Strategic Flexibility,"Ciampi F., Marzi G., Rialti R.","Università degli Studi di Firenze, Firenze, Italy; Lincoln International Business School, Lincoln, United Kingdom; Università di Pisa, Pisa, Italy",2018.0,Proceedings of the International Conferences on WWW/Internet 2018 and Applied Computing 2018,IADIS Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060276264&partnerID=40&md5=7b3b6d7dcae7ca6e4d0e4cd8b7e3a83c,,20230520-160000,20230521-044735,"['artificial', 'intelligence,', 'big', 'data,', 'strategic', 'flexibility,', 'agility,', 'and', 'organizational', 'resilience:', 'a', 'conceptual', 'framework', 'based', 'on', 'existing', 'literature']",False,20230521-205332,,,,
255,scopus,Health Care Transformation: An Academic Application System Case Study,"During the 1st Semester of 2017, at the Brazilian Aeronautics Institute of Technology (Instituto Tecnológico de Aeronáutica - ITA), a successful Interdisciplinary Problem-Based Learning (IPBL) experience took place. At that time, almost 30 undergraduate and graduate students from 3 different courses within just 17 academic weeks had the opportunity of conceptualizing, modeling, and developing a Computer System based on Big Data, Internet of Things (IoT), and other emerging technologies for government and private organizations. The purpose of this system was to aggregate data from actors such as Patients, Physicians, Hospitals, and Health Care Suppliers, by integrating them into just one decision making process. This academic research project was named in Portuguese as “Soluções Tecnológicas Aplicáveis às Mídias e Produtos em Saúde - STAMPS” meaning in English “Technological Solutions Applicable for Health Care - TSA4HC”. It was planned to allow students to develop health care decision making systems to address crisis management scenarios such as epidemics. Differently from other existing systems from Universities, Research Centers, Governmental Agencies, Public and/or Private, this system was developed and tested in just 17 academic calendar weeks, applying the Scrum agile method and its best practices. This experience was stored in a Google site and implemented as a Proof of Concept (PoC). It represents one example of how to address the old problem of teaching, learning, designing, and implementing complex intelligent systems to solve health care system problems, by collaboratively using the Scrum agile method with Python or Java, Spark, NoSQL databases, Kafka, and other available technologies. © 2019",Agile method; big data; health care system; intelligent systems; interdisciplinarity; Internet of Things; problem-based learning; testing,"da Silva D.A., de Barros Santana R.M., Navas J., Goncalves G.S., Vieira Dias L.A., da Cunha A.M., Tasinaffo P.M.","Brazilian Aeronautics Institute of Technology, São José dos Campos, São Paulo, Brazil",2018.0,IFAC-PapersOnLine,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061136641&doi=10.1016%2fj.ifacol.2019.02.005&partnerID=40&md5=2623078b5304312b861b388e5720c00d,10.1016/j.ifacol.2019.02.005,20230520-160000,20230521-044735,"['health', 'care', 'transformation:', 'an', 'academic', 'application', 'system', 'case', 'study']",False,20230521-205332,,,,
256,scopus,Interdisciplinarity in Data Science Pedagogy: A Foundational Design,"Data science is an interdisciplinary field that generates insights in data to aid decision-making. Recognizing that data scientists must be interdisciplinary, agile, and able to adapt to data analysis across many domains, both academia and the industry are striving to integrate interdisciplinary learning and transferable skills into data science curriculum. This paper introduces an interdisciplinary approach to teaching the foundations of data science. We evaluate two different interdisciplinary formats. The first format considers collaborative efforts among instructors with different academic disciplines. The second involves a sole instructor that discusses data science concepts from different disciplines and related to business processes, computer science, and programming. We demonstrate that interdisciplinarity ensures favorable learning experiences and produces high learning outcomes. We also show that our course design maintains and promotes interdisciplinarity even in situations where logistical constraints would not support the use of multiple instructors to deliver one course. © 2018, © 2018 International Association for Computer Information Systems.",analytics; curriculum design; Data science; interdisciplinarity; pedagogy,"Asamoah D.A., Doran D., Schiller S.","Wright State University, Dayton, OH, United States",2020.0,Journal of Computer Information Systems,Taylor and Francis Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052144057&doi=10.1080%2f08874417.2018.1496803&partnerID=40&md5=59facd5db62fc8e69d4993eba60af49f,10.1080/08874417.2018.1496803,20230520-160000,20230521-044735,"['interdisciplinarity', 'in', 'data', 'science', 'pedagogy:', 'a', 'foundational', 'design']",False,20230521-205332,,,,
257,scopus,FACILITATING TEAM-BASED DATA SCIENCE: LESSONS LEARNED from the DSC-WAV PROJECT,"While coursework provides undergraduate data science students with some relevant analytic skills, many are not given the rich experiences with data and computing they need to be successful in the workplace. Additionally, students often have limited exposure to team-based data science and the principles and tools of collaboration that are encountered outside of school. In this paper, we describe the DSC-WAV program, an NSF-funded data science workforce development project in which teams of undergraduate sophomores and juniors work with a local non-profit organization on a data-focused problem. To help students develop a sense of agency and improve confidence in their technical and non-Technical data science skills, the project promoted a team-based approach to data science, adopting several processes and tools intended to facilitate this collaboration. Evidence from the project evaluation, including participant survey and interview data, is presented to document the degree to which the project was successful in engaging students in team-based data science, and how the project changed the students' perceptions of their technical and non-Technical skills. We also examine opportunities for improvement and offer insight to other data science educators who may want to implement a similar team-based approachto data science projects at their own institutions. © 2023 Sociedad Espanola de Investigacion Osea y del Metabolismo Mineral (SEIOMM). All rights reserved.",Agile; Collaboration; Projectbased learning.; Skill development; Team-based learning,"Legacy C., Zieffler A., Baumer B.S., Barr V., Horton N.J.","Department of Educational Psychology, University of Minnesota, Minneapolis, MN  55455, United States; Program in Statistical and Data Sciences, Smith College, Northampton, MA  01063, United States; Department of Computer Science, Mount Holyoke College, South Hadley, MA  01075, United States; Department of Mathematics and Statistics, Amherst College, Amherst, MA  01002, United States",2023.0,Foundations of Data Science,American Institute of Mathematical Sciences,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147960130&doi=10.3934%2ffods.2022003&partnerID=40&md5=3b112e729a9cbf8f2e452818bfa23367,10.3934/fods.2022003,20230520-160000,20230521-044735,"['facilitating', 'team-based', 'data', 'science:', 'lessons', 'learned', 'from', 'the', 'dsc-wav', 'project']",False,20230521-205332,,,,
258,scopus,A survey study of success factors in data science projects,"In recent years, the data science community has pursued excellence and made significant research efforts to develop advanced analytics, focusing on solving technical problems at the expense of organizational and socio-technical challenges. According to previous surveys on the state of data science project management, there is a significant gap between technical and organizational processes. In this article we present new empirical data from a survey to 237 data science professionals on the use of project management methodologies for data science. We provide additional profiling of the survey respondents' roles and their priorities when executing data science projects. Based on this survey study, the main findings are: (1) Agile data science lifecycle is the most widely used framework, but only 25% of the survey participants state to follow a data science project methodology. (2) The most important success factors are precisely describing stakeholders' needs, communicating the results to end-users, and team collaboration and coordination. (3) Professionals who adhere to a project methodology place greater emphasis on the project's potential risks and pitfalls, version control, the deployment pipeline to production, and data security and privacy. © 2021 IEEE.",data science; factor analysis; project management; success factors; survey,"Martinez I., Viles E., Olaizola I.G.","Basque Research and Technology Alliance, Vicomtech Foundation, Donostia-San Sebastián, 20009, Spain; University of Navarra, TECNUN School of Engineering, Donostia-San Sebastián, 20018, Spain",2021.0,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125297162&doi=10.1109%2fBigData52589.2021.9671588&partnerID=40&md5=675943ed87a232fa08a838c0a804712c,10.1109/BigData52589.2021.9671588,20230520-160000,20230521-044735,"['a', 'survey', 'study', 'of', 'success', 'factors', 'in', 'data', 'science', 'projects']",True,20230521-205332,,,,
259,scopus,Big data analytics on cyber attack graphs for prioritizing agile security requirements,"In enterprise environments, the amount of managed assets and vulnerabilities that can be exploited is staggering. Hackers' lateral movements between such assets generate a complex big data graph, that contains potential hacking paths. In this vision paper, we enumerate risk-reduction security requirements in large scale environments, then present the Agile Security methodology and technologies for detection, modeling, and constant prioritization of security requirements, agile style. Agile Security models different types of security requirements into the context of an attack graph, containing business process targets and critical assets identification, configuration items, and possible impacts of cyber-attacks. By simulating and analyzing virtual adversary attack paths toward cardinal assets, Agile Security examines the business impact on business processes and prioritizes surgical requirements. Thus, handling these requirements backlog that are constantly evaluated as an outcome of employing Agile Security, gradually increases system hardening, reduces business risks and informs the IT service desk or Security Operation Center what remediation action to perform next. Once remediated, Agile Security constantly recomputes residual risk, assessing risk increase by threat intelligence or infrastructure changes versus defender's remediation actions in order to drive overall attack surface reduction. © 2019 IEEE.",Agile Security; Attack Graph; Attack Path; Attack Surface; Cyber Digital Twin; Graph Analytics; Remediation Requirements; Requirements Prioritization; Security Requirements,"Hadar E., Hassanzadeh A.","Accenture Labs, Cyber Fusion Center, Accenture",2019.0,Proceedings of the IEEE International Conference on Requirements Engineering,IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076883569&doi=10.1109%2fRE.2019.00042&partnerID=40&md5=ecee2f9bc74290b942dfc0eb7141fed5,10.1109/RE.2019.00042,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'on', 'cyber', 'attack', 'graphs', 'for', 'prioritizing', 'agile', 'security', 'requirements']",True,20230521-205332,,,,
260,scopus,Building the federation of cloud service for big data,"The demand for agile and flexible business application for big data has sparked interest in using cloud computing technology. Due to the limitation of provider's capability and the magnanimity of task quantity for big data, a single cloud provider may not offer enough service resources. However, a service federation among multiple providers can effectively solve this problem. This paper proposes the framework of cloud federation and introduces the basic processes of building service federation among multiple cloud providers. Moreover, we propose a multi-objectives task assigning model in the federation. A genetic algorithm based heuristic approach is developed as the optimization method. Eventually, some simulation experiments are conducted to illustrate the effectiveness of the model. © 2018 IEEE.",cloud federation; cloud service; genetic algorithm; multiple objectives optimization; task assignment,"Shu J., Liang C., Wang B., Xu J.","School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Statistics and Applied Mathematics, Anhui University of Finance and Economics, Bengbu, Anhui, China",2018.0,"2018 IEEE 3rd International Conference on Big Data Analysis, ICBDA 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048502149&doi=10.1109%2fICBDA.2018.8367670&partnerID=40&md5=7e8234dbe86876f96b25c5c83d1c2f31,10.1109/ICBDA.2018.8367670,20230520-160000,20230521-044735,"['building', 'the', 'federation', 'of', 'cloud', 'service', 'for', 'big', 'data']",True,20230521-205332,,,,
261,scopus,Diftong: a tool for validating big data workflows,"Data validation is about verifying the correctness of data. When organisations update and refine their data transformations to meet evolving requirements, it is imperative to ensure that the new version of a workflow still produces the correct output. We motivate the need for workflows and describe the implementation of a validation tool called Diftong. This tool compares two tabular databases resulting from different versions of a workflow to detect and prevent potential unwanted alterations. Row-based and column-based statistics are used to quantify the results of the database comparison. Diftong was shown to provide accurate results in test scenarios, bringing benefits to companies that need to validate the outputs of their workflows. By automating this process, the risk of human error is also eliminated. Compared to the more labour-intensive manual alternative, it has the added benefit of improved turnaround time for the validation process. Together this allows for a more agile way of updating data transformation workflows. © 2019, The Author(s).",Big data; Big data validation process; Big data validation tool; Big data workflow; Data quality; Data testing; Data validation,"Rizk R., McKeever S., Petrini J., Zeitler E.","Department of Informatics and Media, Uppsala University, Kyrkogådsgatan 10, Uppsala, 753 13, Sweden; Klarna Bank AB, Sveavägen 46, Stockholm, 111 34, Sweden",2019.0,Journal of Big Data,SpringerOpen,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066021315&doi=10.1186%2fs40537-019-0204-5&partnerID=40&md5=5b14492d41dbb1e75fcc08ac3f48d39e,10.1186/s40537-019-0204-5,20230520-160000,20230521-044735,"['diftong:', 'a', 'tool', 'for', 'validating', 'big', 'data', 'workflows']",False,20230521-205332,,,,
262,scopus,Understanding How the Ad Hoc use of Big Data Analytics Impacts Agility: A Sensemaking-Based Model,"As business environments become increasingly complex and turbulent, organizations are required to be more agile. Use of big data analytics (BDA) can be a differentiator for organizations seeking to improve agility to quickly sense and respond to novel and complex events. Usage of BDA comprises two types: The routine use and the ad hoc use. The latter is more associated with the unplanned analysis of big data to understand unexpected events, and its effects have not been studied in distinction to the former in the analytics literature. We draw on sensemaking, the organizational theory of the process of understanding novel and complex events, to investigate how the ad hoc use of BDA improves agility of organizations. Analysis of a survey of 107 business executives and senior managers demonstrated the positive effects of the ad hoc use of BDA on agility, through mediation by sensemaking. © 2018 IEEE.",ad hoc use; agility; analytics; big data; sensemaking,"Hosoya R., Kamioka T.","Hitotsubashi University, Graduate School of Commerce and Management, Kunitachi, Tokyo, Japan",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems, icABCD 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054610362&doi=10.1109%2fICABCD.2018.8465446&partnerID=40&md5=fb3107a6afee57126b1e3531bec1ca7c,10.1109/ICABCD.2018.8465446,20230520-160000,20230521-044735,"['understanding', 'how', 'the', 'ad', 'hoc', 'use', 'of', 'big', 'data', 'analytics', 'impacts', 'agility:', 'a', 'sensemaking-based', 'model']",True,20230521-205332,,,,
263,scopus,An overview of fashion business models in big data environment,"The competitive pressure in the fashion industry not only exist between companies, they also exist between the networks of linked partners (known as supply chains). Consumers' needs are changing faster than ever before. Textile and garment manufactures are forced to lower the production costs and increase the efficiency so that they can respond quickly when there is a new trend in the market. Big data (BD) has been a hot topic for the last decade; this concept is mainly about extracting valuable information from voluminous data. In the fashion business, big data is playing a more and more important role in trend forecasting, consumer behavior studying etc. This paper reviews the history of conducting business in different developing stages of information technology. The basic garment supply chain in the traditional business era and in e-business era, as well as the development in fashion industry has been critically viewed. © 2018 Binary Information Press. All rights reserved.",Agile; Fashion big data; Fashion management; Fast fashion; Supply chain management,"Wang Y.-Y., Li Y., Perry P., Liu Z.-C.","University of Manchester, Mezz 3, Sackvile Street Building, Manchester, Ml 3BU, United Kingdom",2018.0,"Textile Bioengineering and Informatics Symposium Proceedings 2018 - 11th Textile Bioengineering and Informatics Symposium, TBIS 2018",Binary Information Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054556263&partnerID=40&md5=7716b2b73faafe09eccaa8ba7f11e1d0,,20230520-160000,20230521-044735,"['an', 'overview', 'of', 'fashion', 'business', 'models', 'in', 'big', 'data', 'environment']",False,20230521-205332,,,,
264,scopus,Agile Methods and Cyber-Physical Systems Development—A Review with Preliminary Analysis,"The software companies are using Agile methods and practices to tackle challenges in the rapidly changing environments and increasingly complex software systems. However, companies developing cyber physical systems (CPS) are still infancy in the use of Agile methods and hesitate to adopt. This systematic literature review was conducted in order to analyze the current trends of Agile methods use for CPS development. The search strategy resulted in 101 papers, of which 15 were identified as primary studies relevant to our research. The results show growing trend of Agile processes and Scrum is widely used reported for CPS development. The primary studies also exhibits a growing interest in teaching Agile in embedded systems, CPS and other engineering degree programs. The reported challenges included synchronization of software and hardware development, software and hardware developers use different vocabulary, lack of visibility and track of software releases and project progress. Additionally, lesson learned were extracted from the primary studies for guiding the practitioners interested in adopting Agile for CPS development. © 2020, Springer Nature Singapore Pte Ltd.",Agile; Cyber physical systems; Scrum; Software development,Ahmad M.O.,"Department of Mathematics and Computer Science, Karlstad University, Karlstad, Sweden",2020.0,Communications in Computer and Information Science,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090046463&doi=10.1007%2f978-981-15-7530-3_20&partnerID=40&md5=3e2f8ee32688c07c68306b3a39ebba27,10.1007/978-981-15-7530-3_20,20230520-160000,20230521-044735,"['agile', 'methods', 'and', 'cyber-physical', 'systems', 'development—a', 'review', 'with', 'preliminary', 'analysis']",False,20230521-205332,,,,
265,scopus,Information Resilience: the nexus of responsible and agile approaches to information use,"The appetite for effective use of information assets has been steadily rising in both public and private sector organisations. However, whether the information is used for social good or commercial gain, there is a growing recognition of the complex socio-technical challenges associated with balancing the diverse demands of regulatory compliance and data privacy, social expectations and ethical use, business process agility and value creation, and scarcity of data science talent. In this vision paper, we present a series of case studies that highlight these interconnected challenges, across a range of application areas. We use the insights from the case studies to introduce Information Resilience, as a scaffold within which the competing requirements of responsible and agile approaches to information use can be positioned. The aim of this paper is to develop and present a manifesto for Information Resilience that can serve as a reference for future research and development in relevant areas of responsible data management. © 2022, The Author(s).",Data quality; Effective information use; Information Resilience; Responsible data science; Value creation,"Sadiq S., Aryani A., Demartini G., Hua W., Indulska M., Burton-Jones A., Khosravi H., Benavides-Prado D., Sellis T., Someh I., Vaithianathan R., Wang S., Zhou X.","The University of Queensland, Brisbane, Australia; Swinburne University of Technology, Melbourne, Australia; Auckland University of Technology, Auckland, New Zealand; Facebook, New York, United States; The Hong Kong University of Science and Technology, Kowloon, Hong Kong",2022.0,VLDB Journal,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123164859&doi=10.1007%2fs00778-021-00720-2&partnerID=40&md5=43049802fde47e655f63c78c9c3c9c03,10.1007/s00778-021-00720-2,20230520-160000,20230521-044735,"['information', 'resilience:', 'the', 'nexus', 'of', 'responsible', 'and', 'agile', 'approaches', 'to', 'information', 'use']",True,20230521-205332,,,,
266,scopus,"Big data, industry 4.0 and cyber-physical systems integration: A smart industry context","The advancements in the industries have paved the way for the distributed establishment of the big data volumes, cyber-physical systems, and industrie 4.0. The perspectives of modules are integrated with the shop-floor monitoring and controlled by computational paradigms, and digital computational spaces. The performance rises after introducing an intelligent and automated manufacturing industry into the next-generation industry. The scope of this paper is to address the state-of-the-art technologies and phases such as digital twins, big data analytics, artificial intelligence, and internet-of-things. The research challenges are examined with attention on data integrity, data quality, data privacy, data availability, data scalability, data transformation, legitimate and monitoring issues, and governance. Lastly, potential research issues that need considerable research efforts are summarized. We believe that this paper is presenting the research directions for researchers in the area of smart industry towards its integration for the advancements of the industrial sector, and agile management. Some surprising development as industry 4.0 integration with socio-technical systems was found in designing the architecture of vertical, horizontal, and end-to-end integration mechanisms. © 2021 Elsevier Ltd. All rights reserved.",Agile management; Heterogeneity; Internet-of-things; Smart factory; Smart manufacturing,Singh H.,"School of Mechanical Engineering, Faculty of Technology and Sciences, Lovely Professional University, Punjab, Phagwara, 144 411, India",2021.0,Materials Today: Proceedings,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112300682&doi=10.1016%2fj.matpr.2020.07.170&partnerID=40&md5=b054139c11b829323e0c53e0353bb1a7,10.1016/j.matpr.2020.07.170,20230520-160000,20230521-044735,"['big', 'data,', 'industry', '4.0', 'and', 'cyber-physical', 'systems', 'integration:', 'a', 'smart', 'industry', 'context']",False,20230521-205332,,,,
267,scopus,"Studying cloud as IaaS for big data analytics: Opportunity, challenges","James Watt steam engine revolution was greatest revolution in mankind history in 20th century. In 1776, the first steam engines were installed and working in commercial enterprises. This revolution minimize and make world smaller for human being, now world is connected seamlessly. ""Big Data Analytics and Cloud"" these two words are second numerous revolutions in 21st century. We are living in an era of information explosion. These two magical terms are nothing but relatively very new and fortunately diverted all market trends to a new era of computation in last decade. As these two emerging technology are their early childhood, many people were confused with its relevancy and applicability. Cloud Computing is Infrastructure based solution for managing data and computational framework. 2016 was a significantly more important year for this volumes data technology or Big Data eco system as large number of enterprises, and organizations are generating data, storing that data and worried about future aspect of that data. In 2017, corporate world take cognizance of their large volumes structured and unstructured data as these enterprises and organizations continuously generating large volumes data. The term big data doesn't just refer to the massive amounts of data existing today, it also refers to the whole ecosystem of Storing or gathering data, Different types of data and analyzing that data. In traditional data ecosystem all leverages are with legacy system. Transforming or migration of these traditional ecosystems to the cloud is full of great challenges and benefits. Cloud computing is an agile and scalable resource access computation paradigm, provides heterogeneous platform seamlessly with infrastructure of internet, exclusively for the trapped and work on pre and post process of big data. Now the challenges are finding opportunity and challenges for managing, migrating and abstracting cloud based big data using cloud infrastructure for future eco system of Big Data Analysis. This paper is basically focused on this issue. We try to reevaluate the facts of existing Cloud Infrastructure as IaaS for tomorrow's big data analytics. © 2018 Authors.",Big data; Big data analytics; Cloud; Data migration; IaaS; Internet; OLM; RFHC,"Manekar A., Gera P.","Department of CSE, Koneru Lakshmaiah Education Foundation, Guntur, Vaddeswaram, Andhra Pradesh, India",2018.0,International Journal of Engineering and Technology(UAE),Science Publishing Corporation Inc,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082346773&partnerID=40&md5=a0f7332df3128ea2e1e80bd4f941e91f,,20230520-160000,20230521-044735,"['studying', 'cloud', 'as', 'iaas', 'for', 'big', 'data', 'analytics:', 'opportunity,', 'challenges']",False,20230521-205332,,,,
268,scopus,Knowledge sharing for agile distributed teams: A case study of Mauritius,"Knowledge is considered as an important factor during software development process as the latter is a people-based activity where developers' and other stakeholders' knowledge impact on the development. Different ways and techniques have been used to share knowledge in agile software development teams. Additionally rigorous, structured and formalized processes have been used to tackle the difficult task of transferring and sharing knowledge in a software teams. Nowadays, with large amount of information being processed within software companies, agile distributed software teams also need to take into consideration the aspects of Big Data while sharing knowledge within agile teams. A survey has been carried out in software development companies in Mauritius to investigate on knowledge sharing methods adopted by agile software development teams. Main findings have been discussed and recommendations have been made. © 2017 IEEE.",Agile Software Development; Big Data; Knowledge; Knowledge Sharing,"Gervigny M.L.I., Nagowah S.D.","Software and Information Systems Department, University of Mauritius, Réduit, Mauritius",2018.0,"2017 International Conference on Infocom Technologies and Unmanned Systems: Trends and Future Directions, ICTUS 2017",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047072126&doi=10.1109%2fICTUS.2017.8286043&partnerID=40&md5=dd9aa7bb2135833c0465db198aceae28,10.1109/ICTUS.2017.8286043,20230520-160000,20230521-044735,"['knowledge', 'sharing', 'for', 'agile', 'distributed', 'teams:', 'a', 'case', 'study', 'of', 'mauritius']",False,20230521-205332,,,,
269,scopus,An Online-Offline Combined Big Data Mining Platform,"Machine learning libraries are integral to a big data mining platform. There are three limitations on adopting current machine learning libraries in such a platform. First, these algorithms are not implemented for handling both online and offline big data analysis. Second, libraries exist in a variety of frameworks using different programming languages, which make it difficult in integrating several algorithms. Third, most machine learning libraries provides APIs for programming only, thus not user-friendly for those do not have a sufficient understanding of algorithms and those lack of programming skills. In this paper, we implement a comprehensive machine learning library including common algorithms and deep learning algorithms. We integrate this library at a platform level that allows both online and offline data analysis using this library. We further design a user-friendly portal that enables quick and agile data analysis practices. All of these form an Online-Offline Combined Big Data Mining Platform (OOBDP). We present a demonstration of big oil data analysis using this platform. We observe the that OOBDP can easily accommodate industrial requirement for adaptable data mining process, with personalized usage scenarios, and easy to use experiences. © 2017 IEEE.",Big Data Mining; Machine Learning; Online-Offline processing,"Zhang W., Lv H., Xu L., Liu Y., Liu X., Lu Q., Li Z., Zhou J.","Department of Software Engineering, China University of Petroleum, Qingdao, China; Concordia University, Montreal, Canada; College of Computer and Communication Engineering, China University of Petroleum, Qingdao, China; Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland",2018.0,"Proceedings - 2017 IEEE 15th International Conference on Dependable, Autonomic and Secure Computing, 2017 IEEE 15th International Conference on Pervasive Intelligence and Computing, 2017 IEEE 3rd International Conference on Big Data Intelligence and Computing and 2017 IEEE Cyber Science and Technology Congress, DASC-PICom-DataCom-CyberSciTec 2017",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048101571&doi=10.1109%2fDASC-PICom-DataCom-CyberSciTec.2017.195&partnerID=40&md5=5d14131bda94969a510745199b1ed14f,10.1109/DASC-PICom-DataCom-CyberSciTec.2017.195,20230520-160000,20230521-044735,"['an', 'online-offline', 'combined', 'big', 'data', 'mining', 'platform']",False,20230521-205332,,,,
270,scopus,Construction of a Social Security Monitoring and Early Warning Platform Driven by Big Data,"This article focuses on the existing sensitive information early warning mechanism and auxiliary decision-making is not sound, the emergency command and control is not agile, the application system business is solidified, and the existing monitoring and early warning service mode deals with multi-source, heterogeneous terrorism-related data, data utilization inefficiency and limited data processing service functions, the inability to achieve intelligent control of the process, and the inability to achieve precise monitoring, as well as the multi-dimensional and in-depth intelligent analysis of sensitive data. Research on distributed real-time transmission and distribution of big data based on multi-source and multi-channel adaptation, multi-source, heterogeneous big data distributed online real-time processing based on S4/Strom and distributed memory computing, position-based social security event monitoring, and semi-supervised system self-evolution and other key technologies, proposed to build a big data-driven social security monitoring and early warning platform system. © 2021 IEEE.",big data; data mining; data-driven; early warning platform,"Yu J., Guo J., Globa L., Li S., Zhang M., Li X., Liu J.","Shandong Academic of Sciences, Qilu University of Technology, Jinan, China; Igor Sikorsky Kyiv Polytechnic Institute, Institute of Telecommunication Systems of National Technical University of Ukraine, Kyiv, Ukraine; Shandong Normal University, Jinan, China",2021.0,"IMCEC 2021 - IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116151967&doi=10.1109%2fIMCEC51613.2021.9482215&partnerID=40&md5=5acb7772856b574e1d782d213fbf2240,10.1109/IMCEC51613.2021.9482215,20230520-160000,20230521-044735,"['construction', 'of', 'a', 'social', 'security', 'monitoring', 'and', 'early', 'warning', 'platform', 'driven', 'by', 'big', 'data']",True,20230521-205332,,,,
271,scopus,Big data project management approaches in the Czech Republic,"The amount of data grows exponentially every year and the information obtained from their analysis is an asset of every business. Therefore, more and more companies invest in Big Data implementation and use. However, the technology for processing this data is very complex and it is very difficult for companies to successfully master and operate it as to fully utilize its potential. Projects focused on this issue often end in failure. There are many critical factors affecting success of these projects. One of the most critical factors is appropriate project management. The paper aims to identify the approach which is most often used by companies in the Czech Republic to manage Big Data projects, as well as to assess how successful these projects are. The research is based on data from a research which included a questionnaire survey. The paper determines the most frequently used approach to Big Data project management in the Czech Republic, including the resulting success of such projects as perceived by respondents. © 2021 IDIMT 2021 - Pandemics: Impacts, Strategies and Responses, 29th Interdisciplinary Information Management Talks All rights reserved.",Agile; Big data; Czech Republic; Data analytics; Data mining; Data volumes; Project management; Project success,Smolová B.,"Faculty of Economics, Technical University of Liberec",2021.0,"IDIMT 2021 - Pandemics: Impacts, Strategies and Responses, 29th Interdisciplinary Information Management Talks",Johannes Kepler Universitat Linz,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112676025&partnerID=40&md5=53856c91a27bd9fadd2e8b24cd461e76,,20230520-160000,20230521-044735,"['big', 'data', 'project', 'management', 'approaches', 'in', 'the', 'czech', 'republic']",False,20230521-205332,,,,
272,scopus,ENIAD: A reconfigurable near-data processing architecture for web-scale AI-enriched big data service,"To meet the surging demands required by AI-enriched Big Data services, cloud vendors are turning toward domain specific accelerators for improved efficiency, scalability and performance. ENIAD, the first end-to-end infrastructure for AI-enriched Big Data serving in real time, accelerates both deep neural network inferencing and billion-scale indexing at the data-center scale. Exploiting near- data computation, reconfigurable computing and rapid/agile hardware deployment flow, ENIAD serves state-of-the-art, online built indexing service with high efficiency at low batch sizes. A high-performance, index (data)-adaptable FPGA soft processor is at the heart of the system and able to serve 10x larger index size with 14x lower latency compared to state-of-the-art CPU and GPU architectures. © 2021 IEEE.",,"Zhang J., Li J.","Department of Electrical and Systems Engineering, University of Pennsylvania",2021.0,"2021 IEEE Hot Chips 33 Symposium, HCS 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118370682&doi=10.1109%2fHCS52781.2021.9567229&partnerID=40&md5=a1fe451d5340e55223152c7d85ff1b63,10.1109/HCS52781.2021.9567229,20230520-160000,20230521-044735,"['eniad:', 'a', 'reconfigurable', 'near-data', 'processing', 'architecture', 'for', 'web-scale', 'ai-enriched', 'big', 'data', 'service']",True,20230521-205332,,,,
273,scopus,Unlocking the potential of nextGen multi-model databases for semantic big data projects,"A new vision in semantic big data processing is to create enterprise data hubs, with a 360° view on all data that matters to a corporation. As we discuss in this paper, a new generation of multi-model database systems seems a promising architectural choice for building such scalable, non-native triple stores. In this paper, we first characterize this new generation of multi-model databases. Then, discussing an example scenario, we show how they allow for agile and flexible schema management, spanning a large design space for creative and incremental data modelling. We identify the challenge of generating sound triple-views from data stored in several, interlinked models, for SPARQL querying. We regard this as one of several appealing research challenges where the semantic big data and the database architecture community may join forces. © 2019 ACM.",Multi-model DBMS; Schema evolution; Semantic data management,"Holubová I., Scherzinger S.","Charles University, Prague, Czech Republic; OTH Regensburg, Regensburg, Germany",2019.0,Proceedings of the ACM SIGMOD International Conference on Management of Data,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074650090&doi=10.1145%2f3323878.3325807&partnerID=40&md5=00030d1c403a8e2143c5b8b15ee1ec43,10.1145/3323878.3325807,20230520-160000,20230521-044735,"['unlocking', 'the', 'potential', 'of', 'nextgen', 'multi-model', 'databases', 'for', 'semantic', 'big', 'data', 'projects']",True,20230521-205332,,,,
274,scopus,DECIDE: An Agile event-and-data driven design methodology for decisional Big Data projects,"Decision making is the lifeblood of the enterprise — from the mundane to the strategically critical. However, the increasing deluge of data makes it more important than ever to understand and use it effectively in every context. Being “data driven” is more aspiration than reality in most organizations due to the complexity, volume, variability and velocity of data streams from every customer and employee interaction. The purpose of this paper is to provide a flexible and adaptable methodology for governing, managing and applying data throughout the enterprise, called DECIDE. © 2020 Elsevier B.V.",Agile; Big Data; Data governance; Data quality; Decisional systems; Methodology,"Sfaxi L., Ben Aissa M.M.","INSAT, University of Carthage, Tunisia; Tunisia Polytechnic School, University of Carthage, Tunisia",2020.0,Data and Knowledge Engineering,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091850243&doi=10.1016%2fj.datak.2020.101862&partnerID=40&md5=aa1de71bb074353ead7ea5385988d650,10.1016/j.datak.2020.101862,20230520-160000,20230521-044735,"['decide:', 'an', 'agile', 'event-and-data', 'driven', 'design', 'methodology', 'for', 'decisional', 'big', 'data', 'projects']",False,20230521-205332,,,,
275,scopus,"Integrating NoSQL, relational database, and the hadoop ecosystem in an interdisciplinary project involving big data and credit card transactions","The project entitled as Big Data, Internet of Things, and Mobile Devices, in Portuguese Banco de Dados, Internet das Coisas e Dispositivos Moveis (BDIC-DM) was implemented at the Brazilian Aeronautics Institute of Technology (ITA) on the 1st Semester of 2015. It involved 60 graduate students within just 17 academic weeks. As a starting point for some features of real time Online Transactional Processing (OLTP) system, the Relational Database Management System (RDBMS) MySQL was used along with the NoSQL Cassandra to store transaction data generated from web portal and mobile applications. Considering batch data analysis, the Apache Hadoop Ecosystem was used for Online Analytical Processing (OLAP). The infrastructure based on the Apache Sqoop tool has allowed exporting data from the relational database MySQL to the Hadoop File System (HDFS), while Python scripts were used to export transaction data from the NoSQL database to the HDFS. The main objective of the BDIC-DM project was to implement an e-Commerce prototype system to manage credit card transactions, involving large volumes of data, by using different technologies. The used tools involved generation, storage, and consumption of Big Data. This paper describes the process of integrating NoSQL and relational database with Hadoop Cluster, during an academic project using the Scrum Agile Method. At the end, processing time significantly decreased, by using appropriate tools and available data. For future work, it is suggested the investigation of other tools and datasets. © Springer International Publishing AG 2018.",Big data; Credit card transactions; Data integration; Hadoop ecosystem; NoSQL; RDBMS,"Rodrigues R.A., Filho L.A.L., Gonçalves G.S., Mialaret L.F.S., da Cunha A.M., Dias L.A.V.","Computer Science Department, Brazilian Aeronautics Institute of Technology, Instituto Tecnologico de Aeronautica – ITA, Sao Jose dos Campos, SP, Brazil",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048481291&doi=10.1007%2f978-3-319-54978-1_57&partnerID=40&md5=7bf6a691a3e2a9eef8b0156d680b4cb8,10.1007/978-3-319-54978-1_57,20230520-160000,20230521-044735,"['integrating', 'nosql,', 'relational', 'database,', 'and', 'the', 'hadoop', 'ecosystem', 'in', 'an', 'interdisciplinary', 'project', 'involving', 'big', 'data', 'and', 'credit', 'card', 'transactions']",False,20230521-205332,,,,
276,scopus,Agile clinical research: A data science approach to scrumban in clinical medicine,"The COVID-19 pandemic has required greater minute-to-minute urgency of patient treatment in Intensive Care Units (ICUs), rendering the use of Randomized Controlled Trials (RCTs) too slow to be effective for treatment discovery. There is a need for agility in clinical research, and the use of data science to develop predictive models for patient treatment is a potential solution. However, rapidly developing predictive models in healthcare is challenging given the complexity of healthcare problems and the lack of regular interaction between data scientists and physicians. Data scientists can spend significant time working in isolation to build predictive models that may not be useful in clinical environments. We propose the use of an agile data science framework based on the Scrumban framework used in software development. Scrumban is an iterative framework, where in each iteration larger problems are broken down into simple do-able tasks for data scientists and physicians. The two sides collaborate closely in formulating clinical questions and developing and deploying predictive models into clinical settings. Physicians can provide feedback or new hypotheses given the performance of the model, and refinement of the model or clinical questions can take place in the next iteration. The rapid development of predictive models can now be achieved with increasing numbers of publicly available healthcare datasets and easily accessible cloud-based data science tools. What is truly needed are data scientist and physician partnerships ensuring close collaboration between the two sides in using these tools to develop clinically useful predictive models to meet the demands of the COVID-19 healthcare landscape. © 2020 The Authors",Agile; Amazon Web Services; Cloud Computing; Minimal Viable Model; Predictive model; Scrumban,"Lei H., O'Connell R., Ehwerhemuepha L., Taraman S., Feaster W., Chang A.","CHOC Children's Hospital, Orange, CA, United States; The Sharon Disney Lund Medical Intelligence and Innovation Institute (MI3), United States; University of California-Irvine, Department of Pathology, United States; Chapman University School of Computational and Data Science, Orange, CA, United States; Department of Pediatrics, University of California-Irvine, School of Medicine, United States",2020.0,Intelligence-Based Medicine,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112231323&doi=10.1016%2fj.ibmed.2020.100009&partnerID=40&md5=ac5ff500db38dd67e822cabcdc54db93,10.1016/j.ibmed.2020.100009,20230520-160000,20230521-044735,"['agile', 'clinical', 'research:', 'a', 'data', 'science', 'approach', 'to', 'scrumban', 'in', 'clinical', 'medicine']",False,20230521-205332,,,,
277,scopus,How big data analytics use improves supply chain performance: considering the role of supply chain and information system strategies,"Purpose: Drawing on the dynamic capabilities theory, this paper proposes that supply chain (SC) strategies (i.e. the lean SC and agile SC strategies) will mediate the relationship between big data analytics (BDA) and SC performance. Furthermore, from the perspective of strategic alignment, this study hypothesizes that the effect of the SC strategy on SC performance is differently moderated by the information system (IS) strategy (i.e. the IS innovator and IS conservative strategies). Design/methodology/approach: This study used 159 match-paired questionnaires collected from Chinese firms to empirically test the hypotheses. Findings: Results show the positive direct and indirect impact of BDA on SC performance. Specifically, the lean and agile SC strategies mediate the relationship between BDA and SC performance. Furthermore, the results indicate that the IS innovator and IS conservative strategies differentially moderate the effect of the lean and agile SC strategies on SC performance. Specifically, the IS innovator strategy positively moderates the effect of the agile SC strategy on SC performance. By contrast, the IS conservative strategy positively moderates the effect of the lean SC strategy on SC performance but negatively moderates the effect of the agile SC strategy on SC performance. Originality/value: This study provides a comprehensive understanding of how SC and IS strategies can help firms leverage BDA to improve SC performance. © 2022, Emerald Publishing Limited.",Agile supply chain strategy; Big data analytics; IS conservative Strategy; IS innovator Strategy; Lean supply chain strategy; Supply chain performance,"Wei S., Yin J., Chen W.","School of Management, Hefei University of Technology, Hefei, China; College of Economics and Management, Nanjing University of Aeronautics and Astronautics, Nanjing, China; University of Science and Technology of China, Hefei, China",2022.0,International Journal of Logistics Management,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126067147&doi=10.1108%2fIJLM-06-2020-0255&partnerID=40&md5=9b870be3746301dbba92c141d51d29ea,10.1108/IJLM-06-2020-0255,20230520-160000,20230521-044735,"['how', 'big', 'data', 'analytics', 'use', 'improves', 'supply', 'chain', 'performance:', 'considering', 'the', 'role', 'of', 'supply', 'chain', 'and', 'information', 'system', 'strategies']",False,20230521-205332,,,,
278,scopus,Key Considerations in Optimizing the Deployment of Big Data Analytics-as-a-Service Utilizing Cloud Architecture and Machine Learning,"Cloud computing is usually associated with storage and processing on a back-end server that is accessible over the Internet. Increasingly the Cloud has transcended the boundaries of storage and retrieval and moved into the realms of offering services, performing analytics, undertaking collaborations and much more while ensuring security and privacy of data for the user applications. As a result, deployment of any application or service on the Cloud requires a carefully constructed strategy - especially with respect to managing the dynamicity and balancing of that deployment. This strategic need for Cloud Architecture is further important because of the advent of Big Data and Analytics-as-a-Service (AaaS). The Analytical services utilizing Big Data are not limited to a specific Cloud server. Instead, Big Data Analytics are carried out across the entire spectrum of Internet-based nodes ranging from the back-end Cloud server through to the End-user Internet of Things (IoT) devices and everything in between. The time, location and granularity of Big Data Analytics on and off the Cloud is a crucial strategic question. The Quality of Service (QoS) and security of deployment of Analytics-as-a-Service depends on the key considerations in answering this question. This strategic question relates to the dynamic decision making required to deploy a Cloud-based Big Data Analytics solution – which, in turn, is based on understanding the current conditions – security, volume, performance, criticality, among others – of Cloud-based deployment. The need for automation and intelligence with the dynamic optimization of Analytics on the Cloud requires the application of Machine Learning. This paper explores these key considerations of the strategic aspects of deploying Big Data Analytics using a Cloud Architecture. The practical application of these key considerations is demonstrated through the education domain. Finally, this paper proposes areas of research emanating from the study of Cloud Architecture and Machine Learning for Big Data Analytics. © 2020, Springer Nature Switzerland AG.",Agile business; Analytics-as-a-Service; Big data strategies; Cloud Architecture; Cloud deployment; Data Analytics; IoT; Machine Learning,"Unhelkar B., Trivikram Rao V.","University of South Florida, Sarasota-Manatee, Sarasota, FL  34242, United States; PlatiFi, Bengaluru, India",2020.0,Lecture Notes in Electrical Engineering,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075303360&doi=10.1007%2f978-3-030-30577-2_73&partnerID=40&md5=f6faea55627ef5fecf8f00307957bb74,10.1007/978-3-030-30577-2_73,20230520-160000,20230521-044735,"['key', 'considerations', 'in', 'optimizing', 'the', 'deployment', 'of', 'big', 'data', 'analytics-as-a-service', 'utilizing', 'cloud', 'architecture', 'and', 'machine', 'learning']",False,20230521-205332,,,,
279,scopus,Nexus of Internet of Things (IoT) and Big Data: Roadmap for Smart Management Systems (SMgS),"Disruptive technologies are emerging at a breakneck speed and changing the characteristics of businesses by making them smart. The aim of this paper is to show how industries can use Smart Management System (SMgS) to be competitive in the 21st century. Internet of Things (IoT) will be the key to connecting and communicating among different parts of the smart industries using sensor-like devices, and big data will be continuously collected and analyzed to improve performance. The SMgS will generate new possibilities for better product design, improved qualities, agile supply chain, and enhanced customer satisfaction. It will also help industries to achieve lean and sustainable systems with fewer efforts than traditional approaches. We demonstrate how early adopters have already implemented IoT and are currently generating big data. These efforts have resulted in significant improvements in streamlining their operations. The advantages of IoT and big data applications in different sectors are discussed here with several examples from the industry leaders. The reasons behind why many companies are still waiting to adopt IoT despite being enthusiastic about it are also suggested. Embracing SMgS is crucial for companies to gain a differential competitive advantage in the era of Industry 4.0. © 1973-2011 IEEE.",big data; IoT; lean; smart management system; sustainability,"Roy M., Roy A.","Management and Engineering for Manufacturing, University of Connecticut, Storrs, CT  06268, United States; Management, Marketing and Entrepreneurship, University of Scranton, Scranton, PA  18510, United States",2019.0,IEEE Engineering Management Review,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065994574&doi=10.1109%2fEMR.2019.2915961&partnerID=40&md5=245e1f0e31965612275d535d225fdaa3,10.1109/EMR.2019.2915961,20230520-160000,20230521-044735,"['nexus', 'of', 'internet', 'of', 'things', '(iot)', 'and', 'big', 'data:', 'roadmap', 'for', 'smart', 'management', 'systems', '(smgs)']",True,20230521-205332,,,,
280,scopus,"Understand, develop and enhance the learning process with big data","Purpose: With the advent of the internet and communication technology, the penetration of e-learning has increased. The digital data being created by the educational and research institutions is also on the ascent. The growing interest in recent years toward big data, educational data mining and learning analytics has motivated the development of new analytical ways and approaches and advancements in learning settings. The need for using big data to handle, analyze this large amount of data is prime. This trend has started attracting the interest of educational institutions which have an important role in the development skills process and the preparation of a new generation of learners. “A real revolution for education,” it is based on this kind of terms that many articles have paid attention to big data for learning. How can analytics techniques and tools be so efficient and become a great prospect for the learning process? Big data analytics, when applied into teaching and learning processes, might help to improvise as well as to develop new paradigms. In this perspective, this paper aims to investigate the most promising applications and issues of big data for the design of the next-generation of massive e-learning. Specifically, it addresses the analytical tools and approaches for enhancing the future of e-learning, pitfalls arising from the usage of large data sets. Globally, this paper focuses on the possible application of big data techniques on learning developments, to show the power of analytics and why integrating big data is so important for the learning context. Design/methodology/approach: Big data has in the recent years been an area of interest among innovative sectors and has become a major priority for many industries, and learning sector cannot escape to this deluge. This paper focuses on the different methods of big data able to be used in learning context to understand the benefits it can bring both to teaching and learning process, and identify its possible impact on the future of this sector in general. This paper investigates the connection between big data and the learning context. This connection can be illustrated by identifying the several main analytics approaches, methods and tools for improving the learning process. This can be clearer by the examination of the different ways and solutions that contribute to making a learning process more agile and dynamic. The methods that were used in this research are mainly of a descriptive and analytical nature, to establish how big data and analytics methods develop the learning process, and understand their contributions and impacts in addressing learning issues. To this end, authors have collected and reviewed existing literature related to big data in education and the technology application in the learning context. Authors then have done the same process with dynamic and operational examples of big data for learning. In this context, the authors noticed that there are jigsaw bits that contained important knowledge on the different parts of the research area. The process concludes by outlining the role and benefit of the related actors and highlighting the several directions relating to the development and implementation of an efficient learning process based on big data analytics. Findings: Big data analytics, its techniques, tools and algorithms are important to improve the learning context. The findings in this paper suggest that the incorporation of an approach based on big data is of crucial importance. This approach can improve the learning process, for this, its implementation must be correctly aligned with educational strategies and learning needs. Research limitations/implications: This research represents a reference to better understanding the influence and the role of big data in educational dynamic. In addition, it leads to improve existing literature about big data for learning. The limitations of the paper are given by its nature derived from a theoretical perspective, and the discussed ideas can be empirically validated by identifying how big data helps in addressing learning issues. Originality/value: Over the time, the process that leads to the acquisition of the knowledge uses and receives more technological tools and components; this approach has contributed to the development of information communication and the interactive learning context. Technology applications continue to expand the boundaries of education into an “anytime/anywhere” experience. This technology and its wide use in the learning system produce a vast amount of different kinds of data. These data are still rarely exploited by educational practitioners. Its successful exploitation conducts educational actors to achieve their full potential in a complex and uncertain environment. The general motivation for this research is assisting higher educational institutions to better understand the impact of the big data as a success factor to develop their learning process and achieve their educational strategy and goals. This study contributes to better understand how big data analytics solutions are turned into operational actions and will be particularly valuable to improve learning in educational institutions. © 2018, Emerald Publishing Limited.",Algorithm; Big data; E-learning; Higher education; Learning analytics; Learning process,"Sedkaoui S., Khelfaoui M.","Universite de Khemis Miliana, Algeria; Universite de Khemis Miliana, Khemis Miliana, Algeria; SRY Consulting, Montpellier, France",2019.0,Information Discovery and Delivery,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058861359&doi=10.1108%2fIDD-09-2018-0043&partnerID=40&md5=f13ba9a6819d52a6b8927bfefa278ba3,10.1108/IDD-09-2018-0043,20230520-160000,20230521-044735,"['understand,', 'develop', 'and', 'enhance', 'the', 'learning', 'process', 'with', 'big', 'data']",False,20230521-205332,,,,
281,scopus,GAMM: Graph-Based Agile Multidimensional Model,"The advent of big data has continuously offered new opportunities for analysis due to the growth and diversification of data sources. However, traditional data warehouses based on multidimensional models have limitations when it comes to changing and evolving. In recent years, innovative work in the field of data warehouse evolution has been performed; it has mainly focused on the management of big data and the chronological evolution of models in terms of their structures and data. However, an agile decision model is still required. We propose in this paper an agile approach for schema evolution in data warehouses that allows designers to integrate new data sources and take into account new user needs in order to enrich the analysis possibilities of data warehouses in a flexible way. Our approach is based on a multi-version evolutionary schema model. The data instances corresponding to the different versions of the schema are stored in a graph data warehouse. A meta-model will allow the management of the warehouse schema versions. We also propose evolution functions on the schema level. We validate our approach with a software prototype and a case study that illustrates queries on schema versions, cross-queries and the runtime of our approach. Copyright © 2023 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",,"Benhissen R., Bentayeb F., Boussaid O.","ERIC Laboratory, University of Lyon 2, Bron, France",2023.0,CEUR Workshop Proceedings,CEUR-WS,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153402581&partnerID=40&md5=a81680e77831d3b287af67d95485261e,,20230520-160000,20230521-044735,"['gamm:', 'graph-based', 'agile', 'multidimensional', 'model']",False,20230521-205332,,,,
282,scopus,The role of internet of things (IoT) and big data as a road map for smart management systems: Case studies across industries,"The Fourth Industrial Revolution began at the turn of this century. Disruptive technologies are emerging at a dizzying speed and changing the characteristics of industries and businesses by making them smart. Companies and industries will need Smart Management Systems to be competitive in the 21st century. Internet of Things (IoT) is the key to connecting and communicating amongst different parts of the smart industries using sensor-like devices, and Big data is being continuously collected and analyzed. Thus, IoT and Big Data are creating the roadmap for the Smart Management System that can achieve new understanding and insights to these smart industrial systems from analyzing and visualizing the available data. The Smart Management System will generate new possibilities for better product design, improved qualities, agile supply chain, and evermore customer satisfaction. It will also help industries to achieve a lean and sustainable system with fewer efforts than traditional approaches. Many early adopters have already implemented IoT and currently generating Big data, and have achieved significant improvements in seeking innovation and opportunities for increased revenues; however, most of the industries are still waiting to learn from the high-profile companies who have already adopted IoT. The application of IoT in different sectors will be discussed here, and the Smart Management System will be identified in this process. © American Society for Engineering Education, 2018.",Big data; IoT; Lean; Smart management system; Sustainable,Roy M.,"Management and Engineering for Manufacturing (MEM) Program, University of Connecticut, United States",2018.0,"ASEE Annual Conference and Exposition, Conference Proceedings",American Society for Engineering Education,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051172041&partnerID=40&md5=1cba71a2f0ba179ee237883565815e91,,20230520-160000,20230521-044735,"['the', 'role', 'of', 'internet', 'of', 'things', '(iot)', 'and', 'big', 'data', 'as', 'a', 'road', 'map', 'for', 'smart', 'management', 'systems:', 'case', 'studies', 'across', 'industries']",False,20230521-205332,,,,
283,scopus,Online big data chemical batch analytics,"By allowing the manufacturing of multiple product types, batch processes represent a suitable configuration for changing markets that require agile operations. Still, batch processes are complex, dynamic, nonlinear processes, difficult to control and to monitor. The present article describes the development of an online operator assistant system and its validation in a batch chemical plant. The developed system, through the early detection of evolving process abnormal situations, and the isolation of relevant process variables, allows the process operator to timely implement corrective actions reducing therefore the amount of wasted material, energy and production time. © 2018 TeknoScienze. All rights reserved.",Analytics; Big data; Golden batch; Industry 4.0; Machine learning,"Hollender M., Chioua M., Xu C.","ABB Corporate Research, Ladenburg, Germany; ABB Oil, Gas and Chemicals, Mannheim, Germany",2018.0,Chimica Oggi/Chemistry Today,TeknoScienze,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059932523&partnerID=40&md5=18a033c452fee45e2487b5aea6872a45,,20230520-160000,20230521-044735,"['online', 'big', 'data', 'chemical', 'batch', 'analytics']",False,20230521-205332,,,,
284,scopus,Developments in knowledge discovery processes and methodologies: Anything new?,"The process of turning data into knowledge is referred to as “knowledge discovery” (KD) and originated in the 1990s. Since that time many different process models and methodologies have been developed. A genealogy presented in 2010, showed how the different models evolved and presented a refined process model, which represents a synthesis of the models presented before. However, the rise of data analytics and big data have changed how organizations do business. The key to these changes is to use data and turn it into knowledge to create value for the organization. Therefore, this study aims to update our understanding of knowledge discovery processes by reviewing the research into KD processes since 2010 in order to understand if there have been considerable changes and developments in this field. The developments in KD process models and methodologies that were found are threefold: tasks, steps and agile practices. © 2019 Association for Information Systems. All rights reserved.",Agile practice; Big data; Knowledge discovery process; Process methodology; Process model,"Baijens J., Helms R.W.","Open University, Netherlands",2019.0,"25th Americas Conference on Information Systems, AMCIS 2019",Association for Information Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084018815&partnerID=40&md5=e72060cbe202c0248db524707c41ee81,,20230520-160000,20230521-044735,"['developments', 'in', 'knowledge', 'discovery', 'processes', 'and', 'methodologies:', 'anything', 'new?']",False,20230521-205332,,,,
285,scopus,Advanced Data Analytics in Logistics Demand Forecasting,"The logistics demand forecasting is increasingly influenced by digitalization processes in logistics business. Traditional approach to logistics demand forecasting based on human expertise and statistical assessment is still very present, but the use of Big Data, Artificial Intelligence and Machine Learning becomes more prominent. By using these technologies, logistics demand forecasting becomes not only more reliable but also more agile and self-adjusting, with better insight into changing market conditions in the real-time perspective. In this paper, the Authors research the evolution of Data Analytics in logistics demand forecasting. and provide an insight to the features of Big Data, Artificial Intelligence and Machine Learning used for Advanced Data Analytics in logistics demand forecasting. © 2021 Croatian Society MIPRO.",Advanced Data Analytics; Artificial Intelligence; Big Data; logistics demand forecasting; Machine Learning,"Agatic A., Tijan E., Hess S., Jugovic T.P.","University of Rijeka, Faculty of Maritime Studies, Department of Maritime and Transportation Technology, Rijeka, Croatia",2021.0,"2021 44th International Convention on Information, Communication and Electronic Technology, MIPRO 2021 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123051917&doi=10.23919%2fMIPRO52101.2021.9596820&partnerID=40&md5=a3902a7f492c1dda572954cc409193c5,10.23919/MIPRO52101.2021.9596820,20230520-160000,20230521-044735,"['advanced', 'data', 'analytics', 'in', 'logistics', 'demand', 'forecasting']",True,20230521-205332,,,,
286,scopus,Smart hospitality—Interconnectivity and interoperability towards an ecosystem,"The Internet and cloud computing changed the way business operate. Standardised web-based applications simplify data interchange which allow internal applications and business partners systems to become interconnected and interoperable. This study conceptualises the smart and agile hospitality enterprises of the future, and proposes a smart hospitality ecosystem that adds value to all stakeholders. Internal data from applications among all stakeholders, consolidated with external environment context form the hospitality big data on the cloud that enables members to use business intelligence analysis to generate scenarios that enhance revenue management performance. By connecting to smart tourism network, sensors and content extractors can assist to collect external information, and beacons to deliver context-based promotion messages and add value. The proposed model enables fully integrated applications, using big data to enhance hospitality decision making as well as strengthen competitiveness and improve strategies performance. © 2017 Elsevier Ltd",Big data; Hospitality ecosystem; ICT; Interconnectivity and interoperability; Sensor and beacon; Smart hospitality,"Buhalis D., Leung R.","School of Tourism, Bournemouth University, Fern Barrow, Poole, DorsetBH12 5BB, United Kingdom; Department of International Tourism and Hospitality, I-Shou University, No. 1, Section 1, Syue Cheng Road, Dashu District, Kaohsiung, Taiwan",2018.0,International Journal of Hospitality Management,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036626477&doi=10.1016%2fj.ijhm.2017.11.011&partnerID=40&md5=2944ecb57cee87377bb1bbce4c85ca4d,10.1016/j.ijhm.2017.11.011,20230520-160000,20230521-044735,"['smart', 'hospitality—interconnectivity', 'and', 'interoperability', 'towards', 'an', 'ecosystem']",False,20230521-205332,,,,
287,scopus,Agile software development: Methodologies and trends,"Software engineering is a discipline that undergone many improvements that aims to keep up with the new advancements in technologies and the modern business requirements through developing effective approaches to reach the final software product, agile software development is one of these successful approaches. Agile software development is a lightweight approach that was proposed to overcome the convolutional development methods' limitations and to reduce the overhead and the cost while providing flexibility to adopt the changes in requirements at any stage, this is done by managing the tasks and their coordination through a certain set of values and principles. In this work, a comprehensive review that outlines the main agile values and principles, and states the key differences that distinguish agile methods over the traditional ones are presented. Then a discussion of the most popular agile methodologies; their life cycles, their roles, and their advantages and disadvantages are outlined. The recent state of art trends that adopts agile development especially in cloud computing, big data, and coordination are also explored. And finally, this work highlights how to choose the best suitable agile methodology that must be selected according to the task at hand, how sensitive the product is and the organization structure. © 2020 International Association of Online Engineering.",Agile development; Agile methods; Big data; Cloud computing; Coordination,"Al-Saqqa S., Sawalha S., Abdelnabi H.","The University of Jordan, Amman, Jordan; Princess Sumaya University for Technology, Amman, Jordan",2020.0,International Journal of Interactive Mobile Technologies,International Association of Online Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087950431&doi=10.3991%2fijim.v14i11.13269&partnerID=40&md5=908bf9a07ba0af84659c46343f549e9b,10.3991/ijim.v14i11.13269,20230520-160000,20230521-044735,"['agile', 'software', 'development:', 'methodologies', 'and', 'trends']",False,20230521-205332,,,,
288,scopus,Designing a Sourcing Ecosystem for Strategic Innovation Through “Big Data” Applications,"Published research on innovation from Information Technology and Business Process Outsourcing (ITO/BPO) is rare [1]. Strategic innovation involves high uncertainties better addressed through agile methods and a collaborative approach [1–3]. Key success factors in delivering ITO/BPO innovation are high-quality relationships, trust and collaborative cultures [1–4], and establishing an effective governance configuration. The authors report on longitudinal case studies of a global mining company (“GMC”) and a group of its suppliers aimed at understanding how GMC is developing “big data” applications to generate game-changing innovation. This paper describes how GMC has developed a “big data” platform to support internal staff, customers, consultants and third party suppliers to create applications that can transform global mining and smelting industries to deliver a price premium for GMC’s products. GMC has encountered a shortage of suitably experienced data scientists in its key operating locations resulting in a significant skills gap in its big data program. GMC’s sourcing strategy aims to build an open and collaborative ecosystem that draws upon secondary markets to help fill the skills gap. To create an environment in which open innovation [5] can flourish, GMC established an Analytics Speed Team (AST) as an internal consulting and program management group to drive faster progress with big data applications. A contribution of this research is to identify the role of AST in establishing an effective governance configuration for open innovation. A practical contribution is made by analysing the value of secondary markets for ITO services in a sourcing ecosystem optimised for delivering innovation. © 2020, Springer Nature Switzerland AG.",Artificial intelligence; Big data; Cloud services; Innovation in outsourcing/offshoring; Secondary markets; Sourcing configuration; Sourcing ecosystem; “Gig” economy,"Penter K., Perrin B., Wreford J., Pervan G.","Faculty Business and Law, Curtin University, GPO Box U1987, Perth, WA, Australia",2020.0,Lecture Notes in Business Information Processing,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101311865&doi=10.1007%2f978-3-030-66834-1_10&partnerID=40&md5=1bc0bd12881914acf66dc369fd34934e,10.1007/978-3-030-66834-1_10,20230520-160000,20230521-044735,"['designing', 'a', 'sourcing', 'ecosystem', 'for', 'strategic', 'innovation', 'through', '“big', 'data”', 'applications']",False,20230521-205332,,,,
289,scopus,Midas: Towards an Interactive Data Catalog,"This paper presents the ongoing work on the Midas polystore system. The system combines data cataloging features with ad-hoc query capabilities and is specifically tailored to support agile data science teams that have to handle large datasets in a heterogeneous data landscape. Midas consists of a distributed SQL-based query engine and a web application for managing and virtualizing datasets. It differs from prior systems in its ability to provide attribute level lineage using graph-based virtualization, sophisticated metadata management, and query offloading on virtualized datasets. © 2019, Springer Nature Switzerland AG.",Data catalog; Metadata management; Polystore,"Holl P., Gossling K.","Technical University of Munich, Garching b. Muenchen, 85748, Germany",2019.0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077771308&doi=10.1007%2f978-3-030-33752-0_9&partnerID=40&md5=9fb692e6a87d67dfd5d2e8c530b332c4,10.1007/978-3-030-33752-0_9,20230520-160000,20230521-044735,"['midas:', 'towards', 'an', 'interactive', 'data', 'catalog']",False,20230521-205332,,,,
290,scopus,Interplay of Machine Learning and Software Engineering for Quality Estimations,"In this era, the agile mindset has innovated the traditional software engineering (SE) process through the integration of DevOps flow engines, scrum iterations, and automation of continuous integration (CI) and continuous deployment (CD) cycles. However, the CI/CD integration requires manual code-revisions and refactoring at large scales. Recently, machine-learning (ML) is employed in SE that allows legacy codes to be highly dynamic, less coupling in related modules, automatic code versioning, and refactoring, with less coupling among related modules. However, over time, ML models tend to become bulky, with increasing monotonic losses during model training. To address this, SE techniques like code revisions are employed over ML codes to allow low-order training losses, that enables seamless and precise workflow structures. Motivated from the aforementioned discussions, the paper presents a systematic review of the close interplay of SE and ML and possible interactions in different applications. Suitable research questions and case studies are presented for possible adoption scenarios that depict the close ML-SE interplay share with each other, with the concluding remarks. The paper forms useful insights for ML engineers, data science practitioners, and SE quality estimators towards the building of efficient and scalable software solutions. © 2020 IEEE.",Effort estimation; Machine learning; Quality estimation; Software Engineering,"Abubakar H., Obaidat M.S., Gupta A., Bhattacharya P., Tanwar S.","Institute of Technology, Nirma University, Department of Computer Science and Engineering, Ahmedabad, Gujarat, India; College of Computing and Informatics, University of Sharjah, Sharjah, 27272, United Arab Emirates; King Abdullah II School of Information Technology, University of Jordan, Amman, 11942, Jordan; University of Science and Technology Beijing, Beijing, 10008, China",2020.0,"Proceedings of the 2020 IEEE International Conference on Communications, Computing, Cybersecurity, and Informatics, CCCI 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097841067&doi=10.1109%2fCCCI49893.2020.9256507&partnerID=40&md5=3df520df1ae1119f3d35f5962b8a3923,10.1109/CCCI49893.2020.9256507,20230520-160000,20230521-044735,"['interplay', 'of', 'machine', 'learning', 'and', 'software', 'engineering', 'for', 'quality', 'estimations']",True,20230521-205332,,,,
291,scopus,To Offload or Not? An Analysis of Big Data Offloading Strategies from Edge to Cloud,"Large reductions in completion times can result from transfer of Big Data tasks from edge nodes to cloud resources, which can reduce the completion times by up to 97 % and meet client deadlines for computational tasks with responsive and agile solutions. Using scientific programs of varying computational complexity to model resource-intensive tasks, we demonstrate that the task complexity of the computational jobs, the Wide Area Network (WAN) speed and the potential overload of edge servers (as reflected by CPU workloads) are crucial for achieving total reductions in task completion time edge-cloud orchestrators are situated in edge nodes. With continuous access to the parameters of Wireless Local Area Network (WLAN) speed (for data exchanges between client and edge resources), WAN speed (for data exchanges between edge and cloud resources) edge server CPU workload and the complexities in Big Data analytics requirements, accurate edge-to-cloud offloading decisions can be made to minimise total task completion time by the use of cloud computing resources. This work supports the major research efforts have been recently made to develop novel resource orchestration solutions to flexibly link edge nodes with centralised cloud resources so as to maximise the efficiency with which such a continuum of resources can be accessed by users. © 2022 IEEE.",Application-level orchestration; Big Data analytics; Cloud-to-Edge con-tinuum; Computational complexity; Server workload; WAN; WLAN,"Singh R., Kovacs J., Kiss T.","University of Westminster, Centre for Parallel Computing, Department of Computer Science and Engineering, London, United Kingdom; ELKH SZTAKI, Budapest, Hungary",2022.0,"2022 IEEE World AI IoT Congress, AIIoT 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134874749&doi=10.1109%2fAIIoT54504.2022.9817276&partnerID=40&md5=d2e8fd605c9a153fa11a701841b7e351,10.1109/AIIoT54504.2022.9817276,20230520-160000,20230521-044735,"['to', 'offload', 'or', 'not?', 'an', 'analysis', 'of', 'big', 'data', 'offloading', 'strategies', 'from', 'edge', 'to', 'cloud']",True,20230521-205332,,,,
292,scopus,Big Data in Smart Infrastructure,"Infrastructure is becoming smarter due to technical advances such as the Internet of Things (IoT) that enables a greater interconnectivity between assets and Artificial Intelligence (AI) to enhance the decision making task; this paper proposes a Big Data Framework in Smart Infrastructure such as Airports, Stations Intelligent Transport Systems and Buildings. The interconnection of infrastructure systems using Local Area Networks, Wi-Fi, Radio or Mobile Networks is not enough to optimize and expand Infrastructure services and functionality; Big Data integration, management and analytics will play a key role in the next Smart Infrastructure stages when Infrastructure will learn and adapt to users. However, the inconvenient truth behind the Big Data hosted in the cloud is the intrinsically associated Cybersecurity threat and risk. This paper provides the practical application of Digital as a Service (DaaS) with considerations and recommendations that cover the implementation of Big Data in Smart Infrastructure with some practical examples of real Infrastructure projects: Buildings, Airport, Stations and Intelligent Transport Systems. In addition, flagship projects have also to be delivered on time, budget and quality within a Health and Safety environment in order to be successful where the understanding of requirements and solutions is key and an Agile approach has some benefits to the traditional project management delivery. © 2021, Springer Nature Switzerland AG.",Big Data; Cloud; Digital as a Service; Smart Cities; Smart Infrastructure,Serrano W.,"Alumni Imperial College London, South Kensington, London, SW7 2AZ, United Kingdom",2021.0,Advances in Intelligent Systems and Computing,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090094638&doi=10.1007%2f978-3-030-55187-2_51&partnerID=40&md5=35de1df4c04ec763649692d3e58fb801,10.1007/978-3-030-55187-2_51,20230520-160000,20230521-044735,"['big', 'data', 'in', 'smart', 'infrastructure']",False,20230521-205332,,,,
293,scopus,Management Perspectives towards the Data-Driven Organization in the Energy Sector,"This paper explores the current attitudes of managers and executives working in the energy sector towards the Data-Driven Organizational Model implied by Big Data. The aim is to explore and understand the current mindset of senior decision makers, since their success depends as much on cognitive and behavioral processes as on their technical competences. We adopt a grounded-theory approach, developing models of understanding and belief abductively, driven by the data obtained from participants through a reflection guide. We find that managers differ significantly in their understanding and engagement with their challenges; they display interest but differ in their commitment and enthusiasm; they identify a lack of strategy and skills as current barriers; and they are currently unwilling to trust data, treating evidence according to their own prior commitments. This is a significant barrier to establishing the Data-Driven Organizational Model. These findings raise concerns, and the paper concludes that by considering initiatives for implementing more agile and forward-looking approaches, establishing a data-driven organizational culture, and managing such changes effectively. © 2022 by the authors.",big data; big data analytics; data-driven organizational model; digitalization; energy; EU Green Deal,"Pugna I.B., Boldeanu D.M., Gheorghe M., Cozgarea G., Cozgarea A.N.","Department of Management of Information Systems, Bucharest University of Economic Studies, 6 Piața Romană, Sector 1, Bucharest, 010374, Romania",2022.0,Energies,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137689482&doi=10.3390%2fen15165775&partnerID=40&md5=4a731c08bff939e403fb1e63ddda832d,10.3390/en15165775,20230520-160000,20230521-044735,"['management', 'perspectives', 'towards', 'the', 'data-driven', 'organization', 'in', 'the', 'energy', 'sector']",False,20230521-205332,,,,
294,scopus,Workshop on Applied Machine Learning Management,"Machine learning applications are rapidly adopted by industry leaders in any field. The growth of investment in AI-driven solutions created new challenges in managing Data Science and ML resources, people and projects as a whole. The discipline of managing applied machine learning teams, requires a healthy mix between agile product development tool-set and a long term research oriented mindset. The abilities of investing in deep research while at the same time connecting the outcomes to significant business results create a large knowledge based on management methods and best practices in the field. The Workshop on Applied Machine Learning Management brings together applied research managers from various fields to share methodologies and case-studies on management of ML teams, products, and projects, achieving business impact with advanced AI-methods. © 2022 Owner/Author.",data science management; machine learning management; ml product development,"Goldenberg D., Sokolova E., Meir Lador S., Mandelbaum A., Vasilinetc I., Jain A.","Booking.com, Tel Aviv, Israel; Amazon, London, United Kingdom; Intuit, Tel Aviv, Israel; Embie, Tel Aviv, Israel; Meta, London, United Kingdom; Meta, Menlo Park, CA, United States",2022.0,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137143907&doi=10.1145%2f3534678.3542914&partnerID=40&md5=96084d5c30e383ee187bc9bb046b2e4f,10.1145/3534678.3542914,20230520-160000,20230521-044735,"['workshop', 'on', 'applied', 'machine', 'learning', 'management']",False,20230521-205332,,,,
295,scopus,Seven Principles for Rapid-Response Data Science: Lessons Learned from Covid-19 Forecasting,"In this article, we take a step back to distill seven principles out of our experience in the spring of 2020, when our 12-person rapid-response team used skills of data science and beyond to help distribute 340,000+ units of Covid PPE. This process included tapping into domain knowledge of epidemiology and medical logistics chains, curating a relevant data repository, developing models for short-term county-level death forecasting in the US, and building a website for sharing visualization (an automated AI machine). The principles are described in the context of working with Response4Life, a then-new nonprofit organization, to illustrate their necessity. Many of these principles overlap with those in standard data-science teams, but an emphasis is put on dealing with problems that require rapid response, often resembling agile software development. The technical work from this rapid response project resulted in a paper (Altieri et al. (2021)); see also this interview for more background (Yu and Meng (2021)). © Institute of Mathematical Statistics, 2022",Coronavirus; County-level; Datascience; Forecasting,"Yu B., Singh C.","University of California, Berkeley, CA  94720-3860, United States",2022.0,Statistical Science,Institute of Mathematical Statistics,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131406917&doi=10.1214%2f22-STS855&partnerID=40&md5=31cf1b032a59a9567838b110651e124f,10.1214/22-STS855,20230520-160000,20230521-044735,"['seven', 'principles', 'for', 'rapid-response', 'data', 'science:', 'lessons', 'learned', 'from', 'covid-19', 'forecasting']",False,20230521-205332,,,,
296,scopus,Research and Implementation of Intelligent Platform for Targeted Employment Poverty Alleviation Based on Cloud Computing and Big Data,"With the development of Internet technology, big data technology provides technical support for China's targeted poverty alleviation. The key to targeted poverty alleviation lies in providing employment. Employment poverty alleviation is the most direct, realistic and effective way for poor workers to get rid of poverty. How to establish an information communication platform between the poor and enterprises is a key problem to be solved urgently. This paper uses cloud computing, big data and intelligent decision making technology to develop the big data 'Internet plus' platform for precision employment and poverty alleviation. It has solved the problems of asymmetric information among enterprises, the poor and government departments, lack of effective supply and demand docking platform, unbalanced regional distribution of employment posts and labor force, inaccurate employment services, long employment chain and difficult tracking services. This paper describes in detail the architecture design, targeted employment framework process, deployment and implementation for the platform adopting scrum and continuous integration development method. The platform has been successfully online, exploring employment poverty alleviation for about one year, successfully solved the employment of nearly 2,000 poor labor forces and 5,000 needy students in secondary vocational and higher vocational education, cooperated with more than 100 large-scale well-known enterprises in manufacturing, logistics and service industry, formed a systematic targeted employment poverty alleviation model, scheme and experience. Compared with the existing systems in the literature, the advantages and transformation effect of this platform are remarkable. The platform construction experience of this paper can provide reference for the application of big data, cloud computing and other technologies in other fields of national construction. © 2021 IEEE.",Big Data; Cloud Computing; Platform; Targeted Employment; Targeted Poverty Alleviation,Jiang C.,"Shandong University of Political Science and Law, School of Library, Jinan, China",2021.0,"Proceedings - 2021 International Conference on Computer Information Science and Artificial Intelligence, CISAI 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127439838&doi=10.1109%2fCISAI54367.2021.00102&partnerID=40&md5=d2593bcec919460139606e7c95fdfb83,10.1109/CISAI54367.2021.00102,20230520-160000,20230521-044735,"['research', 'and', 'implementation', 'of', 'intelligent', 'platform', 'for', 'targeted', 'employment', 'poverty', 'alleviation', 'based', 'on', 'cloud', 'computing', 'and', 'big', 'data']",True,20230521-205332,,,,
297,scopus,Real-Estate Housing Market Analytics and Prediction Using Big Data for Post Pandemic Era,"Big Data has transformed the workings of real estate firms by improving the efficiency, cutting costs and by enhancing decision making. It helps them to become more agile for improved customer satisfaction and experiences. In the past, real estate businesses had to follow traditional methods by following past trends and professional expertise to make major decisions. Big Data has become much easier to access accurate real data, make conclusions and to even predict future prices of properties. This research uses machine learning algorithms for the appraisal of property prices in New York City. The methods are applied to the data sample of about 80,000 properties, which have sufficient information about each property and its demographic aspects. By further analysis and modelling, it is observed that model with Feature Engineering has performed much better that the model in which Random Forest was implemented. The conclusions drawn from the empirical study would be beneficial for real estate agents and people who are looking forward to invest in New York properties and understand the variation of property prices of New York in the post covid era in comparison to the pre covid era. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Big data; Big data in housing prediction; Customer support analytics; Housing market prediction; Machine learning; Real-estate analytics,"Jacob C.B., Asha K.","Department of Advanced Computing, St. Joseph’s University, Karnataka, Bangalore, India",2023.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152566456&doi=10.1007%2f978-3-031-27524-1_9&partnerID=40&md5=430f2ca6c3909ad63f46deb70d64c01d,10.1007/978-3-031-27524-1_9,20230520-160000,20230521-044735,"['real-estate', 'housing', 'market', 'analytics', 'and', 'prediction', 'using', 'big', 'data', 'for', 'post', 'pandemic', 'era']",False,20230521-205332,,,,
298,scopus,Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure,"Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a big data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP?In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better.The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI. © 2020 IEEE.",,"Wang C.J., Kim B.","Toyota Motor North America (TMNA), RandD InfoTech Labs, United States",2020.0,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103834951&doi=10.1109%2fBigData50022.2020.9378045&partnerID=40&md5=b663823470a5e6295963243cb34f33ba,10.1109/BigData50022.2020.9378045,20230520-160000,20230521-044735,"['automotive', 'big', 'data', 'pipeline:', 'disaggregated', 'hyper-converged', 'infrastructure', 'vs', 'hyper-converged', 'infrastructure']",True,20230521-205332,,,,
299,scopus,Kanban-based framework for analysis of heterogeneous academic data,"Bibliometric techniques are widely used to study the factors leading to successful research, though this is not without its challenges. One notable problem is that academic data is very diverse, and involves complex interactions between many different entities and players. In this paper, a novel framework for analyzing heterogeneous academic data is proposed. While such a framework would have many different applications, this paper focuses on the design of an academic recommendation system, which is one interesting use case for this framework. © 2017 IEEE.",academic data; bibliometrics; big data; kanban; recommender systems; requirements engineering,"Alshebli B., Alibasic A., Woon W.L., Svetinovic D.","Department of Computer Science, Khalifa University of Science and Technology, Masdar Institute, P.O. Box 54224, Masdar City, Abu Dhabi, United Arab Emirates; Engineering Systems and Management, Khalifa University of Science and Technology, Masdar Institute, P.O. Box 54224, Masdar City, Abu Dhabi, United Arab Emirates",2018.0,"2017 25th Telecommunications Forum, TELFOR 2017 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045855541&doi=10.1109%2fTELFOR.2017.8249470&partnerID=40&md5=d242519dc94d021011eb1583b4494aba,10.1109/TELFOR.2017.8249470,20230520-160000,20230521-044735,"['kanban-based', 'framework', 'for', 'analysis', 'of', 'heterogeneous', 'academic', 'data']",False,20230521-205332,,,,
300,scopus,Improving agile development from perspective of design-informing model,"Agile development is usually used to solve the problem of inflexibility which the other project management models, like the Waterfall model and the V model, may meet. However, conventional agile development still faces many problems under rapid iterations. Frequent iteration lacks efficient communication a large community, resources to share information, and quality of product. For better project management, this article describes a method, called the design-informing model (DIM), to improve the agile development. The design-informing model consists of four parts, user mental mode, developer mental model, system model, and environmental model. At the end of the paper, some discussions will be conducted to evaluate DIM in practice. © 2020 IEEE",Agile development; Model optimization; Project management; Software engineering,Zhang Z.,"University of Toronto, Toronto, Canada",2020.0,"Proceedings - 2020 International Conference on Computing and Data Science, CDS 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098863035&doi=10.1109%2fCDS49703.2020.00011&partnerID=40&md5=38b73053708539110ddaa459943b3cd6,10.1109/CDS49703.2020.00011,20230520-160000,20230521-044735,"['improving', 'agile', 'development', 'from', 'perspective', 'of', 'design-informing', 'model']",True,20230521-205332,,,,
301,scopus,An improved agile framework for implementing data science initiatives in the government,"Implementing data mining projects in governmental organizations is emerging in the Middle East. The literature has been showing that there is a significant gap between the problems defined by the research in data mining and the problems in real world projects. The gap is to the level of semantics between the data scientists and the business users. Trying to fill this gap, we have developed an improved Agile data mining framework to fulfill the government business objectives and needs. The previous works had been claiming that handling such project is not yet mature in the region. For this an Agile implementation framework is required. We are also proposing a systematic way for identifying business problems as part of the framework. The process is Agile, so it would start from investigating the data set dimensions to identify business problems. It also allows early Business people cooperation with data scientist. We've applied the proposed framework in one of the Middle East government organizations. The business team and the data scientists have been showing their satisfaction regarding the results of using the proposed framework. The proposed framework have helped both business and data scientist to implement their first initiative in data mining. The proposed framework also helped in efficiently mapping the project with the core business objectives and problems using real world dataset. © 2020 IEEE.",Agile framework; Business objectives; Business problems; Data mining; Data science,"Qadadeh W., Abdallah S.","Faculty of Engineering and Information Technology, British University in Dubai, Dubai, United Arab Emirates",2020.0,"Proceedings - 3rd International Conference on Information and Computer Technologies, ICICT 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085576456&doi=10.1109%2fICICT50521.2020.00012&partnerID=40&md5=c261872ec2c3c18f1e9e8d19d7813f2b,10.1109/ICICT50521.2020.00012,20230520-160000,20230521-044735,"['an', 'improved', 'agile', 'framework', 'for', 'implementing', 'data', 'science', 'initiatives', 'in', 'the', 'government']",True,20230521-205332,,,,
302,scopus,"Contactless Technologies for Smart Cities: Big Data, IoT, and Cloud Infrastructures","Intelligent systems are enhancing city environments and improving their overall performance in all possible aspects. Innovations in the field of information and communication technologies (ICT) and the proliferation of big data, internet-of-things (IoT), and cloud (BIC) infrastructures revolutionize the existing agile city ecosystems while effectively addressing customers and citizens needs. In this paper, we address the technology-driven applications that are capable of influencing the existing city infrastructures during their transformation towards smart cities with contactless technologies. We present applications, design principles, technology standards, and cost-effective techniques that leverage BIC for contactless applications and discuss user interfaces deployed in smart city environments. We further discuss state-of-the-art sensing methods and smart applications that support cities with smart contactless features. Finally, a case study is reported on how BIC can assist in efficiently handling and managing emergency situations such as the COVID-19 pandemic. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.",Big data; Cloud; Contactless technologies; COVID-19; Internet-of-things; Smart city,"Manimuthu A., Dharshini V., Zografopoulos I., Priyan M.K., Konstantinou C.","Energy Research Institute (ERI@N), Nanyang Technological University, Singapore, Singapore; APTECH Solutions PVT LTD, Bangalore, India; Division of Computer, Electrical and Mathematical Sciences and Engineering, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955, Saudi Arabia; Department of Computer Engineering, Kyung Hee University, Seoul, South Korea",2021.0,SN Computer Science,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116239179&doi=10.1007%2fs42979-021-00719-0&partnerID=40&md5=544f6baa831e90710b378e576a1976ac,10.1007/s42979-021-00719-0,20230520-160000,20230521-044735,"['contactless', 'technologies', 'for', 'smart', 'cities:', 'big', 'data,', 'iot,', 'and', 'cloud', 'infrastructures']",False,20230521-205332,,,,
303,scopus,Growing smart farming services: How to get the best out of farming data,"Many enterprises in the agricultural sector can access a lot of data, but often (still) fail to treat this data as an asset. Even though farming data has great potential for the creation of new business models, most manufacturers of agricultural equipment do not know which data they possess as it is spread across different data silos of complex and historically grown application landscapes. In order to come up with innovative data-driven smart farming services, seamless collaboration of cross-functional teams staffed with different roles like software engineers, data scientists, business experts, and end users is crucial for the successful realization of smart farming services. In a joint research cooperation, John Deere and Fraunhofer IESE have developed an agile engineering method for the value-driven creation of smart farming services. In this paper, we present our method, which is based on different design thinking techniques used to identify concrete data-driven user stories that are of true value to farmers. We also present a data science notation that we developed to facilitate the targeted analysis of the data-science-significant requirements of data-driven user stories and to foster interdisciplinary collaboration and knowledge dissemination in our cross-functional team. We also demonstrate the Insights Collaboration (short: ICSpace) app, which supports the application of the notation. © VDI Verlag GmbH · Düsseldorf 2019.",,"Braun S., Trapp M., Nass C., Gerbershagen M., Schweitzer S., Falcão R., Schweitzer M., Wire N.","Fraunhofer IESE, Kaiserslautern, Germany; John Deere European Technology Innovation Center, Kaiserslautern, Germany",2019.0,VDI Berichte,VDI Verlag GMBH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105989502&partnerID=40&md5=ee8462b80ca5451bcd796b7e0219632d,,20230520-160000,20230521-044735,"['growing', 'smart', 'farming', 'services:', 'how', 'to', 'get', 'the', 'best', 'out', 'of', 'farming', 'data']",False,20230521-205332,,,,
304,scopus,A Simulator and Compiler Framework for Agile Hardware-Software Co-design Evaluation and Exploration,"As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and hardware-software co-design. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support heterogeneous combinations of general-purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we describe our compiler and simulator pair: DEC++ and MosaicSim. Together, they provide a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. The simulator and corresponding compiler were developed as part of the DECADES project, a multi-team effort to design and tape out a new heterogeneous architecture. We will present two case-studies in important data-science applications where DEC++ and MosaicSim enable straightforward design space explorations for emerging full-stack systems. © 2020 Association on Computer Machinery.",hardware-software co-design. LLVM simulation; heterogeneous systems; performance modeling,"Sorensen T., Manocha A., Tureci E., Orenes-Vera M., Aragon J.L., Martonosi M.","UC Santa Cruz, United States; Princeton University, United States",2020.0,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097943775&doi=10.1145%2f3400302.3415751&partnerID=40&md5=04ecc940584174df64b9abff88934f79,10.1145/3400302.3415751,20230520-160000,20230521-044735,"['a', 'simulator', 'and', 'compiler', 'framework', 'for', 'agile', 'hardware-software', 'co-design', 'evaluation', 'and', 'exploration']",True,20230521-205332,,,,
305,scopus,What Are the Critical Success Factors for Agile Analytics Projects?,"To get value from BI (Business Intelligence) and Big Data initiatives, organizations need to develop the capability to successfully execute their analytics projects. Via updating Chow and Cao’s list of 12 success factors for agile projects, 43 attributes of these potential critical success factors (CSFs) were identified. Data from four case studies of analytics projects suggest that the critical success factors for analytics projects may be Strong Customer Involvement and a Methodical Project Definition Process. © 2020 Taylor & Francis.",agile project management; agile projects; Analytics projects; project success factors,"Tsoy M., Staples D.S.","Smith School of Business, Queen’s University, Kingston, Canada",2021.0,Information Systems Management,Taylor and Francis Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090761786&doi=10.1080%2f10580530.2020.1818899&partnerID=40&md5=674e6c4c8ff9e5ced96022ae5068ef4e,10.1080/10580530.2020.1818899,20230520-160000,20230521-044735,"['what', 'are', 'the', 'critical', 'success', 'factors', 'for', 'agile', 'analytics', 'projects?']",False,20230521-205332,,,,
306,scopus,A reconciliation model of agile C2 organization based on converged networks,"With the promotion of information technology and big data technology, and the traction of new operational concepts such as Mosaic Warfare and Joint Global Operations, the research and practice of agile command control(C2) organization has become a hot issue in the field of C2. One of the focal points of the debate is the contrast between the traditional hierarchy structure of C2 organizations and the edge structure. Is the traditional hierarchy structure of C2 necessarily in conflict with the edge structure? Can these two organizational structure models be reconciled to achieve organizational agility transformation? How to reconcile these two models of organizational structure? In order to solve the above problem, we put forward a kind of suitable reconciliation model of agile C2 organization considering our actual situation. On this basis, we use ontology modeling method to form characteristics of adaptive and intelligent cross-domain integrated solutions, through the establishment of agile ontology and reasoning mechanism of C2 organization. © 2020 IEEE.",agility; command control; converged networks; organization mode; reconciliation model,"Zhou W., Bao W., Sun X., Wan J., Xu Y., Gao Y.","College of Systems Engineering, National University of Defense Technology, Changsha, China; International Studies College, National University of Defense Technology, Nanjing, China",2020.0,"Proceedings - 2020 6th International Conference on Big Data and Information Analytics, BigDIA 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104374187&doi=10.1109%2fBigDIA51454.2020.00018&partnerID=40&md5=b1c80992f3ec7d33ae6aafb4c68f9722,10.1109/BigDIA51454.2020.00018,20230520-160000,20230521-044735,"['a', 'reconciliation', 'model', 'of', 'agile', 'c2', 'organization', 'based', 'on', 'converged', 'networks']",True,20230521-205332,,,,
307,scopus,Big Data Analytics Capability Ecosystem Model for SMEs,"The unprecedented COVID-19 pandemic, together with globalization and advanced technologies, has drastically changed the business environment and forced companies to become more innovative and agile in the way they run their business and respond to the needs and wants of customers. Survival highly depends on the adaptability of SMEs to this ever-changing complex dynamic environment by taking steps in implementing Big Data Analytics as the next frontier for innovation, competition, productivity, and value creation. Based on the grounded theory, this study employed a qualitative method via focus group discussion. Focus groups were conducted with 14 government agencies, SMEs associations, business owners, Chief Operating Officers (CEOs), academic and industrial experts and directors of SMEs in Malaysia. The study revealed the challenges of Malaysian SMEs in adopting Big Data Analytics Capability, presents the criticality of Big Data Analytics Capability to overcome the identified challenges, and develops a BDA Capability Ecosystem Model that integrates the internal enablers, external barriers and support to explain the adoption of BDA Capability for value creation and support the decision-making process. This paper is followed by some policy suggestions for companies’ owners, policymakers, government agencies, universities, and SMEs. This study directly impacts Malaysia’s economy as a whole by addressing Malaysia’s Shared Prosperity Vision 2030. This research contributes to industries that are still in the low value added category with low adoption of technology. Furthermore, it will ultimately lead to the realization of SMEs as ‘game changers’ to transition the economy to a high-income nation. This study proposes a model that could help SMEs improve their value creation performance, directly influencing the country’s GDP and employability. © 2022 by the authors.",Big Data Analytics; business model; capability; competencies; SMEs; value creation,"Falahat M., Cheah P.K., Jayabalan J., Lee C.M.J., Kai S.B.","Centre for Entrepreneurial Sustainability, Universiti Tunku Abdul Rahman (UTAR), Sungai Long Campus, Bandar Sungai Long, 43000, Malaysia; Faculty of Arts and Social Science, Universiti Tunku Abdul Rahman (UTAR), Kampar Campus, Kampar, 31900, Malaysia; Institute of Strategic Analysis Policy Research, Kuala Lumpur, 50450, Malaysia",2023.0,Sustainability (Switzerland),MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146036098&doi=10.3390%2fsu15010360&partnerID=40&md5=01253af41fdc9f90b1c099385ab06d41,10.3390/su15010360,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'capability', 'ecosystem', 'model', 'for', 'smes']",False,20230521-205332,,,,
308,scopus,Development of a Digital ESP Performance Monitoring System Based on Artificial Intelligence,"Wintershall Dea is developing together with partners a digital system to monitor and optimize electrical submersible pump (ESP) performance based on the data from Mittelplate oil field. This tool is using machine learning (ML) models which are fed by historic data and will notify engineers and operators when operating conditions are trending beyond the operating envelope, which enables an operator to mitigate upcoming performance problems. In addition to traditional engineering methods, such a system will capture knowledge by continuous improvement based on ML. With this approach the engineer has a system at hand to support the day-to-day work. Manual monitoring and on demand investigations are now backed up by an intelligent system which permanently monitors the equipment. In order to create such a system, a proof of concept (PoC) study has been initiated with industry partners and data scientists to evaluate historic events, which are used to train the ML-systems. This phase aims to better understand the capabilities of machine learning and data science in the subsurface domain as well as to build up trust for the engineers with such systems. The concept evaluation has shown that the intensive collaboration between engineers and data scientist is essential. A continuous and structured exchange between engineering and data science resulted in a mutual developed product, which fits the engineer's needs based on the technical capabilities and limits set by ML-models. To organize such a development, new project management elements like agile working methods, sprints and scrum methods were utilized. During the development Wintershall Dea has partnered with two organizations. One has a pure data science background and the other one was the data science team of the ESP manufacturer. After the PoC period the following conclusions can be derived: (1) data quality and format is key to success; (2) detailed knowledge of the equipment speeds up the development and the quality of the results; (3) high model accuracy requires a high number of events in the training dataset. The overall conclusion of this PoC is that the collaboration between engineers and data scientists, fostered by the agile project management toolkit and suitable datasets, leads to a successful development. Even when the limits of the ML-algorithms are hit, the model forecast, in combination with traditional engineering methods, adds significant value to the ESP performance. The novelty of such a system is that the production engineer will be supported by trusted ML-models and digital systems. This system in combination with the traditional engineering tools improves monitoring of the equipment and taking decisions leading to increased equipment performance. © Copyright 2021, Society of Petroleum Engineers",,"Diker G., Frühbauer H., Bi Mba E.M.B.",Wintershall Dea,2021.0,"Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference, ADIP 2021",Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127643978&doi=10.2118%2f207929-MS&partnerID=40&md5=02051226cf9095f2760efd6a4fdb7f40,10.2118/207929-MS,20230520-160000,20230521-044735,"['development', 'of', 'a', 'digital', 'esp', 'performance', 'monitoring', 'system', 'based', 'on', 'artificial', 'intelligence']",False,20230521-205332,,,,
309,scopus,Discover the digital technology application in fashion business models,"In the last few decades, there has been a surge of interest in the development of fashion business models to assist fashion companies in reducing the cost and to e±ciently manage business processes. These business models are developed to manage the internal operations within the company through adopting complex formulae and algorithms to reduce the waste at each procedure. However in today's fashion business market, global sourcing and global corporation are much more important than before. The relationship between the fashion company and its suppliers, the relationship between the fashion company and its customers, and the management of these relationships. All of them are crucial parts in the business strategy. The competition between fashion companies is no longer in company level but instead is supply chain versus supply chain. Trying to take the massive information into consideration by using traditional digital technology is not a wise decision when developing business strategy. Further thinking, the information flow through the supply chain has the same characteristics \5Vs""as big data: Volume, Velocity, Variety, Value and Veracity. Put another word: the management of information flow in supply chain is the management of big data. There is no doubt that the digital technology under big data environment will fundamentally change the whole supply chain. The first objective of this paper is to identify the key weakness of lean and agile logistic supply chain models in literature. The second objective is to point out the technology challenges to develop the Tomorrow's models which build an agile response upon a lean platform: How to set up virtual networks from the early designing stage to the last consuming and feedback stage? How to set up the information standardization and synchronisation process in the system? How to specify the consumer requirements in fitting effects and functional performance of garments? The last objective is to discover the digital technology under big data environment which enable the information e±ciently to flow through the whole supply chain. Copyright © 2020 Textile Bioengineering and Informatics Society.",Big Data; Business Model; Digital Technology; Information Flow Management; Supply Chain Logistic,"Liu Z., Song Q., Cao K., Wang Y., Li Y.","University of Manchester, E2, MSS Tower, Manchester, M1 2PG, United Kingdom; Xi'An Polytechnic University, Xi'an, 710048, China",2020.0,Journal of Fiber Bioengineering and Informatics,Global Science Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096741898&doi=10.3993%2fJFBIM00313&partnerID=40&md5=c72624c32204a0e92d8ae7fe329ffb03,10.3993/JFBIM00313,20230520-160000,20230521-044735,"['discover', 'the', 'digital', 'technology', 'application', 'in', 'fashion', 'business', 'models']",False,20230521-205332,,,,
310,scopus,Role of joint 5G-IoT framework for smart grid interoperability enhancement,"The ever-growing development in communication technology and very fast advances in data science are transferring the power systems in a new era. The level of autonomy is improving by means of Internet-of-Things (IoT), while the level of intelligence is improving through artificial intelligence. The applications of big data analytics and cloud computing techniques in smart grids are also new topics, which have been paid particular attention recently. These paradigms can be used in both grid-scale and local-scale, while the central grid operation center has interoperability with an abundant number of sub-controllers, and aggregators in a wide variety of scales. On the one hand, the system operator must deal with multiple parameters with different kinds of uncertainties. On the other hand, the new structures are evolving toward transactive energy trading models in microgrids. In such a circumstance, a myriad of elements is producing critical data, which should be acquired, transferred, stored, analyzed, and finally, proper controlling actions must be sent. These data are producing at different intervals, even in a fraction of a second. This matter makes it possible to maintain grid security and better real-time operation as well as to get better demand responsiveness. A smart grid consists of many embedded or interconnected systems that are linked to each other through various communication platforms in the cyber layer. A flexible, highly-autonomous, and intelligent smart grid entails an agile communication system, whether wired or wireless. However, cellular networks have prominent benefits. Hence, 5G technology, which is state-of-the-art technology in this field, can be deployed. The communication infrastructure links many components to each other in cyber-physical smart grids. The velocity of data exchange has a profound importance for some purposes, while 5G technology can be the best solution. The joint integration of IoT and 5G procures more reliability, resiliency, security, and economy. © 2020 IEEE.",5G; Big data analytics; Blockchain; Communication infrastructure; Internet of things (IoT); Smart Grids,"Shahinzadeh H., Mirhedayati A.-S., Shaneh M., Nafisi H., Gharehpetian G.B., Moradi J.","Amirkabir University of Technology, Department of Electrical Engineering, Tehran, Iran; Najafabad Branch, Islamic Azad University, Department of Electrical Engineering, Najafabad, Iran; Najafabad Branch, Islamic Azad Universityy, Smart Microgrid Research Center, Najafabad, Iran; Khomeinishahr Branch, Islamic Azad University, Young Researchers and Elite Club, Esfahan, Iran",2020.0,"2020 15th International Conference on Protection and Automation of Power Systems, IPAPS 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103456982&doi=10.1109%2fIPAPS52181.2020.9375539&partnerID=40&md5=c162d82a37b458a79a57aec1de34ba2e,10.1109/IPAPS52181.2020.9375539,20230520-160000,20230521-044735,"['role', 'of', 'joint', '5g-iot', 'framework', 'for', 'smart', 'grid', 'interoperability', 'enhancement']",True,20230521-205332,,,,
311,scopus,Managing Blockchain Projects with Agile Methodology,"Blockchain technology is one of the latest and recent famous technologies in the digital world. Most organizations, especially financial institutions observed and felt the changes that were created in cryptocurrency markets. As blockchain is the hosted environment and the backbone of the crypto currencies like Bitcoin, Litecoin and Ethereum they believe they should adopt some of their provided services on this technology. Many entities in the region are interested to be pioneers on providing services on recent and widely trusted and accepted technologies like blockchain. Researchers and interested personnel expected that, blockchain technology will be capable to minimize the requirement of multiple participants in many businesses. Business processes will need to be reengineered on the firm. In addition, it is expected to reduce required time and resources to complete a transaction. Managing projects on blockchain technology will be different from managing other projects as these types of project will require the ability to change and a lot of preparations for unexpected. This paper highlights briefly this technology mentioning its concepts, types and phases. In addition, it is listed how agile project management could suite the management of blockchain applications. © 2020, Springer Nature Singapore Pte Ltd.",Agile; Blockchain; Cryptocurrency; Scrum; Smart contract,"Al-Mazrouai G., Sudevan S.","Modern Collage of Business and Science, Muscat, Oman",2020.0,"Smart Innovation, Systems and Technologies",Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075583056&doi=10.1007%2f978-981-32-9889-7_14&partnerID=40&md5=cbb2ec9c54534400b7c60769e1226ce3,10.1007/978-981-32-9889-7_14,20230520-160000,20230521-044735,"['managing', 'blockchain', 'projects', 'with', 'agile', 'methodology']",False,20230521-205332,,,,
312,scopus,Ambidextrous organization and agility in big data era: The role of business process management systems,"Purpose: The purpose of this paper is to explore the effect of big data analytics-capable business process management systems (BDA-capable BPMS) on ambidextrous organizations’ agility. In particular, how the functionalities of BDA-capable BPMS may improve organizational dynamism and reactiveness to challenges of Big Data era will be explored. Design/methodology/approach: A theoretical analysis of the potential of BDA-capable BPMS in increasing organizational agility, with particular attention to the ambidextrous organizations, has been performed. A conceptual framework was subsequently developed. Next, the proposed conceptual framework was applied in a real-world context. Findings: The research proposes a framework highlighting the importance of BDA-capable BPMS in increasing ambidextrous organizations’ agility. Moreover, the authors apply the framework to the cases of consumer-goods companies that have included BDA in their processes management. Research limitations/implications: The principal limitations are linked to the need to validate quantitatively the proposed framework. Practical implications: The value of the proposed framework is related to its potential in helping managers to fully understand and exploit the potentiality of BDA-capable BPMS. Moreover, the implications show some guidelines to ease the implementation of such systems within ambidextrous organizations. Originality/value: The research offers a model to interpret the effects of BDA-capable BPMS on ambidextrous organizations’ agility. In this way, the research addresses a significant gap by exploring the importance of information systems for ambidextrous organizations’ agility. © 2018, Emerald Publishing Limited.",Agile; Agility; Ambidexterity; Big data; Information systems,"Rialti R., Marzi G., Silic M., Ciappei C.","Dipartimento di Economia e Management, Università di Pisa, Pisa, Italy; Lincoln Business School, Lincoln, United Kingdom; Institute of Information Management, Universitat Sankt Gallen School of Management, Sankt Gallen, Switzerland; DISEI – Dipartimento di Scienze per l’Economia e L’impresa, Università degli Studi di Firenze, Firenze, Italy",2018.0,Business Process Management Journal,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048868415&doi=10.1108%2fBPMJ-07-2017-0210&partnerID=40&md5=dbe662121194e23055f358d478fcc8e9,10.1108/BPMJ-07-2017-0210,20230520-160000,20230521-044735,"['ambidextrous', 'organization', 'and', 'agility', 'in', 'big', 'data', 'era:', 'the', 'role', 'of', 'business', 'process', 'management', 'systems']",False,20230521-205332,,,,
313,scopus,Agile Construction of Data Science DSLs (Tool Demo),"Domain Specific Languages (DSLs) have proven useful in the domain of data science, as witnessed by the popularity of SQL. However, implementing and maintaining a DSL incurs a significant effort which limits their utility in context of fast-changing data science frameworks and libraries. We propose an approach and a Python-based library/tool NLDSL which simplifies and streamlines implementation of DSLs modeling pipelines of operations. In particular, syntax description and operation implementation are bundled together as annotated and terse Python functions, which simplifies extending and maintaining a DSL. To support ad hoc DSL elements, NLDSL offers a mechanism to define DSLlevel functions as first-class DSL elements. Our tool automatically supports each DSL by code completions and in-editor documentation in a multitude of IDEs implementing the Microsoft's Language Server Protocol. To circumvent the problem of a limited expressiveness of a external DSL, our tool allows embedding DSL statements in the source code comments of a general purpose language and to translate the DSL to such a language during editing. We demonstrate and evaluate our approach and tool by implementing a DSL for data tables which is translated to either Pandas or to PySpark code. A preliminary evaluation shows that this DSL can be defined in a concise and maintainable way, and that it can cover a majority of processing steps of popular Spark/Pandas tutorials. Copyright © 2019 by the Association for Computing Machinery, Inc. (ACM).",Apache Spark; Assisted editing and IntelliSense; Code generation; Data analysis frameworks; DSL development; Python Pandas,"Andrzejak A., Kiefer K., Costa D.E., Wenz O.","Heidelberg University, Heidelberg, Germany",2019.0,"GPCE 2019 - Proceedings of the 18th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2019","Association for Computing Machinery, Inc",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077074838&doi=10.1145%2f3357765.3359516&partnerID=40&md5=1add386e50762445abc8d5c8c79e9f9e,10.1145/3357765.3359516,20230520-160000,20230521-044735,"['agile', 'construction', 'of', 'data', 'science', 'dsls', '(tool', 'demo)']",True,20230521-205332,,,,
314,scopus,Smart cities semantics and data models,"Data models and semantics are a key aspect for the valorization of data in cross-domain applications and to obtain knowledge/insights beyond the original applications (vertical use cases). An important role of Big Data and a key fundament of its success is this capacity to discover and extract new knowledge beyond the original use of data, in order to learn, optimize processes and understand the hidden rules of our world. This works presents the different data models from standardization bodies such as IEEE PAR2530, ITU-T FG DPM, ETSI ISG CIM and oneM2M, W3C SSN, OMA LwM2M etc. An analysis and comparative among all of them and also the opportunities to link them in order to guarantee that we can obtain the major value through co-operation among cities and different departments. This work is contextualized in the principles from the Open and Agile Smart Cites (OASC) and linked initiatives focused on data management cross-cities and large scale pilots. © Springer International Publishing AG 2018.",Data models; ETSI ISG CIM; FIWARE; Internet of things; ITU-T; OASC; oneM2M; Open and agile smart cities; Semantics; Smart cities,"Jara A.J., Serrano M., Gómez A., Fernández D., Molina G., Bocchi Y., Alcarria R.","Mobility Lab, University of Applied Sciences Western Switzerland (HES-SO), Technopole. 3, Sierre, 3960, Switzerland; Insight Research Centre, National University of Ireland Galway (NUIG), Galway, Ireland; HOP Ubiquitous S.L. (HOPU), Luis Buñuel. 6, Ceutí, Murcia, 30562, Spain; Escuela Técnica Superior de Ingeniería en Telefomunicaciones, Universidad Politécnica de Madrid (UPM), Madrid, Spain",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041063079&doi=10.1007%2f978-3-319-73450-7_8&partnerID=40&md5=affb741738b5d8fdd1faf9902f39b9cd,10.1007/978-3-319-73450-7_8,20230520-160000,20230521-044735,"['smart', 'cities', 'semantics', 'and', 'data', 'models']",False,20230521-205332,,,,
315,scopus,What is Good Feedback in Big Data Projects for Cyberinfrastructure Diffusion in e-Science?,"This paper investigates the role of feedback in big data projects for cyberinfrastructure (CI) diffusion in e-science. For many of these projects, large-scale and heterogeneous datasets, multidisciplinary and dispersed experts, and advanced technologies are brought together to harness analytic insights. However, without effective CI and computational tools, the accuracy and meaningfulness of analytics results are compromised. In fact, without CI tools, raw data remain raw with hidden insights, as data analytics cannot be executed at all. In order to improve such tools for meaningful results, we argue to conceptualize the communication mechanism of 'feedback' in agile software development, with the goal of producing CI tools that are responsive to users. Based on a grounded analysis of interview data, we concluded that feedback helps developers in big data projects understand users' needs, makes tools user-friendly, prevents emergencies, and is better for developers than no feedback. Furthermore, good feedback is often structured, specific, actionable, timely, generalizable, and delivered in a tactful way. Despite the limitation of the findings being exploratory and yet to be evaluated experimentally, we argued that they still can motivate developers to be proactive seekers of feedback for their tools, productively guide developers' communication with users, and ultimately promote further adoption and diffusion of CI tools in e-science. © 2018 IEEE.",agile software development; cyberinfrastructure; diffusion of innovations; e-science; feedback; technology adoption,"Kee K.F., McCain J.C.","School of Communication, Chapman University, Orange, CA, United States",2019.0,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062626202&doi=10.1109%2fBigData.2018.8622573&partnerID=40&md5=1ddbc52dcf8198b13a4dd0941f06ed62,10.1109/BigData.2018.8622573,20230520-160000,20230521-044735,"['what', 'is', 'good', 'feedback', 'in', 'big', 'data', 'projects', 'for', 'cyberinfrastructure', 'diffusion', 'in', 'e-science?']",True,20230521-205332,,,,
316,scopus,Discover the digital technology application in fashion business models,"In the last few decades, there has been a surge of interest in the development of fashion business models to assist fashion companies in reducing cost and to efficiently manage the business processes. These business models are developed to manage the internal operations within the company through adopting complex formulae and algorithms to reduce waste at each procedure. However in today's fashion business market, global sourcing and global corporation are much more important than before. The relationship between the fashion company and its suppliers, the relationship between the fashion company and its customers, and the management of these relationships: all of them are critical components of an effective business strategy. The competition between fashion companies is no longer on a company level but instead is subjected to supply chain versus supply chain. Trying to take the massive information into consideration by using traditional digital technology is not a wise decision when developing business strategy. On further thinking, the information flow through the supply chain has the same characteristics ""5Vs"" as big data: Volume, Velocity, Variety, Value and Veracity. In other words, the management of information flow in supply chain is the management of big data. There is no doubt that digital technology under the big data environment will fundamentally change the whole supply chain. The first objective of this paper is to identify the key weakness of lean and agile logistic supply chain models in literature. The second objective is to point out the technological challenges in developing Tomorrow's models to build an agile response with a lean platform: How to set up virtual networks from the early designing stage to the last consuming and feedback stage? How to set up the information standardization and synchronisation process in the system? How to specify the consumer requirements in fitting effects and functional performance of garments? The last objective is to discover the digital technology under big data environment which will enable the information to efficiently flow through the whole supply chain. © 2018 Binary Information Press. All rights reserved.",Big data; Business model; Digital technology; Information flow management; Supply chain logistic,"Liu Z.-C., Li Y., Wang Y.-Y.","University of Manchester, E2, MSS Tower, Manchester, Ml 2PG, United Kingdom",2018.0,"Textile Bioengineering and Informatics Symposium Proceedings 2018 - 11th Textile Bioengineering and Informatics Symposium, TBIS 2018",Binary Information Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054572752&partnerID=40&md5=269a4d994d0318915f9b11da80c592a3,,20230520-160000,20230521-044735,"['discover', 'the', 'digital', 'technology', 'application', 'in', 'fashion', 'business', 'models']",True,20230521-205332,,,,
317,scopus,Machine Learning Experiments with Artificially Generated Big Data from Small Immunotherapy Datasets,"Big data and machine learning result in agile and robust healthcare by expanding raw data into useful patterns for data-enhanced decision support. The available datasets are mostly small and unbalanced, resulting in non-optimal classification when the algorithms are implemented. In this study, five novel machine learning experiments are conducted to address the challenges of small datasets by expanding these into big data and then utilising Random Forests. The experiments are based on personalised adaptable strategies for both balanced and unbalanced datasets. Multiple datasets from cryotherapy and immunotherapy are considered, however, hereby only immunotherapy is used. In the first experiment, artificially generated data is presented by increasing the observations of the dataset, each new data is four-time larger than the previous one, resulting in better classification. In the second experiment, the effect of volume on classification is considered based on the number of attributes. The attributes of each new dataset are built based on conditional probabilities. It did not make any difference, in obtained classification, when the number of attributes is increased to more than 879. In the third simulation experiment, classes of data are classified manually by dividing the data into a two-dimensional plane. This experiment is first performed on small data and then on expanded big data: by increasing observations, an accuracy of 73.68% is attained. In the fourth experiment, the visualisation of the enlarged data did not provide better insights. In the fifth experiment, the impact of correlations among datasets' attributes on classification is observed, however, no improvements in performance are achieved. The experiments generally improved performance by comparing the classification results using the original and artificial data. © 2022 IEEE.",Big data; Classification; Cryotherapy; Health-care; Immunotherapy; Machine learning; Random Forests; Warts,"Yunas Mahmoud A., Neagu D., Scrimieri D., Rashad Ahmed Abdullatif A.","University of Bradford, Faculty of Engineering and Informatics, Bradford, United Kingdom",2022.0,"Proceedings - 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152213560&doi=10.1109%2fICMLA55696.2022.00165&partnerID=40&md5=9b0ddf57fea6bde20b24a8d18c3c3ec1,10.1109/ICMLA55696.2022.00165,20230520-160000,20230521-044735,"['machine', 'learning', 'experiments', 'with', 'artificially', 'generated', 'big', 'data', 'from', 'small', 'immunotherapy', 'datasets']",True,20230521-205332,,,,
318,scopus,Big Data Platform for Oil and Gas Production Based on Apache Spark,"For promoting the construction of intelligent oil field and applying big data technology to the daily production activities of oil field, this paper proposes a data mining platform based on Apache Spark multi-functional oil and gas production big data. This platform combines real-time and historical data processing-related framework and machine learning framework, designs massive oil and gas production data processing for different oil fields, supports real-time and offline processing data mining and other functions, supports the prediction of some data using related machine learning algorithms, supports the cleaning of large amounts of data, is used to train various deep learning models and will provide corresponding interfaces and permissions to relevant oil fields. Docker container is used to build the training environment of deep learning and machine learning, and the Kubernetes framework is used to complete the scheduling function. Struts, Spring and Hibernate relatively classic background processing framework is adopted at the Web framework level of the platform, different functions are decomposed into independent functional modules to reduce coupling, and agile development is used to improve the extended performance of the whole big data platform. This platform allows our data analysts to focus on data analysis and model training, without spending a lot of time and effort to deal with data problems, while the related calculation results are returned to other oil companies in an interface way or provide relevant operation authority to the field operation and maintenance personnel to access the data platform and data analysis. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Big data; Data mining; Hadoop; Machine learning; Spark; Web,"Qing P., Li Y., Luo S., Xu Z.","Tsinghua University, Shenzhen, GD  518000, China",2021.0,"Smart Innovation, Systems and Technologies",Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107360179&doi=10.1007%2f978-981-33-6141-6_14&partnerID=40&md5=182b0e253b9673397922517bbd67f7bf,10.1007/978-981-33-6141-6_14,20230520-160000,20230521-044735,"['big', 'data', 'platform', 'for', 'oil', 'and', 'gas', 'production', 'based', 'on', 'apache', 'spark']",False,20230521-205332,,,,
319,scopus,An agile product development methodology for personalisation under industry 4.0,"Industry 4.0, as the fourth Industrial Revolution, comprises of a variety of technologies resulting in cost reduction and efficiency improvement. Industry 4.0 changes the way that value creation transformed towards personalised product development. Industries and business sectors have faced challenges to improve customer satisfaction while there is a continuously growing demand for product personalisation worldwide. To address affordable personalisation, there are limited studies about how Industry 4.0 could bring significant value to personalisation at scale. Affordable personalisation is one of the ultimate goals to achieve in the era of Industry 4.0. The high customer demand and industrial completion encouraged almost all business sectors to meet customer’s requirements with the cost near to mass production. This paper investigates an agile methodology for mass personalisation under Industry 4.0. The cutting-edge Industry 4.0 technologies for personalisation, in addition to product development and personalisation, has been reviewed. Agile product development along with Cloud-enabled customer profile (CCP), personalised customer backlog (PCB), personalised product backlog (PPB), augmented, and 3D printing prototyping for personalisation has been proposed. A case study for personalised facial mask has been presented by using the Internet of Things (IoT), Big data, additive manufacturing (AM), augmented reality (AR) and Cloud technologies through an iterative and incremental process. Finally, the challenges and future perspectives have been identified. This study leads to a sustainable development approach when developing mass personalisation as a service. In this paper, the proposed methodology has been validated by using augmented reality and 3D printing based prototyping, which has been achieved by measuring performance through Big data and Edge computing. Academia and practitioners could refer to this study when implementing Industry 4.0 in manufacturing product personalisation. © 2019, Computers and Industrial Engineering. All rights reserved.",Agile; Augmented reality; Big data; Industry 4.0; Internet of things,"Aheleroff S., Xu X., Zhong R.Y.","Department of Mechanical Engineering, The University of Auckland, New Zealand; Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Hong Kong",2019.0,"Proceedings of International Conference on Computers and Industrial Engineering, CIE",Computers and Industrial Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079495199&partnerID=40&md5=83a47296572e6fa5a92fc9a4bf94adf0,,20230520-160000,20230521-044735,"['an', 'agile', 'product', 'development', 'methodology', 'for', 'personalisation', 'under', 'industry', '4.0']",False,20230521-205332,,,,
320,scopus,The Complexity of Business Process Digitalization and Organisational Challenges,"Business process digital transformation is going together with many challenges agile approach to the digitalization process requirements. These issues related to this complexity can be translated on come more specific r hypothetical subjects: business incapability for fast adoption of change management techniques, deficiency in strategic approach to digital transformation, and inability to take iterative organisational actions towards simplification of technology complexity. Consequently, this research aims to address the potential causes of lack of agile approach, strategic questions, and the approach applied responding to the complex requirements of digitalization process. The target population is composed of regional enterprises with a fixed sample. Qualitative analysis has resulted in the flow of important information related to forward thinking regarding issues of complexity and organization. While the quantitative research has resulted in the testing of the raised hypotheses. Copyright © 2022 The Authors.",Agility; Complexity Theory; Data Science; Digital Technologies; Flexibility; Transformation,"Limani Y., Hajrizi E., Stapleton L.","UBT College, Prishtina Kosovo, Department for Information Systems, Serbia; INSYTE Research Centre, Waterford Institute of Technology, Cork Road, Waterford, Ireland",2022.0,IFAC-PapersOnLine,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147027177&doi=10.1016%2fj.ifacol.2022.12.051&partnerID=40&md5=502dda87ae50b8bbe8061b85ef5293bf,10.1016/j.ifacol.2022.12.051,20230520-160000,20230521-044735,"['the', 'complexity', 'of', 'business', 'process', 'digitalization', 'and', 'organisational', 'challenges']",False,20230521-205332,,,,
321,scopus,Design and Application of a Testing Framework of Online Course Based on Agile,"On the basis of the feature analysis on development of online course from the perspective of software engineering, a testing framework of online course based on agile is designed firstly. The framework consists of four test cycles with iteration by test stages on preparing for testing, pre-testing, functionality testing and regression testing, and with a test process of acceptance testing at the end of four test cycles before product delivery. The evaluation on organization of the contents of chapter-section structure is also embodied in this framework. Secondly, the framework is fully applied to the agile testing project for an actual online course of ""Software Engineering"", experimental result shows that more bugs for types of structure of contents, usability, compatibility, installing, security, and navigability of the online course are detected in time and test result is noticeable. Finally, putting forward that some features and aspects on non-functionality testing through test automation together with effective exploratory testing method, and constructing an automated testing environment on cloud computing for big data processing will be the future research. © Published under licence by IOP Publishing Ltd.",,Yu J.,"College of Computer Engineering, Anhui SanLian University, Hefei, 230601, China",2018.0,IOP Conference Series: Materials Science and Engineering,Institute of Physics Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052319920&doi=10.1088%2f1757-899X%2f394%2f3%2f032099&partnerID=40&md5=bc1e2a55208b557e5adb06a8a4b995c7,10.1088/1757-899X/394/3/032099,20230520-160000,20230521-044735,"['design', 'and', 'application', 'of', 'a', 'testing', 'framework', 'of', 'online', 'course', 'based', 'on', 'agile']",False,20230521-205332,,,,
322,scopus,Design and research of insurance survey claims system based on big data analysis,"In order to overcome the cumbersome procedures of insurance investigation and claim settlement and the difficulty of precise promotion of insurance services for specific customers, this paper proposes an insurance investigation and claim system based on big data analysis. This method is developed on the basis of agile model. It has case information management, investigation information management, claim settlement management, intelligent insurance recommendation, etc. Intelligent customer service and other core functions, relying on Web, mobile applications and social networks for data collection, filtering and real-time analysis of the collected large data information, using Hadoop framework to convert structured data into semi-structured or unstructured data, storage of data information, through advanced analysis, prediction model Type and visual query, mining and analyzing the extracted data, and finally displaying the results after analysis. The experimental results show that the insurance survey and claim system completes the business processing of one-click report, survey photos upload, efficient claim settlement and insurance recommendation, speeds up the claim processing speed, and realizes the personalized service and precise marketing of customer insurance. © 2019 IEEE.",Claim Settlement; Insurance; Intelligence,"Wu J., Wang J., Liu Y.","Dalian Neusoft University of Information, Dalian, Liaoning, 116032, China",2019.0,"Proceedings - 2019 International Conference on Virtual Reality and Intelligent Systems, ICVRIS 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077109412&doi=10.1109%2fICVRIS.2019.00059&partnerID=40&md5=dd9eacbc6506789a0ca3c7e52fbfbaf6,10.1109/ICVRIS.2019.00059,20230520-160000,20230521-044735,"['design', 'and', 'research', 'of', 'insurance', 'survey', 'claims', 'system', 'based', 'on', 'big', 'data', 'analysis']",True,20230521-205332,,,,
323,scopus,Contribution in Big Data Projects Management,"Nowadays, the necessity of the data becomes more attractive by companies in different areas (IT, space, automotive) who need to create and capture the value from the huge amounts of data generated from various sources. Many fields need to use this amount in the right way in real time with high level processing, this evolution is called Big Data (BD). In this case, to manage a BD project the specific tools like Machine Learning, Data Mining, and more are very important to achieve the customer satisfaction with the expected quality of services. The majority of BD projects fall due to the lack of managing skills and team training, also the sophisticated materials and technologies are required. This paper presents our contribution in the project management of BD based on other discussed methods like Project Management Body of Knowledge (PMBoK) and Agile approaches, and we use them to construct a rigid model for managing any project dedicated to work with BD. © The Authors.",,"Errezgouny A., Cherkaoui A.","Laboratory of Innovative Technologies (LIT), National School of Applied Sciences, Abdelmalek Essaadi University, Tangier, Morocco",2022.0,E3S Web of Conferences,EDP Sciences,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145308780&doi=10.1051%2fe3sconf%2f202235101066&partnerID=40&md5=b27205000f794faad6fd9a2a219677c0,10.1051/e3sconf/202235101066,20230520-160000,20230521-044735,"['contribution', 'in', 'big', 'data', 'projects', 'management']",False,20230521-205332,,,,
324,scopus,Discovering and merging related analytic datasets,"The production of analytic datasets is a significant big data trend and has gone well beyond the scope of traditional IT-governed dataset development. Analytic datasets are now created by data scientists and data analysts using big data frameworks and agile data preparation tools. However, despite the profusion of available datasets, it remains quite difficult for a data analyst to start from a dataset at hand and customize it with additional attributes coming from other existing datasets. This article describes a model and algorithms that exploit automatically extracted and user-defined semantic relationships for extending analytic datasets with new atomic or aggregated attribute values. Our framework is implemented as a REST service in SAP HANA and includes a careful theoretical analysis and practical solutions for several complex data quality issues. © 2020 Elsevier Ltd",Data quality; SAP HANA; Schema augmentation; Schema complement,"Liu R., Simon E., Amann B., Gançarski S.","SAP France, Paris, France; LIP6, Sorbonne Université, CNRS, Paris, France",2020.0,Information Systems,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078400723&doi=10.1016%2fj.is.2020.101495&partnerID=40&md5=b44b824496f176eed2eda68160d5936e,10.1016/j.is.2020.101495,20230520-160000,20230521-044735,"['discovering', 'and', 'merging', 'related', 'analytic', 'datasets']",False,20230521-205332,,,,
325,scopus,Leadership decision-making processes in the context of data driven tools,"Digital economy vast streams of data have created a new paradigm for the business intelligence processes, increasing the potential of advanced analytics and cognitive data tools. Big data structures are used in business intelligence to work with massive amount of dataset to extract value for effective business decision. The current research seeks to address the following question: how can leaders integrate new technology in their decision process to achieve business goals? Emerging technologies directly created organizational power shift and internal bureaucracy adjustments as a result of data transparency trend and decision-making levels changes. A new type of organizational culture and the leadership role in the organizational development becomes necessary. The significant impact over the organizational systems and business goals requires a strategic approach in implementing data driven decision-making processes. © 2018, SRAC - Romanian Society for Quality. All rights reserved.",Advanced analytics; Agile; Artificial intelligence; Big data; Business intelligence; Continuous development; Data management; Digital economy; Machine learning; Organization culture; Technology,Bratasanu V.,"The Institute for Business Administration, Bucharest, Romania",2018.0,Quality - Access to Success,SRAC - Romanian Society for Quality,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053694764&partnerID=40&md5=c923df2f735d8d5d7ba0413f26fd5d71,,20230520-160000,20230521-044735,"['leadership', 'decision-making', 'processes', 'in', 'the', 'context', 'of', 'data', 'driven', 'tools']",False,20230521-205332,,,,
326,scopus,Digital inclusion in Nothern England: Training women from underrepresented communities in tech: A data analytics case study,"The TechUPWomen programme takes 100 women from the Midlands and North of England, particularly from underrepresented communities, with degrees or experience in any subject area, retrains them in technology and upon graduation guarantees an interview with a company. The retraining programme, developed by the Partner Universities in conjunction with the Industrial Partners, has modules at level 6/7 including: Technology: coding, data science, cyber security, machine learning, agile project management; Workplace readiness skills: public speaking, clear communication, working as a team. In this paper, we introduce, for the first time, the TechUPWomen programme, and we analyse its temporal evolution and special features via a data analytics nowcasting approach. Deepening these women's experience with applied upskilling includes one-to-one mentoring (100-100), strong networking, residentials, close industry connection with two directions (non-technical technical) and four job-focussed final tracks: business analyst, agile project manager, data scientist, developer. TechUPWomen also has significant representation of traditionally underrepresented communities, with focus on enabling instead of teaching approach. Beside the originality of the unique combination of features of the programme, this is, to the best of our knowledge, the first analysis based on data analytics of a women in tech(nology) retraining programme, based on nowcasting. Results show that the approach is effective; topic analysis shows that frequent topics include joy, BAME, networking, residential, industry, learning. © 2020 IEEE.",Computer Science Education; Data Analytics; Digital Inclusion; TechUPWomen; Underrepresented Communities,"Aduragba O.T., Yu J., Cristea A.I., Hardey M., Black S.","Durham University, Department of Computer Science, Durham, United Kingdom",2020.0,"15th International Conference on Computer Science and Education, ICCSE 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093103649&doi=10.1109%2fICCSE49874.2020.9201693&partnerID=40&md5=dc006ce8678ba86f176a314bfc58cdca,10.1109/ICCSE49874.2020.9201693,20230520-160000,20230521-044735,"['digital', 'inclusion', 'in', 'nothern', 'england:', 'training', 'women', 'from', 'underrepresented', 'communities', 'in', 'tech:', 'a', 'data', 'analytics', 'case', 'study']",True,20230521-205332,,,,
327,scopus,Designing knowledge management system with big data for hospital inpatient services: (case study at Islamic Hospital XYZ Pekanbaru),"The quality of health services is an important indicator in the health business and industry, especially for the XYZ ISLAMIC HOSPITAL in Pekanbaru. The need for performance improvements that can directly improve the quality of inpatient health services is a major problem. The role of doctors and nurses' knowledge becomes a benchmark in determining the performance and quality of services, in this case the Knowledge Management System (KMS) can be a solution in supporting the knowledge management process. However, the growth of innovation in knowledge management is also needed in practice. So Big Data as a large data processing technology and various types of data will be a supporter in the process of increasing and accelerating the growth of knowledge of doctors and nurses at the XYZ ISLAMIC HOSPITAL by providing relevant information as needed. Then it is necessary to design a KMS that uses Big data as one of the enablers in the process of creating knowledge for doctors and nurses and then can be stored and shared. This design is done by using the Knowledge Management System Agile Implementation Methodology (KMSAIM) which prioritizes the initiation process in each problem domain so that each component has the right and relevant solutions. The KMS design results are in the form of site-based applications that have file sharing features, discussion forums for sharing medical experiences and there are search features needed by doctors and nurses for inpatient services at XYZ ISLAMIC HOSPITAL. © 2019 IEEE",Big Data; Inpatient Medical Service; Knowledge Management; Knowledge Management System,"Perdana T.R., Mujiatun S., Sfenrianto S., Kaburuan E.R.","Information System Management, BINUS Graduate Program, Master of Information Systems Management, Bina Nusantara University, Jakarta, 11530, Indonesia",2019.0,"2019 International Conference on Information and Communications Technology, ICOIACT 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077963180&doi=10.1109%2fICOIACT46704.2019.8938469&partnerID=40&md5=0cc586577c434f7d81327994a8cf8617,10.1109/ICOIACT46704.2019.8938469,20230520-160000,20230521-044735,"['designing', 'knowledge', 'management', 'system', 'with', 'big', 'data', 'for', 'hospital', 'inpatient', 'services:', '(case', 'study', 'at', 'islamic', 'hospital', 'xyz', 'pekanbaru)']",True,20230521-205332,,,,
328,scopus,Experimenting cloud infrastructure for tomorrows big data analytics,"Agile Cloud computing is today’s need. Most of the business and enterprises already acquire cloud storage as their mainstream solution for data processing. These mainstream solution are already struggling with limited infrastructure of cloud computing. In day to day business processes large amount of data is generated and these data are migrated on cloud at the end of day. Today’s cloud enables data processing, storage and distribution, system are not competent for moving large amounts of data in and out of the cloud. This actually is nothing but challenge for organizations with terabytes of digital content and managing cloud infrastructure for their daily real-time data crunching operation on demand. A high speed transport solution is required for transforming agility of on demand cloud infrastructure and merging big data analytics. Researchers need to developed such kind of mechanism where progressive data will be transferred on cloud with limited infrastructure of cloud computing. Today data migration is still carried out by managing hardware and dumping data on that hardware. No online solution and mechanism which can take care of this progressive data is available. Traditional hardware moving approach i.e. dumping data in hard drive or copy data in to magnetic tape and then transfer this data to cloud enable environment manually have many challenges associated it. In this paper we tried to explore opportunity of migrating big data to cloud infrastructure in optimized way. First part of this research work is discussing traditional data migration techniques and second part is experimenting these traditional data migration techniques on simulation based environment with ORTm algorithm which is modified version of ORT (Optimal Response Time). Here in ORTm we have focused on two parameter basically completion time of the last task and maximum resource utilization. © BEIESP.",Big Data Analytics; Cloud; Data Migration; Migration Algorithm’s; ORTm,"Manekar A.S., Pradeepini G.","Department of CSE, KLEF, Vijaywad, Andhra Pradesh, India",2019.0,International Journal of Innovative Technology and Exploring Engineering,Blue Eyes Intelligence Engineering and Sciences Publication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062985522&partnerID=40&md5=37113b9f5d2dfdefca045ce11f425550,,20230520-160000,20230521-044735,"['experimenting', 'cloud', 'infrastructure', 'for', 'tomorrows', 'big', 'data', 'analytics']",False,20230521-205332,,,,
329,scopus,Software Development Governance for VSE-SCRUM teams: Model and evaluation in a developing country,"Using DSR approach, this research proposes the design and evaluation of a model type artifact for Software Development Governance in VSE Teams. Mainly, the model design is based on IT Governance best practices, COBIT 5, and SCRUM, with structural and dynamic components. The validation phase is done through the model application, in a case study, into an Ecuadorian Public Sector Organization. As a part of the research, the results of a survey show that, in a developing country, the IT and Software Development Governance practices are similar in public and private organizations, and in VSE and not-VSE teams. Besides, the model allowed to have the appropriate responses to the software requirements and facilitated the solution of the drawbacks presented in the project development. The work contributes providing a practical tool for the practitioners and academics and on the expansion of the existing body of knowledge in a topic where there is a research lack. © 2018 Association for Computing Machinery.",Agile process; COBIT; DSR; Software development governance; VSE,"Montenegro C., Arévalo R.","Escuela Politécnica Nacional, Quito, Ecuador; Universidad Politécnica Salesiana, Quito, Ecuador",2018.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045410774&doi=10.1145%2f3178461.3178474&partnerID=40&md5=425ff453f7c78894b2fbca5cad83346b,10.1145/3178461.3178474,20230520-160000,20230521-044735,"['software', 'development', 'governance', 'for', 'vse-scrum', 'teams:', 'model', 'and', 'evaluation', 'in', 'a', 'developing', 'country']",False,20230521-205332,,,,
330,scopus,Agile Project Management Software for Construction and Management Industries,"While Industry Revolution 4.0 concept is implementing, most of the working environment are automatized and interoperated with Internet of Things and Big Data being processed real time using cloud computing. The use of efficient project management software in the modern world is increasing in order to achieve organizational objectives. There are several software in market that being used by people in the idustry, but the satisfaction and opinion of the users need to be clarify. The objectives of this research is to identify the implementation of project management software PlanGrid and ZenTao, to analysed the advantages and disadvanatges of the two software. To develop a theoretical basis for this study, literature related to the experiences and lessons learned in the project management software and application was reviewed. A questionnaire survey was conducted to asses the level of implementation and the satisfaction of the software by the users. The findings revealed that the the people working in construction and management industry is not very aware and implement the project management software PlanGrid and ZenTao in their daily working life. Furthermore, users could be more happy if the interface come up with interactive display. The good thing about agile approach is that it has adaptability to changes over the life cycle of the project and to different projects in general. Including Kanban in project management software would be good since it can visualize the workflow. Thus, more effective and efficient work output can be produce via online and towards Industry Revolution 4.0. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Kanban; Project management; Software,"Ali N.H.M., Ahmad F., Abidin N.I.A., Suhaili S., Rahman M.A.A., Harun H., Awang M., Hamid N.H.A., Musa M.K., Hamidon N., Yusop F.M., Syafiq Syazwan M.M.","Department of Civil Engineering Technology, Faculty of Engineering Technology, Universiti Tun Hussein Onn Malaysia, Pagoh, Muar, 84600, Malaysia; Department of Structure and Materials, School of Civil Engineering, Faculty of Engineering, Universiti Teknologi Malaysia, Johor Bahru, Johor, 81310, Malaysia",2021.0,Lecture Notes in Mechanical Engineering,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111389208&doi=10.1007%2f978-981-16-0742-4_7&partnerID=40&md5=0f6433256355386f00a976ccd19e26a3,10.1007/978-981-16-0742-4_7,20230520-160000,20230521-044735,"['agile', 'project', 'management', 'software', 'for', 'construction', 'and', 'management', 'industries']",False,20230521-205332,,,,
331,scopus,Advancing the agile software process: The case of modernizing the army community service's information technology infrastructure,"There is a gap between the promises of big data, interoperability, and service-oriented systems and what most governmental agencies currently receive in return from their information systems. Such disparity is apparent in the domain of health and human services, as government organizations are grappling with the challenge of streamlining their business processes and delivery of care to adhere to a person-centered approach that relies on interoperable systems and meaningful data exchange. Since 2014, the Georgia Tech Research Institute has supported the U.S. Department of the Army in this endeavor by modernizing a suite of information systems used to provide family-centric social services, in support of family readiness and inclusive of child wellbeing, healthy marriages and parenting, and the treatment and prevention of domestic violence and child abuse. In this paper, we discuss how agile software development methodology on its own is not conducive to modernization efforts where legacy systems, data, and human processes cannot be replaced entirely. Instead, the authors propose an adapted model that combines agile development with enhanced usercentered design techniques as a socio-Technical approach to software modernization. We will describe our process, reflect on lessons learned, and discuss select future implications associated with this type of work. '. Copyright 2018. © by the International Institute of Informatics and Systemics.",Agile software development; Computer supported cooperative work; Data integration; Qualitative methods; socio-Technical systems; software modernization,"Pater J., Lie-Tjauw S., Gonzalez M., Kim M., Isbell S., Severson D.","Information and Communications Lab, Georgia Tech Research Institute, Atlanta, GA  30332, United States; Army Community Services Division, Family and MWR Programs, IMCOM G-9, San Antonio, TX  78234, United States",2018.0,"WMSCI 2018 - 22nd World Multi-Conference on Systemics, Cybernetics and Informatics, Proceedings","International Institute of Informatics and Systemics, IIIS",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055632230&partnerID=40&md5=78e2fb2e18e204a80d29b4dff9f798f4,,20230520-160000,20230521-044735,"['advancing', 'the', 'agile', 'software', 'process:', 'the', 'case', 'of', 'modernizing', 'the', 'army', 'community', ""service's"", 'information', 'technology', 'infrastructure']",False,20230521-205332,,,,
332,scopus,Big Data Analytics APIs Architecture for Formative Assessors,"This Research to Practice Full Paper is driven by the question: Within limited time resources available to trainers in projects for Big Data Analytics (BDA) problems, how can they define project requirements for Formative Assessment (FA) actions? The paper suggests BDA APIs architecture as helping tool for formative assessors. It helps them effectively produce and adapt visual diagnostic reports for FA-actions in agile based requirements (i.e. features) definition. The paper presents two core architectures: Architecture for a parametrized feature-descriptor-system to define/refine a BDA API feature and its visual diagnostic reports, and an initial resources architecture for BDA API to initialize an analytics algorithm with its input big data sets. Clarifying visually the trainee's challenges (i.e. incremental features in a BDA API) is our main FA action. The FA action is designed based on Csikszentmihalyi's flow model to support a trainee in matching balance between his/her challenges and his/her skills. To test the architecture's functions, the paper has test setups for two formal projects (each has 1 to 6 trainees) and two informal projects (each has 1 to 3 trainees). The projects are to attack BDA problems in learning analytics and in image automatic classification. The test results show that the visual diagnostic reports produced by the trainers are very effective in clarifying visually incremental BDA API features not only for simple classifiers (i.e. classical data mining algorithms) but also for complex classifiers (i.e. deep learning algorithms). The results show also how visual diagnostic reports are easily produced for comparing the algorithm performances using different input big data sets, whereas other reports are produced for comparing performances between different algorithms, using one input data set. Related works are also discussed to show the architecture's differences and advantages. Its main advantages are: 1) it enables the trainers to use deep learning algorithms beside classical data mining algorithms in its BDA API parameterizable feature descriptors for visual diagnostic reports. 2) The descriptors can be extended, reused, shared, and scaled out to help trainers in other universities providing flow model based FA actions. 3) Finally, it has extensions to integrate other theoretical frameworks like Buckingham Shum and Deakin Crick's framework for dispositional learning analytics instead of the used flow model. © 2021 IEEE.",assessment in engineering education; Big Data Analytics; planning for formative assessment,"Mahfouz W., Wuttke H.-D.","Ilmenau University of Technology, Faculty of Computer Science and Automation, Germany",2021.0,"Proceedings - Frontiers in Education Conference, FIE",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123873245&doi=10.1109%2fFIE49875.2021.9637431&partnerID=40&md5=79cad0f437a6bfb1b6744a34d02468c0,10.1109/FIE49875.2021.9637431,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'apis', 'architecture', 'for', 'formative', 'assessors']",True,20230521-205332,,,,
333,scopus,An alternative approach to fostering African economic integration through the utilization and alignment of information technology,"Attempts in the last 20 years to achieve regional integration in Africa have not yielded tangible results. Despite unparalleled technological innovation such as cloud computing, blockchain technology, and big data functional capabilities to drive real implementation of regional economic integration in Africa, the status quo remains with minor evidence of an agile continental and integrated commerce and financial services. Hence, this study argued that economic integration is a viable and alternative approach to achieve a United States of Africa with an integrated financial and economic architecture to foster regional integration. It employed a bibliometric review as an agile methodology to map knowledge trajectories of regional integration. The findings revealed gaps in the literature and lack of focus on the part of the African Union on how to replace the current sub-regional cooperation among the six clusters of economic communities of Africa with effective regional integration. The lack of, and the inability to utilize and align technological innovation to drive regional integration would make achieving this an arduous task. This study recommended that a business and IT alignment approach should be adopted in implementing African economic integration. © 2020 Adonis and Abbey Publishers Ltd. All rights reserved.",Africa; Big data; Business-IT Alignment; E-governance; Economic Integration; IT alignment,"Ajibade P., Mutula S.M.","Information Studies Programme, University of KwaZulu-Natal, Pietermaritzburg, South Africa",2020.0,Journal of African Union Studies,Adonis and Abbey Publishers Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090640645&doi=10.31920%2f2050-4306%2f2020%2fS9N1A3&partnerID=40&md5=10a4ab10d2e5ffa55b627dbefca2e4d6,10.31920/2050-4306/2020/S9N1A3,20230520-160000,20230521-044735,"['an', 'alternative', 'approach', 'to', 'fostering', 'african', 'economic', 'integration', 'through', 'the', 'utilization', 'and', 'alignment', 'of', 'information', 'technology']",False,20230521-205332,,,,
334,scopus,Big Data Analytics Applications in Information Management Driving Operational Efficiencies and Decision-Making: Mapping the Field of Knowledge with Bibliometric Analysis Using R,"Organizations may examine both past and present data with the aid of information management, giving them access to all the knowledge they need to make sound strategic choices. For the majority of contemporary enterprises, using data to make relevant, valid, and timely choices has become a must for success. The volume and format of data have changed significantly over the past few years as a result of the development of new technologies and applications, but there are also impressive possibilities for their analysis and processing. This study offers a bibliometric analysis of 650 publications written by 1977 academics on the use of information management and big data analytics. The Bibliometrix function in the R package and VOSviewer program were used to obtain the bibliographic data from the Scopus database and to analyze it. Based on citation analysis criteria, the top research journals, authors, and organizations were identified. The cooperation network at the author level reveals the connections between academics throughout the world, and Multiple Correspondence Analysis (MCA) identifies the research holes in the area. The recommendations for further study are influenced by the findings. © 2023 by the authors.",agile management; business model; data analytics; decision-making; efficiency; information management; operational performance; SMEs,"Ragazou K., Passas I., Garefalakis A., Galariotis E., Zopounidis C.","Department of Accounting and Finance, University of Western Macedonia, Kozani, GR50100, Greece; Department of Business Administration, Neapolis University Pafos, Pafos, 8042, Cyprus; Department of Business Administration and Tourism, Hellenic Mediterranean University, Heraklion, GR71410, Greece; Department of Finance, Audencia Business School, Nantes, 44300, France; The Financial Engineering Laboratory, Technical University of Crete, Chania, GR73100, Greece",2023.0,Big Data and Cognitive Computing,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151096878&doi=10.3390%2fbdcc7010013&partnerID=40&md5=fc3cb7bf9fcc604a9baccb233ad26fb8,10.3390/bdcc7010013,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'applications', 'in', 'information', 'management', 'driving', 'operational', 'efficiencies', 'and', 'decision-making:', 'mapping', 'the', 'field', 'of', 'knowledge', 'with', 'bibliometric', 'analysis', 'using', 'r']",False,20230521-205332,,,,
335,scopus,Interactive Visualization for Statistical Modelling through a Shiny App in R,"The importance of analytics and visualization tools has been growing over the last decades to handle big data which steamed from all aspects of life. The focus of this paper was on visualization as a crucial tool in presenting complex raw data and modelling results to provide easy-to-understand actionable information that facilitate decision-making. However, limited research distinguished between 'data visualization' and 'model visualization', which has been clearly made in this paper. Furthermore, this paper aimed to shed light on the importance of interactive visualizations to compliment statistical data modelling using R and Shiny for its advanced capabilities. Specifically, a methodology has been proposed based on a hybrid development lifecycle that adopts the Agile Software Development Lifecycle and the Data Analytics Lifecycle. Finally, by presenting a case study to model the dynamics of COVID-19, it was found that R and Shiny alongside the proposed hybrid development lifecycle significantly reduced the amount of time required to build visually interactive applications. The reported results highlighted the effectiveness of the adopted approach in assisting and guiding researchers and developers in building interactive applications that leverage Big Data Analytics. © 2021 IEEE.",Data Analytics; Interactive Applications; R; Shiny; Visualization,"Khedr A., Hilal S.","University of Bahrain, Big Data Science and Analytics, Sakhir, Bahrain; University of Bahrain, College of Science, Sakhir, Bahrain",2021.0,"2021 International Conference on Data Analytics for Business and Industry, ICDABI 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124646750&doi=10.1109%2fICDABI53623.2021.9655841&partnerID=40&md5=1b2592e1bf181d5601b84a66f05f7b6d,10.1109/ICDABI53623.2021.9655841,20230520-160000,20230521-044735,"['interactive', 'visualization', 'for', 'statistical', 'modelling', 'through', 'a', 'shiny', 'app', 'in', 'r']",True,20230521-205332,,,,
336,scopus,Scaling agile software development approach in government organization in New Zealand,"Agile methods are based on an iterative and incremental cycles of development where requirements and solutions are developed through collaboration and coordination between cross-functional teams and their customer. Agile software development focuses on flexibility, allowing changes in requirements to occur during the software development process. The use of Agile software development is increasing in both the private and public sectors. However, there is little knowledge about the use of Agile in the public sector. This paper presents important factors such as communication, transparency, feedback, product owner engagement, confidence and organization culture that contribute to the outcome of Agile Software development projects in public sector organisations. This study compares the main challenges in the public and the private sector. Transparency and Product Owner engagement were found to be the main difference in the challenges in the public and private sectors. © 2020 Association for Computing Machinery.",Agile in public sectors; Agile teams; Challenges in Agile,"Ghimire D., Charters S., Gibbs S.","Aspire2 International, 289 Tuam Street, Christchurch, New Zealand; Lincoln University, Ellesmere Jct Rd, Lincoln Canterbury, New Zealand; Royal Melbourne Institute of Technology, Melbourne, Australia",2020.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081993223&doi=10.1145%2f3378936.3378945&partnerID=40&md5=2d74780de8ab1b08d986f9e6c1ae3dbd,10.1145/3378936.3378945,20230520-160000,20230521-044735,"['scaling', 'agile', 'software', 'development', 'approach', 'in', 'government', 'organization', 'in', 'new', 'zealand']",False,20230521-205332,,,,
337,scopus,Empowering the Workforce of the Future Through Strategic Data Science Framework to Demystify Digitalization in ADNOC Onshore to Create Sustainable Business Value,"Oil and Gas industry is seeking new ways to improve efficiencies, reducing operating costs and increasing revenues in the current volatile market conditions. Data Science and all the new emerging technologies enable the discovery of new opportunities and digitalization is a vital element for making business more effective and efficient. While COVID19 has disrupted the world, ADNOC Onshore has recognized the importance of reskilling and empowering the future workforce through strategic enterprise data science and analytics program to achieve 2030 smart growth strategy. This paper talks about successful approach and enablers for development of in-house capability for transformation that lead to generating significant business value The digital transition can pose both challenges and opportunities in this transformation. ADNOC ONSHORE has developed an integrated framework to encourage and accelerate data science capabilities. This framework promotes a vision with collaborative, sustainable mechanisms to develop talent. It is not just the formal learning and additional professional qualification that make it possible to build this in house capability. There are five major areas are enabled this framework such as data science & analytics skills competency model, sustainable on-line collaborative learning program, organizational culture change, democratizing AI through open platform & a digital business model for performing real business problems/use case PoCs. Each area has a detailed program and execution strategy with a collaborative effort from technical and non-technical stakeholders. ADNOC ONSHORE has successfully implemented this framework and able to certify 20 employees as part of this program. The Data Science Competency Model identified and defined the skills required to be successful within the enterprise with a clear learning path and mentorship. The leadership played a pivotal role to encourage data driven decision making and predictive capabilities in addition to executive awareness to lead the change with clear performance indicators. By democratizing AI platform across upstream user community, six real business cases have been successfully developed with clear business value in subsurface and production workflows according to the defined digital business model. The successful business cases have improved efficiency by 75% in performing cement & corrosion log interpretation & well portfolio optimization. Data driven analytics have been evaluated in subsurface workflows such as infill location optimization, gas-lift candidate identification and they have complemented the existing techniques. The framework has been successfully extended to other group companies in ADNOC. The rapid growth of AI in business in the last five years presents an opportunity for oil and gas professionals for enhancing the skills and transformation. This paper talks about an integrated framework, learning path, democratizing AI, engagement of leadership, digital business model for business case evaluation by applying agile way of working and sustainable value creation. Copyright © 2022, Society of Petroleum Engineers.",,"Reddicharla N., Varnam P.R., Nair P., Al-Marzooqi S.M., Ali M.A.S.","ADNOC Onshore, United Arab Emirates",2022.0,Society of Petroleum Engineers - ADIPEC 2022,Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143087794&doi=10.2118%2f210907-MS&partnerID=40&md5=4549dece12c50a744125205c9bd19cbb,10.2118/210907-MS,20230520-160000,20230521-044735,"['empowering', 'the', 'workforce', 'of', 'the', 'future', 'through', 'strategic', 'data', 'science', 'framework', 'to', 'demystify', 'digitalization', 'in', 'adnoc', 'onshore', 'to', 'create', 'sustainable', 'business', 'value']",False,20230521-205332,,,,
338,scopus,An approach for the implementation of semantic Big Data Analytics in the Social Business Intelligence process on distributed environments (Cloud computing),"Managing and extracting useful knowledge from social media sources is a challenge. It has attracted a lot of attention from universities and industry. To meet this challenge, semantic analysis of textual data is the subject matter. Today, with the connection present everywhere and at any time, considerable data is born. These data or data become a key player for understanding, analyzing, anticipating and solving major economic, political, social and scientific problems. Data also changes our working procedures, our cultural environment, even restructuring our way of thinking. And just as the scientific, managerial and financial world is interested in Big Data, a new discipline is growing: Fast Data. In addition to the salient volume of data; another variant becomes decisive, the ability to efficiently process data in all their diversity, transforming it into knowledge by providing the right information to the right person at the right time, or even using it to predict the future. The exploitation of Big Data requires the proposition of new adapted mathematical and IT approaches but also a reengineering of managerial approaches for the control of the informational environment of a public or private organization. While basing itself on a strategic information management approach such as Economic Intelligence (EI). The latter combines and encompasses Business Intelligence techniques for internal data management and business intelligence techniques for monitoring and controlling external information flows. However, Big Data, as a boundless source of information for EI, has upset the traditional EI process, which requires a reengineering of the EI approach. My research works perfectly in this context characterized by an uncertain and unpredictable environment. We ask to propose an ontology-based, service-oriented, agile and scalable Social Business Intelligence approach to extract the semantics of textual data and define the domain of massive data. In other words, we semantically analyze social data at two levels, namely the level of the entity and the level of the domain. © 2019 Association for Computing Machinery.",Big Data; Cloud; Distributed Processing; Fast Data; Ontology; Social BI,"Alcabnani S., Oubezza M., Elkafi J.","Computer Science dept, Faculty of Sciences, Chouaib Doukkali University, ElJadida, Morocco",2019.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117539016&doi=10.1145%2f3372938.3373003&partnerID=40&md5=c084ea69fb9a50bd90682adb5a73a0f8,10.1145/3372938.3373003,20230520-160000,20230521-044735,"['an', 'approach', 'for', 'the', 'implementation', 'of', 'semantic', 'big', 'data', 'analytics', 'in', 'the', 'social', 'business', 'intelligence', 'process', 'on', 'distributed', 'environments', '(cloud', 'computing)']",True,20230521-205332,,,,
339,scopus,Integration of Lean practices and Industry 4.0 technologies: smart manufacturing for next-generation enterprises,"Industry 4.0 technologies have attempted to transform current industrial settings to a level that we have never seen before. While at the same time, prevailing applications of Lean tools and techniques over the last 20 years have already dramatically reduced wastes ranging from shop floor production to cross-functional enterprise processes. This paper aims to provide a comprehensive review and report on links between Lean tools and Industry 4.0 technologies, and on how simultaneous implementation of these two paradigms affects the operational performance of factories. The existing and potential enhancements of Lean practices enabled by Industry 4.0 technologies such as wireless networks, big data, cloud computing, and virtual reality (VR) will also be explored. A cloud-based Kanban decision support system is also presented as a real-world demonstrator for integration of an Industry 4.0 technology (cloud computing) and a major Lean tool (Kanban). © 2020, Springer-Verlag London Ltd., part of Springer Nature.",Cloud Kanban; Industry 4.0; Lean tools; Smart factory,"Shahin M., Chen F.F., Bouzary H., Krishnaiyer K.","Department of Mechanical Engineering, The University of Texas at San Antonio, one UTSA circle, TX78249, San Antonio, United States",2020.0,International Journal of Advanced Manufacturing Technology,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082950987&doi=10.1007%2fs00170-020-05124-0&partnerID=40&md5=eb782593dbf445382b33e9a6bc407675,10.1007/s00170-020-05124-0,20230520-160000,20230521-044735,"['integration', 'of', 'lean', 'practices', 'and', 'industry', '4.0', 'technologies:', 'smart', 'manufacturing', 'for', 'next-generation', 'enterprises']",False,20230521-205332,,,,
340,scopus,STAMP 4 NLP – An Agile Framework for Rapid Quality-Driven NLP Applications Development,"The progress in natural language processing (NLP) research over the last years, offers novel business opportunities for companies, as automated user interaction or improved data analysis. Building sophisticated NLP applications requires dealing with modern machine learning (ML) technologies, which impedes enterprises from establishing successful NLP projects. Our experience in applied NLP research projects shows that the continuous integration of research prototypes in production-like environments with quality assurance builds trust in the software and shows convenience and usefulness regarding the business goal. We introduce STAMP 4 NLP as an iterative and incremental process model for developing NLP applications. With STAMP 4 NLP, we merge software engineering principles with best practices from data science. Instantiating our process model allows efficiently creating prototypes by utilizing templates, conventions, and implementations, enabling developers and data scientists to focus on the business goals. Due to our iterative-incremental approach, businesses can deploy an enhanced version of the prototype to their software environment after every iteration, maximizing potential business value and trust early and avoiding the cost of successful yet never deployed experiments. © 2021, Springer Nature Switzerland AG.",Avoiding pitfalls; Best practices; Machine learning; Natural language processing; Process model; Quality assurance,"Kohl P., Schmidts O., Klöser L., Werth H., Kraft B., Zündorf A.","FH Aachen - University of Applied Sciences, Jülich, 52428, Germany; University of Kassel, Kassel, 34127, Germany",2021.0,Communications in Computer and Information Science,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115254981&doi=10.1007%2f978-3-030-85347-1_12&partnerID=40&md5=9933480e60447114aeca7b66f5aeea7b,10.1007/978-3-030-85347-1_12,20230520-160000,20230521-044735,"['stamp', '4', 'nlp', '–', 'an', 'agile', 'framework', 'for', 'rapid', 'quality-driven', 'nlp', 'applications', 'development']",False,20230521-205332,,,,
341,scopus,Log Sinks and Big Data Analytics along with User Experience Monitoring to Tell a Fuller Story,"Understanding and continually improving the user experience is critical to the success of web applications, especially those that are business-driven. There exist a multitude of tools to monitor user activities on a website, which then provide metrics to help developers and company leadership understand where their users experience pain-points. However, all tools suffer from their own limitations and ultimately it is important for companies to have as much control (as possible) over all data collected by third-party tools, and be able to make decisions related to its storage, retention, processing, etc., in an agile manner. At Dottid, we use a third-party tool to understand and enhance the user experience on our web application, recently however, we ran into a problem regarding failed logins that required us to architect a solution ourselves, since the tool cannot address this issue for us. The solution leverages log collection and big data analytics and its architecture has paved the way for us to build more actionable insights than if we were using the tool as-is. We transparently share our experiences, and the details of our solution and rationale, with the goal of benefiting others, and promoting further industry-academic collaboration, in this space. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Analytics; Big Data; Logging; Monitoring; Software,"Debroy V., Miller S., Blake M., Hibbard A., Beavers C.","Product and Development, Dottid, Dallas, TX, United States",2022.0,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Knowledge Systems Institute Graduate School,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137153344&doi=10.18293%2fSEKE2022-175&partnerID=40&md5=7cd217b7bc69b191167e17d29bccbaf8,10.18293/SEKE2022-175,20230520-160000,20230521-044735,"['log', 'sinks', 'and', 'big', 'data', 'analytics', 'along', 'with', 'user', 'experience', 'monitoring', 'to', 'tell', 'a', 'fuller', 'story']",False,20230521-205332,,,,
342,scopus,Using Industry 4.0 Capabilities for Identifying and Eliminating Lean Wastes,"This paper conducts a review of the literature to identify associations in operations between Industry 4.0 capabilities such as Additive Manufacturing, Augmented Reality, Autonomous Robots, Big Data, Cloud Computing, IIoT, Simulation, and Systems Integration wit h the commonly identified lean manufacturing wastes of Trans port, Inventory, Movement, Waiting, Overproduction, Overprocessing, Defects, and Underutilized skills. The paper documents research that links various capabilities and wastes, including how IIoT can be used to reduce defects in manufacturing, and how it can mitigate overproduction across industries. There is also evidence that big data implementation in manufacturing has positive effects on reducing waiting times across the manufacturing process and delivery, and that cloud computing techno logies guarantee better estimates for product and predicted inventory amounts. The research finds impacts on the social aspect of manufacturing by how augmented reality tools are increasingly used in the manufacturing sector to improve workers' knowledge, skills, and abili ties, and that simulation software applications are capable of decreasing operator motion wastes. The paper concludes that there is a clear benefit for SMEs in using Industry 4.0 in lean implementation journeys, and it supports the efforts of manufacturing organizations to become leaner using Industry 4.0 capabilities and solutions. © 2022 The Authors. Published by Elsevier B.V.",Industry 4.0; Lean Manufacturing; Operations Management; Wastes,"Rajab S., Afy-Shararah M., Salonitis K.","Sustainable Manufacturing Systems Centre, Cranfield University, Bedford, MK43 0AL, United Kingdom",2022.0,Procedia CIRP,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132282459&doi=10.1016%2fj.procir.2022.04.004&partnerID=40&md5=3bf01ec7c6dc2615809a587e16d6b849,10.1016/j.procir.2022.04.004,20230520-160000,20230521-044735,"['using', 'industry', '4.0', 'capabilities', 'for', 'identifying', 'and', 'eliminating', 'lean', 'wastes']",False,20230521-205332,,,,
343,scopus,Artificial Intelligence for Media Operations Why AI algorithms will become a must for every network management system,"Artificial intelligence already has a big impact on a lot of different segments in the media industry. With the broadcast industry moving to all-IP and data center deployments those environments are more agile and complex than ever before. With fast-evolving technologies and cycles, ever more mission critical systems and constantly changing operational practices and devops style operations, traditional network management systems (NMS) and their paradigms don't fit the bill anymore. This paper explores why machine-learning algorithms must find their way into network monitoring and management solutions to orchestrate a modern media data center dynamically and in a proactive way. The foundation for an AI-driven NMS platform is a solid big data storage architecture; a lack of profound data and data hygiene is often one of the biggest obstacles to successfully deploy big data projects. As in today's all-IP environments nothing is static anymore, an AI entity must be highly intelligent. Unsupervised learning is key to automatically adapt to changing environments. Augmented operation and a zero-configuration and zero-maintenance approach will be crucial to successfully deploy the right management strategy. © 2018 Society of Motion Picture and Television Engineers, Inc.",advanced analytics; artificial intelligence; augmented operation; deep root cause analysis; forecasting; incident detection; intelligent fault detection; machine learning; NMS,"Gunkel T., Vandenberghe B.","Skyline Communications, United States",2019.0,SMPTE 2018,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063083289&doi=10.5594%2fM001813&partnerID=40&md5=cfc2463328590c02464b7d7f7f7ceb2c,10.5594/M001813,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'for', 'media', 'operations', 'why', 'ai', 'algorithms', 'will', 'become', 'a', 'must', 'for', 'every', 'network', 'management', 'system']",True,20230521-205332,,,,
344,scopus,An Empirical Study on Data-driven Requirements Elicitation: Reflections from Nordic Enterprises,"There is a plethora of digital data sources that may be exploited for collecting requirements for system development and evolution. In contrast to human sources, i.e. stakeholders, digital sources continuously generate data that is often not originally created for the purposes of requirements elicitation, e.g. on forums, microblogs, machine-generated trace logs, and sensor data. Streams of large volumes of data can be exploited to enable automation of a continuous requirements elicitation process using AI techniques that combine natural language or machine data processing, with machine learning. On the other hand, the complex characteristics of big data due to its size, lack of structure, high dynamics, and low predictability, present numerous challenges on the process of extracting requirements-related information that would be of a clear value for companies. The purpose of this interview study was to, from the practitioners' perspective, elicit their overall expectations and needs for a method for the elicitation of system requirements from digital data sources. Semi-structured interviews were conducted with several industrial experts from different business domains and the collected empirical data has been analyzed using thematic analysis. The results lead to the identification of a set of high-level requirements related to the method for the elicitation from digital data sources. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Agile requirements engineering; Big data; Data-driven requirements engineering; Enterprise modeling; Requirements elicitation,"Martinez A., Melin M., Koutsopoulos G., Zdravkovic J.","Nexer Group AB, Valhallavägen 117G, Stockholm, 11553, Sweden; Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, Stockholm, 16407, Sweden",2021.0,CEUR Workshop Proceedings,CEUR-WS,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121677414&partnerID=40&md5=1afef275483717e0dddbe3fe39640347,,20230520-160000,20230521-044735,"['an', 'empirical', 'study', 'on', 'data-driven', 'requirements', 'elicitation:', 'reflections', 'from', 'nordic', 'enterprises']",False,20230521-205332,,,,
345,scopus,Physics-inspired models for agile code and data in federated edges,"We study the problem of flexibly, dynamically, and adaptively moving, positioning, and instantiating computing tasks and data in federated, distributed edge systems. We call this process 'agile code and agile data' (ACAD). We explore the adaptation of physics-inspired models, used for atomistic simulations, to the ACAD problem, treating the code and data as particles on a graph, interacting through different potential energy models. We discuss the mapping between the different elements of ACAD problem and our particles-on-A-graph model, considering different frameworks for data analytics. We explore gravitational, elastic and Coulombic models, both with global and local energy minimization, finding that the Coulombic model obtains the most efficient solution. © 2017 IEEE.",agile code; physical models,"Ko B., Kraczek B., Salonidis T., Basu P., Chan K.S., Porta T.L., Martens A.","IBM T. J. Watson Research, United States; US Army Research Laboratory, United States; Raytheon BBN Technologies, United States; Penn State University, United States; IBM United Kingdom, United Kingdom",2018.0,"2017 IEEE SmartWorld Ubiquitous Intelligence and Computing, Advanced and Trusted Computed, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People and Smart City Innovation, SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI 2017 - Conference Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050178851&doi=10.1109%2fUIC-ATC.2017.8397418&partnerID=40&md5=bd1db19d7806a73ab7e3d126169961e1,10.1109/UIC-ATC.2017.8397418,20230520-160000,20230521-044735,"['physics-inspired', 'models', 'for', 'agile', 'code', 'and', 'data', 'in', 'federated', 'edges']",False,20230521-205332,,,,
346,scopus,Developing a virtual smart total learning environment for future teaching-learning system,"The world of education system after this COVID19 pandemic will have to change its dimension to map the needs of learners. The proposed framework is focused on transforming the learning experience into two possible ways like online and on-campus learning through groundbreaking agile methodologies. The new interfaces for learners will be included like Gamification, animated tutorial etc. The framework designed here is the outcome of the e-learning experiences of the authors and it tries to add all relevant technologies with cutting-edge research to provide inspirational and transformative knowledge to learners of all ages, social status, communities who form worldwide communities of special-learners. It will rise to the occasion to use its open source technology along with the emerged technologies like IoT, 5G etc, to transcend physical and social borders. This framework is a total learning environment as it will incorporate all possible latest technologies like big data and machine learning. The e-learning system possesses features like personalized e-learning, anomaly detection, student performance monitoring, dynamic content preparations, students' satisfaction monitoring etc. The new framework will include big data, cloud applications, machine learning and artificial intelligence to make the system faster, efficient and smart. The new features will make the e-learning system based on Virtual Smart Total Learning Environment (VSTLE) more technologically sound and efficient in processing, predicting, evaluating and making storage backup. This framework is designed in such a way that the minimum human intervention will be needed for its functioning. As a result, the final output will be more accurate as compared to other e-learning systems available. © 2020 IEEE.",Adaptive learning; Big data; Learning-environment; Machine learning; Smart; Virtual,"Akour M.A., Das A.","A'Sharqiyah University, Sultanate, Oman; Cotton University, India",2020.0,"Proceedings of 2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102971550&doi=10.1109%2fTALE48869.2020.9368373&partnerID=40&md5=efcabdb50cd7753bab213cdc5cf24d0d,10.1109/TALE48869.2020.9368373,20230520-160000,20230521-044735,"['developing', 'a', 'virtual', 'smart', 'total', 'learning', 'environment', 'for', 'future', 'teaching-learning', 'system']",True,20230521-205332,,,,
347,scopus,Hard and soft skills for scrum global software development teams,"Scrum is considered as one of the solutions to overcome problems encountered in global software development (GSD). The skills of a Scrum team largely determine the successful implementation of Scrum in a GSD project. The present study aims to identify and rank the essential skills for Scrum GSD teams. First, we identified five hard skills and five soft skills by conducting a literature study and depth interviews with a software engineering expert. Second, these skills were arranged into a questionnaire, which was then distributed to thirty undergraduate students taking software engineering subjects. The students were considered as Scrum beginners in development teams. The questionnaire data were subsequently analyzed by ranking the importance of the skills. Next, the rankings were validated in a focus group discussion (FGD) with four practitioners, two academics, one policymaker, and one representative of a relevant professional association. All members of the FGD had at least five years of experience in Scrum GSD. In the following stage, frequency analysis was employed to achieve a consensus among the experts. After that, a round table discussion was conducted to confirm the consensus. The results show that programming is the most important hard skill, while interpersonal and communication are the most important soft skills. Database expertise and leadership were identified as the least important hard and soft skills, respectively. Furthermore, the rank of these skills by importance is aligned with the nature of Scrum and GSD. Our findings can be used as a foundation to construct competencies in Scrum GSD teams. © 2020 Association for Computing Machinery.",Global Software Development; Hard Skills; Scrum GSD Team; Soft Skills,"Hidayati A., Budiardjo E.K., Purwandari B.","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia",2020.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081989871&doi=10.1145%2f3378936.3378966&partnerID=40&md5=61bf407d3cbb7c9cd0256f8ec5e5adfd,10.1145/3378936.3378966,20230520-160000,20230521-044735,"['hard', 'and', 'soft', 'skills', 'for', 'scrum', 'global', 'software', 'development', 'teams']",False,20230521-205332,,,,
348,scopus,Ecopolytechnic: A sustainable and flexible e-learning system for agile smart learning scenarios,"The rapid change of technological and human-machine co-evolutionary processes due to smart working and smart industries, present several issues that are also influencing the world of e-learning systems. Nowadays is quite hard to distinguish between learning spaces/systems/organizations and working organizations especially when smart working and tele-monitoring are becoming widespread. In this work we analyze smart learning concepts that are leading to a new emerging scenario in which the distinction between learning and working activities is dynamic and in evolution. In particular we present an integrated smart learning model called EcoPolytechnic which aims to redesigns the organization model of a Polytechnic by introducing several concepts of agile learning and project-based learning. The model is built upon the notion of smart learning cell that replaces in a flexible and sustainable way the notion of set of courses and can be used in a better way in smart learning scenarios. The result is a complete and easy to be configured smart learning organization system for which a comparative analysis is carried out. The benefits in terms of innovation and adaptive learning performance are given by using agile learning analysis. © Proceedings of the 14th IADIS International Conference e-Learning 2020, EL 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020. All rights reserved.",Agile Learning; Data Science; Smart Learning,Angelaccio M.,"University of Rome Tor Vergata, Management Engineering Dept, Via del Politecnico 1, Rome, 00100, Italy",2020.0,"Proceedings of the 14th IADIS International Conference e-Learning 2020, EL 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020",IADIS,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101076449&partnerID=40&md5=a95af31c769fa5f0b11ae52e7523cb81,,20230520-160000,20230521-044735,"['ecopolytechnic:', 'a', 'sustainable', 'and', 'flexible', 'e-learning', 'system', 'for', 'agile', 'smart', 'learning', 'scenarios']",False,20230521-205332,,,,
349,scopus,IoT Analytics and Agile Optimization for Solving Dynamic Team Orienteering Problems with Mandatory Visits,"Transport activities and citizen mobility have a deep impact on enlarged smart cities. By analyzing Big Data streams generated through Internet of Things (IoT) devices, this paper aims to show the efficiency of using IoT analytics, as an agile optimization input for solving real-time problems in smart cities. IoT analytics has become the main core of large-scale Internet applications, however, its utilization in optimization approaches for real-time configuration and dynamic conditions of a smart city has been less discussed. The challenging research topic is how to reach real-time IoT analytics for use in optimization approaches. In this paper, we consider integrating IoT analytics into agile optimization problems. A realistic waste collection problem is modeled as a dynamic team orienteering problem with mandatory visits. Open data repositories from smart cities are used for extracting the IoT analytics to achieve maximum advantage under the city environment condition. Our developed methodology allows us to process real-time information gathered from IoT systems in order to optimize the vehicle routing decision under dynamic changes of the traffic environments. A series of computational experiments is provided in order to illustrate our approach and discuss its effectiveness. In these experiments, a traditional static approach is compared against a dynamic one. In the former, the solution is calculated only once at the beginning, while in the latter, the solution is re-calculated periodically as new data are obtained. The results of the experiments clearly show that our proposed dynamic approach outperforms the static one in terms of rewards. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",agile optimization; big data streams; dynamic team orienteering problem; IoT analytics; smart cities; transport analytics,"Li Y., Peyman M., Panadero J., Juan A.A., Xhafa F.","Department of Computer Science, Multimedia and Telecommunication, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; Department of Applied Statistics and Operations Research, Universitat Politècnica de València, Alcoy, 03801, Spain; Department of Computer Science, Universitat Politècnica de Catalunya, Barcelona, 08034, Spain",2022.0,Mathematics,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127551875&doi=10.3390%2fmath10060982&partnerID=40&md5=39606be9a8814ea45f8a7a389c15a09d,10.3390/math10060982,20230520-160000,20230521-044735,"['iot', 'analytics', 'and', 'agile', 'optimization', 'for', 'solving', 'dynamic', 'team', 'orienteering', 'problems', 'with', 'mandatory', 'visits']",False,20230521-205332,,,,
350,scopus,An Optimization Model to Evaluate Dynamic Assignment Capability of Agile Organization,"Recently the planning under the uncertain and competitive environment is the hot topic in the agile organization. Many studies highlight how to rapidly make or change the plans with detecting advance information. One of the widely used solutions is to evaluate the agile organization's decision-making capability based the time-domain metrics. However, the dynamic assignment capability always changed during task operating within time-domain. It caused that the planning used the wrong organization capability in the most time. In this paper, we develop an improved simulated annealing algorithm to address this problem. In order to discretize the time-domain, we propose a horizon partition that is based on the task dynamic state. Finally, the optimization model is tested in a toy example. Compared with the traditional models, the results show the proposed model has better outcomes for accurately estimating dynamic agile organization capability. © 2018 IEEE.",Adaptive Optimization; Agile organization; Decision Making; Operational System of Systems (SoS); Simulated Annealing,"Feng Y., Huang H., Cheng G., Chen C., Huang J., Liu Z., Huang K.","College of System Engineering, National University of Defense Technology, Changsha, China",2019.0,"4th International Conference on Big Data and Information Analytics: Theories, Algorithms and Applications in Data Science, BigDIA 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062879122&doi=10.1109%2fBigDIA.2018.8632798&partnerID=40&md5=3fccfd791b5ebc356acb72c962053d9a,10.1109/BigDIA.2018.8632798,20230520-160000,20230521-044735,"['an', 'optimization', 'model', 'to', 'evaluate', 'dynamic', 'assignment', 'capability', 'of', 'agile', 'organization']",True,20230521-205332,,,,
351,scopus,Facilitating the Management of Agile and Devops Activities: Implementation of a Data Consolidator,"Organizations are confronted with a growing array of methodologies, tools and cloud offerings to address their business needs. On one hand, engineers and operations staff can leverage innovative DevOps oriented approaches for Continuous Delivery, Continuous Integration, containerization etc. On the other hand, project and operation leads are increasingly relying on agile methodologies to manage software development and release lifecycles. The number of tools available and used to run agile project tasks effectively is increasing and can yield an immense number of unmanageable information views for stakeholders. This paper focuses on the consolidation of these views through an information system built during a case study at South African SME, GZ Consulting Services. By designing an information system which is used as a central portal to aggregate data from internal systems used by the firm, we argue that an organization could better manage its agile and DevOps activities. © 2018 IEEE.",Activity Theory; Agile; Dev-Ops; Project Management; SME,"Doukoure G.A.K., Mnkandla E.","University of South Africa(UNISA), School of Computing, Pretoria, South Africa",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems, icABCD 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054633183&doi=10.1109%2fICABCD.2018.8465451&partnerID=40&md5=e1ff8b87acb21b34b8435f31e8623727,10.1109/ICABCD.2018.8465451,20230520-160000,20230521-044735,"['facilitating', 'the', 'management', 'of', 'agile', 'and', 'devops', 'activities:', 'implementation', 'of', 'a', 'data', 'consolidator']",True,20230521-205332,,,,
352,scopus,A method of verification in chisel based deep learning accelerator design,"Chisel is a new generation of hardware construction language (HCL) for agile development. More and more developers have developed their project in agile design. At the same time, a considerable part of Verilog-based design has also been released in agile design versions. However, there is no comprehensive verification flow for Chisel based design. Due to the difficulties of verification in Chisel based design, it is a tough task to attach Chisel based design on Verilog based design. We purpose a feasible verification flow in chisel-based deep learning accelerator (DLA) design, which is composed by performance equivalence check at module-level and function equivalence check at pin-level. Compared to Universe Verification Method in RTL level codes that cost considerable time and funds, this verification flow improves the verification efficiency and reduce the difficulty of debug. © 2020 IEEE.",Chisel; Deep learning accelerator; Verification,"Li Z., Chen Y., Zhao D.","Beijing University of Post and Telecommunications, Beijing, China; The Institute of Computing Technology of the Chinese Academy of Sciences, Beijing, China",2020.0,"Proceedings of 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence, ICIBA 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099277892&doi=10.1109%2fICIBA50161.2020.9277284&partnerID=40&md5=57b57a8022dea7d5d5c9e8af1f23981f,10.1109/ICIBA50161.2020.9277284,20230520-160000,20230521-044735,"['a', 'method', 'of', 'verification', 'in', 'chisel', 'based', 'deep', 'learning', 'accelerator', 'design']",True,20230521-205332,,,,
353,scopus,Impact of artificial intelligence-driven big data analytics culture on agility and resilience in humanitarian supply chain: A practice-based view,"This study attempts to understand the role of artificial intelligence-driven big data analytics capability in humanitarian relief operations. These disasters play an important role in mobilizing several organizations to counteract them, but the organizations often find it hard to strike a fine balance between agility and resilience. Operations Management Scholars’ opinion remains divided between responsiveness and efficiency. However, to manage unexpected events like disasters, organizations need to be agile and resilient. In previous studies, scholars have adopted the resource-based view or dynamic capability view to explain the combination of resources and capabilities (i.e., technology, agility, and resilience) to explain their performance. However, following some recent scholarly debates, we argue that organizational theories like the resource-based view or dynamic capability view are not suitable enough to explain humanitarian supply chain performance. As the underlying assumptions of the commercial supply chain do not hold true in the case of the humanitarian supply chain. We note this as a potential research gap in the existing literature. Moreover, humanitarian organizations remain sceptical regarding the adoption of artificial intelligence-driven big data analytics capability (AI-BDAC) in the decision-making process. To address these potential gaps, we grounded our theoretical model in the practice-based view which is proposed as an appropriate lens to examine the role of practices that are not rare and are easy to imitate in performance. We used Partial Least Squares (PLS) to test our theoretical model and research hypotheses, using 171 useable responses gathered through a web survey of international non-governmental organizations (NGOs). The findings of our study suggest that AI-BDAC is a significant determinant of agility, resilience, and performance of the humanitarian supply chain. Furthermore, the reduction of the level of information complexity (IC) on the paths joining agility, resilience, and performance in the humanitarian supply chain. These results offer some useful theoretical contributions to the contingent view of the practice-based view. In a way, we have tried to establish empirically that the humanitarian supply chain designs are quite different from their commercial counterparts. Hence, the use of a resource-based view or dynamic capability view as theoretical lenses may not help capture true perspectives. Thus, the use of a practice-based view as an alternative theoretical lens provides a better understanding of humanitarian supply chains. We have further outlined the limitations and the future research directions of the study. © 2022",Artificial intelligence; Big data analytics; Culture; Humanitarian operations management; Humanitarian supply chain; PLS-SEM; Practice-based view; Supply chain agility; Supply chain resilience,"Dubey R., Bryde D.J., Dwivedi Y.K., Graham G., Foropon C.","Montpellier Business School, 2300 Avenue des Moulins, Montpellier, 34185, France; Liverpool Business School, Liverpool John Moore's University, Merseyside, Liverpool, L3 5UG, United Kingdom; Emerging Markets Research Centre (EMaRC), School of Management, Swansea University, Bay Campus, Fabian Bay, Wales, Swansea, United Kingdom; Department of Management, Symbiosis Institute of Business Management, Pune & Symbiosis International (Deemed University), Maharashtra, Pune, India; Leeds University Business School, University of Leeds, Maurice Keyworth Building, Leeds, LS2 9JT, United Kingdom",2022.0,International Journal of Production Economics,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138517376&doi=10.1016%2fj.ijpe.2022.108618&partnerID=40&md5=37420499b3d72060c1716fd577d8e52b,10.1016/j.ijpe.2022.108618,20230520-160000,20230521-044735,"['impact', 'of', 'artificial', 'intelligence-driven', 'big', 'data', 'analytics', 'culture', 'on', 'agility', 'and', 'resilience', 'in', 'humanitarian', 'supply', 'chain:', 'a', 'practice-based', 'view']",False,20230521-205332,,,,
354,scopus,IBM Z development transformation,"This article discusses how the product development cycle is being transformed with 'Artificial Intelligence' (AI) for the first time in zSeries history. This new era of AI, under the project name IBM Z Development Transformation (zDT), has allowed the team to grow and learn new skills in data science. This transformation forces change structurally in how data is prepared and stored. In z14, there were incremental productivity gains with enhancements to automation with eServer Automation Test Solution and a technology data analysis engine called zDataAssist. However, in z15, AI will significantly accelerate our efficiency. This article explains how Design Thinking and Agile principles were used to identify areas that are of high impact and feasible to implement: 1) what and how data is collected via System Test Event Logging and Analysis engine, Problem ticket management system (Jupitr), and Processor data analysis engine (Xrings); 2) problem identification, analysis, and management (AutoJup) along with Intelligent Recovery Verification Assistant; 3) product design documentation search engine (AskTheMachine); and 4) prototype microprocessor allocation processes Intelligent Commodity Fulfillment System using Machine Learning. This article details the approach of these areas for z15, the implementation of these solutions under the zDT project, as well as the results and future work. © 1957-2012 IBM.",,"McCain E.C., Bastien P., Belmar B.F., Bhattacharya B., Cheruiyot K.K., Coq M., Dartey R., Deekaram K., Ghadai K., Lalima L.D., Nettey J., Owolabi A.W., Phillips K., Shiling T.M., Schroeder D.T., Slegel C., Steen B., Thorne D.A., Venuto E., Willoughby J.D., Yaniv D., Ziemis N.","Ibm Systems, Poughkeepsie, NY  12601, United States; Ibm Z, Poughkeepsie, NY  12601, United States; Ibm Systems and Technology Group, Singapore, 486072, Singapore; Ibm Systems and Technology Group, Poughkeepsie, NY  12601, United States; Ibm Systems, Z Ras Engineering, Poughkeepsie, NY  12601, United States; Ibm System Z Firmware, Bangalore, 560045, India; Ibm India Systems Development Lab (ISDL), Bangalore, 560045, India; Ibm Hardware and Physical Design Team, Instruction Decode Unit, Poughkeepsie, NY  12601, United States; Ibm Systems and Technology Group, Microprocessor Test and Development LabNY  12533-6683, United States; Ibm Systems /ZPET, Poughkeepsie, NY  12603, United States; Ibm Z Technical Support, Poughkeepsie, NY  12603, United States; Ibm Z Test Engineering, Poughkeepsie, NY  12601, United States",2020.0,IBM Journal of Research and Development,IBM Corporation,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090433629&doi=10.1147%2fJRD.2020.3008122&partnerID=40&md5=8342fbfedb3f40be412cc1703d23dc44,10.1147/JRD.2020.3008122,20230520-160000,20230521-044735,"['ibm', 'z', 'development', 'transformation']",True,20230521-205332,,,,
355,scopus,"MosaicSim: A Lightweight, Modular Simulator for Heterogeneous Systems","As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and domain-specific hardware-software co-designs. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support rich heterogeneous combinations of general purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we introduce MosaicSim, a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. By integrating the LLVM toolchain, MosaicSim enables efficient modeling of instruction dependencies and flexible additions across the stack. Its modularity also allows the composition and integration of different hardware components. We first demonstrate that MosaicSim captures architectural bottlenecks in applications, and accurately models both scaling trends in a multicore setting and accelerator behavior. We then present two case-studies where MosaicSim enables straightforward design space explorations for emerging systems, i.e. data science application acceleration and heterogeneous parallel architectures. © 2020 IEEE.",accelerators; hardware-software co design; heterogeneity; multi-core architectures; performance modeling,"Matthews O., Manocha A., Giri D., Orenes-Vera M., Tureci E., Sorensen T., Ham T.J., Aragon J.L., Carloni L.P., Martonosi M.","Princeton University, United States; Columbia University, United States; Uc Santa Cruz, United States; Seoul National University, South Korea; University of Murcia, Spain",2020.0,"Proceedings - 2020 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097156267&doi=10.1109%2fISPASS48437.2020.00029&partnerID=40&md5=3d8031419580528886daf1dc3b75f7c1,10.1109/ISPASS48437.2020.00029,20230520-160000,20230521-044735,"['mosaicsim:', 'a', 'lightweight,', 'modular', 'simulator', 'for', 'heterogeneous', 'systems']",True,20230521-205332,,,,
356,scopus,Machine Learning-based Estimation of Story Points in Agile Development: Industrial Experience and Lessons Learned,"Estimating story points is an important activity in agile software engineering. Story-point estimation enables software development teams to, among other things, better scope products, prioritize requirements, allocate resources and measure progress. Several machine learning techniques have been proposed for automated story-point estimation. However, most of these techniques use open-source projects for evaluation. There are important differences between open-source and commercial projects with respect to story authoring. The goal of this paper is to evaluate a state-of-the-art machine learning technique, known as Deep-SE [3], for estimating story points in a commercial project. Our dataset is comprised of 4,727 stories for a data anonymization product developed by a 27-member agile team at a healthcare data science company, IQVIA. Over this dataset, Deep-SE achieved a mean absolute error of 1.46, significantly better than three different baselines. Model performance nonetheless varied across stories, with the estimation error being larger for stories that had higher points. Our results further indicate that model performance is correlated with certain story characteristics such as the level of detail and the frequency of vague terms in the stories. An important take-away from our study is that, before organizations attempt to introduce machine learning-based estimation into agile development, they need to better embrace agile best practices, particularly in relation to story authoring and expert-based estimation. © 2021 IEEE.",Agile Development; Machine Learning; Story-point Estimation,"Abadeer M., Sabetzadeh M.","Privacy Analytics Inc., IQVIA company, Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada",2021.0,Proceedings of the IEEE International Conference on Requirements Engineering,IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118461307&doi=10.1109%2fREW53955.2021.00022&partnerID=40&md5=3c8f05991b322e5b9f7f6c68962a4777,10.1109/REW53955.2021.00022,20230520-160000,20230521-044735,"['machine', 'learning-based', 'estimation', 'of', 'story', 'points', 'in', 'agile', 'development:', 'industrial', 'experience', 'and', 'lessons', 'learned']",True,20230521-205332,,,,
357,scopus,SymPlot: A Web-Tool to Visualise Symbolic Musical Data,"Some complex musical parameters might be especially difficult to understand for someone with no theoretical expertise in music. Musicians and music scholars alike normally evaluate such parameters visually by departing from scores, which present the musical events at once. Yet for the under-standing of such symbolic representations, musical training is essential, making scores mostly incomprehensible for amateurs. Data visualisation has been applied to meaningfully represent complex musical parameters, thus enabling music amateurs to grasp concepts such as texture or structure. Although scores are one of the ""primary""sources to understand music, previous work shows a strong bias towards the visualisation of acoustic data, in detriment of the visualisation of symbolic information. To bridge the gap, we present SymPlot, a web-based open source tool to automatically visualise textural density, scoring, and structure from MusicXML files. Due to the multidisciplinary nature of the topic, in this project we have applied the Scrum's agile methodology, an iterative incremental approach specifically tailored for interdisciplinary projects. The tool, aimed at enhancing musical understanding in amateurs and students, as well as in scholars of other disciplines who need to incorporate music into their discourses, i.e., historians, philologists, etc., enables visualisation of local features at various hierarchical levels, highlighting similarities both within and across scores. Our evaluation of SymPlot-based on a five-level rating-scale test performed by 50 participants-suggests that colours increase users' understanding of complex musical parameters. © 2020 IEEE.",computational musicology; data science; digital humanities; music; score; symbolic music data; visualisation,"Munoz-Lago P., Llorens A., Parada-Cabaleiro E., Torrente A.","Universidad Complutense de Madrid, Instituto Complutense de Ciencias Musicales (ICCMU), Spain; Universidad Complutense de Madrid, Instituto Complutense de Ciencias Musicales (ICCMU), Spain",2020.0,Proceedings of the International Conference on Information Visualisation,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102933267&doi=10.1109%2fIV51561.2020.00092&partnerID=40&md5=bb89c83831b5ff3c4517cde8e2686f1b,10.1109/IV51561.2020.00092,20230520-160000,20230521-044735,"['symplot:', 'a', 'web-tool', 'to', 'visualise', 'symbolic', 'musical', 'data']",True,20230521-205332,,,,
358,scopus,Reproducible research and GIScience: An evaluation using AGILE conference papers,"The demand for reproducible research is on the rise in disciplines concerned with data analysis and computational methods. Therefore, we reviewed current recommendations for reproducible research and translated them into criteria for assessing the reproducibility of articles in the field of geographic information science (GIScience). Using this criteria, we assessed a sample of GIScience studies from the Association of Geographic Information Laboratories in Europe (AGILE) conference series, and we collected feedback about the assessment from the study authors. Results from the author feedback indicate that although authors support the concept of performing reproducible research, the incentives for doing this in practice are too small. Therefore, we propose concrete actions for individual researchers and the GIScience conference series to improve transparency and reproducibility. For example, to support researchers in producing reproducible work, the GIScience conference series could offer awards and paper badges, provide author guidelines for computational research, and publish articles in Open Access formats. © 2018 Nüst et al.",AGILE; Data science; GIScience; Open access; Open science; Reproducible conference publications; Reproducible research,"Nüst D., Granell C., Hofer B., Konkol M., Ostermann F.O., Sileryte R., Cerutti V.","Institute for Geoinformatics, University of Münster, Münster, Germany; Institute of New Imaging Technologies, Universitat Jaume I de Castellón, Castellón, Spain; Interfaculty Department of Geoinformatics - Z-GIS, University of Salzburg, Salzburg, Austria; Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, Enschede, Netherlands; Faculty of Architecture and the Built Environment, Delft University of Technology, Delft, Netherlands",2018.0,PeerJ,PeerJ Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049995495&doi=10.7717%2fpeerj.5072&partnerID=40&md5=57255b0a57d9b4a4a4d8f23c40477717,10.7717/peerj.5072,20230520-160000,20230521-044735,"['reproducible', 'research', 'and', 'giscience:', 'an', 'evaluation', 'using', 'agile', 'conference', 'papers']",False,20230521-205332,,,,
359,scopus,HerdMonitor: Monitoring Live Migrating Containers in Cloud Environments,"Cloud computing uses pools of virtual machines to provide shared computing resources. Provisioning and management of these resources are generally done using statistical algorithms to help decide how to better utilize available compute power; recently, this has been performed mostly by using live migration of virtual machines. Nowadays containers deliver the flexibility to handle many software environments and tasks in a lighter-weight virtualization scheme, providing a more agile alternative to virtual machines for certain applications. Application checkpointing coupled with a container manager allows the live migration of a container. In this work, we present Herd-Monitor, a resource monitoring system to gather performance metrics of containers and their respective compute hosts. This data can be used to analyze the utilization of available resources, characterize workloads, and develop forecast models. With the analysis of the data provided by the monitoring system, we can fine-tune resource provisioning policies, with the end goal of constructing a cloud resource provisioning platform that enables an improvement in usage and execution of container workloads through the use of live migration. The design, development, performance evaluation and characterization of our lightweight resource monitoring tool that enables offline and real-time resource utilization analysis of live migration workloads as well as the performance impact on their hosts are presented. © 2020 IEEE.",Big Data Infrastructure; Cloud Architecture; Cloud computing; Containers; Data Streaming; Live Migration; Performance Monitoring; Realtime Monitoring; Software Systems to Support Big Data Computing,"Gonzalez A.E., Arzuaga E.","University of Puerto Rico, Department of Electrical and Computer Engineering, Mayagüez, Puerto Rico",2020.0,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103825181&doi=10.1109%2fBigData50022.2020.9378473&partnerID=40&md5=0a3a6e1b8fa59bf9cef3216cda37ab71,10.1109/BigData50022.2020.9378473,20230520-160000,20230521-044735,"['herdmonitor:', 'monitoring', 'live', 'migrating', 'containers', 'in', 'cloud', 'environments']",True,20230521-205332,,,,
360,scopus,Agile-Style Development of CMOS-Integrated Micro Electro Chemical Mechanical Systems by LSI Foundry and Nanotechnology Platform,"We report our attempts of agile-style development of CMOS-Integrated Micro Electro Chemical Mechanical Systems, also known as μ-TAS. Agile development is a well known alternative concept of software development. In contrast to classical development (often referred to waterfall model), both users and developers form a team and closely collaborate, and produce many ""ready-to-use (but not necessarily be perfect)"" versions of ""release package""s. Powered by LSI foundry and open facility are enabling factor, we are trying to apply this concept to MEMS devices research and development. Such a quick and efficient development may provide us with future applications of lab-on-chips, which is the theme of the ISESD 2018 conference. The concept and some outcomes are presented in this invited talk. © 2018 IEEE.",agile development model; Chemical MEMS; CMOS Integration; foundry,"Mita Y., Lebrasseur E., Denoual M., Yamada K., Grand J., Okamoto Y., Reddy R.R., Agnès T.-M., Mintova S., Higo A.","University of Tokyo, Tokyo, Japan; ENSI de Caen, Caen, France",2019.0,ISESD 2018 - International Symposium on Electronics and Smart Devices: Smart Devices for Big Data Analytic and Machine Learning,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061914554&doi=10.1109%2fISESD.2018.8605484&partnerID=40&md5=de1fb7855d26aa077ea767884740b4bc,10.1109/ISESD.2018.8605484,20230520-160000,20230521-044735,"['agile-style', 'development', 'of', 'cmos-integrated', 'micro', 'electro', 'chemical', 'mechanical', 'systems', 'by', 'lsi', 'foundry', 'and', 'nanotechnology', 'platform']",False,20230521-205332,,,,
361,scopus,Agile project management challenges and mapping solutions: A systematic literature review,"The Project Management Institute reported that the Agile approach is widely being used for project management practices. This approach has a significant impact on business growth and project performance. However, its implementation is challenging. Therefore, a systematic literature review (SLR) is used to reveal the challenges faced in Agile project execution. The Project Management Body of Knowledge (PMBOK) knowledge areas were adopted to classify the challenges. A total of 23 papers from 400 were identified as the result of SLR extraction. The challenges from related studies were categorized into the PMBOK knowledge areas. A mapping from the challenges to the solutions was performed using the PMBOK Guide, Prince2 Agile, Agile Practice Guide, and other related references. This study provides a list of Agile challenges and their mapped solutions. The biggest challenge arises from stakeholder management, which includes challenges related to Agile adaption, Agile transition, and Agile transformation. Other challenges include project resource management, project integration management, project scope management, and project schedule management. For academicians, this study provides a new understanding of Agile challenges and their suitable solutions from the perspective of project management. For practitioners, the findings provide potential lessons learned and recommendations to deal with the challenges. © 2020 Association for Computing Machinery.",Agile; Agile Approach; Agile Project Management; Systematic Literature Review,"Raharjo T., Purwandari B.","Universitas Indonesia, Depok, Indonesia",2020.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081992987&doi=10.1145%2f3378936.3378949&partnerID=40&md5=593ac43cd263ee3d05f7bdcecec17889,10.1145/3378936.3378949,20230520-160000,20230521-044735,"['agile', 'project', 'management', 'challenges', 'and', 'mapping', 'solutions:', 'a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
362,scopus,"MAP: Design, Development, Deployment, and Maintenance of Industrie 4.0 AI Applications","This paper presents a proven process and method to design, develop, deploy, and maintain Industrie 4.0 Big Data Artificial Intelligence (AI) scalable solutions at ABB called modular adaptive process (MAP). The method follows a hybrid DevOps-Agile-Waterfall approach that takes advantage of different elements of all three methodologies to bring to fruition Artificial Intelligence (AI) and Machine Learning (ML) solutions. The described methodology has three phases that include Definition, Development, and Deployment. An important and novel concept that will be discussed is the development of a Value-based Work Breakdown Structure (VWBS) that facilitates DevOps development. Another important discussion is related to the re-training of AI/ML models once the application is deployed. © 2022 IEEE.",Agile; Artificial Intelligence; DevOps; Industrie 4.0; Machine Learning; Model re-training; UX; value-based WBS,"Dagnino A., Kolomycki M., Kucheria A.","GBS IS Innovation and Emerging Services, ABB Inc, Cary, United States; GBS IS Innovation and Emerging Services, ABB Ltd, Krakow, Poland",2022.0,"Proceedings - IEEE 8th International Conference on Big Data Computing Service and Applications, BigDataService 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141047215&doi=10.1109%2fBigDataService55688.2022.00024&partnerID=40&md5=4b0af6036061fea3092cd6f7a5ade132,10.1109/BigDataService55688.2022.00024,20230520-160000,20230521-044735,"['map:', 'design,', 'development,', 'deployment,', 'and', 'maintenance', 'of', 'industrie', '4.0', 'ai', 'applications']",True,20230521-205332,,,,
363,scopus,Lean manufacturing and industry 4.0 combinative application: Practices and perceived benefits,"This paper investigates the industry practices regarding the combinative use of Industry 4.0 and lean tools in the manufacturing sector. Following review of the literature, a questionnaire survey was distributed among manufacturing professionals in organizations which have already adopted Industry 4.0 technology and lean manufacturing, with the aim to highlight the popular combinations of tools as seen in manufacturing practice and capture the perceived level of their contribution to operational performance. The survey results show that Real time data, IoT for data exchange, big data analytics, Cyber -Physical Systems (CPS), predictive algorithms and robots are among the most popular I4.0 applications used to support lean attributes like continuous flow, Kanban, standardised work, TPM and continuous improvement. It also emerges that although the beneficial impact of lean production across the respondents' organizations is widely accepted, the perceived impact of Industry 4.0 tools is not as clear. © 2021 The Authors. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0)",Decision making; Industry 4.0; Information technology; Lean production; Production management,"Marinelli M., Ali Deshmukh A., Janardhanan M., Nielsen I.","School of Engineering, University of Leicester, Leicester, LE17RH, United Kingdom; Department of Materials and Production, Aalborg University9220, Denmark",2021.0,IFAC-PapersOnLine,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120669881&doi=10.1016%2fj.ifacol.2021.08.034&partnerID=40&md5=7ea2d9128f14814638b8ab85b88be3bc,10.1016/j.ifacol.2021.08.034,20230520-160000,20230521-044735,"['lean', 'manufacturing', 'and', 'industry', '4.0', 'combinative', 'application:', 'practices', 'and', 'perceived', 'benefits']",False,20230521-205332,,,,
364,scopus,"Big data empowered agility for dynamic, volatile, and time-sensitive service industries: the case of tourism sector","Purpose: Dynamic, volatile, and time-sensitive industries, such as tourism, travel and hospitality require agility and market intelligence to create value and achieve competitive advantage. The aim of the current study is to examine the influence of big data (BD) on the performance of service organizations and to probe for a deeper understanding of implementing BD, based on available technologies. Design/methodology/approach: An ethnographic study was conducted following an abductive approach. A primary qualitative research scheme was used with 35 information technology and database professionals participating in five online focus groups of seven participants each. Analytical themes were developed simultaneously with the literature being revisited throughout the study to ultimately create sets of common themes and dimensions. Findings: BD can help organizations build agility, especially within dynamic industries, to better predict customer behavioral patterns and make tailor-made propositions from the BD. An integrated BD-specific framework is proposed to address value according to the dimensions of need, value, time and utility. Research limitations/implications: Little research exists on the key drivers of BD use for dynamic, real-time and agile businesses. This research adds to the developing literature on BD applications to support organizational decision-making and business performance in the tourism industry. Originality/value: This study responds to scholars’ recent calls for more empirical research with contextual understanding of the use of BD to add value in marketing intelligence within business ecosystems. It delineates factors contributing to BD value creation and explores the impacts on the respective service encounters. © 2021, Emerald Publishing Limited.",BD-specific framework; Big data; IT experts; Online focus groups; Tourism organizations,"Stylos N., Zwiegelaar J., Buhalis D.","School of Management, University of Bristol, Bristol, UK and Department of Hotel Management, College of Tourism, Tainan University of Technology, Tainan City, Taiwan; Department of Business and Management, Oxford Brookes University, Oxford, United Kingdom; Faculty of Management, Bournemouth University, Poole, United Kingdom",2021.0,International Journal of Contemporary Hospitality Management,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100569054&doi=10.1108%2fIJCHM-07-2020-0644&partnerID=40&md5=f6e5d98b0653dc101e035da3e9ba8496,10.1108/IJCHM-07-2020-0644,20230520-160000,20230521-044735,"['big', 'data', 'empowered', 'agility', 'for', 'dynamic,', 'volatile,', 'and', 'time-sensitive', 'service', 'industries:', 'the', 'case', 'of', 'tourism', 'sector']",False,20230521-205332,,,,
365,scopus,Working life within a hybrid world – How digital transformation and agile structures affect human functions and increase quality of work and business performance,"Digitization is dramatically changing economy and society. With current developments in the field of e.g. artificial intelligence and machine learning, big data and data analytics, cloud computing, conversational systems and adaptive architectures, robotics as well as virtual and augmented reality work life is facing huge challenges. On the other side the networking over the internet, more effective handling and sharing of data and new forms of human-machine-collaboration offer a great variety of potentials for designing even more flexible business processes, agile working structures and even smarter working setups and environments. Technique, organizational aspects and humans in the future are going to be within a new triad. Instead of taking the role of a “dominator” or “captain” as in former times, humans now more and more have to fulfill tasks as a “conductor”. The role of building up and interacting within new hybrid networks and holistic systems is gaining higher importance – leading to massive changes with reference to all dimensions of work. Total new requirements concerning work objectives, working tasks, work equipment, workspace as well as new challenges for organization, qualification, employment and leadership arise. Work is becoming more and more digitally and going to look quite different than expected today. Combining the physical and virtual world is representing the key success factor for future work. The study examines how digitization is going to penetrate working life further on displaying central measures and selected solutions for resulting organizational structures, human qualification needs and optimized working conditions in a hybrid world. © Springer International Publishing AG 2018.",Agility; Collaboration; Data; Digitization; Industry 4.0; Organization; Performance; Qualifications; Requirements; Technology,"Bauer W., Schlund S., Vocke C.","Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, Stuttgart, 70569, Germany",2018.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031300069&doi=10.1007%2f978-3-319-60372-8_1&partnerID=40&md5=123529b16d107fb56f9ae64d95f32cf3,10.1007/978-3-319-60372-8_1,20230520-160000,20230521-044735,"['working', 'life', 'within', 'a', 'hybrid', 'world', '–', 'how', 'digital', 'transformation', 'and', 'agile', 'structures', 'affect', 'human', 'functions', 'and', 'increase', 'quality', 'of', 'work', 'and', 'business', 'performance']",False,20230521-205332,,,,
366,scopus,A systematic review of disruptive technology within accounting and accounting sector,"Disruptive technology offers both opportunities and challenges for intensifying the organisational governance within the lens of the accounting sector. A collaborative decision making becomes necessities for competent and beneficial governance across the accounting sector. Through paradigm shift across the sector, thinking of how to form new governance from a repercussion of disruptive technology facing the sector is crucial. Disruptive technology occurred from the progressing of Big Data, cloud, and artificial intelligence which currently allocated to the transactions in the ledgers that have control over an unprecedented shift and frequently disrupting the works of accounting practitioners. The capabilities to manage and control a huge amount of digitised data in the complex and expeditious journey within these digital age has also promoted the accounting sector to become flexible, have good networking and uses a multi-platform that can support these emerging technologies and the Industrial 4.0. Therefore, the sector crucially needed a knowledgeable and proactive people surrounding as to control outstanding pressure to support futuristic and agile governance practices. The review of this study has a great focus on big data, cloud, artificial intelligence and blockchain within management accounting, auditing & accounting sector with respect of these emerging technologies. © 2021 American Institute of Physics Inc.. All rights reserved.",,"Ibrahim S., Yusoff W.S., Rashid I.M.A.","School of Business Innovation And Technopreneurship, Universiti Malaysia Perlis, Kangar, Perlis  01000, Malaysia",2021.0,AIP Conference Proceedings,American Institute of Physics Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105616443&doi=10.1063%2f5.0044297&partnerID=40&md5=9be9afcea8b2c3d8e68a1f1649ab13d1,10.1063/5.0044297,20230520-160000,20230521-044735,"['a', 'systematic', 'review', 'of', 'disruptive', 'technology', 'within', 'accounting', 'and', 'accounting', 'sector']",False,20230521-205332,,,,
367,scopus,A katana design experience,"Increases in computation power have allowed design software to become more complex. At the same time, big data and artificial intelligence, question the traditional tools of the human designer. Morphogenetic (concerned with the beginning of the form of an object) prototyping provides a method for designers to control this complexity by separating the design into pseudo developmental stages to enable the manipulation of its development at different stages. This paper investigates the tools, processes, theory and systems that would be needed to simulate this design experience. Through this process a katana sword is selected as the metaphor for the design experience to relate the affordance of cutting to the simulation of a pseudo biological sub division. A sword prototype is used to identify appropriate gestures to map to biological behaviours in order to trigger the simulation of staged pseudo biological processes in the design model. Finally, the tangible user interface (TUI) tool based on the katana sword is refined and future work is outlined. © Springer International Publishing AG, part of Springer Nature 2018.",Agile biomimetics; Design experience; Morphogenetic prototyping; Narrative prototyping; Tangible user interface,"McGinley T., Hoshi K., Gruber P., Haddy S., Zavoleas Y., Tan L., Blaiklock D.","University of South Australia, Adelaide, SA  5000, Australia; University of Akron, Akron, OH, United States; The University of Newcastle, Newcastle, NSW, Australia; Ctrl_Space Lab, Athens, Greece; Swinburne University of Technology, Melbourne, VIC, Australia",2018.0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045421688&doi=10.1007%2f978-3-319-78795-4_10&partnerID=40&md5=31b95c58051e4618f2ffd5559db11c33,10.1007/978-3-319-78795-4_10,20230520-160000,20230521-044735,"['a', 'katana', 'design', 'experience']",False,20230521-205332,,,,
368,scopus,Production optimization under constraints: Development and application of software combining data science and petroleum engineering knowledge,"OMV New Zealand gas/condensate fields’ gas production is limited by commercial demand, which also constrain production of associated condensate. No test separators nor individual well multiphase flow meters are installed, only single-phase gas flow meters (V-cones flow meters and orifice plate) for each individual well. In order to produce the maximum revenue for the fields, the wells with the highest condensate-gas-ratio need to be prioritized, while still ensuring that well and facilities constraints are managed. An agile crew of engineers, developers and data scientists, have been mobilized to design and create reliable, easy to use and easy to maintain software solutions to solve three different parts of the optimization problem: A live, dynamic visualization of the wells operating envelopes for dynamic monitoring of the current status of individual wells versus the constraints and direct comparison with simulation models results. A software solution to automatically identify step-changes in well gas, water and condensate rates at facility output level, using these changes to improve CGR and WGR allocated value for each individual well. A software application to calculate the best combination of individual well rates to meet gas export demand while maximizing condensate production, within facility limits and well operating envelopes. © EAGE 2019.",,Joffre G.,"OMV Exploration and Production, Austria",2020.0,1st EAGE Digitalization Conference and Exhibition,"European Association of Geoscientists and Engineers, EAGE",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092662249&doi=10.3997%2f2214-4609.202032033&partnerID=40&md5=16f206cfe9ea156e2db96b5572e6e91e,10.3997/2214-4609.202032033,20230520-160000,20230521-044735,"['production', 'optimization', 'under', 'constraints:', 'development', 'and', 'application', 'of', 'software', 'combining', 'data', 'science', 'and', 'petroleum', 'engineering', 'knowledge']",False,20230521-205332,,,,
369,scopus,Building a rig state classifier using supervised machine learning to support invisible lost time analysis,"This paper covers the development of a key component of an internal system to report invisible lost time (ILT) metrics across drilling operations. Specifically this paper covers the development of a generalizable rig state engine based on the application of supervised machine learning. The same steps used in the creation of the production rig state engine are appled here to a smaller data set to demonstrate both the tractability of the problem and the methods used to create the rig state engine in the production system. The project objective was to provide efficiency and engineering metrics in a central repository covering operated regions. The system is designed to require minimal user configuration and management and provides both historic and near real time analysis to deliver a rich resource for offset comparison and benchmarking. Identifying rig-state is at the heart of every performance and engineering analysis system. This can be thought of as a machine learning classification problem. A large supervised learning set was constructed and used to train classification models which were compared for accuracy. A key success metric was the ability to generalise the selected model across different operations. Output from the rig-state classifier was then used to derive KPI data which was presented through a web based front end. A pilot system was then developed using agile principles allowing for rapid user engagement. Testing demonstrated that the system can support all real time operations within the company simultaneously and rapidly process historic well data for offset benchmarking. The cloud-based architecture allows rapid deployment of the system to new groups significantly reducing deployment costs. The system provides a foundation for onward data science and more advanced functionality. Minimal configuration, cloud storage and processing, combining contextual data with real-time rig data, near-real-time and historic analysis capabilities, rapid deployment, low cost, high accuracy and consistent metrics are all key and proven value drivers for the system. The output data is aso a valuable resource for additional machine learning and data science projects. Copyright 2019, SPE/IADC International Drilling Conference and Exhibition.",,Coley C.,"BP, United Kingdom",2019.0,"SPE/IADC Drilling Conference, Proceedings",Society of Petroleum Engineers (SPE),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063161513&doi=10.2118%2f194136-ms&partnerID=40&md5=61e26e420396974d5943e2788748c23d,10.2118/194136-ms,20230520-160000,20230521-044735,"['building', 'a', 'rig', 'state', 'classifier', 'using', 'supervised', 'machine', 'learning', 'to', 'support', 'invisible', 'lost', 'time', 'analysis']",False,20230521-205332,,,,
370,scopus,Research on the Middle Platform Service System of Battlefield Data Governance Information based on 5G Technology,"In order to enable fast and agile battlefield data service support capabilities, orderly advance the construction of military big data, and accelerate the implementation of digital battlefields, this paper makes full use of 5G technology and service center integration ideas to build a battlefield data governance information service system. Network slicing technology is used to guarantee differentiated network transmission capabilities for different data requirements, cloud-edge coordination technology is used to guarantee real-time computing power for distributed battlefield data, and service capability opening technology is used to guarantee agile data customization services in complex and changeable environments. New technologies are systematically integrated to achieve value-added empowerment of different operational application data, and provide fast and flexible digital service guarantee for the battlefield. © 2021 ACM.",5G technology; Battlefield data; Information service system; Systematic governance,"Ou X., Liao J., Chen K., Hu Z.","Wuhan Maritime Communication Research Institute, Wuhan, China",2021.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126671889&doi=10.1145%2f3495018.3495109&partnerID=40&md5=8eb682e8a8c8276141dc94e1fb6e8854,10.1145/3495018.3495109,20230520-160000,20230521-044735,"['research', 'on', 'the', 'middle', 'platform', 'service', 'system', 'of', 'battlefield', 'data', 'governance', 'information', 'based', 'on', '5g', 'technology']",True,20230521-205332,,,,
371,scopus,DESIGN AN AGILE OF MACHINE LEARNING TO PREDICTIVE HOUSE PRICING AND TARGETING SEGMENTED MARKET,"Because of too high expectations or having a wrongly segmented target market, the developer hasn't received a good response from the target market. Developers need a new marketing tool that is based on data. The use of machine learning systems as marketing tools to help solve the problems in house price prediction is an important topic in the real estate industry. The design of machine learning will use CRISP-DM as a framework and to analyze using linear regression and random forest as the best possible accuracy. Besides that, to find a potential market, we will use K-Means as a clustering method. The modeling and experiments to design a machine learning engine that can predict a range of selling prices using linear regression can give maximum accuracy and analyze the target market. The research focusing on different attributes will bring different dominant attributes to the table too. © 2022 ACM.",Agile; data analytics; data science; house development market; influence factor; linear regression; machine learning; predictive pricing; random forest; target market,"Wijaya J., Ipung H.P., Soetomo M.A.","Information Technology, Swiss German University, Indonesia",2022.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143254038&doi=10.1145%2f3557738.3557856&partnerID=40&md5=40ca612fb9a90d6b72e9fcebe0ea1a9b,10.1145/3557738.3557856,20230520-160000,20230521-044735,"['design', 'an', 'agile', 'of', 'machine', 'learning', 'to', 'predictive', 'house', 'pricing', 'and', 'targeting', 'segmented', 'market']",True,20230521-205332,,,,
372,scopus,Data Ecosystem and Data Value Chain: An Exploration of Drones Technology Applications,"The drones’ market is anticipated to grow significantly because of its increasing use for commercial and professional purposes. They are currently used in many industries and the next frontier is represented by the automotive industry. The volume of disposable data is growing exponentially, reaching more than 44 zettabytes of valuable data in 2020. In order to be able to fully reap the value of data available, firms must delve in big data and Data Value Chain (DVC) discipline. This paper explores the ecosystem formation as well as the challenges and criticalities encountered by Dronus and Here in their interaction and exchange of data. Ecosystems are network of distributed companies that shows multiple links toward their environment that interact via standard and business rules which permit them to be independent but also connected. Data have been collected through multiple sources, i.e. semi-structured interviews with firm’s representatives and direct observation. This study will give a contribution for future literature as it focuses on the analysis and research of an important gap that sees knowledge of bottlenecks as a way of conscious and efficient growth. In this way, firms and ecosystems that have successfully understood the importance of these variables found will be able to better answer to changes becoming more agile. Successful big data integration, accessibility and standard business rules, as we identify as the main roadblocks, will allow firms in data-driven sectors, and in particular in computer vision-based data set, to be efficient in the interconnection and to become more agile. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Data ecosystem; Data value chain; Digital transformation,"De Simone C., Ceci F., Alaimo C.","Dipartimento di Impresa e Management, Luiss University Rome, Rome, Italy; Department of Business Administration, University G. d’Annunzio Chieti-Pescara, Chieti, Italy; Department of Political Sciences, Luiss University Rome, Rome, Italy",2023.0,Lecture Notes in Information Systems and Organisation,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144397783&doi=10.1007%2f978-3-031-15770-7_13&partnerID=40&md5=9b7c43c277299f08d41a2be688e684b2,10.1007/978-3-031-15770-7_13,20230520-160000,20230521-044735,"['data', 'ecosystem', 'and', 'data', 'value', 'chain:', 'an', 'exploration', 'of', 'drones', 'technology', 'applications']",False,20230521-205332,,,,
373,scopus,SMVS: A Web-based Application for Graphical Visualization of Malay Text Corpus,"Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur'an corpus. © 2020 IEEE.",Big data; data visualization; knowledge representation; natural language processing; Qur'an knowledge,"Ahmat Baseri N.B., Bakar J.A., Ahmad A., Jafferi H., Zamri M.F.","School of Computing, Universiti Utara Malaysia, Kedah, Malaysia",2020.0,ISCAIE 2020 - IEEE 10th Symposium on Computer Applications and Industrial Electronics,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086630533&doi=10.1109%2fISCAIE47305.2020.9108705&partnerID=40&md5=4f14d49a069a896c0808d13dde22bcfc,10.1109/ISCAIE47305.2020.9108705,20230520-160000,20230521-044735,"['smvs:', 'a', 'web-based', 'application', 'for', 'graphical', 'visualization', 'of', 'malay', 'text', 'corpus']",True,20230521-205332,,,,
374,scopus,Manufacturing Systems at Scale with Big Data Streaming and Online Machine Learning,"Real time analysis of data collected from the shop floor opens the path towards efficient scheduling of batch execution for large scale distributed manufacturing systems. Prediction of the shop floor activities has a great potential to reduce manufacturing costs, by providing the information required for operational decisions like preventive maintenance, automatic remediation or scheduling optimization. Research has been focusing on how machine learning algorithms can be used to better understand and extract insights from historical data collected from manufacturing systems. However, in the current manufacturing environments, driven by mass customization and short time to market, these approaches fail to be agile enough to be useful. In this paper we propose a real-time machine learning approach for large scale manufacturing systems that can predict various scenarios before service degradation occurs, thus allowing for corrective actions. At the same time, outliner detection algorithms can be used to evaluate the system’s health at a holistic level. Scalability requirements are achieved by modelling the architecture around data streams processed in real time by map-reduce operations. The concepts presented in this paper build on recent developments on flexible, distributed and cloud based manufacturing, where these real time actions can be efficiently implemented. © 2018, Springer International Publishing AG.",Big data; Machine learning; MES; MSB,"Morariu O., Morariu C., Borangiu T., Răileanu S.","Department of Automation and Applied Informatics, University Politehnica of Bucharest, Bucharest, Romania",2018.0,Studies in Computational Intelligence,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042123108&doi=10.1007%2f978-3-319-73751-5_19&partnerID=40&md5=9d76ff49e1c66e698557b01e6c8639d7,10.1007/978-3-319-73751-5_19,20230520-160000,20230521-044735,"['manufacturing', 'systems', 'at', 'scale', 'with', 'big', 'data', 'streaming', 'and', 'online', 'machine', 'learning']",False,20230521-205332,,,,
375,scopus,Agile requirement engineering maturity framework for industry 4.0,"Industry 4.0 (I4.0) is changing business models and processes. I4.0 uses innovative trends such as Big Data, Cloud Computing, and Internet of things (IOT) to maximize economic benefits and return on investments. However, developing an I4.0 project may be costly, complex and risky for some companies. Therefore, careful requirements definition and mature Requirement Engineering (RE) processes are necessary. Undeveloped RE processes and poorly defined business requirements will often result in an inferior or a cancelled project. In addition, to ensure agility and allow for iterative changes in developing projects for I4.0, agile methodologies should be applied and prudently assessed. Unfortunately, most of existing assessment models are narrow focused and lack theoretical foundation and proper validation. This research proposes a comprehensive maturity framework called agile Requirement Engineering Maturity Model for Industry 4.0 (ARE-MMI4.0). The framework provides assessment of the minimum maturity levels to start a project for I4.0. The framework integrates an I4.0 maturity model with RE and agile maturity models to ensure the ultimate maturity assessment for the business processes. © 2019, Springer Nature Switzerland AG.",Agile; Industry 4.0; Maturity models integration; Requirements engineering,"Elnagar S., Weistroffer H., Thomas M.","Virginia Commonwealth University, Information Systems, Richmond, VA, United States",2019.0,Lecture Notes in Business Information Processing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060799150&doi=10.1007%2f978-3-030-11395-7_31&partnerID=40&md5=8e8a0a82f21143bfa9027a3b3ad8e568,10.1007/978-3-030-11395-7_31,20230520-160000,20230521-044735,"['agile', 'requirement', 'engineering', 'maturity', 'framework', 'for', 'industry', '4.0']",False,20230521-205332,,,,
376,scopus,Big Data Analytics Role in Managing Complex Supplier Networks and Inventory Management,"In today's world, competition is not only restricted between the marketing aspects of two companies or big firms. The competition has expanded between the supply chain management perspectives of two firms. In order to sustain within the current competitive environment supply chain professionals of a firm are struggling hard to handle large-scale data, that is important to reach an integrated, efficient, effective as well as agile supply chain process within their business. As a result, explosive growth of data volume and amount of data within business, made it mandatory for the supply chain processionals to use an effective data analytic tool in order to manage these data. The main aim of this study is to identify use of various data analytic tools in order to manage large data of supply process and inventory management process with several advantages and disadvantages. As per the literature findings, it has been observed that use of data analytic tools within an organisation can be helpful to investigate new insights of the supply chain process, which can be able to detect different parts and elements of that process. A mixed method approach has been incorporated within this research paper by collecting primary and secondary both data collection process. Total 50 employees engaged with inventory and supply chain management of different firm are chosen to conduct a survey. Secondary data are collected from secondary sources. As per the findings, it can be stated that big data analytics plays a positive role in organization for managing large data. © 2022 IEEE.",challenges; Cloud-computing; Data processing. NoSQL; Inventory management; IoT; large-scale data; machine learning algorithm; Regression; Supply chain management,"Anusha D.J., Panga M., Hadi Fauzi A., Sreeram A., Issabayev A., Arailym N.","Sri Padmavati Mahila Visvavidyalayam, Department of Computer Science Engineering, Tirupati, India; Economic Prestige Institute of Management and Research Indore; Universitas Padjadjaran, Faculty of Political and Social Sciences, Business Administration Department, Indonesia; Operations It Icfai Business School, (A Constituent of Ifhe University), Hyderabad, India; International Education Corporation, Department of Architecture, Almaty, Kazakhstan; International Education Corporation, Department of Design, Almaty, Kazakhstan",2022.0,"International Conference on Sustainable Computing and Data Communication Systems, ICSCDS 2022 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130095576&doi=10.1109%2fICSCDS53736.2022.9761008&partnerID=40&md5=f52d59521e77e62f8f927930a73e0fd0,10.1109/ICSCDS53736.2022.9761008,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'role', 'in', 'managing', 'complex', 'supplier', 'networks', 'and', 'inventory', 'management']",True,20230521-205332,,,,
377,scopus,Prediction of voltage distribution using deep learning and identified key smart meter locations,"The energy landscape for the Low-Voltage (LV) networks is undergoing rapid changes. These changes are driven by the increased penetration of distributed Low Carbon Technologies, both on the generation side (i.e. adoption of micro-renewables) and demand side (i.e. electric vehicle charging). The previously passive ‘fit-and-forget’ approach to LV network management is becoming increasing inefficient to ensure its effective operation. A more agile approach to operation and planning is needed, that includes pro-active prediction and mitigation of risks to local sub-networks (such as risk of voltage deviations out of legal limits). The mass rollout of smart meters (SMs) and advances in metering infrastructure holds the promise for smarter network management. However, many of the proposed methods require full observability, yet the expectation of being able to collect complete, error free data from every smart meter is unrealistic in operational reality. Furthermore, the smart meter (SM) roll-out has encountered significant issues, with the current voluntary nature of installation in the UK and in many other countries resulting in low-likelihood of full SM coverage for all LV networks. Even with a comprehensive SM roll-out privacy restrictions, constrain data availability from meters. To address these issues, this paper proposes the use of a Deep Learning Neural Network architecture to predict the voltage distribution with partial SM coverage on actual network operator LV circuits. The results show that SM measurements from key locations are sufficient for effective prediction of the voltage distribution, even without the use of the high granularity personal power demand data from individual customers. © 2021 The Author(s)",Analytic methods in power networks; Big Data Analytics; Deep neural learning; Distribution network operation; Privacy-preserving data analysis; Smart meters; Voltage prediction,"Mokhtar M., Robu V., Flynn D., Higgins C., Whyte J., Loughran C., Fulton F.","Smart System Research Group, Heriot-Watt University, Riccarton Campus, Edinburgh, UK  EH14 4AS, United Kingdom; CWI, National Research Institute for Mathematics and Computer Science, Amsterdam, 1098XG, Netherlands; Algorithmics Group, EEMCS, Delft University of Technology, Delft, 2628XE, Netherlands; Derryherk Ltd., Renfrewshire, PA11 3BE, United Kingdom; Smart Meter Systems, SP Energy Networks, Glasgow, G2 5AD, United Kingdom",2021.0,Energy and AI,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112707710&doi=10.1016%2fj.egyai.2021.100103&partnerID=40&md5=5e569accd3fdf61a7b392a4f2c7437bb,10.1016/j.egyai.2021.100103,20230520-160000,20230521-044735,"['prediction', 'of', 'voltage', 'distribution', 'using', 'deep', 'learning', 'and', 'identified', 'key', 'smart', 'meter', 'locations']",False,20230521-205332,,,,
378,scopus,Di-ANFIS: An integrated blockchain-IoT-big data-enabled framework for evaluating service supply chain performance,"Service supply chain management is a complex process because of its intangibility, high diversity of services, trustless settings, and uncertain conditions. However, the traditional evaluating models mostly consider the historical performance data and fail to predict and diagnose the problems' root. This paper proposes a distributed, trustworthy, tamper-proof, and learning framework for evaluating service supply chain performance based on blockchain and adaptive network-based fuzzy inference systems (ANFIS) techniques, named Di-ANFIS. The main objectives of this research are as follows: (1) presenting hierarchical criteria of service supply chain performance to cope with the diagnosis of the problems' root; (2) proposing a smart learning model to deal with the uncertainty conditions by a combination of neural network and fuzzy logic; and (3) introducing a distributed blockchain-based framework due to the dependence of ANFIS on big data and the lack of trust and security in the supply chain. Furthermore, the proposed six-layer conceptual framework consists of the data layer, connection layer, blockchain layer, smart layer, ANFIS layer, and application layer. This architecture creates a performance management system using the Internet of Things, smart contracts, and ANFIS based on the blockchain platform. The Di-ANFIS model provides a performance evaluation system without needing a third party and a reliable intermediary that provides an agile and diagnostic model in a smart and learning process. It also saves computing time and speeds up information flow. © 2021 The Author(s) 2021. Published by Oxford University Press on behalf of the Society for Computational Design and Engineering.",big data; blockchain; industry 4.0; Internet of Things (IoT); performance evaluation; service supply chain,"Bamakan S.M.H., Faregh N., Zareravasan A.","Data Science Research Center, Yazd University, Yazd, 89195-741, Iran; Department of Industrial Management, Yazd University, Yazd, 89195-741, Iran; Department of Corporate Economy, Masaryk University, Brno, 602 00, Czech Republic",2021.0,Journal of Computational Design and Engineering,Oxford University Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104053632&doi=10.1093%2fjcde%2fqwab007&partnerID=40&md5=92b3281e6f8f475b74b9bf41cb9565e8,10.1093/jcde/qwab007,20230520-160000,20230521-044735,"['di-anfis:', 'an', 'integrated', 'blockchain-iot-big', 'data-enabled', 'framework', 'for', 'evaluating', 'service', 'supply', 'chain', 'performance']",False,20230521-205332,,,,
379,scopus,Diaspore: Diagnosing Performance Interference in Apache Spark,"Apache Spark is being increasingly used to execute big data applications on cluster computing platforms. To increase system utilization, cluster operators often configure their clusters such that multiple co-located applications can simultaneously share the resources of a cluster node. With resource sharing, applications can compete with each other for shared node resources thereby interfering with each other's performance. Many Spark applications take a long time to execute. Performance interference from other applications can thus cause a Spark application to fail or take even longer time to execute thereby wasting cluster resources and frustrating users. This motivates the need for an automated technique that can detect interference quickly and also diagnose the root cause of the interference to facilitate mitigation of the problem. Most existing approaches are not designed to offer quick interference detection and diagnosis. For example, they typically require extensive training data for every application of interest under various possible input data sizes and resource allocations. In this paper, we systematically investigate the design of a Machine Learning (ML) based technique that addresses this open problem. We implement a tool called Diaspore that integrates our findings. We evaluate the tool with a diverse set of 13 Spark applications executing on a real cluster. Experimental results show that Diaspore requires only small scale training data, i.e., executions under small input sizes and resource allocations. Furthermore, our results show that the tool can offer accurate predictions for applications not present in the training data. Consequently, Diaspore reduces the training time needed to offer predictions. Finally, the feature engineering underlying Diaspore ensures that the tool can detect and diagnose interference quickly in an online manner by sampling only a small fraction of a long running application's execution. This can allow cluster operators to mitigate interference in an agile manner. © 2013 IEEE.",big data; Interference detection; machine learning,"Shah S., Amannejad Y., Krishnamurthy D.","Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada; Mathematics and Computing Department, Mount Royal University, Calgary, AB, Canada",2021.0,IEEE Access,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111066601&doi=10.1109%2fACCESS.2021.3098426&partnerID=40&md5=0905bdc634f8c87626b85bf55de03386,10.1109/ACCESS.2021.3098426,20230520-160000,20230521-044735,"['diaspore:', 'diagnosing', 'performance', 'interference', 'in', 'apache', 'spark']",True,20230521-205332,,,,
380,scopus,Information modeling for cyber-physical production system based on digital twin and AutomationML,"Production systems play an important role in intelligent manufacturing. A large number of manufacturing resources are designed and developed with virtual (digital) ones, which will be associated with the physical ones throughout their lifecycle. With the recent emergence of information and communications technologies (ICTs), such as internet of things, big data, virtual reality, artificial intelligence, and 5G, the interconnection and interaction between physical resources and virtual ones become possible in production systems. Digital twin (DT) shows great potential to realize the cyber-physical production system (CPPS) in the era of Industry 4.0. In this paper, we present our vision on integrating various physical resources into CPPS via DT and AutomationML. To elaborate on how to apply ICTs, this paper firstly explores a generic architecture of CPPS based on DT. DT is a virtual and authoritative representation of physical manufacturing resource, since DT includes various models and manufacturing big data of resource. The proposed architecture is illustrated in detail as follows: (1) physical layer, (2) network layer, (3) virtual layer, and (4) application layer. A case of expert fault diagnose for aircraft engine is presented using the proposed information fusion in the architecture. Secondly, this paper proposes an approach of information modeling for CPPS based on AutomationML. Various manufacturing services can be encapsulated and defined in the standardized format (AutomationML), and then the corresponding virtual manufacturing resources (DTs) will be integrated into CPPS. Finally, this paper describes a case of information modeling for blisk machining and demonstrates the modeling approach in real-life scenarios for support manufacturing resource sharing via DT. Furthermore, the conclusion and further work is briefly summarized. © 2020, Springer-Verlag London Ltd., part of Springer Nature.",AutomationML; Digital twin; Information modeling; Intelligent manufacturing; Production system,"Zhang H., Yan Q., Wen Z.","School of Aeronautical Engineering, Zhengzhou University of Aeronautics, Zhengzhou, 450015, China; School of Management Engineering, Zhengzhou University of Aeronautics, Zhengzhou, 450015, China",2020.0,International Journal of Advanced Manufacturing Technology,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081887346&doi=10.1007%2fs00170-020-05056-9&partnerID=40&md5=5cbee16d340ef0f59f2891ffa48117fe,10.1007/s00170-020-05056-9,20230520-160000,20230521-044735,"['information', 'modeling', 'for', 'cyber-physical', 'production', 'system', 'based', 'on', 'digital', 'twin', 'and', 'automationml']",False,20230521-205332,,,,
381,scopus,Towards Prediction of Security Attacks on Software Defined Networks: A Big Data Analytic Approach,"Cyber-physical systems (CPS) tightly integrate physical and computing processes by monitoring and control data interacting between them via underlying networks. Software Defined Network (SDN) Technology has increasingly become essential in many advanced computer networks, including those in modern CPS, to provide flexible and agile network development. Despite many benefits that SDN offers, malicious attacks that can eventually prevent network services are unavoidable. Among the most predominant attacks on SDN controller layer, Link Discovery Attack and ARP (Address Resolution Protocol) Spoofing Attack are fundamental in that they are the gateways of many other SDN threats and attacks. To defend these attacks, most existing techniques either rely on relatively complex data validation techniques or use thresholds that can be subjective and unable to detect more than one type of attacks at a time if one deciding factor is used. While Big data technology, particularly machine learning, has been widely used for intrusion/anomaly detection, little has been done in SDN. This paper explores how well this technology can be used to predict these SDN attacks. By employing typical machine learning algorithms on simulated data of routing in SDN when attacks occur, preliminary results, obtained from four machine learning models, show the average area under ROC curve of over 96% and 92% for sample size 50,970 (12 switches) and 60,000 (20 switches), respectively. Further experiments show near-linear scaling in training time for the best performing algorithm when sample size grows up to 100,000. © 2018 IEEE.",ARP Spoofing attack; Data Analytic Applications; Link Discovery attack; Machine Learning; SDN-specific security; Software-Defined Networking,"Unal E., Sen-Baidya S., Hewett R.","Department of Computer Science, Texas Tech University, Lubbock, TX, United States",2019.0,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062638917&doi=10.1109%2fBigData.2018.8622524&partnerID=40&md5=6cdf78325f66a42ccafa8373387fd11c,10.1109/BigData.2018.8622524,20230520-160000,20230521-044735,"['towards', 'prediction', 'of', 'security', 'attacks', 'on', 'software', 'defined', 'networks:', 'a', 'big', 'data', 'analytic', 'approach']",True,20230521-205332,,,,
382,scopus,Sidelobe coherency recovery technique of interpulse diversity based on inverse filtering,"Transmitting the pulse-to-pulse agile waveforms will break up the sidelobe coherency of impulse responses, which makes the static clutter fail to be completely suppressed, and has a negative impact on radar detection. In this paper, inspired by inverse filtering, we propose an effective method for designing pulse-compression filters that recover the sidelobe coherency of the agile waveforms. By selecting an appropriate window function in the frequency-domain, the impulse responses can be all identical while achieving marked sidelobe level improvement. Furthermore, we analyse the echoes of targets with different speeds and point out the situation which would happen in modern radar application. Simulations are conducted to verify the effectiveness of this method. © 2020 IEEE.",Clutter suppression; Interpulse diversity; Inverse filtering; Low sidelobe level; Sidelobe coherency recovery,"Ge Q., Zhao D., Yao Y., Wu G.","Nanjing Research Institute of Electronic Technology, Nanjing, China",2020.0,"Proceedings of 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence, ICIBA 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099294567&doi=10.1109%2fICIBA50161.2020.9277065&partnerID=40&md5=0bee6a5be854da892551cdfc3f93a04b,10.1109/ICIBA50161.2020.9277065,20230520-160000,20230521-044735,"['sidelobe', 'coherency', 'recovery', 'technique', 'of', 'interpulse', 'diversity', 'based', 'on', 'inverse', 'filtering']",True,20230521-205332,,,,
383,scopus,A Way of Students' Ability Cultivation of 'Five-one' for Software Engineering Major under Background of New Engineering,"Based on the individualized development of students for software engineering major under background of new engineering education, a possible way of students' ability cultivation of 'Five-one' is put forward. As a case study of Anhui Sanlian University, from the three levels of interest and hobby, practical ability, and scientific research expansion to construct of the framework of 'Five-one' on students' ability cultivation, and good results on implementation are achieved. Finally, further work is expected in the future. Firstly, a sustainable agile curriculum selecting system should be developed soon. Secondly, a platform for innovative practice should be established based on Outcomes-Based Education (OBE) by the form of school-enterprise cooperation. © 2020 IEEE.",ability cultivatio; agile; Five-one; new engineering; Outcomes-Based Education(OBE); software engineering,"Yu J., Mei Y., Zhang J., Zhang D., Chen Y., Zhu C., Wu N., Zhu L.","Anhui Sanlian University, College of Computer Engineering, Hefei, China",2020.0,"Proceedings - 2020 International Conference on Big Data and Informatization Education, ICBDIE 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092370200&doi=10.1109%2fICBDIE50010.2020.00047&partnerID=40&md5=bb0d61fbea84593abc0ce35916ea34a8,10.1109/ICBDIE50010.2020.00047,20230520-160000,20230521-044735,"['a', 'way', 'of', ""students'"", 'ability', 'cultivation', 'of', ""'five-one'"", 'for', 'software', 'engineering', 'major', 'under', 'background', 'of', 'new', 'engineering']",True,20230521-205332,,,,
384,scopus,“Hacking marketing”: how do firms develop marketers' expertise and practices in a digital era?,"Purpose: Digital technologies, digitalised consumers and the torrent of customer data have been transforming marketing practice. In discussing such trends, existing research has either focussed on the skills marketers need or broad-based approaches such as agile methods but has given less consideration to just how such skills or approaches might be developed and used in marketers' day-to-day activities and in the organisation of marketing in the firm. This is what the authors address in this paper. Design/methodology/approach: This paper adopts an in-depth case study approach to examine an exemplary digital enterprise in transformation of their digital marketing. The insights were gathered from 25 interviews, netnography and document analysis of the case organisation in addition to 10 interviews with independent experts. Findings: Drawing on practice-oriented approach, the authors show how organisations respond to the emerging trends of digital consumers and big data by taking a ‘hacking marketing’ approach and developing novel marketing expertise at disciplinary boundaries. The authors put forward three sets of practices that enable and shape the hacking marketing approach. These include spanning the expertise boundary, making value measurable and experimenting through which their adaptive, iterative and multidisciplinary work occurs. This explains how managing digital consumers and big data is not within the realm of information technology (IT) functions but marketing and how marketing professionals are changing their practice and moving their disciplinary boundaries. Practical implications: This study offers practical contributions for firms in terms of identifying new work practices and expertise that marketing specialists need in managing digital platforms, digitalised consumers and big data. This study’s results show that enterprises need to design and implement strong training programmes to prepare their marketing workforce in adopting experimentations of agile approach and data-driven decision making. In addition, Marketing education should be changed so that programmes consider a review of their courses and include the novel marketing models and approaches into their curriculum. Originality/value: This study contributes to the nascent discussions by unpacking how enterprises can develop new marketing expertise and practices beyond skillsets and how such practices form new hacking marketing approach which addresses the problem of the inability of the conventional marketing approach to show its value within the firm. © 2023, Emerald Publishing Limited.",Digital marketing; Digital organisation; Digitalised consumers; Expertise; Hacking; Occupations; Practice,"Hafezieh N., Pollock N., Ryan A.","School of Business and Management, Royal Holloway University of London, Egham, United Kingdom; Business School, The University of Edinburgh, Edinburgh, United Kingdom; Kemmy Business School, University of Limerick, Limerick, Ireland",2023.0,Journal of Enterprise Information Management,Emerald Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147450405&doi=10.1108%2fJEIM-12-2021-0530&partnerID=40&md5=42d3d2bce95a0eb14a0bbed64b192128,10.1108/JEIM-12-2021-0530,20230520-160000,20230521-044735,"['“hacking', 'marketing”:', 'how', 'do', 'firms', 'develop', ""marketers'"", 'expertise', 'and', 'practices', 'in', 'a', 'digital', 'era?']",False,20230521-205332,,,,
385,scopus,Mission Replanning for Multiple Agile Earth Observation Satellites Based on Cloud Coverage Forecasting,"Recent decades have witnessed a tremendous growth in the number of Earth observation satellites (EOSs), which presents a huge challenge for mission planning. For the EOSs with optical sensors particularly, the observation mission is significantly influenced by the uncertainty of cloud coverage, which has been identified as the most dominant factor for the invalidation of remote sensing images. To overcome this uncertainty, uncertainty programming methods, namely, chance constraint programming (CCP), stochastic expectation model, and robust optimization, are put forth. Despite their success, these approaches are limited in that they simplified the complex cloud coverage uncertainty, which may be different from the true cloud conditions, and they did not take the true cloud information into consideration. Motivated by these recent trends toward Big Data of satellite cloud images and machine learning for spatiotemporal prediction, this article explores a dynamic replanning scheme for multiple EOSs based on cloud forecasting. Specifically, we propose a new approach mainly in the following three steps: first, proactive scheduling based on a CCP is implemented and uploaded via ground control; second, cloud forecasting can be continuously conducted relying on the predictive recurrent neural network and the latest satellite cloud image; and third, mission replanning can be conducted according to the initial schedule and relatively accurate cloud information. Simulation results show that the cloud forecasting method is effective, and the replanning approach presents highly efficient and accurate scheduling results. © 2008-2012 IEEE.",Agile Earth observation satellite (AEOS); artificial neural network; cloud forecasting; mission replanning; uncertainty programming,"Gu Y., Han C., Chen Y., Xing W.W.","School of Astronautics, Beihang University, Beijing, China; School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China",2022.0,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121842843&doi=10.1109%2fJSTARS.2021.3135529&partnerID=40&md5=b461ed4a45f32b6c834c758780ea079e,10.1109/JSTARS.2021.3135529,20230520-160000,20230521-044735,"['mission', 'replanning', 'for', 'multiple', 'agile', 'earth', 'observation', 'satellites', 'based', 'on', 'cloud', 'coverage', 'forecasting']",True,20230521-205332,,,,
386,scopus,Using Big Data Analytics to Create a Predictive Model for Joint Strike Fighter,"The amount of information needed to acquire knowledge on today's acquisition systems is growing exponentially due to more complex, higher resolution, software-intensive acquisition systems that need to operate in System-of-Systems (SoS), Family-of-Systems (FoS), Joint, and Coalition environments. Unfortunately, the tools and methods necessary to rapidly collect, aggregate, and analyze this information have not evolved as a whole in conjunction with this increased system complexity and, therefore, has made analysis and evaluation increasingly deficient and ineffective. The Test Resource Management Center's (TRMC's) vision is to build a DoD test and evaluation (TE) knowledge management (KM) and analysis capability that leverages commercial big data analysis and cloud computing technologies to improve evaluation quality and reduce decision-making time. An evaluation revolution, starting with the Joint Strike Fighter (JSF) program, is underway to ensure the TE community can support the demands of next-generation weapon systems.The true product of TE is knowledge ascertained through the collection of information about a system or item under test. However, the TE community's ability to provide this knowledge is hampered by more complex systems, more complex environments, and the need to be more agile in support of strategic initiatives, such as agile acquisition and the 3rd Offset Strategy. This increased complexity and need for speed cause delayed analysis and problems that go undetected during TE. The primary reason for these shortfalls is antiquated tools and processes that make data hard to locate, aggregate, and convert into knowledge. In short, DoD has not evolved its evaluation infrastructure as its weapon systems have evolved.Conversely, commercial entities, such as medical observation and diagnosis, electric power distribution, retail, and industrial manufacturing, have embraced agility in their methodologies while modernizing analytics capabilities to keep up with the massive influx of data. Raw physical sensors could provide data, higher-quality image or video cameras, radio frequency identification (RFID) devices, faster data collectors, more detailed point-of-sale information or digitized records, and ultimately is providing more data to analysts in size and complexity than ever before. As more data has become available, an interrelated phenomenon is the desire of analysts to ask more detailed questions about their consumers and their business infrastructure. To drive the process of implementing big data analytics, businesses have begun establishing analytics centers which either take pre-defined business cases and apply methods to address them or implement existing knowledge within the data architecture to create a higher level of awareness to business groups or the company at-large. To meet these demands, data storage and computation architectures have become more sophisticated, dozens of technologies were developed for large-scale processing (such as Apache Hadoop or GreenPlum), and streaming architectures which allow data to be processed and actioned on in real-time as it is collected have become commonplace. The net result of these commercial best practices is a solid foundation for the DoD to transform how it uses data to achieve faster, better, and smarter decisions throughout the acquisition lifecycle. © 2018 IEEE.",Big Data; Cloud Computing; Data Analytics; Data Management; Department of Defense; Knowledge Management; Predictive Maintainance; Test and Evaluation; Virtualization,"Norman R., Bolin J., Powell E.T., Amin S., Nacker J.","Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA, United States; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA, United States",2019.0,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062614522&doi=10.1109%2fBigData.2018.8622388&partnerID=40&md5=fa3bbbd2c0b848274b26be8ee5dd159a,10.1109/BigData.2018.8622388,20230520-160000,20230521-044735,"['using', 'big', 'data', 'analytics', 'to', 'create', 'a', 'predictive', 'model', 'for', 'joint', 'strike', 'fighter']",True,20230521-205332,,,,
387,scopus,Digital contact tracing based on a graph database algorithm for emergency management during the COVID-19 epidemic: Case study,"Background: The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. Objective: Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. Methods: A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. Results: An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government’s big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. Conclusions: During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing. © Zijun Mao, Hong Yao, Qi Zou, Weiting Zhang, Ying Dong.",Big data; China; COVID-19; Digital contact tracing; Emergency management; Graph database; Visualization,"Mao Z., Yao H., Zou Q., Zhang W., Dong Y.","College of Public Administration, Huazhong University of Science and Technology, Wuhan, China; Non-traditional Security Research Center, Huazhong University of Science and Technology, Wuhan, China; School of Law and Humanities, China University of Mining and Technology, Beijing, China",2021.0,JMIR mHealth and uHealth,JMIR Publications Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100358068&doi=10.2196%2f26836&partnerID=40&md5=ce1a030c006754d8bd9fed722d25d55f,10.2196/26836,20230520-160000,20230521-044735,"['digital', 'contact', 'tracing', 'based', 'on', 'a', 'graph', 'database', 'algorithm', 'for', 'emergency', 'management', 'during', 'the', 'covid-19', 'epidemic:', 'case', 'study']",False,20230521-205332,,,,
388,scopus,How big data analytics can help future regulatory issues in carbon capture and sequestration CCS projects,"In this age of data, there is a significant need for tracking and prediction of non-compliance of rules & regulations in various industries including the oil & gas sector. In this paper, we will be reviewing some of the anticipated regulatory issues in commercial implementations of carbon capture & sequestration (CCS) and discuss how machine learning and big data analytics can diminish future non-compliance incidents. With the rising awareness of advanced data-driven technologies such as ""Big Data Analytics"" and ""Machine Learning"", a contemporary approach to regulation and compliance is developing. This emerging approach, called ""Algorithmic Regulation"", defines an alternative framework for systematic collection of data (real-time or near real-time) and continuous generation of knowledge through intelligent computational algorithms in order to regulate a domain of activities. In this study, we will look at some of the major data management challenges in the pilot CCS operations with regards to rules and regulations. We will then discuss how an algorithmic regulatory framework can help in conducting CCS operations in a manner that are compliant with environmental, safety and health policies and regulations. Field operators collect a lot of data which needs to be formatted and modelled in a fashion acceptable to understand the operator's compliance with regulation. Generally, such compliance qualification criteria are verified using human intellect and basic querying software. In other industries, the idea of converting rules & regulations in a format understandable by machines is gaining momentum and great strides have been taken. The technological progresses made possible by data-driven analytical techniques can create a paradigm shift in the way rules and regulations are designed and implemented. Large-scale deployment of CCS projects is bound to bring with it a number of regulatory issues, making it a necessity to proactively explore and address the anticipated issues. These technologies can equip regulated entities as well as regulators with advanced tools for managing complexity in CCS projects. These improved solutions will help companies to better meet the regulatory data collection, reporting and governance requirements in large scale CCS operations. This paper looks into advanced data management and modeling techniques like ""algorithmic regulations"" to increase compliance in carbon capture and sequestration projects. The concept of handling rules and regulations in the form of big data will change the outlook and compliance management will become increasingly more agile and responsive. © 2019, Society of Petroleum Engineers",Artificial Intelligence; Carbon Capture; Machine Learning; Regulations & Policy; Sequestration,"Balaji K., Zhou Z., Rabiei M.","University of North Dakota, United States",2019.0,SPE Western Regional Meeting Proceedings,Society of Petroleum Engineers (SPE),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066309646&doi=10.2118%2f195284-ms&partnerID=40&md5=a3dc9e3fff05ff9e7440eac70ed72f9c,10.2118/195284-ms,20230520-160000,20230521-044735,"['how', 'big', 'data', 'analytics', 'can', 'help', 'future', 'regulatory', 'issues', 'in', 'carbon', 'capture', 'and', 'sequestration', 'ccs', 'projects']",False,20230521-205332,,,,
389,scopus,"The adoption of Design Thinking, Agile Software Development and Co-creation concepts A case study of Digital Banking innovation","Acceleration of technology, especially the mobile internet, causes changes all aspects of human life, including in the banking sector. New emerging technology such as Artificial Intelligence, Blockchain, Big Data, and Cloud computing change the business and operation of the bank. The bank's services have become more personalized, furthermore change customers' lifestyles. Banks are competing to create innovations and breakthroughs to create added value and building a digital ecosystem with fintech and big tech companies in the era of sharing economy. This case study explores the process of creating digital innovation in banking institutions by focusing on adopting design thinking (DT), agile software development (ASD), and co-creation concepts for building digital banking platforms. The case study involved IT executives from four banks in Indonesia. Data were taken through semi-structured interviews and analyzed using NVIVO12. The implication of this research is to accelerate the process of digital banking innovation and produce high-quality digital banking platforms in terms of features and technology. © 2021 IEEE.",Agile Software Development; Co-creation; Design Thinking; Digital Banking; Digital Innovation,"Indriasari E., Prabowo H., Gaol F.L., Purwandari B.","Bina Nusantara University, Computer Science, Jakarta, Indonesia; Universitas Indonesia, Jakarta, Indonesia",2021.0,"2021 International Conference on Platform Technology and Service, PlatCon 2021 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124106100&doi=10.1109%2fPlatCon53246.2021.9680763&partnerID=40&md5=8cc14b4829110a62de9d93e27e9905d0,10.1109/PlatCon53246.2021.9680763,20230520-160000,20230521-044735,"['the', 'adoption', 'of', 'design', 'thinking,', 'agile', 'software', 'development', 'and', 'co-creation', 'concepts', 'a', 'case', 'study', 'of', 'digital', 'banking', 'innovation']",True,20230521-205332,,,,
390,scopus,A systematic literature review of improved knowledge management in agile software development,"Agile Software Development (ASD) is an adaptive software development approach that easily adapts to changing software requirements. It offers an advantage in time management but has disadvantages such as lack of software documentation and knowledge management. This research aims to understand more about research development in the knowledge management improvisation in Agile Software Development by collecting various themes of improved area and method used. To achieve this goal, 226 articles written in 2009-2018 are screened by using Kitchenham method to produce 15 best articles. This systematic literature review (SLR) results in a summary of improvements in knowledge management. The summary includes various approaches of several themes such as documentation, tools or technology, and others. The areas that need improvement are tools for supporting communication and documentation. The suggested improvement that has been proposed by researcher focuses mostly on artifact documentation, decision making, effort estimation and tools. In these studies, research question can be identified, analyzed, and answered. © 2019 Association for Computing Machinery.",Agile software development; Improvement; Knowledge management; Systematic literature review,"Hafidz M.U.A., Sensuse D.I.","Faculty of Computer Science, Universitas Indonesia, Indonesia",2019.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063593728&doi=10.1145%2f3305160.3305192&partnerID=40&md5=aeec2ad4593f835a7f039c858f9a87d9,10.1145/3305160.3305192,20230520-160000,20230521-044735,"['a', 'systematic', 'literature', 'review', 'of', 'improved', 'knowledge', 'management', 'in', 'agile', 'software', 'development']",False,20230521-205332,,,,
391,scopus,Combining terrier with apache spark to create agile experimental information retrieval pipelines,"Experimentation using IR systems has traditionally been a procedural and laborious process. Queries must be run on an index, with any parameters of the retrieval models suitably tuned. With the advent of learning-to-rank, such experimental processes (including the appropriate folding of queries to achieve cross-fold validation) have resulted in complicated experimental designs and hence scripting. At the same time, machine learning platforms such as Scikit Learn and Apache Spark have pioneered the notion of an experimental pipeline , which naturally allows a supervised classification experiment to be expressed a series of stages, which can be learned or transformed. In this demonstration, we detail Terrier-Spark, a recent adaptation to the Terrier Information Retrieval platform which permits it to be used within the experimental pipelines of Spark. We argue that this (1) provides an agile experimental platform for information retrieval, comparable to that enjoyed by other branches of data science; (2) aids research reproducibility in information retrieval by facilitating easily-distributable notebooks containing conducted experiments; and (3) facilitates the teaching of information retrieval experiments in educational environments. © 2018 Author.",Apache spark; Jupyter notebooks; Terrier ir platform,Macdonald C.,"University of Glasgow, United Kingdom",2018.0,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018","Association for Computing Machinery, Inc",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051500638&doi=10.1145%2f3209978.3210174&partnerID=40&md5=677bf14abb8dbdbd1e578896882564f7,10.1145/3209978.3210174,20230520-160000,20230521-044735,"['combining', 'terrier', 'with', 'apache', 'spark', 'to', 'create', 'agile', 'experimental', 'information', 'retrieval', 'pipelines']",False,20230521-205332,,,,
392,scopus,A comparison of computational thinking approaches in hci-seo design: Implications to teaching and learning ste(a)m,"Search engine optimization has often been through tagging (metadata descriptions) and appropriate placement of these metadata in inherent document structures e.g. XML. This paper presents a complement whereby the structure and information design based on design thinking and computational thinking results in more effective scoping of user requirements and leaner, agile design. This form of human-computer interaction-search engine optimization is much used in successful e-commerce websites due to Data Science. Comparison between the standard 4 CT aspects approach and Brennan and Resnick’s 3 CT aspects approach and implications to STE(A)M teaching and learning are investigated through a meta-analysis of two Project Management course assignments. Significance of the paper is direct link and greater specificity between design thinking, computational thinking, human-computer interaction, Project Management and search engine optimization within an entrepreneurial project management framework. © 2020, The Education University of Hong Kong. All rights reserved.",Computational thinking approaches; Design optimization; Design thinking; Higher education; STE(A)M,Lee C.-S.,"Sunway University, Malaysia",2020.0,Proceedings of International Conference on Computational Thinking Education,The Education University of Hong Kong,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103848119&partnerID=40&md5=06ccbfba378e69000a0cb8243de4a689,,20230520-160000,20230521-044735,"['a', 'comparison', 'of', 'computational', 'thinking', 'approaches', 'in', 'hci-seo', 'design:', 'implications', 'to', 'teaching', 'and', 'learning', 'ste(a)m']",False,20230521-205332,,,,
393,scopus,Towards Agile Integration: Specification-based Data Alignment,"Utilizing data sets from multiple domains is a common procedure in scientific research. For example, research on the performance of buildings may require data from multiple sources that lack a singular standard for data reporting. The Building Management System might report data at regular 5minute intervals, whereas an air-quality sensor might capture values only when there has been significant change from the previous value. Many systems exist to help integrate multiple data sources into a single system or interface. However, such systems do not necessarily make it easy to modify an integration plan, for example, to accommodate data exploration, new and changing data sets or shifts in the questions of interest. We propose an agile data-integration system to enable quick and adaptive analysis across many data sets, concentrating initially on the data alignment step: combining data values from multiple time-series based data sets whose time schedules. To this end, we adopt a Domain Specific Language approach where we construct a domain model for alignment, provide a specification language for describing alignments in the model and implement an interpreter for specification in that language. Our implementation exploits a rank-based join in SQL that produces faster alignment times than the commonly suggested method of aligning data sets in a database. We present experiments to demonstrate the advantage of our method and exploit data properties for optimization. © 2020 IEEE.",data alignment; data integration; time series,"Giossi C., Maier D., Tufte K., Gall E., Barnes M.","Dept. of Computer Science, United States; Dept. of Mechanical Engineering, Portland State University, Portland, OR, United States",2020.0,"Proceedings - 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science, IRI 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092195480&doi=10.1109%2fIRI49571.2020.00055&partnerID=40&md5=3909b610ac1494065d951a7114d23aba,10.1109/IRI49571.2020.00055,20230520-160000,20230521-044735,"['towards', 'agile', 'integration:', 'specification-based', 'data', 'alignment']",True,20230521-205332,,,,
394,scopus,Failure Prediction Approach in Agile Software Development,"Software failure prediction is an important activity during agile software development as it can help managers to identify the failure modules. Thus, it can reduce the test time, cost, and assign testing resources efficiently. RapidMiner Studio9.4 has been used to perform all the required steps from preparing the primary data to visualizing the results and evaluating the outputs, as well as verifying and improving them in a unified environment. Two datasets are used in this work. The results for the first one indicate that the percentage of failure to predict the time used in the test for all 181 rows, for all test times recorded, is 3% for mean time between failures (MTBF). SVM achieved a 97% success in predicting compared to previous work whose results indicated that the use of administrative delay time (ADT) achieved a statistically significant overall success rate of 93.5%. At the same time, the second dataset result indicates that the percentage of failure to predict the time used is 1.5% for MTBF; SVM achieved 98.5% prediction. Copyright © 2022, IGI Global.",Agile; Big Data; Correlation Coefficient; Decision Making; Software Failure; Software Testing; Support Vector Machine,"Alajaleen B., Alhroob A.","Isra University, Jordan",2022.0,International Journal of Software Innovation,Taru Publications,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149486929&doi=10.4018%2fIJSI.292025&partnerID=40&md5=0c09be7c991539ce160ccc0bf67a3b89,10.4018/IJSI.292025,20230520-160000,20230521-044735,"['failure', 'prediction', 'approach', 'in', 'agile', 'software', 'development']",False,20230521-205332,,,,
395,scopus,Harnessing the Power of the Internet of Things (IoT) to Achieve an Agile Business Education Model: A Visionary Paper,"The emergence of artificial intelligence, big data, and the Internet of Things (IoT) has shifted human-human, human-machine, and machine-machine interaction to a new level. This shift is affecting all aspects of society's behavior toward the adoption of technology. One important pillar of society that is especially impacted by this radical change is that of education. The advancement of new technologies as well as the occurrence of unexpected global events has forced education systems in many countries to look differently at traditional educational issues and work toward becoming a more agile education system. This means being responsive to any unpredicted changes that may occur in the education environment. Indeed, the agility of business schools and technological adaptability is one of the standards required by program accreditation organizations (i.e., AACSB). This paper discusses the application of IoT in business education, focusing on the opportunities, challenges, and paths forward this presents. © 2021 IEEE.",Business Education; Education Agility; Higher Education; IoT,"Qasim A., Refae G.A.E., Eletter S., Al-Chahadah A.R.","Al Ain University, College of Business, Abu Dhabi, United Arab Emirates; Alzaytoonah University, College of Business, Amman, Jordan",2021.0,"2021 8th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125636345&doi=10.1109%2fIOTSMS53705.2021.9704939&partnerID=40&md5=47080f4ea9660b459b8753a0b3b677b3,10.1109/IOTSMS53705.2021.9704939,20230520-160000,20230521-044735,"['harnessing', 'the', 'power', 'of', 'the', 'internet', 'of', 'things', '(iot)', 'to', 'achieve', 'an', 'agile', 'business', 'education', 'model:', 'a', 'visionary', 'paper']",True,20230521-205332,,,,
396,scopus,"Utilizing high-performance embedded computing, agile condor, for intelligent processing: An artificial intelligence platform for remotely piloted aircraft","A newly invented, high performance, pod-based computer architecture, called Agile Condor (patent pending), has been designed and developed. Agile Condor is supporting autonomous operations by providing a platform for the innovative use of artificial intelligence, machine learning, and decision making algorithms upstream, near the information source, where the data is collected. In September 2016, experimental tests successfully demonstrated the ability to implement advanced neural networks and deep learning techniques on Agile Condor. We continue to use this new processing architecture, algorithms and bio-inspired computing methods to demonstrate existing, refine emerging and invent new artificial intelligence techniques that are highly applicable and needed for sensor platforms. For the first time ever, and in real-time, the system demonstrated: image processing, video processing and pattern recognition through the use of deep convolutional neural networks. Because of Agile Condor's modular architecture and performance characteristics, the system is providing flexible computational resources that will continue to bring new artificial intelligence (AI) capabilities closer to sensor platforms. © 2017 IEEE.",Artificial intelligence platform; autonomous operations; big data; high-performance embedded computing; information processing; machine learning platform; massive analytics,"Barnell M., Raymond C., Isereau D., Capraro C., Cote E.","Air Force Research Lab (AFRL), Information Direct., Rome, NY  13441, United States; SRC, Inc., North Syracuse, NY  13212, United States",2018.0,"2017 Intelligent Systems Conference, IntelliSys 2017",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050856170&doi=10.1109%2fIntelliSys.2017.8324277&partnerID=40&md5=819312551fc8feea92bea8b0cc53bf92,10.1109/IntelliSys.2017.8324277,20230520-160000,20230521-044735,"['utilizing', 'high-performance', 'embedded', 'computing,', 'agile', 'condor,', 'for', 'intelligent', 'processing:', 'an', 'artificial', 'intelligence', 'platform', 'for', 'remotely', 'piloted', 'aircraft']",False,20230521-205332,,,,
397,scopus,Dealing with the big data - The challenges for modern mission monitoring and reporting,"EUMETSAT maintains a combination of proprietary and commercial-off-the-shelf software, along with supporting infrastructure in order to perform monitoring and reporting of mission performance. The monitoring and reporting falls into three main categories-periodic system monitoring, on-event log file monitoring, and closed loop end-to-end data flow monitoring, which is used not only for near-real time monitoring but also as a basis for operational performance reporting of Key Performance Indicators (KPIs). This system has grown over the past 15 years from processing less than a thousand log file entries per day up to a projected 80 million entries with the advent of upcoming Satellite Programmes-EUMETSAT Polar System (EPS) Second Generation, Jason-CS/Sentinel-6 and Meteosat Third Generation. The combined amount of data from these programmes falls into the big data category and agile solutions must be found in order to provide sufficient processing, storage, and retrieval capability. This paper explores the challenges and potential solutions of preparing for big data in the mission performance monitoring systems, including the software and technology stacks used, methods such as pre-processing data to allow quick access to KPIs, and an scalable infrastructure allowing for easy migration to more performant hardware through the use of virtualized environments. In recent years the technology stack as well as the architectural design for the proprietary monitoring and reporting tools have been evolved in readiness for big data. Storage of data is now performed using a Relational Database Management System, with a Java processing layer contained within a web server. The default method of event persistence is now based on Message Queue (MQ) technology, however other methods of persistence are available such as HTTP RESTful and legacy FTP to ensure compatibility. One major consideration for a big data system is the ability to aggregate data in order to report on KPIs. In order to facilitate this, reporting data is pre-processed and aggregated on a daily basis, meaning the underlying data does not need to be accessed for common reports. For ad-hoc style reporting, there is an option to run reports as a background task with a notification to the user upon completion. The reporting made available to the users through an intuitive web interface, including options to subscribe to report delivery via email. In terms of hardware, the platform used to support the mission performance monitoring has been upgraded as a matter of obsolescence replacement to a virtualized environment based on Hypervisors. While this current generation of hardware is only sufficient for the current missions, moving to a virtualized environment ensures that migration to more performance hardware can be performed easily and in a way that is largely transparent to the users. While scalability on the hardware level is therefore ensured, and the current software design and technology stack fulfils the current requirements and projected data sizing, there are still concerns regarding software performance in accessing such large amounts of information. Therefore alternative COTS solutions for the proprietary software are also being considered with a potential for hybrid solutions based on proven and reliable technologies. In addition, it is intended to re-analyse the overall approach for mission performance monitoring and reporting along with an industry and best-practice study to understand the most efficient and effective methods of meeting user needs for mission performance monitoring and reporting. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.",,Edwards T.,"European Organization for the Exploitation of Meteorological Satellites (EUMETSAT), Eumetsat-Allee 1, Darmstadt, 64295, Germany",2018.0,"15th International Conference on Space Operations, 2018","American Institute of Aeronautics and Astronautics Inc, AIAA",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066490890&doi=10.2514%2f6.2018-2507&partnerID=40&md5=30068e3cd950310603e89f93f8c07c6d,10.2514/6.2018-2507,20230520-160000,20230521-044735,"['dealing', 'with', 'the', 'big', 'data', '-', 'the', 'challenges', 'for', 'modern', 'mission', 'monitoring', 'and', 'reporting']",False,20230521-205332,,,,
398,scopus,Agility measurement of agile supply chain network based on complex network theory,"With the development of information technology, the supply chain has developed into a new stage of intelligent supply chain which is deeply integrated with the Internet and the Internet of Objects. In order to give full play to the characteristics of innovation, collaboration, win-win, openness and greenness in supply chain, and to build a smart supply chain system with big data support, network sharing and intelligent collaboration, the agility measurement of supply chain has become an urgent and important topic. This paper presents an agile metric based on complex network theory for agile supply chain network. Firstly, the mathematical expression of agile supply chain network and its agility measurement method are defined, and the constraints of complex network theory are also defined. Secondly, to facilitate the calculation of agility metrics, complex network theory is introduced into agile supply chain network. In addition, a large number of experiments have been designed and implemented to verify the accuracy of the proposed complex network theory in agile supply chain network measurement. At the same time, the agility of the supply chain network is measured, and its changing rules and optimization methods are summarized. The experimental results show that the proposed complex network theory can accurately measure the agility of agile supply chain network. The purpose of this paper is to provide a method to turn agile supply chain system into intelligent information system through mathematical modeling. © 2019 IEEE.",Agile supply chain network; Agility measurement; Complex network theory; Estimated value; Intelligent information system,"Yao Y., Li L.","Anhui Finance and Trade Vocational College, Hefei, China; School of Management Hefei University of Technology, Anhui Finance and Trade Vocational College, Hefei, China",2019.0,"Proceedings - 2019 International Conference on Intelligent Computing, Automation and Systems, ICICAS 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083427243&doi=10.1109%2fICICAS48597.2019.00163&partnerID=40&md5=a6f80f63aeb9b6c6d8a17d3b3452c44e,10.1109/ICICAS48597.2019.00163,20230520-160000,20230521-044735,"['agility', 'measurement', 'of', 'agile', 'supply', 'chain', 'network', 'based', 'on', 'complex', 'network', 'theory']",True,20230521-205332,,,,
399,scopus,What more than a hundred project groups reveal about teaching visualization,"Abstract: The growing number of students can be a challenge for teaching visualization lectures, supervision, evaluation, and grading. Moreover, designing visualization courses by matching the different experiences and skills of the students is a major goal in order to find a common solvable task for all of them. Particularly, the given task is important to follow a common project goal, to collaborate in small project groups, but also to further experience, learn, or extend programming skills. In this article, we survey our experiences from teaching 116 student project groups of 6 bachelor courses on information visualization with varying topics. Moreover, two teaching strategies were tried: 2 courses were held without lectures and assignments but with weekly scrum sessions (further denoted by TS1) and 4 courses were guided by weekly lectures and assignments (further denoted by TS2). A total number of 687 students took part in all of these 6 courses. Managing the ever growing number of students in computer and data science is a big challenge in these days, i.e., the students typically apply a design-based active learning scenario while being supported by weekly lectures, assignments, or scrum sessions. As a major outcome, we identified a regular supervision either by lectures and assignments or by regular scrum sessions as important due to the fact that the students were relatively unexperienced bachelor students with a wide range of programming skills, but nearly no visualization background. In this article, we explain different subsequent stages to successfully handle the upcoming problems and describe how much supervision was involved in the development of the visualization project. The project task description is given in a way that it has a minimal number of requirements but can be extended in many directions while most of the decisions are up to the students like programming languages, visualization approaches, or interaction techniques. Finally, we discuss the benefits and drawbacks of both teaching strategies. Graphic abstract: [Figure not available: see fulltext.]. © 2020, The Author(s).",Education; Information visualization; Interaction; Teaching,"Burch M., Melby E.","Eindhoven University of Technology, Eindhoven, Netherlands",2020.0,Journal of Visualization,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086864622&doi=10.1007%2fs12650-020-00659-6&partnerID=40&md5=2f11872c570920aef353c7a9e7ce1fe8,10.1007/s12650-020-00659-6,20230520-160000,20230521-044735,"['what', 'more', 'than', 'a', 'hundred', 'project', 'groups', 'reveal', 'about', 'teaching', 'visualization']",False,20230521-205332,,,,
400,scopus,Implementation of a Mobile Application: Sales Optimization in a Peruvian Company,"At present, companies in the retail sector seek to expand their markets in various ways, always seeking to sell their products to more and more customers, which is why they have opted for e-commerce. Selling and buying online is today essential in every company. Moreover, most businesses opt for a mobile application because most purchases are made from smartphones. Therefore, this application seeks to help customer loyalty by providing users with an interface that motivates them to buy. The progress of the application was based on five sprints which developed the user stories, prototypes were presented, which were used for surveys in which the dimensions were included, collecting important statistical data for the development and improvement of the application. In this research work, an application was designed using the Scrum methodology to carry out sales processes using mobile devices. Additionally, this work shows, as a result, optimal Technological prototyping in which the personalization of the sales process, attractive design, recommendations, and offers are rescued, and all of this seeks to retain users to convert them into clients. In the future, the use of augmented reality is contemplated, big data and the use of AI. © 2022 Seventh Sense Research Group®",E-commerce; Mobile application; Scrum; Sprint; Users,"Ligarda Motta J.R., Portales Ipanaque E.T., Cano Lengua M.A., Andrade-Arenas L.","Facultad de ingeniería, Universidad Tecnológica del Perú, Lima, Peru",2022.0,International Journal of Engineering Trends and Technology,Seventh Sense Research Group,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144958209&doi=10.14445%2f22315381%2fIJETT-V70I11P206&partnerID=40&md5=ce8ef54d442bdd282f2f3810f150cb0a,10.14445/22315381/IJETT-V70I11P206,20230520-160000,20230521-044735,"['implementation', 'of', 'a', 'mobile', 'application:', 'sales', 'optimization', 'in', 'a', 'peruvian', 'company']",False,20230521-205332,,,,
401,scopus,Digital project management in the era of digital transformation: Hybrid method,"Integrating digital into the DNA of their business model is an essential part of business success for companies across industries today. The digital transformation has become a critical management issue and requires new ways of managerial thinking. In this context, we address the specificity of digital projects compared to IT projects in general, to propose a specific project management method for digital projects while respecting the life cycle of IT projects. To do this, we adopt a methodology based on describing the digital projects characters as a type of IT projects, defining the existing methods and making a comparative study to propose a hybrid method that will be helpful for digital companies to conduct and succeed their digital projects. © 2018 Association for Computing Machinery.",Agile methodology; Digital project; Digital project management; Digital transformation; Hybrid methodology; IT project management; Project management; Project management method; Software project management; Waterfall methodology,"Hassani R., El Bouzekri El Idrissi Y., Abouabdellah A.","National School of Applied Sciences of Kenitra, Morocco",2018.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045395820&doi=10.1145%2f3178461.3178472&partnerID=40&md5=5d57de01991d6c94f8e2510f620ce559,10.1145/3178461.3178472,20230520-160000,20230521-044735,"['digital', 'project', 'management', 'in', 'the', 'era', 'of', 'digital', 'transformation:', 'hybrid', 'method']",False,20230521-205332,,,,
402,scopus,Structured Data for Product Performance Improvement,"Aftermarket reliability data is a cornerstone to understand the performance of one's products against requirements. A successful aftermarket data system goes beyond the basics of supplying reliability figures. Its attributes also include additional metrics for an effective alerting and reporting system to enable proactive response to aftermarket issues. While these system features are key, the implementation and maintenance methodology of the system is crucial to its success. This is because these systems involve big data. In the case presented, it is data which spans several years, for a variety of model numbers on a variety of aircraft platforms or applications. Each set of circumstances yields different reliability figures and associated metrics. With this big data, it is equally crucial to its success to have a methodology to address data integrity, the speed of data, and the portability of data. Our solution with this successful methodology of these features is called Structured Data.A good aftermarket data system is a backbone for any successful organization. A good system in the aerospace industry goes beyond ATA Spec 2000 [1] formatted data and standard reliability figures such as MTBUR (Mean Time Between Unscheduled Removal) and MTBF (Mean Time Between Failure). It is also beyond implementing a Failure Reporting and Corrective Action System (FRACAS). A comprehensive system in the aerospace industry includes several additional measures (i.e. frequency, severity, risk) to represent the Voice of the Customer. And with a built-in mechanism for proactive response to the data, the system can then be considered World-Class.While designing a system with these features is important, its success also hinges upon the methodology of implementation and maintenance. As stated earlier, aftermarket data is considered big data due to the volume of highly specific data. With this big data, it is critical to success to address data integrity, the speed of data, and the portability of data all within a user-friendly experience. For data integrity, do we trust the data? This takes on many forms from cross referencing input and output data to determining an accurate mixed fleet factor. For speed of data, do we have a system in place to handle the cadence of data efficiently? For portability, do we structure our data in such a way where we can be agile to serve potential changes to our system or new systems as our company evolves? For a user-friendly experience, can we structure the data for intuitive analysis for all stakeholders? Thus in the proposed system, all of these aspects of data integrity, the speed of data, the portability of data, and formatting the data per stakeholders are addressed. Our solution with this successful methodology of these features is called Structured Data.The benefits of this newly developed Structured Data extend beyond ATA Spec 2000 in which it is based. The data is structured in a dynamic and interactive environment. This environment includes intuitive analysis and a system of prioritization for corrective action. The key benefit of this Structured Data system is proactive response to aftermarket data analysis. © 2021 IEEE.",Big data; Data integrity Speed of data; FRACAS; MTBUR / MTBF; Natural Language Programming (NLP); Portability of data; Product performance; Reliability metrics; Voice of Customer,"Peter P., Parendo C.",Collins Aerospace,2021.0,Proceedings - Annual Reliability and Maintainability Symposium,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123058232&doi=10.1109%2fRAMS48097.2021.9605770&partnerID=40&md5=8675798f2ad156a13f18c7eb5e8279a8,10.1109/RAMS48097.2021.9605770,20230520-160000,20230521-044735,"['structured', 'data', 'for', 'product', 'performance', 'improvement']",True,20230521-205332,,,,
403,scopus,Modelling the relationship of digital technologies with lean and agile strategies,"As the world becomes globalised, companies fight for survival by connecting their in-house processes with external suppliers/customers. To remain competitive, companies must integrate innovative capabilities like ‘industry-4.0 technologies’ with their operation and supply chain (SC) strategies. The integration of various strategies has been investigated with the associated effect on performance; however, studies on how industry 4.0 technologies might support integrated strategies are still incipient. This work investigates the hierarchical relationships of ‘industry 4.0 technologies’ with lean and agile strategies. Adopting the ‘Interpretive Structural Modelling (ISM)’ technique to present a model depicting the linkage, the work also classifies the technologies and practices according to their ‘driving’ and ‘dependency’ powers. The findings revealed that the technologies have a high affinity to enable the implementation of lean and agile strategies. Among the nine technologies included in the study, ‘Cyber-Physical-System’, ‘Internet-of-Things’, ‘Cloud-Computing’, and ‘Big-Data-Analytics’ have the highest driving powers, signifying their higher affinity with the practices. Meanwhile, all the practices have a high enough affinity to be influenced by the technologies, except for a few (3/16 of lean and 2/9 of agile) that possess affinities too low to be driven by these technologies. The theoretical and managerial impacts of the research are also emphasised. © 2021 Kedge Business School.",agile SCM; digital technologies; industry 4.0; interpretive structural modelling; Lean SCM,"Raji I.O., Shevtshenko E., Rossi T., Strozzi F.","School of Industrial Engineering, Università Carlo Cattaneo – LIUC, Castellanza, Italy; Mechanical and Industrial Engineering, Tallinn University of Technology – TalTech, Tallinn, Estonia",2021.0,Supply Chain Forum,Taylor and Francis Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111704565&doi=10.1080%2f16258312.2021.1925583&partnerID=40&md5=d0494533ce058d830b60d579a6dbfde9,10.1080/16258312.2021.1925583,20230520-160000,20230521-044735,"['modelling', 'the', 'relationship', 'of', 'digital', 'technologies', 'with', 'lean', 'and', 'agile', 'strategies']",False,20230521-205332,,,,
404,scopus,Agile Lossless Compression Algorithm for Big Data of Solar Energy Harvesting Wireless Sensor Network,"Time series data are collected through most of the applications that permeate our lives today. Internet of Things (IoT) sensor data are generated through smart applications and stored in databases. Time series databases require huge storage spaces, as over time they consume a large amount of memory. In this paper, we propose an enhanced compression algorithm for time series data generated by IoT systems that monitor the production of electrical energy by solar panels. The best way to ensure that solar energy systems have high efficiency is to continuously monitor all electrical and environmental factors. However, this requires the collection of enormous quantities of data that can be used to detect defects in the generation of electric energy or in solar panels. As the data must be available for analysis, a lossless compression algorithm is needed. In addition, the compressed data must be in a format that can be queried to perform analysis operations dependent on speed; this means that the decompression of data should not be time-consuming. Our results showed the high speed of the compression process along with good compression rate (16.6%) after applying the proposed compression algorithm. © MYU K.K.",compressed time series data; lossless compression algorithm; solar energy; wireless sensor network,"El-Hageen H.M., Albalawi H., Alatwi A.M., Abd Elrahman W.R., Mohammed Faqeh S.T.","Electrical Engineering Department, Faculty of Engineering, University of Tabuk, P.O. Box 741, Tabuk, 71491, Saudi Arabia; Renewable Energy and Energy Efficiency Center (REEEC), University of Tabuk, P.O. Box 741, Tabuk, 71491, Saudi Arabia; Egyptian Atomic Energy Authority, P.O. Box 29, Naser City, Cairo, 11787, Egypt; Industrial Innovation and Robotic Center (IIRC), University of Tabuk, P.O. Box 741, Tabuk, 71491, Saudi Arabia; Mechanical Engineering Department, Faculty of Engineering, University of Tabuk, P.O. Box 741, Tabuk, 71491, Saudi Arabia",2022.0,Sensors and Materials,M Y U Scientific Publishing Division,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142781398&doi=10.18494%2fSAM4106&partnerID=40&md5=be9b1a4050793d5810b1ed9c9ad8120a,10.18494/SAM4106,20230520-160000,20230521-044735,"['agile', 'lossless', 'compression', 'algorithm', 'for', 'big', 'data', 'of', 'solar', 'energy', 'harvesting', 'wireless', 'sensor', 'network']",False,20230521-205332,,,,
405,scopus,Government open data portals: A measurement of data veracity coverage,"Open data initiative has been adopted by many countries worldwide due to the need for establishing agile open government and knowledge-based economy. As a result, we can witness an increasing amount of government open data shared on public government's portals that become sources of rich big data. While this scenario provides data transparency and eases accessibility for public data consumers, the quality aspect, or the veracity property (as commonly coined to big data) of open data is the topic of concerned. Not only poor quality data causes misleading results, the reputation of the government as an open data provider can also be negatively affected. Thus, to understand how the government's portals deal with the veracity aspect of their data, in this paper, we present the results of examining quality criteria imposed by selected government's data portals for their data contributors. In particular, we extract quality criteria from the open data policy of the government's data portals under study. The result shows that out of 108 portals, only 27% of the portals explicitly state their quality criteria in the policy, with varying coverage of quality criteria. The frequency of the identified 15 quality criteria shows the types of quality criteria that receive more (and less) attention by the open data portals based on their relative importance. We conclude with suggestions on the areas of further research and development in the government's open data. © 2019, Blue Eyes Intelligence Engineering and Sciences Publication. All rights reserved.",Data Veracity; Open data policy; Open data principles; Open government data; Quality criteria,"Sabri N.A.M., Emran N.A., Harum N.","Computational Intelligence Technologies (CIT), Center of Advanced Computing Technologies (CACT), Fakulti Teknologi Maklumat dan Komunikasi, Universiti Teknikal Malaysia (UTeM), Durian Tunggal, Melaka, 76100, Malaysia; Information Security Forensics and Computer Networking (INFORSNET), Center of Advanced Computing Technologies (CACT), Fakulti Teknologi Maklumat dan Komunikasi, Universiti Teknikal Malaysia (UTeM), Durian Tunggal, Melaka, 76100, Malaysia",2019.0,International Journal of Innovative Technology and Exploring Engineering,Blue Eyes Intelligence Engineering and Sciences Publication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073756504&doi=10.35940%2fijitee.L2908.1081219&partnerID=40&md5=ccec9d454e287fb5d5685018d703086b,10.35940/ijitee.L2908.1081219,20230520-160000,20230521-044735,"['government', 'open', 'data', 'portals:', 'a', 'measurement', 'of', 'data', 'veracity', 'coverage']",False,20230521-205332,,,,
406,scopus,IMPLEMENTING AGILE CONTINUOUS EDUCATION (ACE) AT MIT AND BEYOND: THE MIT REFUGEE ACTION HUB (REACT) CASE,"The rapid pace of change in technology, business models, and work practices is causing ever-increasing strain on the global workforce. Companies in every industry need to train professionals with updated skill-sets in a rapid and continuous manner. However, traditional educational models - university classes and in-person degrees- are increasingly incompatible with the needs of professionals, the market, and society as a whole. New models of education require more flexible, granular and affordable alternatives. MIT is currently developing a new educational framework called Agile Continuous Education (ACE). ACE describes workforce level education offered in a flexible, cost-effective and time-efficient manner by combining individual, group, and real-life mentored learning through multiple traditional and emerging learning modalities. This paper introduces the ACE framework along with its different learning approaches and modalities (e.g. asynchronous and synchronous online courses, virtual synchronous bootcamps, and real-life mentored apprenticeships and internships) and presents the MIT Refugee Action Hub (ReACT) as an illustrative example. MIT ReACT is an institute-wide effort to develop global education programs for underserved communities, including refugees, displaced persons, migrants and economically disadvantaged populations, with the goal of promoting the learner's social integration and formal inclusion into the job market. MIT ReACT's core programs are the Certificate in Computer and Data Science (CDS) and the MicroMasters in Data, Economics and Development Policy, which consist of a combination of online courses, bootcamps, and global apprenticeships. Currently, MIT ReACT has regional presence in the Middle East and North Africa, East Africa, South America, Asia, Europe and North America. © 2022 SEFI 2022 - 50th Annual Conference of the European Society for Engineering Education, Proceedings. All rights reserved.",Agile education; flexible study pathways; professional development; refugee education; skills development,"Bagiati A., Salazar-Gomez A.F., Masic A., Cook L., Sastry A., Westerman G., Breazeal C., Kumar V., Kennedy K.D., Sarma S.","Massachusetts Institute of Technology, Cambridge, MA, United States",2022.0,"SEFI 2022 - 50th Annual Conference of the European Society for Engineering Education, Proceedings",European Society for Engineering Education (SEFI),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147518993&doi=10.5821%2fconference-9788412322262.1190&partnerID=40&md5=1a42e1a1425238f124d8e6dcc8d26601,10.5821/conference-9788412322262.1190,20230520-160000,20230521-044735,"['implementing', 'agile', 'continuous', 'education', '(ace)', 'at', 'mit', 'and', 'beyond:', 'the', 'mit', 'refugee', 'action', 'hub', '(react)', 'case']",False,20230521-205332,,,,
407,scopus,"The effect of disruption technology, and the future knowledge management toward service innovation for telecommunication industry 4.0 in Indonesia","The disruption technological creates unprecedented opportunities and challenges that will be strengthened by the convergence of digital, physical technologies that characterize the newly emerging Fourth Industrial Revolution 4.0. This emerging technology is extraordinary and has the potential to become a source of growth. The telecommunications industry 4.0 is undergoing transformational development to deal with disruptive technological challenges. Globally, quality has declined from the past few decades, a combination of a stagnant economy and an increase in the quality of income has caused dissatisfaction. Inertia services that are often suffered by large companies are often difficult to shake, customer expectations have also shifted in the market, placing the company in a difficult situation in achieving customer satisfaction, agile and innovative technological trends, cost competition, government policy, and this will increase the level of global competition. Exploration case studies and literature reviews are used to test the antecedents of Service Innovation. The study identifies that disruption of technology services offers opportunities for business development to encourage the use of Internet-based services, increasing demand for cheaper and faster internet for consumers. To facing a competitive advantage, organizations have influenced by Service Innovation with the ability to improve big data analytics and organize future knowledge management capabilities, which are agile and flexible in providing information and solutions. From the managerial perspective, this research provides a comprehensive view of what the impact of Service Innovation is on organizations, how to achieve, what variables contribute, and how to relate with performance. The authenticity of this research lies in the description of how management emerges with a practical oriented framework of how organizations must be formed to be innovative and competitive through the general arrangement of antecedents of service innovation. This study, however, has limitations because the qualitative nature and conceptual framework need to have further investigated through large-scale surveys by quantitative research. © BEIESP.",Big Data Analytics; Competitive Advantage; Disruption Technology; Knowledge Management; Service Innovation,"Arifiani L., Budiastuti I.D., Erika W.K.","Bina Nusantara University, Jakarta, Indonesia",2019.0,International Journal of Engineering and Advanced Technology,Blue Eyes Intelligence Engineering and Sciences Publication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075476836&doi=10.35940%2fijeat.F1040.0986S319&partnerID=40&md5=ec98363fe57f0c69226886e1528f814c,10.35940/ijeat.F1040.0986S319,20230520-160000,20230521-044735,"['the', 'effect', 'of', 'disruption', 'technology,', 'and', 'the', 'future', 'knowledge', 'management', 'toward', 'service', 'innovation', 'for', 'telecommunication', 'industry', '4.0', 'in', 'indonesia']",False,20230521-205332,,,,
408,scopus,Batch-based agile program management approach for coordinating IT multi-project concurrent development,"Software development projects have undergone remarkable changes with the arrival of agile development approaches. Many firms are facing a need to use these approaches to manage entities consisting of multiple projects (i.e. programs) simultaneously and efficiently. New technologies such as big data provide a huge power and rich demand for the IT application system of the commercial bank which has the characteristics of multiple sub-projects, strong inter-project correlation, and numerous project participating teams. Hence, taking the IT program management of a bank in China as a case, we explore the methods to solve the problems in multi-project concurrent development practice through integrating the ideas of program and batch management. First, to coordinate the multi-project development process, this paper presents the batch-based agile program management approach that synthesizes concurrent engineering with agile methods. And we compare the application of batch management between software development projects and manufacturing process. Further, we analyze the concurrent multi-project development practice in the batch-based agile program management, including the overlapping between stages, individual project’s activities, and multiple projects based on common resources and environment to stimulate the knowledge transfer. Third, to facilitate the communication and coordination of batch-based program management, we present the double-level responsibility organizational structure of batch management. © The Author(s) 2021.",banking industry; batch management; coordination; multi-project management; program management; software development project,"Yang Q., Bi Y., Wang Q., Yao T.","School of Economics and Management, University of Science and Technology Beijing, Beijing, China; Alibaba Group US, Washington, United States",2021.0,Concurrent Engineering Research and Applications,SAGE Publications Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107443966&doi=10.1177%2f1063293X211015236&partnerID=40&md5=f8bc20fe962cc985738d1f15f6035a62,10.1177/1063293X211015236,20230520-160000,20230521-044735,"['batch-based', 'agile', 'program', 'management', 'approach', 'for', 'coordinating', 'it', 'multi-project', 'concurrent', 'development']",False,20230521-205332,,,,
409,scopus,Drone Application Model for Image Acquisition of Plantation Areas and Oil Palm Trees Counting,"The area of oil palm plantations in Indonesia increased by 7% from 14 million ha in 2017 to 15 million ha in 2021. The vast land requires the support of effective and efficient management techniques to maintain sustainable productivity. The high-performance computing technologies, Internet of Things (IoT), Big Data, Artificial Intelligence, spatial modeling, and drones are the answers to these needs. This study aims to design an application that can obtain plantation image data and analyze the calculation of the number of oil palm trees. The image of oil palm plantations is obtained from processing photo data from drones through a mosaic and composite process. This study also employed Scrum and UML as a system model development method. The image of the oil palm plantation area is used to build a tree counting model using the Viola-Jones algorithm. The oil palm tree count information generated by this system can then be used by management for fertilizing, harvesting, and monitoring the condition of oil palm trees. © 2022 IEEE.",drone; oil palm; Scrum; tree counting; UML; Viola-Jones,"Sastrohartono H., Suryotomo A.P., Saifullah S., Suparyanto T., Perbangsa A.S., Pardamean B.","Instiper Yogyakarta, Faculty of Agricultural Technology, Department of Agricultural Engineering, Yogyakarta, 55281, Indonesia; Universitas Pembangunan Nasional Veteran Yogyakarta, Department of Informatics, Yogyakarta, 55283, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, 11480, Indonesia; School of Information Systems, Bina Nusantara University, Information Systems Department, Jakarta, 11480, Indonesia; BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia",2022.0,"Proceedings of 2022 International Conference on Information Management and Technology, ICIMTech 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141392028&doi=10.1109%2fICIMTech55957.2022.9915223&partnerID=40&md5=855c5519c643c37ab715ab565fbd239b,10.1109/ICIMTech55957.2022.9915223,20230520-160000,20230521-044735,"['drone', 'application', 'model', 'for', 'image', 'acquisition', 'of', 'plantation', 'areas', 'and', 'oil', 'palm', 'trees', 'counting']",True,20230521-205332,,,,
410,scopus,Big Data IAOM Project Management and Workflow Automation in a Giant Gas Field Digitization Drive,"Integrated asset modeling, application of big data, and automation are among the top emerging trends in the oil and gas industry. The value associated with such implementation projects is very closely linked with the efficient use of the project management approach and a robust strategy to handle the technological challenges. This paper puts light on such initiatives implemented in a giant gas field. In this giant gas condensate field, a vast amount of data is generated and monitored on a daily basis. The frequent need to deliver the dynamic production target was driving this project implementation so that a value-driven system can be established while achieving the business KPIs. A phased approach was used to target multiple requirements into business deliverables where the early offline phases provided a robust base for full online integration. This project followed the agile approach focusing on getting insights from multiple stakeholders and domain experts and developing a lesson-learnt repository in all the project phases. The online integration solution is a critical differentiator in the workforce and process efficiency improvement. The multiple technical solution workflows helped in reducing manual efforts and streamlining the methodology in a standardized fashion. In addition, the standard project management practices, such as initializing the phases in a planned manner, followed by an interactive execution, monitoring, and controlling stages, ensured delivering project outcomes in an efficient way. This implementation also established a robust collaborative team effort to identify various different roles and responsibilities for stakeholders. This helped in the end phase when the project sustainability was essential. A strong team base maintained and updated the integrated system while delivering daily well and facility surveillance objectives and KPIs from users ranging from planning, engineering, operation, and management team. A special focus on IT team involvement throughout the project phase led to a successful data integration and diagnostic, as the core of the solution was a data-driven analytical framework integrated with multiple corporate and real-time data sources. In addition, this solution was equipped with various one-of-its-kind solution features such as business intelligence, advanced surveillance, dynamic-reservoir integration, manage-by-exception workflows, intelligence alerts, along with a strong digital framework and data architecture. The unique hybrid and agile project management approach focusing on delivering emerging trends and technologies to end-users in the most efficient way paved the way for achieving asset digitalization and standardization goals. © Copyright 2021, Society of Petroleum Engineers",,"Alsaeedi A.A.A.S., Elabrashy M.M.M., Alzeyoudi M.A., Albadi M.M., Soni S., Isambertt J., Tripathi D., Shah A.",Adnoc Onshore; Weatherford International,2021.0,"Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference, ADIP 2021",Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127642368&doi=10.2118%2f207737-MS&partnerID=40&md5=12e1b706d909405c635284d518c02084,10.2118/207737-MS,20230520-160000,20230521-044735,"['big', 'data', 'iaom', 'project', 'management', 'and', 'workflow', 'automation', 'in', 'a', 'giant', 'gas', 'field', 'digitization', 'drive']",False,20230521-205332,,,,
411,scopus,How to implement tech in shipbuilding: Charting the course to success,"From 3D printing to the use of robotics and drones. From AI and Big Data, to Virtual and Augmented Reality. From Generative Design to cloud based distributed computing. There are so many innovative technologies currently converging, improving and expanding that shipbuilders have incredible opportunities to positively transform their businesses, especially if they can take significant steps towards creating a digital twin. However, the industry must be realistic; there are multiple challenges that need to be addressed along the way. If shipbuilders want to be successful on this journey, they will have to find a way to navigate around various obstacles. This paper charts a course on how to do so. © 2018 The Society of Naval Architects and Marine Engineers. All Rights Reserved.",Agile; Digital Twin; Platform,"Morais D., Waldie M., Roberts P., David P.","SSI, United States",2018.0,"SNAME Maritime Convention, SMC 2018",Society of Naval Architects and Marine Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059405926&partnerID=40&md5=6b8bc9d72daded7dbeccd8e6614f956e,,20230520-160000,20230521-044735,"['how', 'to', 'implement', 'tech', 'in', 'shipbuilding:', 'charting', 'the', 'course', 'to', 'success']",False,20230521-205332,,,,
412,scopus,Parallel processing proposal by clustering integration of low-cost microcomputers,"Regarding parallel processing, a study brings a parallel computing approach by integrating low-cost microcomputers. In the given research, the main aspects linked to parallel processing and its motivation are exposed, widespread today by the need for data mining integrated with large-scale databases, prominent data characteristics, large volumes of data, lack of agile processing for real-time analysis, and high variability of data. For a given proposal, a case study scenario is addressed, where the database composed of more than twelve years of continuous records was processed, requiring processing and processing of the data present for the feasibility of a machine learning project. In the study, the main gains of the implemented system are presented, mainly the use of only 18% of the time required if it was considered a traditional model in the processing of the base. At the end of the article, considerations under the research and proposals for future works are presented. © 2022 The Authors. Published by Elsevier B.V.",Big Data; Microcomputer integration; Parallel processing,"De Souza Rocha Junior C., Moreira M.A.L., De Araújo Costa I.P., Gomes C.F.S., Dos Santos M., Silva F.C.A., Pereira R.C.A., Basilio M.P., De Moura Pereira D.A.","Fluminense Federal University, RJ, Niterói, 24210-240, Brazil; Naval Systems Analysis Center, RJ, Rio de Janeiro, 20091-000, Brazil; Military Institute of Engineering, Urca RJ22290-270, Brazil",2022.0,Procedia Computer Science,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146117179&doi=10.1016%2fj.procs.2022.11.154&partnerID=40&md5=8481db4440e5eaf76d73d580e617b030,10.1016/j.procs.2022.11.154,20230520-160000,20230521-044735,"['parallel', 'processing', 'proposal', 'by', 'clustering', 'integration', 'of', 'low-cost', 'microcomputers']",False,20230521-205332,,,,
413,scopus,Internet of things and other e-solutions in supply chain management may generate threats in the energy sector—the quest for preventive measures,"Energy firms are the beneficiaries and initiators of innovation, and energy investments are a crucial area of business activity that is specially protected in any country. This is no wonder, as energy security is the basis for the functioning of states and economies. The Internet of Things and Big Data create both new challenges and new threats. This study aimed to identify the potential threats and determine preventive measures, as well as to establish the agile principles related to energy firms’ logistics. The method of the narrative summary in combination with the literature searching method was used. Two conclusions emerged: first, research serves to develop the disci-pline of management science; second, the identification of risks associated with innovation serves practitioners. In addition, the study defined further research directions. © 2021 by the author. Licensee MDPI, Basel, Switzerland.",Agile; Bid data; Energy; Framing; Industry 4.0; Internet of Things; Logistics; Risk; Supply chain management,Dobrowolski Z.,"Institute of Public Affairs, Jagiellonian University, Kraków, 31-007, Poland",2021.0,Energies,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114105518&doi=10.3390%2fen14175381&partnerID=40&md5=9ffdd6f6f8d0e254e98a215d584aa755,10.3390/en14175381,20230520-160000,20230521-044735,"['internet', 'of', 'things', 'and', 'other', 'e-solutions', 'in', 'supply', 'chain', 'management', 'may', 'generate', 'threats', 'in', 'the', 'energy', 'sector—the', 'quest', 'for', 'preventive', 'measures']",False,20230521-205332,,,,
414,scopus,Health and safety in smart industry: State-of-the-art and future trends,"Industry 4.0, also known as smart manufacturing, is the name of what is considered as the fourth industrial revolution. The drivers behind are globalization, mass customization, and the rapid increase in computational power which makes it now possible to process big data and perform advanced analytics. In response, manufacturers require production systems that have more resilient, predictive and adaptable capabilities to achieve a truly agile production that is capable of lean, competitive production of mass customized products. The digitization of manufacturing has many implications not only on the shop floor. The biggest potential improvements identified in the survey is that Industry 4.0 brings to health and safety in the form of advanced monitoring of the worker and their environment through wearables, vision, and other sensor systems. The implementation of these technologies in turn also challenges that require further addressing, these challenges are not only technical but also organizational in nature. © 2021 Taylor & Francis Group, London.",,"Bakker O.J., Kendall T., Bartolo P.","School of Mechanical, Aerospace and Civil Engineering, Faculty of Engineering, The University of Manchester, United Kingdom",2019.0,"Industry 4.0 - Shaping The Future of The Digital World - Proceedings of the 2nd International Conference on Sustainable Smart Manufacturing, S2M 2019",CRC Press/Balkema,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117571509&partnerID=40&md5=b4d360ff93b5cade6c38299e12d3abbd,,20230520-160000,20230521-044735,"['health', 'and', 'safety', 'in', 'smart', 'industry:', 'state-of-the-art', 'and', 'future', 'trends']",False,20230521-205332,,,,
415,scopus,"Operational Data-Driven Intelligent Modelling and Visualization System for Real-World, On-Road Vehicle Emissions—A Case Study in Hangzhou City, China","On-road vehicle emissions play a crucial role in affecting air quality and human exposure, particularly in megacities. In the absence of comprehensive traffic monitoring networks with the general lack of intelligent transportation systems (ITSs) and big-data-driven, high-performance-computing (HPC) platforms, it remains challenging to constrain on-road vehicle emissions and capture their hotspots. Here, we established an intelligent modelling and visualization system driven by ITS traffic data for real-world, on-road vehicle emissions. Based on the HPC platform (named “City Brain”) and an agile Web Geographic Information System (WebGISs), this system can map real-time (hourly), hyperfine (10~1000 m) vehicle emissions (e.g., PM2.5, NOx, CO, and HC) and associated traffic states (e.g., vehicle-specific categories and traffic fluxes) over the Xiaoshan District in Hangzhou. Our results show sharp variations in on-road vehicle emissions on small scales, which even fluctuated up to 31.2 times within adjacent road links. Frequent and widespread emission hotspots were also exposed. Over custom spatiotemporal scopes, we virtually investigated and visualized the impacts of traffic control policies on the traffic states and on-road vehicle emissions. Such results have important implications for how traffic control policies should be optimized. Integrating this system with chemical transport models and air quality measurements would bridge the technical gap between air pollutant emissions, concentrations, and human exposure. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",big-data intelligent system; hyperfine modelling; on-road vehicle emissions; real-time visualization; traffic monitoring,"Wang L., Chen X., Xia Y., Jiang L., Ye J., Hou T., Wang L., Zhang Y., Li M., Li Z., Song Z., Jiang Y., Liu W., Li P., Zhang X., Yu S.","Research Center for Air Pollution and Health, Key Laboratory of Environmental Remediation and Ecological Health, Ministry of Education, College of Environment and Resource Sciences, Zhejiang University, Hangzhou, 310058, China; Bytedance Inc, Hangzhou, 310058, China; College of Science and Technology, Hebei Agricultural University, Baoding, 071000, China; Chinese Academy of Meteorological Sciences, China Meteorological Administration, Beijing, 100081, China",2022.0,Sustainability (Switzerland),MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130766177&doi=10.3390%2fsu14095434&partnerID=40&md5=f3d46c2ee28dc136f2c4f458345bc32d,10.3390/su14095434,20230520-160000,20230521-044735,"['operational', 'data-driven', 'intelligent', 'modelling', 'and', 'visualization', 'system', 'for', 'real-world,', 'on-road', 'vehicle', 'emissions—a', 'case', 'study', 'in', 'hangzhou', 'city,', 'china']",False,20230521-205332,,,,
416,scopus,Sustainable value stream mapping and technologies of Industry 4.0 in manufacturing process reconfiguration: A case study in an apparel company,"To optimize resource use in production, Lean manufacturing is the most widely implemented method in the world. One of the most useful tools in Lean production is Value Stream Mapping (VSM). With focus on visualizing key data of a production process in a single picture, VSM attempts to reveal bottleneck steps in a process. As a consequence, industrial engineers can determine which stages of the process should be put emphasis on improving. However, VSM sole consideration is economics and other aspects of sustainability such as societal and environmental are neglected. With Sustainable Value Stream Mapping (SVSM), all necessary illustrations for a sustainable manufacturing process can be visualized, which leads to higher chances to identify potential problems in the efficiency of production processes beyond the ones identified using lean manufacturing. This research provides a case study where SVSM is applied in an apparel company in order to identify potential issues in the sustainability of their production process. Furthermore, this paper highlights several potential solutions such as Radio-frequency identification (RFID), big data and ergonomics improvement by discussing the impact of their implementation on the process sustainability. Finally, the conclusion section discusses limits in the solutions implementation and suggest future research. © 2018 IEEE.",apparel industry; big data; lean manufacturing; radio-frequency identification; Sustainability; Sustainable value stream mapping,"Phuong N.A., Guidat T.","Global Production Engineering and Management Faculty of Engineering, Vietnamese German University, Binh Duong, Viet Nam; Global Production Engineering Program Institute of Machine Tools and Factory Operation, Technical University of Berlin, Berlin, Germany",2018.0,"Proceedings of the 2018 IEEE International Conference on Service Operations and Logistics, and Informatics, SOLI 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055664449&doi=10.1109%2fSOLI.2018.8476750&partnerID=40&md5=c0df3948acc89b8d0118afd85ae88f87,10.1109/SOLI.2018.8476750,20230520-160000,20230521-044735,"['sustainable', 'value', 'stream', 'mapping', 'and', 'technologies', 'of', 'industry', '4.0', 'in', 'manufacturing', 'process', 'reconfiguration:', 'a', 'case', 'study', 'in', 'an', 'apparel', 'company']",False,20230521-205332,,,,
417,scopus,E-monitoring the nature of water,"The critical need for hydrological observations in support of water resources management, particularly during extreme events, has transformed traditional methods of hydrological data management. This transformation has given rise to a framework of e-monitoring the hydrological cycle, the aim of which is to improve understanding of the nature of water. New trends in data science, coupled with increasing technological evolution, make the new generation of data systems more agile and responsive to the needs and expectations for efficient and effective data sharing and service delivery. The WMO Hydrological Observing System was designed around the integration of observations, data exchange, research, data processing, modelling and forecasting, in such a way that societal needs for disaster risk reduction, improved sustainability of environmental resources, climate resilience and economic growth can be effectively met. With its implementation of conceptual functionalities for sustainable data management, the WHOS operational architecture is hydrology’s system for the future. © 2020, © 2020 IAHS.",data discovery and access; hydrological observations; interoperability,"Pecora S., Lins H.F.","World Meteorological Organization, Commission for Hydrology, Geneva, Switzerland",2020.0,Hydrological Sciences Journal,Taylor and Francis Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079365822&doi=10.1080%2f02626667.2020.1724296&partnerID=40&md5=3f5f96bcff22ecbc1d19df93a077e085,10.1080/02626667.2020.1724296,20230520-160000,20230521-044735,"['e-monitoring', 'the', 'nature', 'of', 'water']",False,20230521-205332,,,,
418,scopus,Leveraging Modern Big Data Stack for Swift Development of Insights into Social Developments,"Insights of social development, presented in various forms, such as metrics, figures, text summaries, whose purpose is to summarize, explain, and predict the situations and trends of society, is extremely useful to guide organizations and individuals to better realize their own objectives in accordance with the whole society. Deriving these insights accurately and swiftly has become an interest for a range of organizations, including agencies governing districts, city even the whole country, they use these insights to inform policy-makings. Business investors who peak into statistical numbers for estimating current economical situations and future trends. Even for individuals, they could look at some of these insights to better align themselves with macroscopical social trends. There are many challenges to develop these insights in a data-driven approach. First, required data come from a large number of heterogeneous sources in a variety of formats. One single source’s data could be in the size of hundreds of Gigabytes to several TeraBytes, ingesting and governing such huge amount of data is not a small challenge. Second, many complex insights are derived by domain human experts in a trail-and-error fashion, while interacting with data with the aid of computer algorithms. To quickly experiment various algorithms, it asks for software capabilities for infusing human experts and machine intelligence together, this is challenging but critical for success. By designing and implementing a flexible big data stack that could bring in a variety of data components. We address some of the challenges to infuse data, computer algorithm and human together in Zilian Tech company [20]. In this paper we present the architecture of our data stack and articulate some of the important technical choices when building such stack. The stack is designed to be equipped with scalable storage that could scale up to PetaBytes, as well as elastic distributed compute engine with parallel computing algorithms. With these features the data stack enables a) swift data analysis, by human analysts interacting with data and machine algorithms via software support, with on-demand question answering time reduced from days to minutes; b) agile building of data products for end users to interact with, in weeks if not days from months. © 2022, The Author(s).",Cloud; Data stack; Social development,"Huang H., He Y., Zhang L., Zeng Z., Ouyang T., Zeng Z.","University of Melbourne, Parkville, VIC  3010, Australia; Computer and Data Science department, Case Western Reserve University, 10900 Euclid Ave., Cleveland, OH  44106, United States; University of Electronic Science and Technology of China, ChengDu, China; Zilian Tech Inc., ShenZhen, China",2022.0,Lecture Notes in Electrical Engineering,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135069136&doi=10.1007%2f978-981-19-2456-9_34&partnerID=40&md5=1140b75e1b0d3dc9a168d2966e375c23,10.1007/978-981-19-2456-9_34,20230520-160000,20230521-044735,"['leveraging', 'modern', 'big', 'data', 'stack', 'for\xa0swift', 'development', 'of\xa0insights', 'into\xa0social', 'developments']",False,20230521-205332,,,,
419,scopus,Digital Lighthouse: A Scalable Model for Digital Transformation in Oil & Gas,"Energy companies are latecomers to digitization with respect to other business, but new technologies like Big Data, Cloud infrastructure and Artificial Intelligence offer great opportunities. Here we present an integrated approach to the digitalization of an O&G plant aiming to offer operator safety enhancement, production optimization and reduction of the environmental impact to maximize the asset value. This has been accomplished by complex and continuous work powered by the people who are the engine and the real target of the digital transformation process. In the key study hereby presented, an all-round effort has been made to empower the operator's everyday work with digital and innovative tools supporting reservoir, maintenance, production and HSE workflow. Starting from a number of various legacy systems, a single integrated dashboard was built: The Integrated Operation Centre (IOC). IOC is now available on PC and smartphones to all site personnel both at the operational and managerial level. New innovative systems were developed and deployed into IOC to capitalize on the data acquired during years of plant activities. Machine learning and advanced analytics solutions provide new daily insight on how to efficiently schedule maintenance operations and avoid off-specs and downtime on critical equipment, while complex production optimizers help technicians react to unexpected situations and maximize production. Via IoT (Internet of Things) and portable devices, new tools and workflows were deployed onsite to ease the work and enhance the safety of workers with focus on usage of PPE and providing rapid information to locate workers during emergency situations. People from both site and company headquarters ensured the success of the digital transformation by working together in an Agile Method during the development phase and by coaching in the roll-out phase. New professional roles, like data scientist and big data engineers, joined effort with experienced operators to ensure the success of this journey. This cooperation was at the basis of a comprehensive change management effort, which ensured a smooth and constant change in the way the personnel thinks, acts and reacts. This, we believe, is at the very heart of any fundamental transformation, being it digital or not. Copyright 2022, Society of Petroleum Engineers.",,"Cadei L., Rossi G., Lancia L., Loffreno D., Corneo A., Milana D., Montini M., Purlalli E., Fier P., Carducci F., Nizzolo R.",Eni SpA; The Boston Consulting Group GAMMA,2022.0,"Society of Petroleum Engineers - SPE Conference at Oman Petroleum and Energy Show, OPES 2022",Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127983332&doi=10.2118%2f200149-MS&partnerID=40&md5=f9ee7fff86c963224656d5a40c52cc22,10.2118/200149-MS,20230520-160000,20230521-044735,"['digital', 'lighthouse:', 'a', 'scalable', 'model', 'for', 'digital', 'transformation', 'in', 'oil', '&', 'gas']",False,20230521-205332,,,,
420,scopus,A built-in criteria analysis for best IT governance framework,"The implementation of IT governance is important to lead and evolve the information system in agreement with stakeholders. This requirement is seriously amplified at the time of the digital area considering all the new technologies that have been launched recently (Big DATA, Artificial Intelligence, Machine Learning, Deep learning, etc.). Thus, without a good rudder, every company risks getting lost in a sea endless and unreachable goal. This paper aims to provide decision-making system that allows professionals to choose IT governance framework suitable to desired criteria and their importance based on a multi-criteria analysis method (WSM), we did implement a case study based on a Moroccan company. Moreover, we present a better understanding of IT Governance aspects such as standards and best practices. This paper goes into a global objective that aims to build an integrated generated meta-model for a better approach of IT Governance. © 2019 International Journal of Advanced Computer Science and Applications.",CMMI; COBIT; ISO 38500; IT Governance; ITIL; PMBOK; PRINCE 2; SCRUM; TOGAF,"Hamzane I., Abdessamad B.","Ben M'sik Faculty of Science, Hassan, Morocco; University Casablanca, Morocco",2019.0,International Journal of Advanced Computer Science and Applications,Science and Information Organization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075735916&partnerID=40&md5=50df938a908a51266d741d5894f74d51,,20230520-160000,20230521-044735,"['a', 'built-in', 'criteria', 'analysis', 'for', 'best', 'it', 'governance', 'framework']",False,20230521-205332,,,,
421,scopus,HCOBASAA: Countermeasure Against Sinkhole Attacks in Software-Defined Wireless Sensor Cognitive Radio Networks,"Software-defined wireless sensor cognitive radio network is one of the emerging technologies which is simple, agile, and flexible. The sensor network comprises of a sink node with high processing power. The sensed data is transferred to the sink node in a hop-by-hop basis by sensor nodes. The network is programmable, automated, agile, and flexible. The sensor nodes are equipped with cognitive radios, which sense available spectrum bands and transmit sensed data on available bands, which improves spectrum utilization. Unfortunately, the Software-defined wireless sensor cognitive radio network is prone to security issues. The sinkhole attack is the most common attack which can also be used to launch other attacks. We propose and evaluate the performance of Hop Count-Based Sinkhole Attack detection Algorithm (HCOBASAA) using probability of detection, probability of false negative, and probability of false positive as the performance metrics. On average HCOBASAA managed to yield 100%, 75%, and 70% probability of detection. © 2018 IEEE.",change in position; sinkhole attack; software-defined wireless sensor cognitive radio network,"Sejaphala L., Velempini M., Dlamini S.V.","Department of Computer Science, University of Limpopo, Limpopo, South Africa; Council for Scientific Industrial Research, CSIR, Mareka Institute, Pretoria, South Africa",2018.0,"2018 International Conference on Advances in Big Data, Computing and Data Communication Systems, icABCD 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054682713&doi=10.1109%2fICABCD.2018.8465449&partnerID=40&md5=38474e3e15f7e69739c68e6ce169927e,10.1109/ICABCD.2018.8465449,20230520-160000,20230521-044735,"['hcobasaa:', 'countermeasure', 'against', 'sinkhole', 'attacks', 'in', 'software-defined', 'wireless', 'sensor', 'cognitive', 'radio', 'networks']",True,20230521-205332,,,,
422,scopus,A Methodology to Manage Structured and Semi-structured Data in Knowledge Oriented Graph,"Data has become fundamental to every business process and research area like never before. To date, one of the main open points of research activities is to manage the data acquired in the field by sensors, logs etc. by modeling the data structures according to the analyzes that will be carried out. In fact, with the advent of Big Data, the need to have a single reference data structure has been reduced, but with modern architectures there is a tendency to generate specific and optimized data structures for the analyzes that will be carried out. In this work we propose an agile data modeling methodology guided by analytics focused on the management of structured and semi-structured data sources. © 2022, Springer Nature Switzerland AG.",Data management; Events graphs; Graph rewriting,"Bellandi V., Ceravolo P., D’Andrea G.A., Maghool S., Siccardi S.","Computer Science Department, Università Degli Studi di Milano, Via Celoria 18, Milano, Italy",2022.0,Communications in Computer and Information Science,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133024375&doi=10.1007%2f978-3-031-08223-8_18&partnerID=40&md5=18f7abc95928b7824396f02cfe0c2302,10.1007/978-3-031-08223-8_18,20230520-160000,20230521-044735,"['a', 'methodology', 'to\xa0manage', 'structured', 'and\xa0semi-structured', 'data', 'in\xa0knowledge', 'oriented', 'graph']",False,20230521-205332,,,,
423,scopus,Digital marketing: Incompatibilities between performance marketing and marketing creativity,"Within digital marketing, marketing intelligence fosters two major developments. First — and even in the absence of key performance indicators — it improves marketing efficiency, as life-cycle marketing, automated price adjustment and programmatic advertising based on artificial intelligence (AI) all support the vision of fully standardised marketing automation, with real-time, optimised customer centricity. Secondly, new marketing areas such as viral marketing, social media marketing and content marketing emphasise the increasing significance of creative marketing. Looking for paradigmatic principles reveals that performance marketing is shaped by analytic, processual and lean thinking. In contrast, creative marketing depends on agile outside-in thinking as a key element in the debate regarding marketing 3.0. Thus, digitisation seems to foster paradigmatic incompatibilities within marketing 4.0. This paper argues that until Big Data and AI can judge creativity, the digitisation of marketing will continue to suffer teething problems. © Henry Stewart Publications 2050-0076 (2021).",Creativity; Marketing 3.0; Marketing 4.0; Marketing intelligence; Paradigm; Performance marketing,Lies J.,"FOM University of Applied Science, Lissaboner Allee 7, Dortmund, 44269, Germany",2021.0,Journal of Digital and Social Media Marketing,Henry Stewart Publications,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103991839&partnerID=40&md5=d969f234f10d720dcb9133926f026eea,,20230520-160000,20230521-044735,"['digital', 'marketing:', 'incompatibilities', 'between', 'performance', 'marketing', 'and', 'marketing', 'creativity']",False,20230521-205332,,,,
424,scopus,Organizing Global Democratic Collaboration in Crisis Contexts: The International Triangulation System,"The 2020 global crisis triggered by the Covid-19 pandemic progressively shut down economies from East to West as the virus spread worldwide. Progressively, nations suffered massive economic losses as their markets became both disrupted and polarized, reflecting public authorities’ weaknesses to collaborate on a socio-economic speed adaptation. Beyond an organizational crisis, significant management and leadership concerns were raised on the sporadic and disjoint initiatives taken across sectors. Paradoxically, big data utilization wasn’t optimized and fully potentialized. It, in turn, leads to a worrying number of R&D waste in time and outputs. Globalized trans-disciplinary and multi-sectorial ecosystems’ intertwined character adds to a Global Alliance’s organizational complexity to operate successfully. This paper proposes the International Collaboration Guideline on Crisis Management (ICGCM), which aims to be automatized by International Triangulation Systems (ITS). © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Agile operations; Business transformation innovation; Covid19; Diplomatic coopetition; Global alliance; Global collaborative management; Global crisis management; International relations; Knowledge management; Project management,"Markopoulos E., Kirane I.S., Balaj D., Vanharanta H.","Queen Mary University of London, School of Business and Management, 327 Mile End Road, London, E1 4NS, United Kingdom; Turku University of Applied Sciences, Faculty of Engineering and Management, Joukahaisenkatu 3, Turku, 20520, Finland; Hult International Business School, 35 Commercial Road, London, E1 1LD, United Kingdom; School of Technology and Innovations, University of Vaasa, Wolffintie 34, Vaasa, 65200, Finland",2021.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112183756&doi=10.1007%2f978-3-030-80094-9_25&partnerID=40&md5=d4cea78b878e9fcdcaaae71dc90b3f3b,10.1007/978-3-030-80094-9_25,20230520-160000,20230521-044735,"['organizing', 'global', 'democratic', 'collaboration', 'in', 'crisis', 'contexts:', 'the', 'international', 'triangulation', 'system']",False,20230521-205332,,,,
425,scopus,Transformational shifts through digital servitization,"Manufacturers increasingly look to digitalization to drive service growth. However, success is far from guaranteed, and many firms focus too much on technology. Adopting a discovery-oriented, theories-in-use approach, this study examines the strategic organizational shifts that underpin digital servitization. Notwithstanding strong managerial and academic interest, this link between digitalization and servitization is still under-investigated. Depth interviews with senior executives and managers from a global market leader revealed that to achieve digital service-led growth, a firm and its network need to make three interconnected shifts: (1) from planning to discovery, (2) from scarcity to abundance, and (3) from hierarchy to partnership. Organizational identity, dematerialization, and collaboration play a key role in this transformation. For managers, the study identifies a comprehensive set of strategic change initiatives needed to ensure successful digital servitization. © 2020 The Authors",Agile mindset; Big data monetization; Data-centric business model; Digital servitization; Digital transformation; Organizational culture,"Tronvoll B., Sklyar A., Sörhammar D., Kowalkowski C.","Inland Norway University of Applied Sciences, Elverum, 2418, Norway; CTF – Service Research Center, Karlstad University, Karlstad, 651 88, Sweden; Department of Management and Engineering, Linköping University, Linköping, 581 83, Sweden; Stockholm Business School, Stockholm University, Stockholm, 106 91, Sweden; Hanken School of Economics, Department of Marketing, CERS—Centre for Relationship Marketing and Service Management, Helsinki, 00101, Finland",2020.0,Industrial Marketing Management,Elsevier Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079186838&doi=10.1016%2fj.indmarman.2020.02.005&partnerID=40&md5=aa9de9eec3d5db6c2638d5bda5434bd0,10.1016/j.indmarman.2020.02.005,20230520-160000,20230521-044735,"['transformational', 'shifts', 'through', 'digital', 'servitization']",False,20230521-205332,,,,
426,scopus,Model-based manufacturing system supported by virtual technologies in an industry 4.0 context,"Industry 4.0 concept of the new industrial revolution is based on the application of front-end and base technologies for producing digital solutions. Converging Smart Manufacturing and Smart Products with Big Data and Analytics plays a central role in implementing the I4.0 concept in today’s industry. This paper presents the virtual components of the proposed Model-based Manufacturing System and their role in the I4.0 context. Two different industrial cases demonstrate the application and benefits of the MBM approach, which integrates virtual and rapid technologies for the design, analysis and validation of a product and its fabrication processes of sheet metal forming and forging. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.",Additive manufacturing; Industry 4.0; Metal forming; Model-based manufacturing; Virtual manufacturing; Virtual reality,Mandic V.,"Faculty of Engineering Sciences, University of Kragujevac, Kragujevac, Serbia",2020.0,Lecture Notes in Mechanical Engineering,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085771391&doi=10.1007%2f978-3-030-46212-3_15&partnerID=40&md5=7a8b4c7042058e93d0bf8495332a08bf,10.1007/978-3-030-46212-3_15,20230520-160000,20230521-044735,"['model-based', 'manufacturing', 'system', 'supported', 'by', 'virtual', 'technologies', 'in', 'an', 'industry', '4.0', 'context']",False,20230521-205332,,,,
427,scopus,On the future of ramp-up management,"The aim of this paper is to present research hypotheses and practical implications on developing a novel ramp-up management approach facing recent challenges and trends in the field of agile production. Applying a mixed-method design based on a quantitative pre-study with 67 researchers and qualitative interviews with seven practitioners in ramp-up-relevant fields showed a consensus on the continuing importance of human factors for future ramp-up management. For managing ramp-up phases, real-time data infrastructure is central to support the learning and decision making process and thus to increase ramp-up agility. Along with this requirement, organizations are expected to have flatter hierarchical structures and be able to extend their product portfolio by implementing new technologies such as additive manufacturing. © 2018 CIRP",Agility; Big data; Industrie 4.0; Internet of things; Paradigm shift; Ramp-up management,"Schmitt R., Heine I., Jiang R., Giedziella F., Basse F., Voet H., Lu S.","Chair of Production Metrology and Quality Management, RWTH Aachen University, Aachen, 52062, Germany; Chair of Technology and Innovation Management, RWTH Aachen University, Aachen, 52062, Germany; Chair of Operations Management, RWTH Aachen University, Aachen, 52062, Germany; Chair of Production Engineering, RWTH Aachen University, Aachen, 52062, Germany; University of Southern California, Los Angeles, CA  90089, United States",2018.0,CIRP Journal of Manufacturing Science and Technology,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044321160&doi=10.1016%2fj.cirpj.2018.03.001&partnerID=40&md5=33b65e9b47a6e15b59c6518677fb9b13,10.1016/j.cirpj.2018.03.001,20230520-160000,20230521-044735,"['on', 'the', 'future', 'of', 'ramp-up', 'management']",False,20230521-205332,,,,
428,scopus,Insights on Creative Networks: A Social Network Analysis of Five Arts Organisations,"Many arts organisations can generate large amounts of value through their activities and networks, but often find it difficult to gather, analyse and evidence the data that can inform business decisions and leverage opportunities for product and service innovation. Compared to larger corporations, the creative ecosystem in which they operate depends on “quick business” and requires them to be more agile, adaptive and faster when identifying hidden potential within their networks. Moreover, their interdisciplinary and collaborative ways of working create emerging opportunities for spin-off companies and other entrepreneurial ventures. This study (part of the Arts API Project) aimed to examine the networks of arts organisations to understand some of their defining features and characteristics. The project aimed to show that by visualising and analysing relational data, it was envisioned that arts organisations would be able to operate on a more evidence-based, commercial and entrepreneurial basis, enabling better informed decision making and more defined business strategies. This paper focuses on the role and value of big data in the Arts and Humanities, provides the context and background to the Arts API Project and outlines the methodological approach, presenting one particular aspect of the larger research project. Adopting the technique of Social Network Analysis (SNA), the networks of five UK-based art organisations were visually mapped and analysed using measures such as Density, Connectivity, Centralization and Clique Participation Index. Within the limitations of the study, the findings reveal valuable insights on the effect of de/centralisation of information flow within creative networks, the importance of maintaining a balance between weak and strong network ties and mitigating risk by distributing responsibility across networks. © 2022, Academic Conferences and Publishing International Limited. All right reserved.",big data; creativity; innovation; network structures; relationships; value,"Bruce F., O’neill S., Hawari-Latter S.","University of Dundee, United Kingdom",2022.0,"Proceedings of the European Conference on Innovation and Entrepreneurship, ECIE",Academic Conferences and Publishing International Limited,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152630125&doi=10.34190%2fecie.17.1.538&partnerID=40&md5=783d1ad28a1b6f8f3595db7656af915b,10.34190/ecie.17.1.538,20230520-160000,20230521-044735,"['insights', 'on', 'creative', 'networks:', 'a', 'social', 'network', 'analysis', 'of', 'five', 'arts', 'organisations']",False,20230521-205332,,,,
429,scopus,Cyber-Physical Systems in Smart City: Challenges and Future Trends for Strategic Research,"Modern cities today compete with each other to be smarter, maintain a more sustainable with high-quality living, acquire talents, and provide jobs. This digital transformation through agile drivers will help address the increasing challenges of urbanization in a couple of decades. The Cyber-Physical System (CPS) is becoming pervasive in every aspect of smart city daily life and considered as one of the four fundamental conceptual approaches of the fourth generation industrial revolution (Industry 4.0). CPS used to describe the next generation of a diverse spectrum of complicated, multidisciplinary, physically comprehending engineered systems that integrates embedded cyber aspects into the physical world. It implants computation technologies, communication control, the convergence of information, and physical processes together with strategic importance internationally. CPS is still a vast research area. As a result, it opens venues for applications across multiple scales. This paper presents an in-depth survey of the related works, focusing on the design and how it relates to different research fields, current concepts, and real-life applications to understand CPS more precisely. Further, it enumerates an extensive set of CPS challenges and opportunities, introducing visionary ideas, research strategies, and future trends expected for future-oriented technological solutions, like cloud computing, Internet of Things, and Big Data. These technological solutions are to play a critical role in CPS research and have significant impacts on the smart city. © Springer Nature Switzerland AG 2020.",Big Data; Cloud computing; Cyber-physical systems; Future trends; Industry 4.0; Internet of Things; Research strategies; Smart city,"Juma M., Shaalan K.","Faculty of Engineering and Information Technology, British University in Dubai, Dubai International Academic City, Block 11, 1st and 2nd Floor, Dubai, United Arab Emirates",2020.0,Advances in Intelligent Systems and Computing,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075625719&doi=10.1007%2f978-3-030-31129-2_78&partnerID=40&md5=b3938f43a6d969b0cc1c44b361b7b596,10.1007/978-3-030-31129-2_78,20230520-160000,20230521-044735,"['cyber-physical', 'systems', 'in', 'smart', 'city:', 'challenges', 'and', 'future', 'trends', 'for', 'strategic', 'research']",False,20230521-205332,,,,
430,scopus,"Enterprise meta-architecture for megacorps of unmanageably great size, speed, and technological complexity","The discipline of enterprise architecture (EA) provides valuable tools for aligning an organization’s business strategy and processes, IT strategy and systems, personnel structures, and organizational culture, with the goal of enhancing organizational agility, adaptability, and efficiency. However, the centralized and exhaustively detailed approach of conventional EA is susceptible to failure when employed in organizations demonstrating exceedingly great size, speed of operation and change, and IT complexity – a combination of traits that characterizes, for example, some emerging types of “technologized” oligopolistic megacorps reflecting the Industry 4.0 paradigm. This text develops the conceptual basis for a variant form of enterprise architecture that can be used to enact improved target architectures for organizations whose characteristics would otherwise render them “unmanageable” from the perspective of conventional EA. The proposed approach of “enterprise meta-architecture” (or EMA) disengages human enterprise architects from the fine-grained details of architectural analysis, design, and implementation, which are handled by artificially intelligent systems functioning as active agents rather than passive tools. The role of the human enterprise architect becomes one of determining the types of performance improvements a target architecture should ideally generate, establishing the operating parameters for an EMA system, and monitoring and optimizing its functioning. Advances in Big Data and parametric design provide models for enterprise meta-architecture, which is distinct from other new approaches like agile and adaptive EA. Deployment of EMA systems should become feasible as ongoing advances in AI result in an increasing share of organizational agency and decision-making responsibility being shifted to artificial agents. © 2019, Springer Nature Switzerland AG.",Enterprise architecture; Industry 4.0; Megacorps; Organizational complexity; Parametric design; Unmanageability,Gladden M.E.,"Institute of Computer Science, Polish Academy of Sciences, Warsaw, 01-248, Poland",2019.0,Advances in Intelligent Systems and Computing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053259307&doi=10.1007%2f978-3-319-99993-7_22&partnerID=40&md5=4b56c881dd7801afb443b4f4c4585e28,10.1007/978-3-319-99993-7_22,20230520-160000,20230521-044735,"['enterprise', 'meta-architecture', 'for', 'megacorps', 'of', 'unmanageably', 'great', 'size,', 'speed,', 'and', 'technological', 'complexity']",False,20230521-205332,,,,
431,scopus,Design and Implementation of a Virtual Machine for a Dynamic Object-Oriented Programming Language,"Over the last years, dynamic, interpreted and JIT-compiled programming languages have become a primary choice for fields such as web development, data science, and artificial intelligence. The primary concept of these language interpreters is that they usually generate a set of machine code-like instructions (often called “bytecode”) instead of directly generating machine code for the targeted platform. This does not only allow programmers to follow program execution instantly but also to develop and deploy applications more efficiently, often in combination with agile practices. Their first simple functional prototypes are usually implemented in another high-level language such as Python, Java, or JavaScript due to larger flexibility for implementing algorithms and the language grammar and later converted to a low-level system language such as C or C++ with special emphasis on memory management and bytecode optimizations. This paper presents some of the common examples, approaches, and algorithms for implementing such systems with sufficient or acceptable portability and efficiency, and also describes the design and implementation of Stella, a simple, yet powerful and user-friendly dynamic programming language designed to provide an optimal infrastructure for scalable and safe object-oriented design. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Bytecode; Call frame; Closure; Garbage collection; Interpreter; Java; Parsing; Python; Stack-based virtual machine; UML; Visual Paradigm,"Marevac E., Keleštura M., Junuzović A., Hodžić M., Muhić S.","Polytechnic Faculty, University of Zenica, Zenica, Bosnia and Herzegovina",2023.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141667531&doi=10.1007%2f978-3-031-17697-5_59&partnerID=40&md5=9375ee684fa3bd3a92e6188adc2a96fc,10.1007/978-3-031-17697-5_59,20230520-160000,20230521-044735,"['design', 'and', 'implementation', 'of', 'a', 'virtual', 'machine', 'for', 'a', 'dynamic', 'object-oriented', 'programming', 'language']",False,20230521-205332,,,,
432,scopus,Internet of Vehicles and Real-Time Optimization Algorithms: Concepts for Vehicle Networking in Smart Cities,"Achieving sustainable freight transport and citizens’ mobility operations in modern cities are becoming critical issues for many governments. By analyzing big data streams generated through IoT devices, city planners now have the possibility to optimize traffic and mobility patterns. IoT combined with innovative transport concepts as well as emerging mobility modes (e.g., ridesharing and carsharing) constitute a new paradigm in sustainable and optimized traffic operations in smart cities. Still, these are highly dynamic scenarios, which are also subject to a high uncertainty degree. Hence, factors such as real-time optimization and re-optimization of routes, stochastic travel times, and evolving customers’ requirements and traffic status also have to be considered. This paper discusses the main challenges associated with Internet of Vehicles (IoV) and vehicle networking scenarios, identifies the underlying optimization problems that need to be solved in real time, and proposes an approach to combine the use of IoV with parallelization approaches. To this aim, agile optimization and distributed machine learning are envisaged as the best candidate algorithms to develop efficient transport and mobility systems. © 2022 by the authors.",agile optimization; data analytics; distributed machine learning; Internet of Vehicles; IoT analytics; smart cities; vehicle networking,"Adelantado F., Ammouriova M., Herrera E., Juan A.A., Shinde S.S., Tarchi D.","Department of Computer Science, Multimedia and Telecommunication, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; Department of Applied Statistics and Operations Research, Universitat Politècnica de València, Alcoy, 03801, Spain; Department of Electrical, Electronic, and Information Engineering “Guglielmo Marconi”, University of Bologna, Bologna, 40126, Italy",2022.0,Vehicles,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144654376&doi=10.3390%2fvehicles4040065&partnerID=40&md5=79dbe3c5ed061325599971cdc94f089e,10.3390/vehicles4040065,20230520-160000,20230521-044735,"['internet', 'of', 'vehicles', 'and', 'real-time', 'optimization', 'algorithms:', 'concepts', 'for', 'vehicle', 'networking', 'in', 'smart', 'cities']",False,20230521-205332,,,,
433,scopus,Real time series analysis for early frac-hit detection in Vaca Muerta’s natural flowing wells,"Unconventional developments generate a characteristic phenomenon known as well interference. They are signaled by a disturbance in a well given the influence of a neighboring well. We can classify three types of interferences: Completion to Drilling, Drilling to Production and Completion to Production. The last kind, also known as a frac-hit, is the subject of this study, being the most frequent and with the most productivity impact, caused by liquid loading or wells shut-in. The goal of this project is to deliver an early frac-hit detection system for Vaca Muerta’s natural flowing wells integrated into YPF’s Unconventional Decision Support Center (DSC). Using this system, shutting certain wells for frac-hit protection could be avoided, shutting them in when there is a deviation from natural well-head pressure decline. To achieve this objective, we use real-time pressure data from well head pressure gauges. The trend component of the head pressure time series is extracted, and a model is made using one-month data for each well. The model forecasts the next 3 days of well head pressure, predicting its's natural decay and it was tested with a set of 34 wells labeled as interfered. By comparing the modelled pressure with the real data, we can detect the beginning of the interference when the pressure difference is above a defined threshold, and the difference persists a given number of hours. An alarm is raised when these conditions are met. The alarm is displayed in a dashboard accessible for DSC supervisors, and operational engineers, to take corrective actions, e.g.: decide which wells need to be shut-in. Monitoring begins when the fracking equipment starts the new well stimulation process. If no alarms are registered, the model is automatically recalculated. As a result of this work, a dashboard for monitoring the state of natural flowing wells on the DSC was developed. We can expect to have less production loss for wells shut-in, unless an early frac-hit detection alarm is raised. This work is directly applied to the unconventional play of Vaca Muerta, decreasing the supervisory needs to detect frac-hits when several frac rigs are operating simultaneously with tens of wells under risk of being hit. The novelty is the application of time series analytics over well head pressure data to enhance DSC’s supervisor’s productivity and decrease production losses for the unconventional assets. This project was developed working in a multidisciplinary team with agile methodologies, with people from the following teams: Analytics CoE, Upstream Data Science, Digital Oilfield, and Asset’s Reservoir Engineering, Production Engineering, and Production DSC. © LURT 20209.All right reserved.",,"Romero A., Del Campo N., Villagra F., Gonzalez Day L., Quezada B., Pol’la M., Barresi M., Bertoldi F., Baieli F., Álvarez Claramunt J.I., Rozzisi M., Martinez G., Silva K., Spairani J.",YPF; Recursos Naturales Treland,2020.0,"SPE/AAPG/SEG Latin America Unconventional Resources Technology Conference 2020, LURT 2020",Unconventional Resources Technology Conference (URTEC),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126470329&doi=10.15530%2furtec-2020-1420&partnerID=40&md5=ddd93b7629c08ce5c0743b3f68e3eb19,10.15530/urtec-2020-1420,20230520-160000,20230521-044735,"['real', 'time', 'series', 'analysis', 'for', 'early', 'frac-hit', 'detection', 'in', 'vaca', 'muerta’s', 'natural', 'flowing', 'wells']",False,20230521-205332,,,,
434,scopus,AD4ML: Axiomatic Design to Specify Machine Learning Solutions for Manufacturing,"Machine learning is increasingly adopted in manufacturing use cases, e.g., for fault detection in a production line. Each new use case requires developing its own machine learning (ML) solution. A ML solution integrates different software components to read, process, and analyze all use case data, as well as to finally generate the output that domain experts need for their decision-making. The process to design a system specification for a ML solution is not straight-forward. It entails two types of complexity: (1) The technical complexity of selecting combinations of ML algorithms and software components that suit a use case; (2) the organizational complexity of integrating different requirements from a multidisciplinary team of, e.g., domain experts, data scientists, and IT specialists. In this paper, we propose several adaptations to Axiomatic Design in order to design ML solution specifications that handle these complexities. We call this Axiomatic Design for Machine Learning (AD4ML). We apply AD4ML to specify a ML solution for a fault detection use case and discuss to what extent our approach conquers the above-mentioned complexities. We also discuss how AD4ML facilitates the agile design of ML solutions. © 2020 IEEE.",design; machine-learning; manufacturing,"Zacarias A.G.V., Ghabri R., Reimann P.","University of Stuttgart, GSaME, Stuttgart, Germany; University of Stuttgart, Ipvs, Stuttgart, Germany",2020.0,"Proceedings - 2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science, IRI 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092149155&doi=10.1109%2fIRI49571.2020.00029&partnerID=40&md5=5485ae092f35f058ba8c0ec6eccca96f,10.1109/IRI49571.2020.00029,20230520-160000,20230521-044735,"['ad4ml:', 'axiomatic', 'design', 'to', 'specify', 'machine', 'learning', 'solutions', 'for', 'manufacturing']",True,20230521-205332,,,,
435,scopus,"Design-computational thinking, transfer and flavors of reuse: Scaffolds to Information and Data Science for sustainable systems in Smart Cities","This paper investigates how to increase understanding of design and sustainable systems by scaffolding transfer of learning using eclectic approaches to experiment with networks of design potentials. Transfer of learning simulates multi-criteria case indexing, refined from knowledge induction derived from analyses of random but related cases based on search strategies. Randomization of the search space encourages emergence of heuristic solutions, fuzzy though informed transfers and further refinement of schema. We investigate the type of navigational structures/design resulting from creative reuse/refactoring and lean management; and whether there will be evidences of knowledge induction from randomized search scaffolded by Case-based Reasoning (CBR), which leads to heuristic transfer and learning. Examples from two courses carried out August-December 2017 within the participatory design-agile framework for engagement in Smart Cities are assessed for creative reuse regarding: a) people, process and tools; b) domain engineering; c) component mining and d) open source vs. systematic reuse. Findings confirm longitudinal insights: CBR-informed but emergent search leads to more efficient and higher quality heuristic transfer; such modelling/design/learning is scaffolded by four factors. © 2018 IEEE.",Creativity; Deeper learning; Design centering; Engineering management systems; Integration; Reuse; Technology,"Lee C.-S., Wong K.D.","Sunway University, Malaysia; Universiti Tunku Abdul Rahman, Malaysia; Daniel Wireless Software Pte. Ltd., Singapore, Singapore",2018.0,"Proceedings - 2018 IEEE 19th International Conference on Information Reuse and Integration for Data Science, IRI 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052290789&doi=10.1109%2fIRI.2018.00040&partnerID=40&md5=cc6df57f7cfa45ef864d2b126ccc69b7,10.1109/IRI.2018.00040,20230520-160000,20230521-044735,"['design-computational', 'thinking,', 'transfer', 'and', 'flavors', 'of', 'reuse:', 'scaffolds', 'to', 'information', 'and', 'data', 'science', 'for', 'sustainable', 'systems', 'in', 'smart', 'cities']",True,20230521-205332,,,,
436,scopus,The Internet of Things (IoT) upheaval: Overcoming management challenges,"Products based on the Internet of Things (IoT) concept use a combination of physical devices embedded with sensors, other electronic hardware, software and the Internet to utilize meaningful data. Recently there has been a boom in IoT projects, but many of these projects are failing. One of the major reasons for this failure is a lack of specific project management methodologies that appropriately deal with the complexity and interdisciplinary nature of IoT projects. This article looks at the existing literature to find business, management and technical issues with these projects. In order to find solutions to these issues, various IoT stakeholders were surveyed and asked about which tools, processes and management strategies they find most useful. Ultimately, the goal of this article is to provide detailed knowledge about the existing IoT management philosophies, tools and their challenges, pros and cons, and how to scale these to improve the success rate of such projects. © 2020 Editora Mundos Sociais. All rights reserved.",Agile; Big data; Cloud computing; Internet of Things; Project management; Sensors,"Prasher V.S., Onu S.","Harrisburg University of Science and Technology, Philadephia, PA, United States",2020.0,Journal of Modern Project Management,Editora Mundos Sociais,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109716237&doi=10.19255%2fJMPM02402&partnerID=40&md5=5b91f0d107dd70310af11b582ef71884,10.19255/JMPM02402,20230520-160000,20230521-044735,"['the', 'internet', 'of', 'things', '(iot)', 'upheaval:', 'overcoming', 'management', 'challenges']",False,20230521-205332,,,,
437,scopus,Use of Technologies and Sensors to Generate Intelligence in Inspection,"The human eye is able to see a small frequency range of electromagnetic radiation, the visible light. Technologies and sensors allow expand the detection and analysis of the electromagnetic spectrum in other bands of frequencies beyond vision, like airport X-rays, night vision goggles, radars and others. New technological frontiers offered at more affordable costs. Some sensors and technological platforms tested by TRANSPETRO / PETROBRAS were used in this comparative study, aiming monitoring and inspecting the pipeline right of way (row). Besides that, new computational technologies based on Big Data, Machine Learning facilitating analysis and helping in decision making for the manager providing opportunities of efficiency in the operation, management of the resources, reduction of risks for the operator and of agile form. All this combined with the monitoring and detection of terrain changes using independent platforms: satellites, remotely piloted aircraft (fixed wing and multi-rotor) and fixed balloons (aerostat). © 2019, Instituto Brasileiro de Petroleo. All rights reserved.",Change Detection; Geographic Information System (GIS); Georeference; Inspection; Knowledge; Remote Sensing; Technology,"Okamoto M., Fagundes F., Bullos J.","TRANSPETRO, Brazil",2019.0,"Rio Pipeline Conference and Exposition, Technical Papers",Instituto Brasileiro de Petroleo,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148863739&partnerID=40&md5=46140982f1731c5a4123f19d1b673382,,20230520-160000,20230521-044735,"['use', 'of', 'technologies', 'and', 'sensors', 'to', 'generate', 'intelligence', 'in', 'inspection']",False,20230521-205332,,,,
438,scopus,An Overview on Technical Characteristics of Blockchain Platforms,"The blockchain is an emerging technology which has a web of applications and potentials. A wide range of blockchain platforms has been developed to meet different technical and non-technical requirements and issues. Due to the diverse type of these platforms and the rapid evolution of blockchain technology, it would be necessary to have a big picture of existing blockchain platforms. Determining the characteristics of technology is an important factor to have such a total view and to standardize and expand technology. Despite the research has already been done on blockchain, due to the agile growth, rapid expansion and immaturity of this technology, determining its features is still challenging. In this paper, the results of studying and assessing the current state of blockchain technology from a technical point of view are presented. Furthermore, technical aspects of the blockchain are categorized as a two level taxonomy of characteristics and features. © 2019, Springer Nature Switzerland AG.",Blockchain technology; Cryptocurrency; Distributed systems; Taxonomy; Technical characteristic,"Moezkarimi Z., Nourmohammadi R., Zamani S., Abdollahei F., Golmirzaei Z., Arabsorkhi A.","Iran Telecommunication Research Center (ITRC), Tehran, Iran",2019.0,Communications in Computer and Information Science,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075829273&doi=10.1007%2f978-3-030-33495-6_20&partnerID=40&md5=d26519dcd96b0ef305bd5eeb377c69a2,10.1007/978-3-030-33495-6_20,20230520-160000,20230521-044735,"['an', 'overview', 'on', 'technical', 'characteristics', 'of', 'blockchain', 'platforms']",False,20230521-205332,,,,
439,scopus,A knowledge management and sharing business model for dealing with disruption: The case of Aramex,"The current study investigates the global logistics player Aramex and how it deals with disruptive technologies. In particular, it focuses on the unique business model that the case organisation has adopted and that allows for disruption to be managed through collaborative knowledge management. The study is qualitative and uses video, document/text and interview material for the case organisation. Data was analysed in two coding stages to derive at the categories/themes that have the most explanatory power. Aramex, a global logistics providers originating from the Middle East, is utilised to illustrate their business concept that determines and permeates their organisational culture. Disruptive technological innovations, such as Big Data Analytics, new hardware, smart apps that can connect individuals to the corporation in different contexts, feature strongly, to manage their collective knowledge of innovation and value creation. Disruption is embedded in their business model and an important part of their business operations. © 2017 Elsevier Inc.",Agile; Aramex; Asset-Light; Business Model; Disruptive Technologies; Knowledge sharing and management,"v. Alberti-Alhtaybat L., Al-Htaybat K., Hutaibat K.","King Abdulaziz University, PO Box 80200, Jeddah, 21589, Saudi Arabia; King Abdulaziz University, Jeddah, Saudi Arabia; Mutah University, Karak, Jordan",2019.0,Journal of Business Research,Elsevier Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044505908&doi=10.1016%2fj.jbusres.2017.11.037&partnerID=40&md5=924396d47d7f9464f9f670dcd434001a,10.1016/j.jbusres.2017.11.037,20230520-160000,20230521-044735,"['a', 'knowledge', 'management', 'and', 'sharing', 'business', 'model', 'for', 'dealing', 'with', 'disruption:', 'the', 'case', 'of', 'aramex']",False,20230521-205332,,,,
440,scopus,Confidential smart-sensing framework in the IoT era,"With the revolution of the Internet technology, smart-sensing applications and the Internet of Things (IoT) are coupled in critical missions. Wireless sensor networks (WSNs), for example, present the main enabling technology in IoT architectures and extend the spectrum of their smart applications. However, this technology has limited resources and suffers from several vulnerabilities and security issues. Since the wireless networks used by this technology are deployed in open areas, several challenges are faced by the service provider in terms of privacy and the quality of service. Encryption can be a good solution to preserve confidentiality and privacy, but it raises serious problems concerning time latency and performance. In this paper, we propose agile framework that enables authentication, confidentiality and integrity while collecting the sensed data by using elliptic curve cryptography. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.",Big data; Data delivery; Internet of Things (IoT); Routing; Wireless networks,"Al-Turjman F., Alturjman S.","Antalya Bilim University, Antalya, Turkey",2018.0,Journal of Supercomputing,Springer New York LLC,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051862655&doi=10.1007%2fs11227-018-2524-1&partnerID=40&md5=de953f617556dd5b39224c75a1e5ac5f,10.1007/s11227-018-2524-1,20230520-160000,20230521-044735,"['confidential', 'smart-sensing', 'framework', 'in', 'the', 'iot', 'era']",False,20230521-205332,,,,
441,scopus,Large scale quality transformation in hybrid development organizations – A case study,"As the software industry transitions to a subscription-based software-as-a-service (SaaS) model, software development companies are transforming to hybrid development organizations with increased adoption of Agile and Continuous Integration/ Continuous Delivery (CI/CD) development practices for newer products while continuing to use Waterfall methods for older products. This transformation is a huge undertaking impacting all aspects of the software development life cycle (SDLC), including the quality management system. This paper presents a case study of a large-scale transformation of a legacy quality management system to a modern system developed and implemented at Cisco Systems. The framework for this transformation is defined by six distinct areas: metrics, process, measurement, reporting, quality analytics, and culture & leadership. Our implementation leveraged recent advances in Machine Learning (ML), Artificial Intelligence (AI), connected data, integrated operations, and big data technologies to solve the challenges created by a hybrid software development organization. We believe this case study will help researchers and industry leaders understand the benefits and potential challenges of such sizeable transformations. © 2020 The Authors",Agile; Hybrid development organization; Quality management system; Quality transformation; Waterfall,"Pradhan S., Nanniyur V.","Cisco Systems, Inc. San JoseCA, United States",2021.0,Journal of Systems and Software,Elsevier Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092034144&doi=10.1016%2fj.jss.2020.110836&partnerID=40&md5=44e0e6c04d328c109864d878d01dbeee,10.1016/j.jss.2020.110836,20230520-160000,20230521-044735,"['large', 'scale', 'quality', 'transformation', 'in', 'hybrid', 'development', 'organizations', '–', 'a', 'case', 'study']",False,20230521-205332,,,,
442,scopus,Transformation of Software Project Management in Industry 4.0,"Digital technologies create not only new opportunities, but also form new business challenges caused by the integration of design, product development and business processes (from the moment an order is placed right through to outbound logistics), personalization and adaptive response on customer demands, real-time solving of tasks and problems, openness and access to resources for remote employees, accumulating big data for analytics and adaptive management with clouds. Modern software development in Industry 4.0 is complex process, both human-intensive, technology-intensive, knowledge- intensive and innovative-intensive. The modern software industry moves unrelentingly towards new methods for managing the ever-increasing complexity of software projects. The traditional project management methodology, which contains structured and standardized forms, and is focused on a greater certainty and planning horizon of several decades, no longer allows companies to fully adapt to the new opportunities, speeds and risks of Industry 4.0. The article systematizes new conceptual approaches and forms of projects management, including adaptive management methodologies. Agile-based digital project management creates new opportunities for business: accelerating decision-making and the rapid identification of incorrect approaches, effective cooperation between technical groups and business groups, creating a more attractive environment for collaboration and co-working, reducing the time to prepare documentation and others. The transformation of software project management is associated with dramatic changes, the risk of errors when updating products, diluting responsibility for product quality, and even problems with the companies reputation. Presently it seems to be more sustainable a combined or hybrid model of software projects management, combining traditional and Agile methodologies. © 2022, Springer Nature Switzerland AG.",Agile methodologies; Digital technologies; Industry 4.0; Project management; Software,"Babkin A., Safiullin A., Tronin V., Alexandrov A.","Peter the Great St. Petersburg Polytechnic University, St. Petersburg, Russian Federation; Ulyanovsk State Technical University, Severnyj Venec Street, 32, Ulyanovsk, 432027, Russian Federation",2022.0,Communications in Computer and Information Science,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137002891&doi=10.1007%2f978-3-031-14985-6_11&partnerID=40&md5=ecc824eed05bbb29b4a89b30dfd3b98c,10.1007/978-3-031-14985-6_11,20230520-160000,20230521-044735,"['transformation', 'of', 'software', 'project', 'management', 'in', 'industry', '4.0']",False,20230521-205332,,,,
443,scopus,Testing a Generalizable Machine Learning Workflow for Aquatic Invasive Species on Rainbow Trout (Oncorhynchus mykiss) in Northwest Montana,"Biological invasions are accelerating worldwide, causing major ecological and economic impacts in aquatic ecosystems. The urgent decision-making needs of invasive species managers can be better met by the integration of biodiversity big data with large-domain models and data-driven products. Remotely sensed data products can be combined with existing invasive species occurrence data via machine learning models to provide the proactive spatial risk analysis necessary for implementing coordinated and agile management paradigms across large scales. We present a workflow that generates rapid spatial risk assessments on aquatic invasive species using occurrence data, spatially explicit environmental data, and an ensemble approach to species distribution modeling using five machine learning algorithms. For proof of concept and validation, we tested this workflow using extensive spatial and temporal hybridization and occurrence data from a well-studied, ongoing, and climate-driven species invasion in the upper Flathead River system in northwestern Montana, USA. Rainbow Trout (RBT; Oncorhynchus mykiss), an introduced species in the Flathead River basin, compete and readily hybridize with native Westslope Cutthroat Trout (WCT; O. clarkii lewisii), and the spread of RBT individuals and their alleles has been tracked for decades. We used remotely sensed and other geospatial data as key environmental predictors for projecting resultant habitat suitability to geographic space. The ensemble modeling technique yielded high accuracy predictions relative to 30-fold cross-validated datasets (87% 30-fold cross-validated accuracy score). Both top predictors and model performance relative to these predictors matched current understanding of the drivers of RBT invasion and habitat suitability, indicating that temperature is a major factor influencing the spread of invasive RBT and hybridization with native WCT. The congruence between more time-consuming modeling approaches and our rapid machine-learning approach suggest that this workflow could be applied more broadly to provide data-driven management information for early detection of potential invaders. © Copyright © 2021 Carter, van Rees, Hand, Muhlfeld, Luikart and Kimball.",big data analytics; early detection and rapid response; invasive species; machine learning; remote sensing; species distribution modeling,"Carter S., van Rees C.B., Hand B.K., Muhlfeld C.C., Luikart G., Kimball J.S.","Numerical Terradynamic Simulation Group, WA Franke College of Forestry and Conservation, University of Montana, Missoula, MT, United States; Flathead Lake Biological Station, Division of Biological Sciences, University of Montana, Polson, MT, United States; U.S. Geological Survey, Northern Rocky Mountain Science Center, Glacier National Park, West Glacier, MT, United States; Department of Ecosystem and Conservation Sciences, Franke College of Forestry and Conservation, University of Montana, Missoula, MT, United States",2021.0,Frontiers in Big Data,Frontiers Media S.A.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118408448&doi=10.3389%2ffdata.2021.734990&partnerID=40&md5=a102b0cec20d8dc126e8393d6201778b,10.3389/fdata.2021.734990,20230520-160000,20230521-044735,"['testing', 'a', 'generalizable', 'machine', 'learning', 'workflow', 'for', 'aquatic', 'invasive', 'species', 'on', 'rainbow', 'trout', '(oncorhynchus', 'mykiss)', 'in', 'northwest', 'montana']",False,20230521-205332,,,,
444,scopus,"Toward a Demand-Driven, Collaborative Data Agenda for Adolescent Mental Health","Purpose: Existing datasets and research in the field of adolescent mental health do not always meet the needs of practitioners, policymakers, and program implementers, particularly in the context of vulnerable populations. Here, we introduce a collaborative, demand-driven methodology for the development of a strategic adolescent mental health research agenda. Ultimately, this agenda aims to guide future data sharing and collection efforts that meet the most pressing data needs of key stakeholders. Methods: We conducted a rapid literature search to summarize common themes in adolescent mental health research into a “topic map”. We then hosted two virtual workshops with a range of international experts to discuss the topic map and identify shared priorities for future collaboration and research. Results: Our topic map identifies 10 major themes in adolescent mental health, organized into system-level, community-level, and individual-level categories. The engagement of cross-sectoral experts resulted in the validation of the mapping exercise, critical insights for refining the topic map, and a collaborative list of priorities for future research. Discussion: This innovative agile methodology enables a focused deliberation with diverse stakeholders and can serve as the starting point for data generation and collaboration practices, both in the field of adolescent mental health and other topics. © 2022 Society for Adolescent Health and Medicine",Adolescents; Agenda setting; Crowdsourcing; Data science; Iinternational; Mental health; Questions; Research,"Verhulst S., Vidal Bustamante C.M., Carvajal-Velez L., Cece F., Requejo J.H., Shaw A., Winowatan M., Young A., Zahuranec A.J.","The Governance Lab, Brooklyn, New York, United States; UNICEF, New York, New York, United States",2023.0,Journal of Adolescent Health,Elsevier Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135293255&doi=10.1016%2fj.jadohealth.2022.05.027&partnerID=40&md5=df95335539c6bd37e12cd5a71e143d39,10.1016/j.jadohealth.2022.05.027,20230520-160000,20230521-044735,"['toward', 'a', 'demand-driven,', 'collaborative', 'data', 'agenda', 'for', 'adolescent', 'mental', 'health']",False,20230521-205332,,,,
445,scopus,DMISTA: Conceptual Data Model for Interactions in Support Ticket Administration,"Changing business models and dynamic markets in the globally connected world results in more and more complex system environments. The IT service infrastructure as enabler of innovative business models has to support these innovations by providing agile methods to quickly adapt to new use-cases. This underlines the need to manage the digitized environment systematically in order to foster efficiency. IT Service Management (ITSM) as a discipline evolved and now provides the framework to orchestrate the complexity in Information Technology. The activities, processes, and capabilities to maintain the portfolio are served by individuals, who interact with each other. There is an emphasized need for identifying, acquiring, organizing, storing, retrieving, and analyzing data related to human interaction processes to support finally the business processes. This paper proposes a conceptual data model to capture information about human interactions during support ticket administration (DMISTA). The presented model-structure and -requirements allow for efficient selection of appropriate data for various data science use-cases to understand and optimize business processes. The DMISTA supports different types of relationships (based on causality, joint cases, and joint activities) to enable efficient processing of specific analysis methods. The applicability of the model is shown based on a typical use-case. Copyright © 2022 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Conceptual Data Model; Data Flow Architectures; Data Mining; Enterprise Information System; IT Service Management; Requirements Engineering; Support Ticket Administration,"Mertens C., Nürnberger A.","Otto-von-Guericke-University, Universitätsplatz 2, Magdeburg, 39106, Germany",2022.0,"International Conference on Enterprise Information Systems, ICEIS - Proceedings","Science and Technology Publications, Lda",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140878533&doi=10.5220%2f0010999100003179&partnerID=40&md5=5531a23a8f56764ff8cc399de790bc85,10.5220/0010999100003179,20230520-160000,20230521-044735,"['dmista:', 'conceptual', 'data', 'model', 'for', 'interactions', 'in', 'support', 'ticket', 'administration']",False,20230521-205332,,,,
446,scopus,Digital twin framework for reconfigurable manufacturing systems (RMSs): design and simulation,"Faced with the global crisis of COVID-19 and the strong increase in customer demands, competition is becoming more intense between companies, on the one hand, and supply chains on the other. This competition has led to the development of new strategies to manage demand and increase market share. Among these strategies are the growing interest in sustainable manufacturing and the need for customizable products that create an increasingly complex manufacturing environment. Sustainable manufacturing and the need for customizable products create an environment of increased competition and constant change. Indeed, companies are trying to establish more flexible and agile manufacturing systems through several systems of reconfiguration. Reconfiguration contributes to an extension of the manufacturing system’s life cycle by modifying its physical, organizational and IT characteristics according to the changing market conditions. Due to the rapid development of new information technology (such as IoT, Big Data analytics, cyber-physical systems, cloud computing and artificial intelligence), digital twins have become intensively used in smart manufacturing. This paper proposes a digital twin design and simulation model for reconfigurable manufacturing systems (RMSs). © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Digital twin (DT); Generic model; Modular framework; Reconfigurable manufacturing system (RMS); SysML,"Kombaya Touckia J., Hamani N., Kermad L.","Laboratory Quartz, University of Paris 8, 140 Rue de la Nouvelle, Montreuil, 93100, France; University de Picardie Jules Verne, LTI-EA 3899, Amiens, 80025, France",2022.0,International Journal of Advanced Manufacturing Technology,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127265344&doi=10.1007%2fs00170-022-09118-y&partnerID=40&md5=97e6961ee6d43ea49909533c1e0d7bf9,10.1007/s00170-022-09118-y,20230520-160000,20230521-044735,"['digital', 'twin', 'framework', 'for', 'reconfigurable', 'manufacturing', 'systems', '(rmss):', 'design', 'and', 'simulation']",False,20230521-205332,,,,
447,scopus,Problems and Challenges of Educational and Methodological Activities in Higher Education in the Context of Digitalization of Education,"The article deals with the problems of educational and methodological activity in higher education institutions in the light of the digital transformation of education, analyzes the principles, technologies and tools that can be effectively applied to improve it and bring it into line with modern requirements of society. The existing challenges are explored: the challenge of big data; the challenge of project work; the challenge of distance and blended learning; the challenge of technological change; call for individualization. To respond to these challenges, based on a comparative analysis of educational and methodological activities at the university with related fields, the requirements for the system of educational and methodological support are formulated, including: automation of the management of educational and methodological documentation, integration of the documentation management system with the LMS, synchronization of online and offline education forms, the use of educational analytics, etc. Possible solutions to the identified problems are considered using the experience gained in the framework of mass online courses, as well as taking into account modern principles and trends in business process management. At the same time, such ideas as: patterns and antipatterns, lightweight (Agile) development methodologies adapted for educational and methodological activities, and management of educational and methodological documentation based on automated systems can be successfully involved. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Agile; Educational and methodological activities; Efficiency; Management; University,"Vitchenko O., Shcherbakov S.","Don State Technical University, Gagarin Square, 1, Rostov-on-Don, 344003, Russian Federation; Rostov State University of Economics, B. Sadovaya Str., 69, Rostov-on-Don, 344002, Russian Federation",2022.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119834970&doi=10.1007%2f978-3-030-80946-1_75&partnerID=40&md5=848228a0afb3a3c9502964ec514b1af9,10.1007/978-3-030-80946-1_75,20230520-160000,20230521-044735,"['problems', 'and', 'challenges', 'of', 'educational', 'and', 'methodological', 'activities', 'in', 'higher', 'education', 'in', 'the', 'context', 'of', 'digitalization', 'of', 'education']",False,20230521-205332,,,,
448,scopus,Agile polymorphic software-defined fog computing platform for mobile wireless controllers and sensors,"Softwarisation approaches in networks, storage systems, and smart devices aim to optimise costs and processes and bring new infrastructure definitions and functional values. A recent integration of wireless and mobile cyber-physical systems, with dramatically growing smart sensors, enable new types of pervasive smart and mobile urban surveillance infrastructures that open up new opportunities for boosting the accuracy, efficiency, and productivity of uninterrupted target tracking and situational awareness. Wireless sensors provide the tool for communications and security applications. They offer low-power, multi-functioning and computational capabilities. In this paper, we present a design and prototype of an efficient and effective fog system using light-weight agile software-defined control for mobile wireless nodes. Fog computing or edge computing, a recently proposed extension and complement for cloud computing, enables computing at the network edge in a smart device without outsourcing jobs to a remote cloud. We investigate an effective softwarisation approach in the Fog environment for dynamic big data driven, real-time urban surveillance tasks of uninterrupted target tracking. We address key technical challenges of node mobility to improve the system awareness. We built a preliminary proof-of-concept Light-weight controller architecture on both Android-and Linux-based smart devices and tested various collaborative scenarios among the mobile nodes. © 2019 Inderscience Enterprises Ltd.",Cloud computing; Fog computing; Internet of things; IoT; Network mobility; Network softwarisation; SDN; Software-defined network; Wireless sensors,"Gebre-Amlak H., Jabbari A.M.A., Chen Y., Choi B.-Y., Huang C.-T., Song S.","Department of Computer Science and Electrical Engineering, University of Missouri-Kansas City, Kansas City, MO, United States; Department of Electrical and Computer Engineering, Binghamton University, SUNY, Binghamton, NY, United States; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, United States",2019.0,International Journal of Internet Technology and Secured Transactions,Inderscience Publishers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073238544&doi=10.1504%2fIJITST.2019.102798&partnerID=40&md5=b948403acbf4a60678fa839551194064,10.1504/IJITST.2019.102798,20230520-160000,20230521-044735,"['agile', 'polymorphic', 'software-defined', 'fog', 'computing', 'platform', 'for', 'mobile', 'wireless', 'controllers', 'and', 'sensors']",False,20230521-205332,,,,
449,scopus,"Digital Healthcare: Current Trends, Challenges and Future Perspectives","Healthcare has become a prime global concern with a prompt need for delivering, managing and facilitating fast, reliable and efficient healthcare systems. Recently, the healthcare sector has witnessed a drastic converge towards digitized healthcare owing to the development, involvement, integration and dependency on the Information and Communication Technology (ICT) sector. Consequently, the medical sector is gearing up to become more upgraded, energetic, professional and agile for delivering, supporting and purveying ICT-enabled healthcare services. However, with the changing healthcare scenario particularly after COVID pandemic, there has been a prompt dependency on technology-enhanced healthcare irrespective of the geographical boundaries and time. This paper highlights the current trends in the healthcare sector with an in-depth analysis of global as well as Indian healthcare sector. It focuses on the importance of digital healthcare and its underlying technologies and platforms, entities involved; and applications. It also discusses the key challenges in offering digital healthcare as well as future perspectives. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Big data; Cloud computing; Digital healthcare; Electronic Health Records; Information and Communication Technology; Internet of Things; Technology Enhanced Healthcare,"Shilpa, Kaur T.","Lovely Professional University, Phagwara, Punjab, India",2022.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119821936&doi=10.1007%2f978-3-030-89880-9_48&partnerID=40&md5=8c1a1e172599267096e0e898ac1ed5c5,10.1007/978-3-030-89880-9_48,20230520-160000,20230521-044735,"['digital', 'healthcare:', 'current', 'trends,', 'challenges', 'and', 'future', 'perspectives']",False,20230521-205332,,,,
450,scopus,Organizational agility in industry 4.0: A systematic literature review,"Agility is the dynamic capability of an organization which helps it to manage a change and uncertainties in the environment. The purpose of this research is to review the literature from the perspective of agility in Industry 4.0. This paper systematically reviews 381 relevant articles from peer-reviewed academic journals in the period of the last five years. The results show that agility is important for an organization to adopt Industry 4.0 technologies as it helps companies to cope with the changes that arise along with the adoption of Industry 4.0 technologies. Further, it also indicates that by adopting Industry 4.0 technologies, companies can significantly enhance their agility capability into various aspects with different technologies. The technologies which enhance the agility are: smart manufacturing, internet of things, cyber-physical system, big data and analytics and cloud computing. On the other hand, important aspects of agility include supply chain, workforce, information system, facilities, management, manufacturing and technology agility. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Agile; Agility; Environment; I-4.0 ecosystem; Industry 4.0; Organizational agility,"Mrugalska B., Ahmed J.","Faculty of Engineering Management, Poznan University of Technology, Poznan, 60-965, Poland; Shaheed Zulfikar Ali Bhutto Institute of Science and Technology, Hyderabad Campus, Hyderabad, 17000, Pakistan",2021.0,Sustainability (Switzerland),MDPI AG,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111447575&doi=10.3390%2fsu13158272&partnerID=40&md5=54848766d96010631259bc2279e757da,10.3390/su13158272,20230520-160000,20230521-044735,"['organizational', 'agility', 'in', 'industry', '4.0:', 'a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
451,scopus,Advancing design and runtime management of AI applications with AI-SPRINT,"The adoption of Artificial intelligence (AI) technologies is steadily increasing. However, to become fully pervasive, AI needs resources at the edge of the network. The cloud can provide the processing power needed for big data, but edge computing is close to where data are produced and therefore crucial to their timely, flexible, and secure management. In this paper, we introduce the AI-SPRINT project, which will provide solutions to seamlessly design, partition, and run AI applications in computing continuum environments. AI-SPRINT will offer novel tools for AI applications development, secure execution, easy deployment, as well as runtime management and optimization: AI-SPRINT design tools will allow trading-off application performance (in terms of end-toend latency or throughput), energy efficiency, and AI models accuracy while providing security and privacy guarantees. The runtime environment will support live data protection, architecture enhancement, agile delivery, runtime optimization, and continuous adaptation. © 2021 IEEE.",AI; Cloud computing; Cloud trust security & privacy; Edge computing; Fog computing; Machine learning,"Sedghani H., Ardagna D., Matteucci M., Fontana G.A., Verticale G., Amarilli F., Badia R., Lezzi D., Blanquer I., Martin A., Wawruch K.","Politecnico di Milano, Italy; Barcelona Super Computing Center; Universitat Politècnica de València, Spain; Dresden University of Technology; 7Bulls",2021.0,"Proceedings - 2021 IEEE 45th Annual Computers, Software, and Applications Conference, COMPSAC 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115868821&doi=10.1109%2fCOMPSAC51774.2021.00216&partnerID=40&md5=224401cd6f2af139a96dd6ac3055632e,10.1109/COMPSAC51774.2021.00216,20230520-160000,20230521-044735,"['advancing', 'design', 'and', 'runtime', 'management', 'of', 'ai', 'applications', 'with', 'ai-sprint']",True,20230521-205332,,,,
452,scopus,Study of latencies in ThingSpeak,"IoT platforms play an important role on modern measurement systems because they allow the ingestion and processing of huge amounts of data (big data). Given the increasing use of these platforms, it is important to characterize their performance and robustness in real application scenarios. The paper analyzes the ThingSpeak platform by measuring the latencies associated to data packets sent to cloud and replied back, and by checking the consistency of the returned data. Several experiments were done considering different ways to access the platform: REST API, MQTT API, and MQTT broker alone. For each experiment, the methodology is explained, results are presented, and conclusions are extracted. The REST and MQTT APIs have similar performances, with roundtrip times between 1 s and 3 s. The MQTT broker alone is more agile, with roundtrip times below 250 ms. In all cases, the up and down links are far from being symmetric, with the uplink delay showing higher variance than the downlink delay. The obtained results can serve as a reference for other IoT platforms and provide guidelines for application development. © 2021 ASTES Publishers. All rights reserved.",Delay; IoT; Latency; Measurement; ThingSpeak,"Viegas V., Pereira J.M.D., Girão P., Postolache O.","CINAV - Escola Naval, Base Naval de Lisboa, Almada, 2810-001, Portugal; Instituto de Telecomunicações, Lisboa, 1049-001, Portugal; ESTSetúbal/IPS, Instituto Politécnico de Setúbal, Setúbal, 2914-508, Portugal; Instituto Superior Técnico, Universidade de Lisboa, Lisboa, 1049-001, Portugal; ISCTE - Instituto Universitário de Lisboa, Lisboa, 1649-026, Portugal",2021.0,"Advances in Science, Technology and Engineering Systems",ASTES Publishers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101026841&doi=10.25046%2faj060139&partnerID=40&md5=7c91638d2dc7e6abcf9e869bded39f8c,10.25046/aj060139,20230520-160000,20230521-044735,"['study', 'of', 'latencies', 'in', 'thingspeak']",False,20230521-205332,,,,
453,scopus,Design and implementation of operating management platform of dispatching and control cloud application based on container technology,"With the development of dispatching and control cloud platform, the existing virtual resource management mechanism has been unable to meet the requirements of rapid construction, agile delivery and convenient management of applications. The emergence of container technology provides a good solution. Combined with the Docker technology and the requirements of application lifecycle management, this paper proposes an operating management platform of dispatching and control cloud application based on container technology, introduces the overall architecture of the platform, designs and implements function modules including image management, application management and resource scheduling. With the platform designed in this paper, applications can realize the rapid construction, efficient deployment and convenient management, meet the requirements of flexible elastic expansion and directional scheduling, generally provide strong support for the development and use of the dispatching and control cloud platform. © 2020 IEEE.",Application management; Dispatching and control cloud; Docker technology; Resource scheduling,"Ma X., Yang Q., Tao L., Huang Y., Zhang P., Zhang Z.","Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology, China Electric Power Research Institute, Beijing, China; State Grid Jibei Electric Power Company, Beijing, China",2020.0,"Proceedings of 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence, ICIBA 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099277114&doi=10.1109%2fICIBA50161.2020.9276832&partnerID=40&md5=4b8d285637e60bf787467297644e0407,10.1109/ICIBA50161.2020.9276832,20230520-160000,20230521-044735,"['design', 'and', 'implementation', 'of', 'operating', 'management', 'platform', 'of', 'dispatching', 'and', 'control', 'cloud', 'application', 'based', 'on', 'container', 'technology']",True,20230521-205332,,,,
454,scopus,"A paradigm shift: Supply chain management 4.0 triple “A” method agile, anytime anywhere, always visible","Supply chain management (SCM) Strategy and design have innovate significantly in recent years. The buzzword currently when managing world-wide supply chains is design to growing(prenominal), incremental global complexity and volatility. Growing compression from fiscal nundinal and the impediment of increasing operating margins and working capital in this environment require efficient planning and execution of Supply Chain 4-0 “Supply Chain 4.0 - the relevancy of the Internet of Things, the application of sophisticated robotics, and the application of sophisticated analytics of big data in supply chain management: employment sensors in everything, Collaborative networks everywhere, automatize anything and everything, and analyse everything to significantly improve performance and customer satisfaction and available any time and from any where. Current paper is an effort to focus on the recent technological advances in supply chain management which is considered as Supply chain 4.0. The changes in ecosystem and benefits derived in in terms of efficiency, trackability, traceability, agility and managing bottom lines are significant. © BEIESP.",Agility traceability; Any time anywhere; IOT; Supply chain strategy; Visibility,Chandra A.,"Centre of Excellence Supply Chain, Universal Business School, Karjat, Mumbai, India",2019.0,International Journal of Engineering and Advanced Technology,Blue Eyes Intelligence Engineering and Sciences Publication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073421865&doi=10.35940%2fijeat.E1072.0785S319&partnerID=40&md5=ab18733282961094279c4ea6203261d3,10.35940/ijeat.E1072.0785S319,20230520-160000,20230521-044735,"['a', 'paradigm', 'shift:', 'supply', 'chain', 'management', '4.0', 'triple', '“a”', 'method', 'agile,', 'anytime', 'anywhere,', 'always', 'visible']",False,20230521-205332,,,,
455,scopus,Customer engagement technology in SME’s in Saudi Arabia: Does it ensue in disturbance or disruption,"Technology adaption is not a choice for business especially in today’s world. In fact businesses have to be embedded in the technology in order to be competitive. This paper focuses on how Small to Medium Enterprises (SME) will come up with the customer engagement technology in leveraging competitive advantage and remain customer centric organization. Challenges and complexities have doubled. Social media and big data have been in fore front in cruising business direction and pathways. SMEs also face the dilemma of budget, digitalization, strategic plan, growth etc. How SME’s will harness customer engagement technology with limited resources and capacity constraints. Strategic foresight backed by dynamic of business model best suited has to be saddled and galloped. The question is do SME’s are facing the music of a disturbed or disruptive milieu. Also, SME’s need to be innovative and agile in their business operations. Off late, in a macro environment especially, technology has made the difference in gauging the performance of businesses. SME’s also needed to explore experiment and engage various business models and shortlist the most suitable one. © 2019, Allied Business Academies. All rights reserved.",CET; Digitalization; SME’s; Transformation,"Faridi M.R., Malik A.","Prince Sattam Bin Abdulaziz University, Saudi Arabia",2019.0,International Journal of Entrepreneurship,Allied Business Academies,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065238659&partnerID=40&md5=29ceb36d0b7133ff410c513d991d3823,,20230520-160000,20230521-044735,"['customer', 'engagement', 'technology', 'in', 'sme’s', 'in', 'saudi', 'arabia:', 'does', 'it', 'ensue', 'in', 'disturbance', 'or', 'disruption']",False,20230521-205332,,,,
456,scopus,A Review Study on Cloud Computing Issues,"Cloud computing is the most promising current implementation of utility computing in the business world, because it provides some key features over classic utility computing, such as elasticity to allow clients dynamically scale-up and scale-down the resources in execution time. Nevertheless, cloud computing is still in its premature stage and experiences lack of standardization. The security issues are the main challenges to cloud computing adoption. Thus, critical industries such as government organizations (ministries) are reluctant to trust cloud computing due to the fear of losing their sensitive data, as it resides on the cloud with no knowledge of data location and lack of transparency of Cloud Service Providers (CSPs) mechanisms used to secure their data and applications which have created a barrier against adopting this agile computing paradigm. This study aims to review and classify the issues that surround the implementation of cloud computing which a hot area that needs to be addressed by future research. © 2018 Institute of Physics Publishing. All rights reserved.",Cloud; Computing; Issues; Security,"Kadhim Q.K., Yusof R., Mahdi H.S., Ali Al-Shami S.S., Selamat S.R.","Faculty of Information and Communication Technology, Universiti Teknikal Malaysia Melaka (UTeM), Hang Tuah Jaya, Durian Tunggal, Melaka, 76100, Malaysia; Institute of Technology Management and Entrepreneurship, Universiti Teknikal Malaysia Melaka (UTeM), Hang Tuah Jaya, Durian Tunggal, Melaka, 76100, Malaysia; University of Diyala, Basic Education College, Computer Science Department, Iraq",2018.0,Journal of Physics: Conference Series,Institute of Physics Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048357789&doi=10.1088%2f1742-6596%2f1018%2f1%2f012006&partnerID=40&md5=8ea73baea80227a4292bb7791260f1b2,10.1088/1742-6596/1018/1/012006,20230520-160000,20230521-044735,"['a', 'review', 'study', 'on', 'cloud', 'computing', 'issues']",False,20230521-205332,,,,
457,scopus,A Mathematics Pipeline to Student Success in Data Analytics through Course-Based Undergraduate Research,"This paper reports on Data Analytics Research (DAR), a course-based undergraduate research experience (CURE) in which undergraduate students conduct data analysis research on open real-world problems for industry, university, and community clients. We describe how DAR, offered by the Mathematical Sciences Department at Rensselaer Polytechnic Institute (RPI), is an essential part of an early low-barrier pipeline into data analytics studies and careers for diverse students. Students first take a foundational course, typically Introduction to Data Mathematics, that teaches linear algebra, data analytics, and R programming simultaneously using a project-based learning (PBL) approach. Then in DAR, students work in teams on open applied data analytics research problems provided by the clients. We describe the DAR organization which is inspired in part by agile software development practices. Students meet for coaching sessions with instructors multiple times a week and present to clients frequently. In a fully remote format during the pandemic, the students continued to be highly successful and engaged in COVID-19 research producing significant results as indicated by deployed online applications, refereed papers, and conference presentations. Formal evaluation shows that the pipeline of the single on-ramp course followed by DAR addressing real-world problems with societal benefits is highly effective at developing students' data analytics skills, advancing creative problem solvers who can work both independently and in teams, and attracting students to further studies and careers in data science. © The Author(s) & Dept. of Mathematical Sciences The University of Montana",Course-based undergraduate research; Data analytics; Data visualization; Linear algebra; Machine learning; Project-based learning; Undergraduate education,"Bennett K.P., Erickson J.S., Svirsky A., Seddon J.C.","Rensselaer Polytechnic Institute, United States; University of Rochester, United States",2022.0,Mathematics Enthusiast,University of Montana - ScholarWorks,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123603029&doi=10.54870%2f1551-3440.1573&partnerID=40&md5=48b08bb5783b0a13f0e5ed93cc7ab821,10.54870/1551-3440.1573,20230520-160000,20230521-044735,"['a', 'mathematics', 'pipeline', 'to', 'student', 'success', 'in', 'data', 'analytics', 'through', 'course-based', 'undergraduate', 'research']",False,20230521-205332,,,,
458,scopus,The ecology of open innovation units: adhocracy and competing values in public service systems,"There have been concerted efforts to encourage innovation and to foster a more innovative and “open” culture to government and public service institutions. Policy and service innovation labs constitute one part of a broader “open innovation” movement which also includes open data, behavioral insights, digital services, data science units, visualization capabilities, and agile and lean methods. This article argues that we need to step back and better understand these “ecologies” of innovation capabilities that have emerged across public service institutions, and to recognize that as fellow “innovation” traveling companions they collectively seek to transform the culture of government and public service institutions, producing more effective, efficient and tailored policies and services. This article introduces analytic frameworks that should help locate policy and innovation labs amidst these other innovating entities. First, it delineates the various units and initiatives which can be seen as committed to new ways of working and innovating in public service institutions, often relying on “open innovation” rhetoric and approaches. Second, it shows how–despite the diversity among these entities–they nevertheless share similar attributes as “adhocracies” and are located as part of a broader movement and class of organizations. Third, we locate these diverse OI entities amidst broader public service systems using the Competing Values Framework. Fourth, this article situates the challenges confronting OI units developing and sustaining or broadening niches in public service systems. Finally, it identifies future research questions to take up. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",adhocracies; competing values framework; policy labs; innovation labs; service labs; Open innovation; public service,"Lindquist E.A., Buttazzoni M.","School of Public Administration, University of Victoria, Government of British Columbia, Victoria, Canada; Development and Digital Services Section, Strategic Initiatives & Business Innovation Branch, Information, Innovation, & Technology Division, Ministry of Environment, Victoria, Canada",2021.0,Policy Design and Practice,UBM Exhibition Singapore PTE LTD,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110295652&doi=10.1080%2f25741292.2021.1941569&partnerID=40&md5=3fd2bee1bb3b42480aa6994131921cbd,10.1080/25741292.2021.1941569,20230520-160000,20230521-044735,"['the', 'ecology', 'of', 'open', 'innovation', 'units:', 'adhocracy', 'and', 'competing', 'values', 'in', 'public', 'service', 'systems']",False,20230521-205332,,,,
459,scopus,An agile sample maintenance approach for agile analytics,"Agile analytics can help organizations to gain and sustain a competitive advantage by making timely decisions. Approximate query processing (AQP) is one of the useful approaches in agile analytics, which facilitates fast queries on big data by leveraging a pre-computed sample. One problem such a sample faces is that when new data is being imported, re-sampling is most likely needed to keep the sample fresh and AQP results accurate enough. Re-sampling from scratch for every batch of new data, called the full re-sampling method and adopted by many existing AQP works, is obviously a very costly process, and a much quicker incremental sampling process, such as reservoir sampling, may be used to cover the newly arrived data. However, incremental update methods suffer from the fact that the sample size cannot be increased, which is a problem when the underlying data distribution dramatically changes and the sample needs to be enlarged to maintain the AQP accuracy. This paper proposes an adaptive sample update (ASU) approach that avoids re-sampling from scratch as much as possible by monitoring the data distribution, and uses instead an incremental update method before a re-sampling becomes necessary. The paper also proposes an enhanced approach (T-ASU), which tries to enlarge the sample size without re-sampling from scratch when a bit of query inaccuracy is tolerable to further reduce the sample update cost. These two approaches are integrated into a state-of-the-art AQP engine for an extensive experimental study. Experimental results on both real-world and synthetic datasets show that the two approaches are faster than the full re-sampling method while achieving almost the same AQP accuracy when the underlying data distribution continuously changes. © 2020 IEEE.",,"Zhang H., Zhang Y., He Z., Jing Y., Zhang K., Wang X.S.","Fudan University, School of Computer Science, Shanghai, China; Shanghai Key Laboratory of Data Science, Shanghai, China; Shanghai Institute of Intelligent Electronics and Systems, Shanghai, China",2020.0,Proceedings - International Conference on Data Engineering,IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085858288&doi=10.1109%2fICDE48307.2020.00071&partnerID=40&md5=4567c966073d629d2b2d15e27d9fdda3,10.1109/ICDE48307.2020.00071,20230520-160000,20230521-044735,"['an', 'agile', 'sample', 'maintenance', 'approach', 'for', 'agile', 'analytics']",True,20230521-205332,,,,
460,scopus,"Introducing a New Supply Chain Management Concept by Hybridizing TOPSIS, IoT and Cloud Computing","Supply Chain Management (SCM) is becoming more complex day by day. Functional silos on demand and supply fronts of products are required to be addressed to implement the de-coupling point in preferences of consumers involved in a supply chain for optimization of operational efficiency, and nowadays, it has become a challenge. Again, ‘Amazon Effect’ has forced others to reset their strategies for optimizing their effectiveness. For the optimization of operational efficiency, three technologies have been used in the present work. TOPSIS, one of the Multi-Criteria Decision Making (MCDM) Techniques, has been applied to provide preferences of consumers of different criteria against different attributes (products). For tracking the products on transit, Radio Frequency IDentification (RFID) method can be employed in SCM to collect and share data of event(s) or ‘Things’ for a broad range through the Internet of Things (IoT) application. Finally, Cloud Computing has been proposed to be applied for managing Big Data that will be generated during this entire process of SCM. The optimization method of a quick or agile SCM based on TOPSIS, IoT and Cloud Computing is discussed in detail in this work to benefit industries. © 2020, The Institution of Engineers (India).",Agile SCM; Amazon effect; Consumers’ preference; De-coupling; Functional silos; IoT; RFID; SCM; Supply chain; TOPSIS,"Chakraborty B., Das S.","Department of Mechanical Engineering, Kalyani Government Engineering College, Kalyani, Nadia, West Bengal  741235, India",2021.0,Journal of The Institution of Engineers (India): Series C,Springer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091689158&doi=10.1007%2fs40032-020-00619-x&partnerID=40&md5=ef143eaf00d93822d0b081ba8275d3e1,10.1007/s40032-020-00619-x,20230520-160000,20230521-044735,"['introducing', 'a', 'new', 'supply', 'chain', 'management', 'concept', 'by', 'hybridizing', 'topsis,', 'iot', 'and', 'cloud', 'computing']",False,20230521-205332,,,,
461,scopus,Lean 4.0: A new holistic approach for the integration of lean manufacturing tools and digital technologies,"Due to the highly dynamic and competitive environment, organizations are led to rethink their processes and strategies. In the industrial field, Lean Manufacturing (LM) is widely recognized as a traditional approach to eliminate waste in the value stream and ensure the efficiency of production processes. On the other hand, Industry 4.0 has recently emerged, incurring disruptive changes in manufacturing processes based on a technology-driven approach. The integration of these two philosophies to achieve organizational goals is interesting in order to guarantee competitiveness, especially for man-ufacturing companies. This paper proposed an integration of LM tools and technologies 4.0, considering the perspectives of the industrial field in the digital era. Based on a three-step methodology, which included technological and industrial mapping, it was identified 25 synergy points. From interactions of LM tools mainly with Big Data Analytics, The Cloud, Virtual Simulation and Augmented Reality, multi-level circular diagrams pointed out the main contributions of Just in Time 4.0 (JIT 4.0), Kaizen 4.0, Kanban 4.0, Poka-Yoke 4.0, Value Stream Mapping 4.0 (VSM 4.0) and Total Productive Maintenance 4.0 (TPM 4.0). Also, five attributes of Lean 4.0 were identified, highlighting the integration between pro-cesses, devices and stakeholders; waste minimization; and autonomous, pointing to gains for the organization from this holistic integration approach. © 2020 International Journal of Mathematical, Engineering and Management Sciences.",Digital technologies; Industry 4.0; Lean 4.0; Lean manufacturing; Value chain,"Valamede L.S., Akkari A.C.S.","Science and Technology Center, Mackenzie Presbyterian University, Campinas, Brazil",2020.0,"International Journal of Mathematical, Engineering and Management Sciences","International Journal of Mathematical, Engineering and Management Sciences",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087910642&doi=10.33889%2fIJMEMS.2020.5.5.066&partnerID=40&md5=3be43dfbf79b636ec22ddaadb2cb4ec0,10.33889/IJMEMS.2020.5.5.066,20230520-160000,20230521-044735,"['lean', '4.0:', 'a', 'new', 'holistic', 'approach', 'for', 'the', 'integration', 'of', 'lean', 'manufacturing', 'tools', 'and', 'digital', 'technologies']",False,20230521-205332,,,,
462,scopus,GELAB - The Cutting Edge of Grammatical Evolution,"The advent of cloud-based super-computing platforms has given rise to a Data Science (DS) boom. Many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration. Machine Learning (ML) tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike. Coupled with modern-day computing power, ML tools can be looked at as hammers that can deal with even the most stubborn nails. ML tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly. In order to keep pace with these requirements, a new enterprise, referred to as MLOps has blossomed in recent years. MLOps combines the process of ML and DS with an agile software engineering technique to develop and deliver solutions in a fast and iterative way. One of the key challenges to this is that ML and DS tools should be efficient and have better usability characteristics than were traditionally offered. In this paper, we present a novel software for Grammatical Evolution (GE) that meets both of these expectations. Our tool, GELAB, is a toolbox for GE in Matlab which has numerous features that distinguish it from existing contemporary GE software. Firstly, it is user-friendly and its development was aimed for use by non-specialists. Secondly, it is capable of hybrid optimization, in which standard numerical optimization techniques can be added to GE. We have shown experimentally that when hybridized with meta-heuristics GELAB has an overall better performance as compared with standard GE. © 2013 IEEE.",diversity; Grammatical evolution; hybrid optimization,"Gupt K.K., Youssef A., Murphy A., Raja M.A., Ryan C.","Department of Electrical and Electronic Engineering, Technological University of the Shannon: Midlands Midwest, Limerick, V94 EC5T, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, V94 T9PX, Ireland; Regulated Software Research Center (RSRC), Dundalk Institute of Technology (DkIT), Dundalk, A91 K584, Ireland; Department of Computer Science and Information Systems, University of Limerick, Limerick, V94 T9PX, Ireland; Complex Software Laboratory, University College Dublin, Belfield, Dublin 4, D04V1W8, Ireland; Department of Computers and Systems, Electronics Research Institute, Cairo, 12622, Egypt; The Irish Software Research Centre, University of Limerick, Lero, Limerick, V94 T9PX, Ireland",2022.0,IEEE Access,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128281046&doi=10.1109%2fACCESS.2022.3166115&partnerID=40&md5=db687e581de103111998e5af089ed65d,10.1109/ACCESS.2022.3166115,20230520-160000,20230521-044735,"['gelab', '-', 'the', 'cutting', 'edge', 'of', 'grammatical', 'evolution']",True,20230521-205332,,,,
463,scopus,Software Engineering for Machine Learning: A Case Study,"Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components-models may be 'entangled' in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations. © 2019 IEEE.",Artifical Intelligence; Data; Machine Learning; Process; Software Engineering,"Amershi S., Begel A., Bird C., DeLine R., Gall H., Kamar E., Nagappan N., Nushi B., Zimmermann T.","Microsoft Research, Redmond, WA, United States",2019.0,"Proceedings - 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072111655&doi=10.1109%2fICSE-SEIP.2019.00042&partnerID=40&md5=8c03592773800ea1ac1b5a71f9fae249,10.1109/ICSE-SEIP.2019.00042,20230520-160000,20230521-044735,"['software', 'engineering', 'for', 'machine', 'learning:', 'a', 'case', 'study']",True,20230521-205332,,,,
464,scopus,Applications of Machine Learning for Electronic Warfare Emitter Identification and Resource Management,"Electronic warfare (EW) operators face a multitude of challenges when performing single- and distributed-platform sensing and jamming tasks in increasingly dense and agile threat environments. During an engagement timeline, actions often must be taken quickly and based on the partial information available. Recently, the world has observed a boom in artificial intelligence, a suite of data-driven lateral technologies that has already disrupted multiple fields where autonomy and big data are key elements. Although it is not the solution to all EW tasks, artificial intelligence shows promise in offering potential solutions to improve EW efficiency and effectiveness through informed decision-making beyond the capability of a human operator. The Johns Hopkins University Applied Physics Laboratory (APL) Precision Strike Mission Area has invested in research and development in the specific EW tasks of emitter identification and autonomous resource allocation. This article presents promising results from these projects and describes recommended future work in these areas, as well as additional EW applications that may benefit from research in artificial intelligence. © 2022 John Hopkins University. All rights reserved.",,"Casterline K.A., Watkins N.J., Ward J.R., Li W., Thommana M.J.","Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States",2022.0,Johns Hopkins APL Technical Digest (Applied Physics Laboratory),John Hopkins University,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139472759&partnerID=40&md5=87a8ed598f82de1d1cb4c51b83ea463c,,20230520-160000,20230521-044735,"['applications', 'of', 'machine', 'learning', 'for', 'electronic', 'warfare', 'emitter', 'identification', 'and', 'resource', 'management']",False,20230521-205332,,,,
465,scopus,An Approach Based on Context and Situation Awareness to Improve Functional Safety in Complex Scenarios,"In the Fourth Industrial Revolution, industries are increasingly oriented toward real-time communication, Big Data analysis, human–machine cooperation, remote sensing, monitoring, process control, and autonomous equipment. Industry 4.0 will bring changes that will have an increasing impact on the management of companies’ economic development, the efficiency of workplaces, and the health of employees. In this scenario, which opens up new job opportunities such as agile work and remote control of industries, a key role is played by safety management. In this regard, functional safety plays a significant role, representing the engineering branch dealing with safety systems through electronic and information technologies. The concept of functional safety encompasses the overall safety of equipment and associated control systems. It depends on the proper functioning of the components responsible for mitigating the dangers arising from possible errors, failures, or random or systematic malfunctions. This paper proposes an approach for realizing an intelligent and highly scalable architecture for the supervision and control of plants and infrastructures. This system, characterized by a high level of context awareness, must be implemented through modern methodologies for describing, managing, and analyzing the context itself and risk forecasting. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Context awareness; Functional safety; Situation awareness,"Clarizia F., Colace F., De Santo M., Khan M., Lombardi M., Mosca R., Santaniello D.","DIIN, University of Salerno, Fisciano, SA, Italy; New York University Abu Dhabi, Abu Dhabi, United Arab Emirates",2022.0,Lecture Notes in Networks and Systems,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118972275&doi=10.1007%2f978-981-16-2102-4_11&partnerID=40&md5=adc6f87b5fcb1e584e438f285ccf2a8c,10.1007/978-981-16-2102-4_11,20230520-160000,20230521-044735,"['an', 'approach', 'based', 'on', 'context', 'and', 'situation', 'awareness', 'to', 'improve', 'functional', 'safety', 'in', 'complex', 'scenarios']",False,20230521-205332,,,,
466,scopus,Let's DO - Automotive platform for interoperability,"Developing automotive software applications is one of the most challenging and time-consuming activities in the automotive product development cycle. As of today, classical automotive software applications communicate exclusively using vehicle-specific communication protocols such as Controller Area Network (CAN) and FlexRay communication buses. Automotive applications communicate using transport layer messages that are defined and configured for each vehicle system (car model). This hard-wired design makes out-of-the box integrations between heterogeneous automotive products virtually impossible. It also renders automotive integration projects to digital world (smart devices, cloud, big data, IoT gadgets) hard to develop and maintain. We present in this paper Let's DO, a novel platform for interoperability and data exchange between different noncoherent products, systems and devices (both automotive and nonautomotive). Let's DO platform abstracts automotive communication protocol messages in a unified message standard transported over IP-based Ethernet networks enabling interoperability, quick prototyping, code reuse, and allowing more agile and efficient automotive software development cycles. © 2021 IEEE.",Automotive Software; Digital Transformation; Prototyping,"Elhakim R., Elqadi A., Torky M., Zayed M., Farag I., Agamawi M.","CDA Valeo, Innovation Department, Cairo, Egypt; Driving Systems and Functions, CDA Valeo, Cairo, Egypt; CDA Valeo, Innovation Department, Cairo, Egypt; Smart Service Center Valeo, Cairo, Egypt",2021.0,"Proceedings - 2021 4th International Conference on Information and Computer Technologies, ICICT 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111397555&doi=10.1109%2fICICT52872.2021.00054&partnerID=40&md5=f08db179d0f8c3c28f084a35737d04a5,10.1109/ICICT52872.2021.00054,20230520-160000,20230521-044735,"[""let's"", 'do', '-', 'automotive', 'platform', 'for', 'interoperability']",True,20230521-205332,,,,
467,scopus,A FIWARE-based IoT platform for enabling digital twins in a greenfield smart factory: an application study on a repurposed manufacturing line,"The recent advent of novel concepts and technologies, such as the Internet of Things (IoT), Big Data, Augmented Reality, Cloud Computing, and Artificial intelligence is transforming industry and society as a whole. Today, the large amount of data generated requires the design and development of new schemes for extracting valuable information. At the same time, The COVID-19 epidemic is posing unprecedented challenges for businesses, governments and companies around the world. This article refers to a company in Southern Italy that has decided to repurpose its production line to manufacture surgical masks. The situation is completely new for the firm, which does not have historical data. Therefore, the aim is to propose a FIWARE-based IoT architecture for supporting real-time data acquisition and enabling the creation of a digital twin. Preliminary results show that the proposed solution effectively helps the company in starting the new business. Furthermore, the use of digital twin-based real-time dashboards enables continuous and agile improvement in the management of warehouse, production and maintenance activities. © 2021, AIDI - Italian Association of Industrial Operations Professors. All rights reserved.",COVID-19 Pandemic; Digital Twin; FIWARE; Industry 4.0; Internet of Things,"Frangella J.L., Longo F., Mirabelli G., Padovano A., Solina V.","Department of Mechanical, Energy and Management Engineering, University of Calabria, CS, Arcavacata di Rende, Italy",2021.0,Proceedings of the Summer School Francesco Turco,AIDI - Italian Association of Industrial Operations Professors,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124656634&partnerID=40&md5=49a42418bca9f006c022836672400138,,20230520-160000,20230521-044735,"['a', 'fiware-based', 'iot', 'platform', 'for', 'enabling', 'digital', 'twins', 'in', 'a', 'greenfield', 'smart', 'factory:', 'an', 'application', 'study', 'on', 'a', 'repurposed', 'manufacturing', 'line']",False,20230521-205332,,,,
468,scopus,Impact of Industry 4.0 Concept on the Levers of Lean Manufacturing Approach in Manufacturing Industries,"Industrial companies looking for permanent performance are facing challenges of reducing production costs, reducing customer delivery delays and improving their quality products. These lead them to improve their responsiveness and flexibility to meet the varying needs of customers to cope with these constraints. Several industrial companies have adopted the lean manufacturing (LM) concept based on the Toyota production system to reduce wastage according to a methodical and structured approach that has given this proof for several years. This approach currently finds its limits, since it is based on static data. A dynamic approach, real-time data on customer needs and production performance will readjust the levers of lean manufacturing to improve its efficiency. This paper aims to show that the concept Industry 4.0 incarnates the lean manufacturing approach by feeding a real-time data and a real-time analysis of Big Data in a Cyber Physical Production System (CPPS), in order to improve decision-making and re-adjust real time levers of the lean manufacturing approach. © The Authors 2021. Published by Penerbit UMP. This is an open access article under the CC BY license.",Industrial performance; Industry 4.0; Lean manufacturing; Productivity,"Ghouat M., Haddout A., Benhadou M.","Laboratory of Industrial Management, Energy and Technology of Plastic and Composites Materials, Hassan II University – ENSEM Casablanca, Morocco",2021.0,International Journal of Automotive and Mechanical Engineering,Universiti Malaysia Pahang,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104708817&doi=10.15282%2fijame.18.1.2021.11.0646&partnerID=40&md5=a4770a6563fba8197cb91f14774698e8,10.15282/ijame.18.1.2021.11.0646,20230520-160000,20230521-044735,"['impact', 'of', 'industry', '4.0', 'concept', 'on', 'the', 'levers', 'of', 'lean', 'manufacturing', 'approach', 'in', 'manufacturing', 'industries']",False,20230521-205332,,,,
469,scopus,Managing the professional skills of the future: A model to support competence management,"Big data and digitalization are transforming the world of work, introducing an epochal change. This wild digital phenomenon, also thanks to the introduction of 4.0 industry, is changing the relationship between workers and machines and, if properly governed, can represent a great chance for companies to attain advantages and create value. This stimulating scenario embodies a huge opportunity for HRM. It provides impulses to improve positive social change, as well as develop and adopt new digital systems and innovative organizational solutions. HR professionals can help employees use digital 4.0 modes to manage, organize and drive change. To address this opportunity, HRM 4.0 has to collaborate with IT, spread an agile mind to execute projects, adopt design thinking and use integrated analytics. This paper presents an organizational model based on a technology platform designed for business workers and able to fill the gap between own skills and the request from the labour market. A theoretical framework is proposed, based on an innovative integrated system able to implement the entire workflow of evaluation, selection and training of candidates with the final aims of allowing companies to identify, manage and build business workers’ competencies. We conclude presenting opportunities and challenges for future studies. © 2019 Fondazione Gerardo Capriglione Onlus. All rights reserved.",,"Palmi P., Errico F., Fortunato L., Fietze S.","Department of Organization and Business Management, University of Salento, Italy; University of Salento, Italy; University of Salento, Italy; Department of Entrepreneurship and Organization, University of Southern Denmark, Syddansk University, Denmark",2020.0,Law and Economics Yearly Review,Fondazione Gerardo Capriglione Onlus,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096288091&partnerID=40&md5=3de39ec06c89e9c9e08ded583462351e,,20230520-160000,20230521-044735,"['managing', 'the', 'professional', 'skills', 'of', 'the', 'future:', 'a', 'model', 'to', 'support', 'competence', 'management']",False,20230521-205332,,,,
470,scopus,Securing Distributed SDN Controller Network from Induced DoS Attacks,"With the escalation in security breaches on organizations and institutions that store, maintain and work with critical data, there is a need for a security-enhancing and risk-mitigating solution that works on the fly and is feasible to implement. Software Defined Networks is a networking paradigm that makes the network agile by disaggregating hardware and software. SDN helps enhance security with the help of micro-segmentation. The controller maintains a central view of the network, and its ability to monitor and store network information helps optimize routing. The centralization nature of the controller makes it vulnerable to DoS attacks which can be catastrophic for network functioning. The objective of this paper is to secure the distributed SDN controller architecture against DoS attacks. The proposed architecture is robust, scalable, and uses Big Data techniques to process streams of network traffic in real-time and Machine Learning to detect and mitigate DoS attacks. © 2019 IEEE.",DoS Attack; Kafka; RyuController; Software Defined Networks; Storm; Zodiac FX,"Shravanya G., Swati N.H., Rustagi R.P., Sharma O.","Department of Computer Science and Engineering, PES University, Bengaluru, India; Department of Computer Science and Engineering, KS Institute of Technology, Bengaluru, India",2019.0,"Proceedings - 2019 8th IEEE International Conference on Cloud Computing in Emerging Markets, CCEM 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083672088&doi=10.1109%2fCCEM48484.2019.000-4&partnerID=40&md5=335601caca67048424305ace9b6abbb9,10.1109/CCEM48484.2019.000-4,20230520-160000,20230521-044735,"['securing', 'distributed', 'sdn', 'controller', 'network', 'from', 'induced', 'dos', 'attacks']",True,20230521-205332,,,,
471,scopus,Determining Viability of Deep Learning on Cybersecurity Log Analytics,"The Department of Defense currently maintains a network known as the Defense Research Engineering Network (DREN), which provides various Department of Defense (DoD) sites across the nation connectivity to HPC resource centers. To ensure the security of the DREN system, a defense system known as the Cybersecurity Environment for Detection, Analysis, and Reporting (CEDAR) was created. CEDAR contains a variety of cybersecurity sensors, which constantly monitor and record real time network activity on the DREN. over time, CEDAR has accumulated massive quantities of valuable cybersecurity data, which necessitates a form of automation in the process of reviewing this data. We propose the application of deep learning techniques to CEDAR data in an attempt to automatically detect potentially malicious activity in a more agile and adaptable manner. These deep learning techniques can be carried out in a high performance computing (HPC) environment, allowing for the rapid utilization of large amounts of data. Our most effective model is able to classify CEDAR alerts as malicious with an accuracy sufficient to greatly reduce human analyst workloads. © 2018 IEEE.",Cybersecurity; Deep Learning; High Performance Computing,"Lorenzen C., Agrawal R., King J.","Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS, United States",2019.0,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062613262&doi=10.1109%2fBigData.2018.8622165&partnerID=40&md5=c0ba9d03e137d2c9d1e8293d37977523,10.1109/BigData.2018.8622165,20230520-160000,20230521-044735,"['determining', 'viability', 'of', 'deep', 'learning', 'on', 'cybersecurity', 'log', 'analytics']",True,20230521-205332,,,,
472,scopus,Data agility through clustered edge computing and stream processing,"The Internet of Things is underpinned by the global penetration of network-connected smart devices continuously generating extreme amounts of raw data to be processed in a timely manner. Supported by Cloud and Fog/Edge infrastructures – on the one hand, and Big Data processing techniques – on the other, existing approaches, however, primarily adopt a vertical offloading model that is heavily dependent on the underlying network bandwidth. That is, (constrained) network communication remains the main limitation to achieve truly agile IoT data management and processing. This paper aims to bridge this gap by defining Clustered Edge Computing – a new approach to enable rapid data processing at the very edge of the IoT network by clustering edge devices into fully functional decentralized ensembles, capable of workload distribution and balancing to accomplish relatively complex computational tasks. This paper also proposes ECStream Processing that implements Clustered Edge Computing using Stream Processing techniques to enable dynamic in-memory computation close to the data source. By spreading the workload among a cluster of collocated edge devices to process data in parallel, the proposed approach aims to improve performance, thereby supporting agile data management. The experimental results confirm that such a distributed in-memory approach to data processing at the very edge of an IoT network can outperform currently adopted Cloud-enabled architectures, and has the potential to address a wide range of IoT-related data-intensive time-critical scenarios. © 2018 John Wiley & Sons, Ltd.",cloud computing; clustered edge computing; data agility; edge computing; internet of things; stream processing,"Dautov R., Distefano S., Bruneo D., Longo F., Merlino G., Puliafito A.","Kazan Federal University, Kazan, Russian Federation; University of Messina, Messina, Italy",2021.0,Concurrency and Computation: Practice and Experience,John Wiley and Sons Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057991232&doi=10.1002%2fcpe.5093&partnerID=40&md5=3f1f3be9f322aec71cd2a03d6b4d9e5e,10.1002/cpe.5093,20230520-160000,20230521-044735,"['data', 'agility', 'through', 'clustered', 'edge', 'computing', 'and', 'stream', 'processing']",False,20230521-205332,,,,
473,scopus,Requirement elicitation framework for child learning application - A research plan,"Requirements elicitation are the initial stages in requirements engineering and are crucial stages. Failure in the steps of requirements elicitation can lead to a lack of definition of user needs for the application so that it has an impact on the quality and usability of the software produced. That will also affect the application of children's education, where without involving children in the elicitation process, it can make the software built not by the age development needs of the child. Failure in requirements elicitation occurs because of lack of knowledge of analysts in communicating and choosing elicitation techniques. Both components have a close relationship with the type of users who will become respondents. Nowadays, requirements elicitation framework tends to pay more attention to adults and parents, while for children it is still not found. Children have different characteristics with adults and parents, so it needs to be considered in carrying out approaches or techniques in performing elicitation. The selection of elicitation techniques that are not by the characteristics of children can cause failure in exploring the needs of children for child learning applications built. Based on these problems, we need a requirements elicitation framework in children's education applications. The requirements for the elicitation framework are expected to make it easier for child learning application developers to get application requirements that are appropriate for the child's developmental age. © 2019 Association for Computing Machinery.",Agile method; Child learning application; Framework; Requirements elicitation; Requirements engineering; Usability,"Sabariah M.K., Santosa P.I., Ferdiana R.","Indonesia School of Computing, Telkom University, Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Bandung, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia",2019.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063598007&doi=10.1145%2f3305160.3305195&partnerID=40&md5=804003ea103df9dd1d349864781fdaaa,10.1145/3305160.3305195,20230520-160000,20230521-044735,"['requirement', 'elicitation', 'framework', 'for', 'child', 'learning', 'application', '-', 'a', 'research', 'plan']",False,20230521-205332,,,,
474,scopus,"iOntoBioethics: A Framework for the Agile Development of Bioethics Ontologies in Pandemics, Applied to COVID-19","Background: Few ontological attempts have been reported for conceptualizing the bioethics domain. In addition to limited scope representativeness and lack of robust methodological approaches in driving research design and evaluation of bioethics ontologies, no bioethics ontologies exist for pandemics and COVID-19. This research attempted to investigate whether studying the bioethics research literature, from the inception of bioethics research publications, facilitates developing highly agile, and representative computational bioethics ontology as a foundation for the automatic governance of bioethics processes in general and the COVID-19 pandemic in particular. Research Design: The iOntoBioethics agile research framework adopted the Design Science Research Methodology. Using systematic literature mapping, the search space resulted in 26,170 Scopus indexed bioethics articles, published since 1971. iOntoBioethics underwent two distinctive stages: (1) Manually Constructing Bioethics (MCB) ontology from selected bioethics sources, and (2) Automatically generating bioethics ontological topic models with all 26,170 sources and using special-purpose developed Text Mining and Machine-Learning (TM&ML) engine. Bioethics domain experts validated these ontologies, and further extended to construct and validate the Bioethics COVID-19 Pandemic Ontology. Results: Cross-validation of the MCB and TM&ML bioethics ontologies confirmed that the latter provided higher-level abstraction for bioethics entities with well-structured bioethics ontology class hierarchy compared to the MCB ontology. However, both bioethics ontologies were found to complement each other forming a highly comprehensive Bioethics Ontology with around 700 concepts and associations COVID-19 inclusive. Conclusion: The iOntoBioethics framework yielded the first agile, semi-automatically generated, literature-based, and domain experts validated General Bioethics and Bioethics Pandemic Ontologies Operable in COVID-19 context with readiness for automatic governance of bioethics processes. These ontologies will be regularly and semi-automatically enriched as iOntoBioethics is proposed as an open platform for scientific and healthcare communities, in their infancy COVID-19 learning stage. iOntoBioethics not only it contributes to better understanding of bioethics processes, but also serves as a bridge linking these processes to healthcare systems. Such big data analytics platform has the potential to automatically inform bioethics governance adherence given the plethora of developing bioethics and COVID-19 pandemic knowledge. Finally, iOntoBioethics contributes toward setting the first building block for forming the field of “Bioethics Informatics”. © Copyright © 2021 Odeh, Kharbat, Yousef, Odeh, Tbaishat, Hakooz, Dajani and Mansour.",agile framework; bioethics; bioethics informatics; bioethics ontology; COVID-19; design science research methodology; iOntoBioethics; pandemic,"Odeh M., Kharbat F.F., Yousef R., Odeh Y., Tbaishat D., Hakooz N., Dajani R., Mansour A.","Cancer Care Informatics Programme, King Hussein Cancer Center (KHCC), Amman, Jordan; Faculty of Environment and Technology, University of the West of England, Bristol, United Kingdom; Software Engineering and Computer Science Department, College of Engineering, Al Ain University, Abu Dhabi, United Arab Emirates; Computer Information Systems Department, King Abdullah II School for Information Technology (KASIT), The University of Jordan, Amman, Jordan; Software Engineering Department, Faculty of Information Technology (FIT), Applied Science Private University, Amman, Jordan; Library and Information Science Department, University of Jordan, Amman, Jordan; Department of Biopharmaceutics and Clinical Pharmacy, School of Pharmacy, University of Jordan, Amman, Jordan; Department of Biology and Biotechnology, Hashemite University, Zarqa, Jordan; Jepson School of Leadership, University of Richmond, Richmond, VA, United States",2021.0,Frontiers in Medicine,Frontiers Media S.A.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107441290&doi=10.3389%2ffmed.2021.619978&partnerID=40&md5=68b74e6b38812d79fdb6b636f2749ca8,10.3389/fmed.2021.619978,20230520-160000,20230521-044735,"['iontobioethics:', 'a', 'framework', 'for', 'the', 'agile', 'development', 'of', 'bioethics', 'ontologies', 'in', 'pandemics,', 'applied', 'to', 'covid-19']",False,20230521-205332,,,,
475,scopus,Dynamic allocation of traffic light plans as a traffic reduction strategy,"The city of Medellin, like other cities in the world, is facing major mobility issues caused by the accelerated growth of the vehicle fleet in the last decade. The efficient operation of the traffic light network plays a fundamental role in the search for solutions to achieve an agile, comfortable, safe and sustainable mobility. For this reason, the Municipal Administration has made important investments in its updating and technological modernization that allows actions for a better performance. Currently the traffic lights of the city are operated by classic programming models, mostly at fixed times in different time zones and others in modes actuated and semi-actuated as scheduled, without responding to changing traffic conditions, making it necessary to search for autonomous traffic regulation systems that adapt their behavior according to the conditions. While adaptive systems based on a wide sensorisation for obtaining information online are an alternative, their current costs of implementation, maintenance and operation, has led to evaluate the new global trends in terms of information capture, storage, processing and use in the optimization of the operation of the traffic signal network. This is how the city of Medellin has been consolidating a Big Data storage system and has developed a technological platform capable of receiving it and executing actions on the traffic light system when it identifies that there are events that generate traffic variations different from normal or daily conditions, which has allowed to improve mobility conditions according to the results obtained, which will be detailed later. This first part of this document is an introduction of the different modes of operation of a traffic light network commonly used; the second part contains a brief description of the city’s traffic light network; in the third part, the collaborative data systems are studied; the fourth part develops the solution scheme adopted by Medellin based on the collaborative data system; subsequently the results of the implementation of the system in a specific crossroads of the city are presented; and it ends with some brief conclusions in this regard. © 2018 Institution of Engineering and Technology. All rights reserved.",Big data; Collaborative; Jams optimization; Traffic light; WAZE,"Suarez M.L., Alvarez L.E., Camacho P.A., Marin L.C., Vasquez B., Gutierrez G., Aranzazu R.A., Carranza M., Montoya F.G., Valdes A., Gonzalez C., Jaramillo M., Henao S.","Engineering and Traffic Light Operation Center (CIOS), Cra 80 No 65-223, Colombia, Colombia",2018.0,IET Seminar Digest,Institution of Engineering and Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061344061&partnerID=40&md5=0bb863a14b3bab8898fffc62d3f9fd8d,,20230520-160000,20230521-044735,"['dynamic', 'allocation', 'of', 'traffic', 'light', 'plans', 'as', 'a', 'traffic', 'reduction', 'strategy']",True,20230521-205332,,,,
476,scopus,"Digital assurance for oil and gas 4.0: Role, implementation and case studies","“Barrel through Byte” transformation is the new revolution in the oil and gas industry. Technologies such as the Internet of Things (IoT), Cloud, Blockchain, Data Analytics, Big Data, Robotics (autonomous vehicles, drones, RPA), Artificial Intelligence (AI), Machine Learning (ML), Digital Twins, AR/VR has catalyzed this transformation. For instance, the deployment of AI systems to help optimize Bakken Shale wells running on SRP's, implementation of Blockchain drilling for well construction activities, VR/AR visualization of Canada SAGD oilfields, proactive adjustments to ESP using real-time data analytics in Kazakhstan gas condensate wells are some of the recent transformations the industry has witnessed. As the Oil and Gas 4.0 simplifies, modernizing and securing the legacy environments for the new digital era, a robust Digital Assurance is essential. Digital Assurance is an exclusive digital service employing an end-to-end ecosystem approach with intelligent and automated processes to gain quality and speed for promoting faster business, technology change and better customer experience. The service shall offer evaluation of new tools and testing environments such as the cloud, software testing tools, mobile environment, and application performance. Digital Assurance is more than the traditional QA; the evolution of Agile methods with DevOps tools and techniques for software/simulator development and testing has made its deployment quick, safe and reliable. The end-to-end testing process serves to simulate the real user on-field scenarios and validate the system under test and its components for integration and data integrity. Leveraging Digital 2.0 transformations, smart oilfields (by implementing autonomous robots) can eliminate human intervention in potential risk areas and thereby providing a safe, compliant workplace for engineers, managers, crewmembers and other personnel. Especially, robotics has potential applications in inspection, maintenance, and safety operations. In alignment with this, our personalized robotic testing solution can automate various peripheral devices and has resulted in reduced testing cycle time up to 30% and cost by 40%. The solution enables automated end-to-end IoT device interactions spanning smart devices such as camera, thermostat, sensors and web applications in oil and gas facilities. Adding, our various other in-house digital framework and solutions such as Big Data validation framework, cloud-based on-demand testing, and automated test scriptwriters have eased digital transformations. Digital Assurance by rigorous testing practices can also immune oil and gas majors from the cyber threats for the cloud (grid, storage) and blockchain. To overcome such compromises in hardware failure, our smart and innovative IoT Test Workbench solution for integration testing can reduce the hardware dependency up to 100%. This novel solution virtualizes Rapid IoT Solution development replacing smart devices during testing under extreme conditions such as HPHT wells and permafrost conditions in the Arctic Circle. Furthermore, Digital Assurance compliance coupled with digitalization knowledge and experience can play a paramount role in averting disasters such as GOM deepwater explosion and Montara oil spill in the future. Copyright 2019, Society of Petroleum Engineers",,"Baskaran V., Singh S., Reddy V., Mohandas S.",Cognizant Worldwide Ltd,2019.0,"Society of Petroleum Engineers - SPE/IATMI Asia Pacific Oil and Gas Conference and Exhibition 2019, APOG 2019",Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088761394&doi=10.2118%2f196292-ms&partnerID=40&md5=3e0e581cfcd3fa8dbd8d2781a5b40bc0,10.2118/196292-ms,20230520-160000,20230521-044735,"['digital', 'assurance', 'for', 'oil', 'and', 'gas', '4.0:', 'role,', 'implementation', 'and', 'case', 'studies']",False,20230521-205332,,,,
477,scopus,"Lessons Learned From Interdisciplinary Efforts to Combat COVID-19 Misinformation: Development of Agile Integrative Methods From Behavioral Science, Data Science, and Implementation Science","Background: Despite increasing awareness about and advances in addressing social media misinformation, the free flow of false COVID-19 information has continued, affecting individuals’ preventive behaviors, including masking, testing, and vaccine uptake. Objective: In this paper, we describe our multidisciplinary efforts with a specific focus on methods to (1) gather community needs, (2) develop interventions, and (3) conduct large-scale agile and rapid community assessments to examine and combat COVID-19 misinformation. Methods: We used the Intervention Mapping framework to perform community needs assessment and develop theory-informed interventions. To supplement these rapid and responsive efforts through large-scale online social listening, we developed a novel methodological framework, comprising qualitative inquiry, computational methods, and quantitative network models to analyze publicly available social media data sets to model content-specific misinformation dynamics and guide content tailoring efforts. As part of community needs assessment, we conducted 11 semistructured interviews, 4 listening sessions, and 3 focus groups with community scientists. Further, we used our data repository with 416,927 COVID-19 social media posts to gather information diffusion patterns through digital channels. Results: Our results from community needs assessment revealed the complex intertwining of personal, cultural, and social influences of misinformation on individual behaviors and engagement. Our social media interventions resulted in limited community engagement and indicated the need for consumer advocacy and influencer recruitment. The linking of theoretical constructs underlying health behaviors to COVID-19–related social media interactions through semantic and syntactic features using our computational models has revealed frequent interaction typologies in factual and misleading COVID-19 posts and indicated significant differences in network metrics such as degree. The performance of our deep learning classifiers was reasonable, with an F-measure of 0.80 for speech acts and 0.81 for behavior constructs. Conclusions: Our study highlights the strengths of community-based field studies and emphasizes the utility of large-scale social media data sets in enabling rapid intervention tailoring to adapt grassroots community interventions to thwart misinformation seeding and spread among minority communities. Implications for consumer advocacy, data governance, and industry incentives are discussed for the sustainable role of social media solutions in public health. © 2023 JMIR Publications Inc. All rights reserved.",community engagement; COVID-19; deep learning; health belief model; misinformation; social media,"Myneni S., Cuccaro P., Montgomery S., Pakanati V., Tang J., Singh T., Dominguez O., Cohen T., Reininger B., Savas L.S., Fernandez M.E.","School of Biomedical Informatics, The University of Texas Health Science Center, Houston, TX, United States; Department of Health Promotion & Behavioral Sciences, School of Public Health, The University of Texas Health Science Center, Houston, TX, United States; Center for Health Promotion and Prevention Research, School of Public Health, The University of Texas Health Science Center, Houston, TX, United States; The University of Texas Health Science Center, Tyler, TX, United States; Department of Biomedical Informatics and Medical Education, The University of Washington, Seattle, WA, United States; School of Public Health, Brownsville Regional Campus, The University of Texas Health Science Center, Brownsville, TX, United States",2023.0,JMIR Infodemiology,JMIR Publications Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151819555&doi=10.2196%2f40156&partnerID=40&md5=14d65bf9bf9924be4c23d66a42260135,10.2196/40156,20230520-160000,20230521-044735,"['lessons', 'learned', 'from', 'interdisciplinary', 'efforts', 'to', 'combat', 'covid-19', 'misinformation:', 'development', 'of', 'agile', 'integrative', 'methods', 'from', 'behavioral', 'science,', 'data', 'science,', 'and', 'implementation', 'science']",False,20230521-205332,,,,
478,scopus,Sustainable Industry 4.0 Methodology for Improving SMEs’ Performance,"Industry 4.0 concepts have been elaborated in response to an increasing rate of customized demands, in order to keep high industrial performance for enterprises. These concepts are based on the introduction of new technologies such as collaborative robotics, artificial intelligence, big data or internet of things, in the manufacturing performance improvement. Indeed, the addition of organizational methods in the improvement contributes to the company's positive digital transformation. For instance, lean manufacturing, with reduction of wastes and value-added management, corresponds to a methodology that could be exploited for increasing the performance of SMEs. This paper focuses on how to put sustainability as the kernel of company digital transformation and new technologies as a support for humans in the future manufacturing. Through a use case, this paper presents the concepts of smart manufacturing and flexibility 4.0 for sustainably optimizing the company performance. After a literature review on industry 4.0, flexibilization 4.0, smart manufacturing and lean manufacturing, the concepts developed in this frame will be exposed. Then, the intelligent system being developed for supporting the SME digital transformation will be presented. An application in the electronic card production sector will be shown. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Cobotics; Flexibilization; Industry 4.0; Industry of Engineering; Robotics,"Soudé C., Dossou P.-E., Laouenan G., Duquenne B.","Icam, Site of Grand Paris Sud, Lieusaint, 77127, France; University of Gustave Eiffel, Champs-Sur-Marne, Paris, 77420, France",2023.0,Lecture Notes in Mechanical Engineering,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148249269&doi=10.1007%2f978-3-031-17629-6_44&partnerID=40&md5=af6b6f5c58b26c206d42f2e7bcf84b29,10.1007/978-3-031-17629-6_44,20230520-160000,20230521-044735,"['sustainable', 'industry', '4.0', 'methodology', 'for', 'improving', 'smes’', 'performance']",False,20230521-205332,,,,
479,scopus,Reimagining the Fashion Retail Industry Through the Implications of COVID-19 in the Gulf Cooperation Council (GCC) Countries,"The COVID-19 pandemic has disrupted the fashion retail industry. The Gulf Cooperation Council Countries (GCC) is the home of family-centric shopping malls and brick and mortar stores (B&M). This article aims to provide a critical look at the business strategies which the fashion retail companies need to adopt to provide consumers with an integrated online and B&M service which will be essential to survive in the post-pandemic business environment. This article is based on the rich industry experience of the authors and extensive secondary research on the business strategies being employed by the leading fashion retailers in the GCC region to combat the pandemic disruption. The study highlights the importance of a comprehensive rethink on business strategy for the GCC fashion retailers with adoption of digitalization technologies and an adaptive supply chain as the pillars to survive the post-pandemic normal of business environments. The study concludes with a look to the future strategies for fashion retailers in developing a digitalization blueprint, using cloud technologies and big data analytics, leveraging social media, building an agile and adaptive supply chain with omnichannel capability, and ensuring that future products and services are sustainable and socially responsible. © 2021 Fortune Institute of International Business.",B&M stores; business strategy; COVID-19; e-commerce; fashion retail; GCC,"Rao P.H.N., Vihari N.S., Jabeen S.S.","Supply Chain Projects and Home Operations, Landmark Group, Dubai, United Arab Emirates; BITS Pilani, Dubai Campus, Dubai, United Arab Emirates",2021.0,FIIB Business Review,Sage Publications India Pvt. Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116744689&doi=10.1177%2f23197145211039580&partnerID=40&md5=9bd3035507ef0c67371a7e74fe49d61a,10.1177/23197145211039580,20230520-160000,20230521-044735,"['reimagining', 'the', 'fashion', 'retail', 'industry', 'through', 'the', 'implications', 'of', 'covid-19', 'in', 'the', 'gulf', 'cooperation', 'council', '(gcc)', 'countries']",False,20230521-205332,,,,
480,scopus,Lunule: An agile and judicious metadata load balancer for cephfs,"For a decade, the Ceph distributed file system (CephFS) has been widely used to serve the ever-growing big data in many key fields ranging from Internet services to AI computing. To scale out the massive metadata access, CephFS adopts a dynamic subtree partitioning method, splitting the hierarchical namespace and distributing subtrees across multiple metadata servers. However, this method suffers from a severe imbalance problem that may result in poor performance due to its inaccurate imbalance prediction, ignorance of workload characteristics, and unnecessary/invalid migration activities. To eliminate these inefficiencies, we propose Lunule, a novel CephFS metadata load balancer, which employs an imbalance factor model for accurately determining when to trigger re-balance and tolerate benign imbalanced situations. Lunule further adopts a workloadaware migration planner to appropriately select subtree migration candidates. Compared to baselines, Lunule achieves better load balance, increases the metadata throughput by up to 315.8%, and shortens the tail job completion time by up to 64.6% for five real-world workloads and their mixture, respectively. Besides, Lunule is capable of handling the metadata cluster expansion and the client workload growth, and scales linearly on a cluster of 16 MDSs. © 2021 IEEE Computer Society. All rights reserved.",,"Wang .Y., Li .C., Shao .X., Chen .Y., Yan .F., Xu .Y.","University of Science and Technology of China, Hefei, Anhui, China; Anhui Province Key Laboratory of High Performance Computing, USTC, Hefei, Anhui, China; University of Nevada Reno, Reno, NV, United States",2021.0,"International Conference for High Performance Computing, Networking, Storage and Analysis, SC",IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119957496&doi=10.1145%2f3458817.3476196&partnerID=40&md5=0074832e162004a979583903949f4fc2,10.1145/3458817.3476196,20230520-160000,20230521-044735,"['lunule:', 'an', 'agile', 'and', 'judicious', 'metadata', 'load', 'balancer', 'for', 'cephfs']",True,20230521-205332,,,,
481,scopus,Smart Factory Production and Operation Management Methods based on HCPS,"The human-cyber-physical system (HCPS) is a composite intelligent system comprising humans, cyber systems, and physical systems with the aim of achieving specific manufacturing goals at an optimized level. Smart factory is an important carrier of a new-generation intelligent manufacturing. In order to achieve the comprehensive collaboration of human-machine-thing and other elements in the smart factory, the HCPS is introduced to the smart factory in this paper. Firstly, a smart factory model is constructed based on human-cyber-physical (HCPS). Then, according to the characteristics of big data, Internet-of-Things(IoT) and artificial intelligence(AI), the management methods of smart factory is proposed, including production design, resource intelligent management and knowledge discovery. Finally, a guiding technology architecture of human-centered smart factory production and operation management is given. The smart factory based on HCPS is of great significance to realize the full use of various resources, and agile management. Index Terms-Human-cyber-physical system, Smart Factory, Production and Operation, Management Methods © 2020 IEEE.",Management Methods; Production and Operation; Smart Factory; Terms-Human-cyber-physical system,"Yu J., Sun Y., Zheng W., Zhou X.","School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Research Center for Novel Technology of Intelligent Equipment, Nanjing University, Nanjing, China",2020.0,"2020 IEEE International Conference on Networking, Sensing and Control, ICNSC 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096361570&doi=10.1109%2fICNSC48988.2020.9238110&partnerID=40&md5=ad471db8af9153dffd653071e8f13051,10.1109/ICNSC48988.2020.9238110,20230520-160000,20230521-044735,"['smart', 'factory', 'production', 'and', 'operation', 'management', 'methods', 'based', 'on', 'hcps']",True,20230521-205332,,,,
482,scopus,Evolving profiles of financial risk management in the era of digitization: The tomorrow that began in the past,"The initial phases of digitization have automatized the front-end of banks and financial institutions (FIs). This paper documents the automation of the back-end in the current wave of digitization. In particular, it highlights the use of technology in streamlining risk management and its potential to provide competitive advantage to the FIs embracing digitization. For instance, automated “big data” credit scoring tools built on predictive analytics and machine learning algorithms are employed to examine several credit propositions. This can accurately construct the credit worthiness and risk profile of public, even without any credit history. These developments can widen the access of credit and other financial services to the society. However, on a cautionary note, this study emphasizes that although digitization of back-end financial transactions carries substantive advantages, the FIs must be guarded against cyber, outsourcing, financial exclusion, and macrofinance risks that can manifest with this automation. In this backdrop, the need for robust yet agile regulations and supervisory counsel to control and exploit the digitization towards optimal benefits for banks and FIs and society at large, acquires salience. Furthermore, regulators and supervisory authorities can mitigate the digitization risks and prevent any public fallout by leveraging the use of digitization itself. © 2019 John Wiley & Sons, Ltd.",,Chakraborty G.,"Department of Management, Institute for Financial Management and Research (IFMR), University of Madras, Chennai, India",2020.0,Journal of Public Affairs,John Wiley and Sons Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075309123&doi=10.1002%2fpa.2034&partnerID=40&md5=afa5218cee32f4d4f8bca179021fba30,10.1002/pa.2034,20230520-160000,20230521-044735,"['evolving', 'profiles', 'of', 'financial', 'risk', 'management', 'in', 'the', 'era', 'of', 'digitization:', 'the', 'tomorrow', 'that', 'began', 'in', 'the', 'past']",False,20230521-205332,,,,
483,scopus,Data—The Important Prerequisite for AI Decision-Making for Business,"Today’s companies have to be agile and up-to-date to execute their business in the best way. Within the fourth industrial revolution, pursuing digitalization and on the verge of a leap to Industry 5.0 companies and systems all over the world generate a mass of data. These data have to be collected, analyzed, interpreted, and information derived to take the best business decisions to gain the optimized strategy direction. Due to the large amount of data, analysis for business analysts today is only possible to a limited extent. Therefore, companies need support by Cyber-Physical Systems to group the data, enrich the information, and automate decision-making. In the following paper, the data foundation as an important prerequisite for business decision taking and Artificial Intelligence execution will be researched. Therefore, the required terms are defined and described in theory. Afterward, the data foundation for companies are analyzed by interviews with experts and business representatives as well as field studies. The first finding is that many companies analyze only a small portion of the available data, whereby important insights get lost. Furthermore, the usage of Artificial Intelligence can optimize the data analysis and decision-making by decision proposals up to 90%. © 2020, Springer Nature Switzerland AG.",Artificial intelligence; Big data; Decision making; Future business,"Paschek D., Luminosu C.T., Negrut M.L.","University of Timisoara, Remus str. 14, Timisoara, 300191, Romania; Politehnica University of Timisoara, Remus str. 14, Timisoara, 300191, Romania",2020.0,Springer Proceedings in Business and Economics,Springer Science and Business Media B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126087583&doi=10.1007%2f978-3-030-44711-3_40&partnerID=40&md5=eedd478c47ae4018003b54eee726c82c,10.1007/978-3-030-44711-3_40,20230520-160000,20230521-044735,"['data—the', 'important', 'prerequisite', 'for', 'ai', 'decision-making', 'for', 'business']",False,20230521-205332,,,,
484,scopus,Management Consulting Business Models: Operations through and for Digital Transformation,"Management consulting as a service has become part of almost every company's daily business. The growth is being exponential, even with all the non-consensual issues and controversies in the industry. However, the market is increasingly competitive, with new competitors coming from everywhere. At the same time, the world is changing at a speed never seen before, and the challenges are several: Automatization, scarcity of resources, democratization of the information, big data, and regulation are some examples. Thus, it's not possible for consulting firms to keep providing the market needs without adapting continuously their own business models. The companies that can outperform these challenges more efficiently will win against the competitors. Investigate which strategies and mechanisms adopt to be agile and flexible enough, in which sectors invest the most, and how reinvent their business model in order to be resilient in a fast changing and technological world are the main objectives of this research. Several interviews with the top management of fifteen of the biggest consulting companies in Portugal were conducted. The results suggested that companies are now trying to differentiate by the services delivered, and these business models' adaptation to the digital transformation is rather than a reality, a need. © 2019 IEEE.",Business Models; Digital Transformation; Management Consulting,"Jeronimo C., Pereira L., Sousa H.","BRU-IUL, ISCTE Business School, Lisboa, Portugal",2019.0,"Proceedings - 2019 IEEE International Conference on Engineering, Technology and Innovation, ICE/ITMC 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071431773&doi=10.1109%2fICE.2019.8792592&partnerID=40&md5=17a9e8e081d4acd7b4e01885b468b9bc,10.1109/ICE.2019.8792592,20230520-160000,20230521-044735,"['management', 'consulting', 'business', 'models:', 'operations', 'through', 'and', 'for', 'digital', 'transformation']",True,20230521-205332,,,,
485,scopus,Predicting Visitor Distribution for Large Events in Smart Cities,"The prediction of the distribution of visitors in large events is a valuable piece of information in the context of smart cities. The organizers of large events leverage it for safety and coordination purposes and the Fog computing infrastructures for cost effective, agile and reliable allocation of the mobile apps and festival services workload along the continuum from edge devices to cloud. In this research we examine two sets of supervised Machine Learning techniques in order to predict the visitors' distribution in the next timesteps and evaluate them using real data from a large music event that took place in 2017 and 2018. To enrich the feature space of the predictive models we use and evaluate open data such as the weather and the popularity of artists. A further added value of the examined Machine Learning techniques, in comparison with the current state of the art in mobility prediction, is that they look into the phenomenon of visitors coming and going from the area of interest. © 2019 IEEE.",Classification; Fog Computing; Large Events; Open Data; Points of Interest; Regression; Smart Cities,"Violos J., Pelekis S., Berdelis A., Tsanakas S., Tserpes K., Varvarigou T.","Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Informatics and Telematics, Harokopio University of Athens, Athens, Greece",2019.0,"2019 IEEE International Conference on Big Data and Smart Computing, BigComp 2019 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064674454&doi=10.1109%2fBIGCOMP.2019.8679181&partnerID=40&md5=9410a7f6e2eb1d050ab603117740a54f,10.1109/BIGCOMP.2019.8679181,20230520-160000,20230521-044735,"['predicting', 'visitor', 'distribution', 'for', 'large', 'events', 'in', 'smart', 'cities']",True,20230521-205332,,,,
486,scopus,Agile Requirements Engineering and Software Planning for a Digital Health Platform to Engage the Effects of Isolation Caused by Social Distancing: Case Study,"Background: Social distancing and shielding measures have been put in place to reduce social interaction and slow the transmission of the coronavirus disease (COVID-19). For older people, self-isolation presents particular challenges for mental health and social relationships. As time progresses, continued social distancing could have a compounding impact on these concerns. Objective: This project aims to provide a tool for older people and their families and peers to improve their well-being and health during and after regulated social distancing. First, we will evaluate the tool’s feasibility, acceptability, and usability to encourage positive nutrition, enhance physical activity, and enable virtual interaction while social distancing. Second, we will be implementing the app to provide an online community to assist families and peer groups in maintaining contact with older people using goal setting. Anonymized data from the app will be aggregated with other real-world data sources to develop a machine learning algorithm to improve the identification of patients with COVID-19 and track for real time use by health systems. Methods: Development of this project is occurring at the time of publication, and therefore, a case study design was selected to provide a systematic means of capturing software engineering in progress. The app development framework for software design was based on agile methods. The evaluation of the app’s feasibility, acceptability and usability shall be conducted using Public Health England's guidance on evaluating digital health products, Bandura’s model of health promotion, the Reach Effectiveness Adoption Implementation Maintenance (RE-AIM) framework and the Nonadoption, Abandonment and Challenges to the Scale-up, Spread and Suitability (NASSS) framework. Results: Making use of a pre-existing software framework for health behavior change, a proof of concept was developed, and a multistage app development and deployment for the solution was created. Grant submissions to fund the project and study execution have been sought at the time of publication, and prediscovery iteration of the solution has begun. Ethical approval for a feasibility study design is being sought. Conclusions: This case study lays the foundations for future app development to combat mental and societal issues arising from social distancing measures. The app will be tested and evaluated in future studies to allow continuous improvement of the app. This novel contribution will provide an evidence-based exemplar for future app development in the space of social isolation and loneliness. © Edward Meinert.",Access; Aged; Agile; App; Artificial intelligence; Cellphone; Coronavirus; COVID-19; Data science; Digital health; Evaluation; Exercise; Health care quality; Information science; Mental health; Public reporting of healthcare data; Requirements engineering; Social distancing; Telemedicine,"Meinert E., Milne-Ives M., Surodina S., Lam C.","Digitally Enabled PrevenTative Health Research Group, Department of Paediatrics, University of Oxford, Oxford, United Kingdom; Department of Primary Care and Public Health, Imperial College London, London, United Kingdom; Skein Ltd., London, United Kingdom; Institute of Biomedical Engineering, University of Oxford, Oxford, United Kingdom",2020.0,JMIR Public Health and Surveillance,JMIR Publications Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097846280&doi=10.2196%2f19297&partnerID=40&md5=4be6dfde6b8a1d7afbcf13d37e60cc53,10.2196/19297,20230520-160000,20230521-044735,"['agile', 'requirements', 'engineering', 'and', 'software', 'planning', 'for', 'a', 'digital', 'health', 'platform', 'to', 'engage', 'the', 'effects', 'of', 'isolation', 'caused', 'by', 'social', 'distancing:', 'case', 'study']",False,20230521-205332,,,,
487,scopus,APCC: Agile and precise congestion control in datacenters,"Modern datacenter networks exhibit complicated and time-varying traffic patterns, from long-running flows to burst short-lived flows. Recently in-network-telemetry (INT) is employed by datacenter transports to perform precise congestion control (CC). Current INT-based CC works well for long flows, however, suffers from serious performance downgrades when BDP-level small flows burst in the first RTT, due to the reason that current INT information from the receivers (host-based INT) needs at least one RTT to respond. In this paper, we make the first attempt to propose an agile and precise congestion control, called APCC, in datacenter networks, working for traffic patterns that is a mix of BDP-level short flows and long flows. APCC explores INT information from switches (switch-based INT) to feedback the congestion information eagerly, and effectively manage BDP-level flows. APCC utilizes the switch-based INT to schedule the complicated and time-varying traffic stably and precisely, and achieve low latency, high bandwidth and network stability simultaneously. We conduct extensive experiments to evaluate the performance of APCC. The experiment results show that with data centers load containing many BDP-level flows such as Cache Follower and Web Server, switch-based INT shows huge potential of improving the long tail effect on completion time (FCT). APCC reduces tail delay by 21.7%-28.9% under normal circumstances, and can still reduce tail delay by 9.1% under more severe conditions comparing with HPCC. Moreover, APCC shows better convergence. © 2020 IEEE.",Congestion control; Datacenter networks; Host-based INT; In-network telemetry (INT); Switch-based INT,"Zhou R., Yuan G., Dong D., Huang S.","National University of Defense Technology, Changsha, China",2020.0,"Proceedings - 2020 IEEE International Symposium on Parallel and Distributed Processing with Applications, 2020 IEEE International Conference on Big Data and Cloud Computing, 2020 IEEE International Symposium on Social Computing and Networking and 2020 IEEE International Conference on Sustainable Computing and Communications, ISPA-BDCloud-SocialCom-SustainCom 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108022144&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom51426.2020.00107&partnerID=40&md5=c85778864e90e87a43a46a4dbd998d9f,10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00107,20230520-160000,20230521-044735,"['apcc:', 'agile', 'and', 'precise', 'congestion', 'control', 'in', 'datacenters']",True,20230521-205332,,,,
488,scopus,Reputational intelligence: innovating brand management through social media data,"Purpose: Companies are currently facing the challenge of understanding how their business is affected by the large volume of opinions continually generated by their stakeholders in social media regarding their intangible assets (experiences, emotions and attitudes). With this in mind, the purpose of this paper is to present an innovative management model, named E2AB, to measure and analyse reputational intangibles from digital ecosystems and their impacts on tangible assets. Design/methodology/approach: The methodology applied was big data and business intelligence techniques. These methods were used in the computing process to obtain daily data from every asset guarantees that the model is validated with robust data. This model has been corroborated using data from the banking sector, specifically 402,383 net data inputs from the digital ecosystems. Findings: This study illustrates the existence of a holistic influence of intangible assets over tangible assets. The findings demonstrate complex relationships between tangible and intangible assets, determined not only by the type of variable but also by its valence and intensity. Practical implications: These findings may help chief communication officers and general managers a better understanding of how intangible assets extracted from online users’ opinions are related to their organisation’s tangible assets plus a chance to find out about their impact and how to manage them for a practical and agile decision making in real time. Originality/value: It is a pioneering work in establishing a model, which demonstrates transversal and holistic relationships between relational intangible and tangible assets of firms from digital ecosystems, using business intelligence techniques. © 2019, Emerald Publishing Limited.",Business intelligence; Customer perceptions; Intangible management; Reputational intelligence; Reputational model; Social media data,"Casado-Molina A.-M., Ramos C.M.Q., Rojas-de-Gracia M.-M., Peláez Sánchez J.I.","Department of Economics and Business Administration, University of Malaga, Malaga, Spain; School of Management, Hospitality and Tourism, University of Algarve, Faro, Portugal; Department of Computer Sciences and Languages, Higher Technical School of Computer Science, University of Malaga, Malaga, Spain",2020.0,Industrial Management and Data Systems,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075052168&doi=10.1108%2fIMDS-03-2019-0145&partnerID=40&md5=c4acde4629955845d8b27e4722104f38,10.1108/IMDS-03-2019-0145,20230520-160000,20230521-044735,"['reputational', 'intelligence:', 'innovating', 'brand', 'management', 'through', 'social', 'media', 'data']",False,20230521-205332,,,,
489,scopus,SLA-Based Agile VM Management in Cloud Datacenter,"Cloud Computing is the main root technology to provide various services over the internet in the current scenario, which is basically powered via virtual machines (VMs) over commodity hardware. As soon as a task arrives in the cloud or data center that task is assigned to a VM as per the task scheduler and resource allocation policy. Whenever cloud or data center do not have sufficient spare resources over VM to assign a task, a new VM is created over host machine which have spare resource capacity in the cloud and/or data center. The VM creation should be in such a manner that will follow the Service Level Agreement (SLA) to maintain the Quality of Service (QoS) for the client. We have proposed SLA-based agile VM management algorithm to minimize the VM creation time and VM response time. We use ghost VM to increase the efficiency of cloud, allocation of new VM is from the ghost VM, and using the average creation time is reduced up to 11.98%. We propose two algorithms first for Admission control and second for Rescheduling of VM's. Our aim is to reduce the time taken in the rescheduling of the VM. Currently, we are assuming excess VM which are eligible to Garbage Collection do not put overhead over the cloud and they can be handled via background service, and with do not affect foreground services directly and they are handled via the separate management service. © 2019 IEEE.",Cloud computing; cloud efficiency; data-center; VM management,"Sharma N., Maurya S.","Govt. Women Engineering College, Ajmer, India",2019.0,"Proceedings of the International Conference on Machine Learning, Big Data, Cloud and Parallel Computing: Trends, Prespectives and Prospects, COMITCon 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074139505&doi=10.1109%2fCOMITCon.2019.8862260&partnerID=40&md5=6223dee67613340d190f12aaaea0f27c,10.1109/COMITCon.2019.8862260,20230520-160000,20230521-044735,"['sla-based', 'agile', 'vm', 'management', 'in', 'cloud', 'datacenter']",True,20230521-205332,,,,
490,scopus,Energy Efficient Double Critic Deep Deterministic Policy Gradient Framework for Fog Computing,"Nowadays the data is growing at a faster pace and the big data applications are required to be more agile and flexible. There is a need for a decentralized model to carry out the required substantial amount of computation across edge devices as they has led to the innovation of fog computing. Energy consumption among the edge devices is one of the potential threatening issues in fog computing. Their high energy demand also contributes to higher computation cost. In this paper Double Critic (DC) approach is enforced over the Deep Deterministic Policy Gradient (DDPG) technique to design the DC-DDPG framework which formulates high quality energy efficiency policies for fog computing. The performance of the proposed framework is outstanding compared to existing works based on the metrics like energy consumption, response time, total cost, and throughput. They are measured under two different fog computing scenarios i.e., fog layer with multiple entities in a region and fog layer with multiple entities in multiple regions. Mathematical modeling reveals that the energy efficiency policies formulated are of high quality as they satisfy the quality assurance metrics, such as empirical correctness, robustness, model relevance, and data privacy. copy; 2022 IEEE. © 2022 IEEE.",Deterministic Policy Gradient; Double Critic; Energy; Fog computing; Q-learning,"Krishnamurthy B., Shiva S.G.","Siddaganga Institute of Technology, Department of Computer Science, Tumakuru, India; University of Memphis, Department of Computer Science, Memphis, TN, United States",2022.0,"2022 IEEE World AI IoT Congress, AIIoT 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134877807&doi=10.1109%2fAIIoT54504.2022.9817157&partnerID=40&md5=f812654f652aff1e3587ac375e2b24ac,10.1109/AIIoT54504.2022.9817157,20230520-160000,20230521-044735,"['energy', 'efficient', 'double', 'critic', 'deep', 'deterministic', 'policy', 'gradient', 'framework', 'for', 'fog', 'computing']",True,20230521-205332,,,,
491,scopus,An End-to-End Recommendation System for Urban Traffic Controls and Management under a Parallel Learning Framework,"A paradigm shift towards agile and adaptive traffic signal control empowered with the massive growth of Big Data and Internet of Things (IoT) technologies is emerging rapidly for Intelligent Transportation Systems. Generally, an adaptive signal control system fine-tunes signal timing parameters based on pre-defined control hyperparameters using instantaneous traffic detection information. Once traffic pattern changes, those hyperparameters (e.g., maximum and minimum green times) need to be adjusted according to the evolution of traffic dynamics over a very short-term period. Such adjustment processes are usually conducted by professional and experienced traffic engineers. Here we present a human-in-the-loop parallel learning framework and its utilization in an end-to-end recommendation system that mimics and enhances professional signal control engineers' behaviors. The system has been deployed into a real-world application for an extended period in Hangzhou, China, where signal control hyperparameters are recommended based on large-scale multidimensional traffic datasets. Experimental evaluations demonstrate significant improvements in traffic efficiency through the use of our signal recommendation system. © 2000-2011 IEEE.",deep neural networks; Intelligent traffic control; parallel learning; recommendation systems; traffic signal control,"Jin J., Guo H., Xu J., Wang X., Wang F.-Y.","Enjoyor Co. Ltd., Hangzhou, 310030, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, 310013, China",2021.0,IEEE Transactions on Intelligent Transportation Systems,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102456313&doi=10.1109%2fTITS.2020.2973736&partnerID=40&md5=54b7ba4ad82d7c911c2f91cbebd8a694,10.1109/TITS.2020.2973736,20230520-160000,20230521-044735,"['an', 'end-to-end', 'recommendation', 'system', 'for', 'urban', 'traffic', 'controls', 'and', 'management', 'under', 'a', 'parallel', 'learning', 'framework']",True,20230521-205332,,,,
492,scopus,Transformation Management Office as a Vehicle to Accelerate Digital Transformation,"ADNOC has identified digital technology as a key enabler of sustainable value creation as it delivers its 2030 smart growth strategy. The Transformation Management Office (TMO) has been established to accelerate delivery of ADNOC's digital transformation, actively manage its digital portfolio, build digital capabilities, lead the digital empowerment of local talent and institute a 'new way to operate'. By doing so, it supports ADNOC's ambition to be a data-driven organization, adopting new ways of working, and delivering greater value, while adapting swiftly to competitive threats to its core business. ADNOC's digital transformation is changing the way the organization operates. The adoption of digital technologies, including big data, Artificial Intelligence and Machine Learning and robotics will optimize production, improve efficiency, reduce risk and de-risk multibillion dollar projects. To achieve this requires a change of company culture across the full value chain. The decision to establish the Transformation Management Office was a recognition that ADNOC must evolve to meet the realities of the new energy era by adopting advanced digital technologies to ensure we remain resilient and agile, by making the most of our resources, enhancing our performance, empowering our people and delivering greater value for our shareholders, Abu Dhabi and the UAE. © Copyright 2021, Society of Petroleum Engineers",,"Al Blooshi K., Mohammed H., Al Awadhi K.Y., Carreiras P., Al Mansoori M.H., Al Ameri W., Al Houqani M.S., ALwedami A., Saleh R.H., Alsaeedi A.A., Al Hemeiri A.",ADNOC,2021.0,"Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference, ADIP 2021",Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127684531&doi=10.2118%2f207222-MS&partnerID=40&md5=431d3b8634894383b8c3804a34d7c9ab,10.2118/207222-MS,20230520-160000,20230521-044735,"['transformation', 'management', 'office', 'as', 'a', 'vehicle', 'to', 'accelerate', 'digital', 'transformation']",False,20230521-205332,,,,
493,scopus,The Construction and Practice of Practice Base System Based on Cloud Computing Technology: -Taking Ideological and Political Education in Colleges and Universities as an Example,"The effectiveness of Ideological and political education in Colleges and universities is related to the prosperity of a country. Practice is an important part of Ideological and political education. Practice base is an important carrier and position of practice. The construction of practice base system will have a significant impact on Ideological and political education in Colleges and universities. Cloud computing is a kind of scalable, virtualized and cheap computing mode through the Internet. The practice base system of Ideological and political education in Colleges and Universities Based on cloud computing technology can save costs, and has the characteristics and advantages of resource pool, cheap, sharing, reliable, agile, expandable, virtual, crossing the boundaries of time and space. Therefore, the author thinks that it is necessary for the state to adopt cloud computing technology to build the practice base system of Ideological and political education in Colleges and universities, and take the hierarchical organic filling construction mode to implement from the top-level design of the state macro level, and make case analysis and Discussion on the micro construction design and practice of colleges and universities. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Cloud computing; Construction; Practice; Practice base system,Jiang P.,"Ji Lin Justice Officer Academy, Jilin, Changchun  130062, China",2021.0,Advances in Intelligent Systems and Computing,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098290280&doi=10.1007%2f978-981-33-4572-0_213&partnerID=40&md5=2d1852e682677e25da6a4518951fd1db,10.1007/978-981-33-4572-0_213,20230520-160000,20230521-044735,"['the', 'construction', 'and', 'practice', 'of', 'practice', 'base', 'system', 'based', 'on', 'cloud', 'computing', 'technology:', '-taking', 'ideological', 'and', 'political', 'education', 'in', 'colleges', 'and', 'universities', 'as', 'an', 'example']",False,20230521-205332,,,,
494,scopus,Case study: Factors that hinder and support the adoption of Pair Programming in an agile s of tware development company,"-Pair programming is the XP practice that is the least adopted in s of tware development departments or companies; although previous research suggests there are numerous benefits that can be realised from its use. It is suggested that this practice, which involves two programmers working collaboratively on the same task and following a prescribed approach, produces high quality code, in shorter timeframes, with increased knowledge-sharing and improved developer productivity. This paper investigates the factors that support, and deter, pair programming adoption in a case study at a s of tware development company in the eThekwini (Durban) region, South Africa. The survey and interviews indicate that the most positive influences are the support from senior and peer staff and the company's willingness to provide the necessary hardware, s of tware and physical layout to enable the use of pair programming. The biggest challenge was the personality mix in a pair, for example introvert/extrovert pairs, where extroverts can dominate pair collaboration. This company has specific managerial guidelines and practices which are used to mitigate the challenges and provide support to, not only make pair programming a more operationally feasible option, but also reap its benefits ©2020 IEEE.",Pair programming; S of tware developer; XP (extreme programming),"Dhoodhanath P., Quilling R.","School of Management, Information Technology and Governance University of KwaZulu-Natal (eThekwini), Durban, South Africa",2020.0,"2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems, icABCD 2020 - Proceedings",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092049686&doi=10.1109%2ficABCD49160.2020.9183869&partnerID=40&md5=c068115dafe0aa34ded92bee6c3c0827,10.1109/icABCD49160.2020.9183869,20230520-160000,20230521-044735,"['case', 'study:', 'factors', 'that', 'hinder', 'and', 'support', 'the', 'adoption', 'of', 'pair', 'programming', 'in', 'an', 'agile', 's', 'of', 'tware', 'development', 'company']",True,20230521-205332,,,,
495,scopus,BotCensor: Detecting DGA-Based Botnet Using Two-Stage Anomaly Detection,"Nowadays, most botnets utilize domain generation algorithms (DGAs) to build resilient and agile command and control (C&C) channels. Specifically, botmasters employ DGAs to dynamically produce a large number of random domains and only register a small subset for their actual C&C servers with the purpose to defend them from takeovers and blacklisting attempts. While many approaches and models have been developed to detect DGA-based botnets, they suffer from several limitations, such as difficulties of DNS traffic collection, low feasibility and scalability, and so forth. In this paper, we present BotCensor, a new system that can determine if a host is infected with certain DGA malware with two-stage anomaly detection. In the first stage, we preliminarily attempt to identify malicious domains using a Markov model, and in the second stage, we re-examine the hosts that requested aforementioned malicious domains using novelty detection algorithms. Our experimental results show that our approach performs very well on identifying previously unknown DGA-generated domains and detects DGA bots with high efficiency and efficacy. Our approach not only can be regarded as security forensics tools, but also can be used to prevent malware infections and spread. © 2018 IEEE.",DGA-based botnet detection; DNS traffic; Markov model; Novelty detection algorithms; Two-stage anomaly detection,"Qi B., Jiang J., Shi Z., Mao R., Wang Q.","Institute of Information Engineering, Chinese Academy of Sciences, BeiJing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",2018.0,"Proceedings - 17th IEEE International Conference on Trust, Security and Privacy in Computing and Communications and 12th IEEE International Conference on Big Data Science and Engineering, Trustcom/BigDataSE 2018",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054082628&doi=10.1109%2fTrustCom%2fBigDataSE.2018.00109&partnerID=40&md5=d6dc6c2f2627bae0a4ce4ea42b7083fd,10.1109/TrustCom/BigDataSE.2018.00109,20230520-160000,20230521-044735,"['botcensor:', 'detecting', 'dga-based', 'botnet', 'using', 'two-stage', 'anomaly', 'detection']",True,20230521-205332,,,,
496,scopus,Q-rapids tool prototype: Supporting decision-makers in managing quality in rapid software development,"Software quality is an essential competitive factor for the success of software companies today. Increasing the software quality levels of software products and services requires an adequate integration of quality requirements (QRs) in the software life-cycle, which is still scarcely supported in current rapid software development (RSD) approaches. One of the goals of the Q-Rapids (Quality-aware Rapid Software Development) method is providing tool support to decision-makers for QR management in RSD. The Q-Rapids method is based on gathering data from several and heterogeneous sources, to be aggregated into quality-related strategic indicators (e.g., customer satisfaction, product quality) and presented to decision-makers using a highly informative dashboard. The current release of Q-Rapids Tool provides four sets of functionality: (1) data gathering from source tools (e.g. GitLab, Jira, SonarQube, and Jenkins), (2) aggregation of data into three levels of abstraction (metrics, product/process factors, and strategic indicators), (3) visualization of the aggregated data, and (4) navigation through the aggregated data. The tool has been evaluated by four European companies that follow RSD processes. © Springer International Publishing AG, part of Springer Nature 2018.",Agile; Dashboard; Decision-making; Non-functional requirements; Quality requirement; Rapid software development; Strategic indicator,"López L., Martínez-Fernández S., Gómez C., Choraś M., Kozik R., Guzmán L., Vollmer A.M., Franch X., Jedlitschka A.","Universitat Politècnica de Catalunya (UPC), Barcelona, Spain; Fraunhofer IESE, Kaiserslautern, Germany; ITTI Sp. Z O.O., Poznań, Poland; University of Science and Technology, UTP Bydgoszcz, Bydgoszcz, Poland",2018.0,Lecture Notes in Business Information Processing,Springer Verlag,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048620011&doi=10.1007%2f978-3-319-92901-9_17&partnerID=40&md5=aa3f49415e4eaebbbd18d06751e4cb61,10.1007/978-3-319-92901-9_17,20230520-160000,20230521-044735,"['q-rapids', 'tool', 'prototype:', 'supporting', 'decision-makers', 'in', 'managing', 'quality', 'in', 'rapid', 'software', 'development']",False,20230521-205332,,,,
497,scopus,Characterization and identification of variations in types of primary care visits before and during the covid-19 pandemic in catalonia: Big data analysis study,"Background: The COVID-19 pandemic has turned the care model of health systems around the world upside down, causing the abrupt cancellation of face-to-face visits and redirection of the model toward telemedicine. Digital transformation boosts information systems-the more robust they are, the easier it is to monitor the health care system in a highly complex state and allow for more agile and reliable analysis. Objective: The purpose of this study was to analyze diagnoses from primary care visits and distinguish between those that had higher and lower variations, relative to the 2019 and 2020 periods (roughly before and during COVID-19), to identify clinical profiles that may have been most impaired from the least-used diagnostic codes for visits during the pandemic. Methods: We used a database from the Primary Care Services Information Technologies Information System of Catalonia. We analyzed the register of visits (n=2,824,185) and their International Classification of Diseases (ICD-10) diagnostic codes (n=3,921,974; mean 1.38 per visit), as approximations of the reasons for consultations, at 3 different grouping levels. The data were represented by a term frequency matrix and analyzed recursively in different partitions aggregated according to date. Results: The increase in non-face-to-face visits (+267%) did not counterbalance the decrease in face-to-face visits (-47%), with an overall reduction in the total number of visits of 1.36%, despite the notable increase in nursing visits (10.54%). The largest increases in 2020 were visits with diagnoses related to COVID-19 (ICD-10 codes Z20-Z29: 2.540%), along with codes related to economic and housing problems (ICD-10 codes Z55-Z65: 44.40%). Visits with most of the other diagnostic codes decreased in 2020 relative to those in 2019. The largest reductions were chronic pathologies such as arterial hypertension (ICD-10 codes I10-I16: -32.73%) or diabetes (ICD-10 codes E08-E13: -21.13%), but also obesity (E65-E68: -48.58%) and bodily injuries (ICD-10 code T14: -33.70%). Visits with mental health-related diagnostic codes decreased, but the decrease was less than the average decrease. There was a decrease in consultations-for children, adolescents, and adults-for respiratory infections (ICD-10 codes J00-J06: -40.96%). The results show large year-on-year variations (in absolute terms, an average of 12%), which is representative of the strong shock to the health system. Conclusions: The disruption in the primary care model in Catalonia has led to an explosive increase in the number of non-face-to-face visits. There has been a reduction in the number of visits for diagnoses related to chronic pathologies, respiratory infections, obesity, and bodily injuries. Instead, visits for diagnoses related to socioeconomic and housing problems have increased, which emphasizes the importance of social determinants of health in the context of this pandemic. Big data analytics with routine care data yield findings that are consistent with those derived from intuition in everyday clinical practice and can help inform decision making by health planners in order to use the next few years to focus on the least-treated diseases during the COVID-19 pandemic. © 2021 Journal of Medical Internet Research. All rights reserved.",Big data; Big data; Covid-19; Diagnose variations; Health system; Healthcare system; Icd10; Primary care; Primary care,"Segui F.L., Guillamet G.H., Arolas H.P., Marin-Gomez F.X., Comellas A.R., Morros A.M.R., Mas C.A., Vidal-Alaball J.","Centre de Recerca en Economia i Salut, Pompeu Fabra University, Barcelona, Spain; Institut Català de la Salut, Ger ncia Territorial de la Catalunya Central, Sant Fruit s de Bages, Spain; Health Promotion in Rural Areas Research Group, Institut Català de la Salut, Ger ncia Territorial de la Catalunya Central, Sant Fruit s de Bages, Spain; Unitat de Suport A la Recerca de la Catalunya Central, Fundacio Institut Universitari per A la Recerca A l'Atencio Primaria de Salut Jordi Gol i Gurina, Sant Fruit s de Bages, Spain; Faculty of Medicine, University of Vic, Vic, Spain; Centre d'Atenció Primària Sant Joan de Vilatorrada, Institut Català de la Salut, Ger ncia Territorial de la Catalunya Central, Sant Fruit s de Bages, Spain; Sant Joan de Déu Hospital, Barcelona, Spain",2021.0,Journal of Medical Internet Research,JMIR Publications Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115300801&doi=10.2196%2f29622&partnerID=40&md5=f834754fa3f8b26c72f9bb340d1f2182,10.2196/29622,20230520-160000,20230521-044735,"['characterization', 'and', 'identification', 'of', 'variations', 'in', 'types', 'of', 'primary', 'care', 'visits', 'before', 'and', 'during', 'the', 'covid-19', 'pandemic', 'in', 'catalonia:', 'big', 'data', 'analysis', 'study']",False,20230521-205332,,,,
498,scopus,Successful operational integration of healthcare analytics at Seattle Children's,"Introduction: As the quantity and complexity of health data grows, it is critical for healthcare organizations to devise analytic strategies that power data innovation so they can take advantage of new opportunities and improve outcomes. Seattle Children's Healthcare System (Seattle Children's) is an example of an organization that has built an operating model that integrates analytics into their business and daily operations. We present a roadmap for how Seattle Children's consolidated its fragmented analytics operations into a unified cohesive ecosystem capable of supporting advanced analytics capabilities and operational integration to transform care and accelerate research. Methods: In-depth interviews were conducted with ten leaders at Seattle Children's who have been instrumental in developing their enterprise analytics program. Interviews included the following leadership roles: Chief Data & Analytics Officer, Director of Research Informatics, Principal Systems Architect, Manager of Bioinformatics and High Throughput Analytics, Director of Neurocritical Care, Strategic Program Manager & Neuron Product Development Lead, Director of Dev Ops,Director of Clinical Analytics, Data Science Manager, and Advance Analytics Product Engineer. The interviews were unstructured and consisted of conversations intended to gather information from leadership about their experiences in building out Enterprise Analytics at Seattle Children's. Results: Seattle Children's has built an advanced enterprise analytics ecosystem that is integrated into its daily operations by applying an entrepreneurial mindset and agile development practices that are common in a startup environment. Analytics efforts were approached iteratively by selecting high-value projects that were delivered through Multidisciplinary Delivery Teams that were integrated into service lines. Service line leadership, in partnership with the Delivery Team leads, were responsible for the success of the team by setting project priorities, determining project budgets, and maintaining overall governance of their analytics endeavors. This organizational structure has led to the development of a wide range of analytic products that have been used to improve both operations and clinical care at Seattle Children's. Conclusions: Seattle Children's has demonstrated how a leading healthcare system can successfully create a robust, scalable, near real-time analytics ecosystem- one that delivers significant value to the organization from the ever-expanding volume of health data we see today. © 2022 The Authors. Learning Health Systems published by Wiley Periodicals LLC on behalf of University of Michigan. This article has been contributed to by U.S. Government employees and their work is in the public domain in the USA.",analytics operating model; data ecosystems; healthcare analytics; organizational innovation; scientific computing,"Frisbee K.L., Sousa R.","Department of Veterans Affairs, VHA Office of Connected Care, Washington, DC, United States; Seattle Children's Hospital, Seattle, WA, United States",2023.0,Learning Health Systems,John Wiley and Sons Inc,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136460360&doi=10.1002%2flrh2.10331&partnerID=40&md5=26520e5e3b4d9a2e93fb4ccf43c0e570,10.1002/lrh2.10331,20230520-160000,20230521-044735,"['successful', 'operational', 'integration', 'of', 'healthcare', 'analytics', 'at', 'seattle', ""children's""]",False,20230521-205332,,,,
499,scopus,ACT Testbot and 4S Quality Metrics in XAAS Framework,"The purpose of this paper is to analyze all Cloud based Service Models, Continuous Integration, Deployment and Delivery process and propose an Automated Continuous Testing and testing as a service based TestBot and metrics dashboard which will be integrated with all existing automation, bug logging, build management, configuration and test management tools. Recently cloud is being used by organizations to save time, money and efforts required to setup and maintain infrastructure and platform. Continuous Integration and Delivery is in practice nowadays within Agile methodology to give capability of multiple software releases on daily basis and ensuring all the development, test and Production environments could be synched up quickly. In such an agile environment there is need to ramp up testing tools and processes so that overall regression testing including functional, performance and security testing could be done along with build deployments at real time. To support this phenomenon, we researched on Continuous Testing and worked with industry professionals who are involved in architecting, developing and testing the software products. A lot of research has been done towards automating software testing so that testing of software product could be done quickly and overall testing process could be optimized. As part of this paper we have proposed ACT TestBot tool, metrics dashboard and coined 4S quality metrics term to quantify quality of the software product. ACT testbot and metrics dashboard will be integrated with Continuous Integration tools, Bug reporting tools, test management tools and Data Analytics tools to trigger automation scripts, continuously analyze application logs, open defects automatically and generate metrics reports. Defect pattern report will be created to support root cause analysis and to take preventive action. © 2019 IEEE.",4S Quality Metrics; ACT (Automated Continuous Testing); Auto Bug Logging and Tracking; Cloud; Continuous Delivery; Continuous Deployment; Continuous Integration; Continuous Testing; T-Model; TestBot; XaaS (Everything as a Service),"Chhillar D., Sharma K.","Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India",2019.0,"Proceedings of the International Conference on Machine Learning, Big Data, Cloud and Parallel Computing: Trends, Prespectives and Prospects, COMITCon 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074146880&doi=10.1109%2fCOMITCon.2019.8862212&partnerID=40&md5=97f86de479ad2e395dbe3b6652f3382a,10.1109/COMITCon.2019.8862212,20230520-160000,20230521-044735,"['act', 'testbot', 'and', '4s', 'quality', 'metrics', 'in', 'xaas', 'framework']",True,20230521-205332,,,,
500,scopus,Lean 4.0: Digital Technologies as Strategies to Reduce Waste of Lean Manufacturing,"Originated from Toyota Production System, Lean Manufacturing (LM) is a widely known production system that promotes efficient processes in the industry context, focusing on continuous improvement and value-adding activities to avoid waste. Industry 4.0 (I4.0), in turn, has recently emerged in the manufacturing sector, highlighting digitalization and its incorporation in industrial processes, ensuring improvements in production lines. This work intended to analyze the LM and I4.0 integration by studying the relationship between the classic types of waste with the digital technologies 4.0. Applying a three-phase methodology approach, the principles, attributes, and technologies of LM and I4.0 were identified. A relationship matrix and multidimensional diagrams were designed to investigate how digital technologies can contribute to the reduction of LM waste. A total of 27 associations were established and the emergent technologies with more combinations referred to Automated Guided Vehicles, Big Data Analytics, and Additive Manufacturing. Consequently, LM and I4.0 can work together and provide benefits to each other, highlighting that technologies 4.0 are critical to support waste reduction in manufacturing companies. The main contributions of this paper are the systematization and integrated operationalization of digital technologies in lean environments, aiming to optimize indicators of production processes through waste reduction. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Industry 4.0; Lean 4.0; Lean Manufacturing; Waste,"Valamede L.S., Akkari A.C.S.","Mackenzie Presbyterian University, Campinas, Brazil; Federal University of ABC, Santo André, Brazil",2022.0,"Smart Innovation, Systems and Technologies",Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135054169&doi=10.1007%2f978-3-031-08545-1_7&partnerID=40&md5=b37fffb376cfe3847e48d420a9cc678c,10.1007/978-3-031-08545-1_7,20230520-160000,20230521-044735,"['lean', '4.0:', 'digital', 'technologies', 'as', 'strategies', 'to', 'reduce', 'waste', 'of', 'lean', 'manufacturing']",False,20230521-205332,,,,
501,scopus,Requirements capture and comparative analysis of open source versus proprietary service oriented architecture,"Service Oriented Architecture (SOA) integrates information systems towards an agile and reusable service-based connectivity. It is an approach amalgamating large scale private/public computer systems and other resources with continuous phenomenal advent evolution and leveraging of the World Wide Web (WWW, commonly referred to as the Web) social media, mobile communications, Big Data (BD), data analytics, Machine Learning (ML) based optimisation, Cloud Computing (CC) and Internet of Things (IoT), commonly known as Advanced Technologies (AT). Implementing SOA, whether Open Source Software (OSS) or proprietary or absolute freeware is a choice to be made which depends on the organisation's requirements in light of AT as well as a host of delivery and security concerns. In this paper, a comparative analysis of an open source vs. proprietary SOA for large scale computer systems servicing AT is presented by examining their main efficacies, features, advantages and disadvantages and capturing their generic technical functional and non-functional requirements in a unified manner. Furthermore, the SOA evaluation criteria, recommendations and conclusions are also presented. © 2020 Elsevier B.V.",Advanced technologies; Closed source proprietary; Open source; Requirements capture; SOA; Web 1.0/2.0/3.0/4./5.0/6.0; Web services access,Bamhdi A.,"Department of Computer Sciences, College of Computing, Al Qunfudhah, Umm Al-Qura University, Makkah, Saudi Arabia",2021.0,Computer Standards and Interfaces,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091712492&doi=10.1016%2fj.csi.2020.103468&partnerID=40&md5=b84cfa8deca352a12d055b9556a98802,10.1016/j.csi.2020.103468,20230520-160000,20230521-044735,"['requirements', 'capture', 'and', 'comparative', 'analysis', 'of', 'open', 'source', 'versus', 'proprietary', 'service', 'oriented', 'architecture']",False,20230521-205332,,,,
502,scopus,Development of a smart city service Catalogue for sensor-based digital services,"The increasing urban population growth leads to challenges in cities in many aspects: Urbanisation problems such as excessive environmental pollution or increasing urban traffic demand new and innovative solutions. In this context, the concept of smart cities is discussed. An enabling element of the smart city concept is applying information technology (IT) to improve administrative efficiency and quality of life while reducing costs and resource consumption and ensuring greater citizen participation in administrative and urban development issues. While these smart city services are technologically studied and implemented, government officials, citizens or businesses are often unaware of the large variety of smart city service solutions. Therefore, this work deals with developing a smart city services catalogue that documents best practice services to create a platform that brings citizens, city government, and businesses together. Although the concept of IT service catalogues is not new and guidelines and recommendations for the design and development of service catalogues already exist in the corporate context, there is little work on smart city service catalogues. Therefore, approaches from agile software development and pattern research were adapted to develop the smart city service catalogue platform in this work. © 2021 International Conference on Computer Graphics, Visualization, Computer Vision and Image Processing 2021, CGVCVIP 2021, Connected Smart Cities 2021, CSC 2021 and Big Data Analytics, Data Mining and Computational Intelligence 2021, BIGDACI 2021 - Held at the 15th Multi-Conference on Computer Science and Information Systems, MCCSIS 2021. All rights reserved.",Governance; IoT service; Service Catalogue; Smart City; Smart City service Catalogue platform; Transparency,"Bozkurt Y., Fauser J., Braun R., Hertweck D., Rossmann A.","Department of Computer Science, Reutlingen University, Reutlingen, 72762, Germany",2021.0,"International Conference on Computer Graphics, Visualization, Computer Vision and Image Processing 2021, CGVCVIP 2021, Connected Smart Cities 2021, CSC 2021 and Big Data Analytics, Data Mining and Computational Intelligence 2021, BIGDACI 2021 - Held at the 15th Multi-Conference on Computer Science and Information Systems, MCCSIS 2021",IADIS,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117707702&partnerID=40&md5=92620b0eeccb6f7d20cc32dd17acaf0b,,20230520-160000,20230521-044735,"['development', 'of', 'a', 'smart', 'city', 'service', 'catalogue', 'for', 'sensor-based', 'digital', 'services']",False,20230521-205332,,,,
503,scopus,"The hybrid mas approach for information system development in ""cyber trainer""","Information storage, elaboration, and representation is a key point in developing and maintaining performing Information Systems and is becoming more and more challenging over time. In this paper we present the Multi-Agent Systems (MAS) based techniques being used for the refactoring and the expansion of the e-learning application ""Cyber Trainer"", in particular for specific ad-hoc modules focused on properly filtering and analyzing data. The MAS architecture is based on a set of different ""agents"", i.e., always running programs that can communicate with each other and work together in order to achieve their tasks. In this project, we used a novel hybrid approach blending MAS programming with Object and Event Programming techniques, taking the best from each one, to manage asynchronous events, communication between different modules, and data flows that need to be treated as big data. The Cyber Trainer ""Reporting MAS""design has been focused on scalability, modularity, resistance to change and security. This last point, generally important for every real-world application, in our case is particularly crucial, since Cyber Trainer is distributed over many servers (Reporting MAS Server module agents themself can run on several machines as well). © 14th IADIS International Conf. Infor. Sys. 2021. All rights reserved.",Agile Methodologies; Design and Development Methodologies and Frameworks; E-learning; Hybrid Approaches; Multi-Agent Systems,"Salutari A., Tarantino L., Evangelista M., Nazzicone G.","Università Degli Studi dell'Aquila, DISIM, Italy; Reiss Romoli S.r.l., Italy",2021.0,"14th IADIS International Conference Information Systems 2021, IS 2021",IADIS,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117414423&partnerID=40&md5=8c66d37eb86e653015bffd40050b90b8,,20230520-160000,20230521-044735,"['the', 'hybrid', 'mas', 'approach', 'for', 'information', 'system', 'development', 'in', '""cyber', 'trainer""']",False,20230521-205332,,,,
504,scopus,Application of Container Image Repository Technology in Automatic Operation and Maintenance of the Dispatching and Control Cloud,"With the continuous development of the container technology, the scale of the dispatching and control cloud built by it is expanding continuously. At the same time, the application portability of cloud platform based on virtualization is poor, the man-made operation and maintenance mode of the dispatching and control cloud is inefficient and the error rate is high. It is difficult to guarantee the safe and high-quality operation of power grid and the lean and efficient operation of the dispatching management. Using container technology to containerize cloud platform applications and relying on the Continuous Integration and Continuous Deployment (CI/CD) platform which can achieve efficient and accurate maintenance of the dispatching and control cloud. In this paper, the CI/CD platform which consists of the Jenkins,Kubernetes and Docker is introduced to complete the operation and maintenance tasks of the dispatching and control cloud,such as automatically agile construction, automatic publishing. Finally, through the analysis of the dispatching and control cloud, it is verified that the results show that the platform has a certain effect in automation construction, publishing efficiency, gray publishing update, operation and maintenance quality. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Automated operation and maintenance; Container; Continuous Integration and Continuous Deployment; Dispatching and control cloud; Jenkins+Kubernetes+Docker integration,"Tao L., Huang Y., Liu D., Ma X., Wu S., Cui C.","Beijing Key Laboratory of Research and System Evaluation of Power Dispatching Automation Technology, State Key Laboratory of Power Grid Security and Energy Saving, China Electric Power Research Institute, Haidian District, Beijing, 100192, China",2021.0,Advances in Intelligent Systems and Computing,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098246386&doi=10.1007%2f978-981-33-4572-0_268&partnerID=40&md5=2ab5ff92cbb7fe5bfa8f98f7574d4055,10.1007/978-981-33-4572-0_268,20230520-160000,20230521-044735,"['application', 'of', 'container', 'image', 'repository', 'technology', 'in', 'automatic', 'operation', 'and', 'maintenance', 'of', 'the', 'dispatching', 'and', 'control', 'cloud']",False,20230521-205332,,,,
505,scopus,Blockchain as a service for software defined networks: A denial of service attack perspective,"Software defined networking (SDN) is one of the most popular network technologies which provides an adaptive, agile and flexible network management and visibility. Although SDN architecture provides manifold benefits but on the same time its dependence on a logically centralized controller lead to the single point of failure. An attacker can easily capture the any forwarding device and restrict the availability of the controller using different prevalent attacks. Distributed denial of service (DDoS) is one of the most popular attack of this category which is quiet prevalent in SDN. Here, the aim of the attackers is to inject false script in the open flow tables through malicious switches which multiply exponentially. Therefore, in this paper, a blockchain as a service framework has been presented wherein BlockSDSec model is designed to provide security as a separate service for the SDN architecture. This work provides a mechanism to prevent the threats of DDoS at the switch level by embedding an security using blockchain onto the interaction channels of data and control planes. The load balancing at the controller level is achieved using a virtual controller. The proposed scheme is simulated using MiniNet Emulator to analyze the delay originating from usage of blockchain. © 2019 IEEE.",Blockchain; Distributed denial of service; Malicious switch; MiniNet; Software defined networks,"Bose A., Aujla G.S., Singh M., Kumar N., Cao H.","Computer Science and Engineering Department, Chandigarh University, Mohali, Punjab, India; Computer Science and Engineering Department, Thapar Institute of Engineering and Technology, India; Key Lab of Broadband Wireless Communication and Sensor Network Technology, Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing, 210003, China",2019.0,"Proceedings - IEEE 17th International Conference on Dependable, Autonomic and Secure Computing, IEEE 17th International Conference on Pervasive Intelligence and Computing, IEEE 5th International Conference on Cloud and Big Data Computing, 4th Cyber Science and Technology Congress, DASC-PiCom-CBDCom-CyberSciTech 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075140192&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCyberSciTech.2019.00166&partnerID=40&md5=6c2b8209d3c756cea6dcda7560ee1aae,10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00166,20230520-160000,20230521-044735,"['blockchain', 'as', 'a', 'service', 'for', 'software', 'defined', 'networks:', 'a', 'denial', 'of', 'service', 'attack', 'perspective']",True,20230521-205332,,,,
506,scopus,Can psychology walk the walk of open science?,"An ""open science movement"" is gaining traction across many disciplines within the research enterprise but is also precipitating consternation among those who worry that too much disruption may be hampering professional productivity. Despite this disruption, proponents of open data collaboration have argued that some of the biggest problems of the 21st century need to be solved with the help of many people and that data sharing will be the necessary engine to make that happen. In the United States, a national strategic plan for data sharing encouraged the federally funded scientific agencies to (a) publish open data for community use in discoverable, machinereadable, and useful ways; (b) work with public and civil society organizations to set priorities for data to be shared; (c) support innovation and feedback on open data solutions; and (d) continue efforts to release and enhance high-priority data sets funded by taxpayer dollars. One of the more visible open data projects in the psychological sciences is the presidentially announced ""Brain Research Through Advancing Innovative Neurotechnologies"" (BRAIN) initiative. Lessons learned from initiatives such as these are instructive both from the perspective of open science within psychology and from the perspective of understanding the psychology of open science. Recommendations for creating better pathways to ""walk the walk"" in open science include (a) nurturing innovation and agile learning, (b) thinking outside the paradigm, (c) creating simplicity from complexity, and (d) participating in continuous learning evidence platforms. © 2018 American Psychological Association.",Big data; Culture of science; Data sharing; Open science,Hesse B.W.,"National Cancer Institute, National Institutes of Health, Bethesda, MD, United States",2018.0,American Psychologist,American Psychological Association Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042565821&doi=10.1037%2famp0000197&partnerID=40&md5=3a3a987ffba5ec1af0bad3d25982b4f1,10.1037/amp0000197,20230520-160000,20230521-044735,"['can', 'psychology', 'walk', 'the', 'walk', 'of', 'open', 'science?']",False,20230521-205332,,,,
507,scopus,Smart hospitality: from smart cities and smart tourism towards agile business ecosystems in networked destinations,"Purpose: Building on recent smart hospitality systematic reviews and extensive literature analyses, this paper aims to explore recent developments, themes and issues within smart hospitality. It synthesises existing knowledge, extrapolating forward and contributes to the future development of smart hospitality by serving as a reference to enrich academic/industry discussions and stimulate future research. Design/methodology/approach: The research examined 8 recent review articles on smart hospitality and tourism and extracted 145 articles in peer-reviewed sources from Web of Science focussed on smart hospitality. These publications supported in-depth analysis to explore the body of knowledge and develop foresight for the future of smart hospitality within business ecosystems at tourism destinations. It synthesises knowledge and provides the basis for the development of a comprehensive in-depth research agenda in smart hospitality innovations as well as the formulation of agile hospitality ecosystems. Findings: This paper illustrates that smart hospitality introduces disruptive innovations that affect the entire hospitality ecosystem. Smart hospitality takes advantage of smart cities and smart tourism towards establishing agile business ecosystems in networked destinations. Having reviewed the existing literature, the study developed a conceptual framework and introduced a comprehensive future research agenda. This includes the drivers of smart hospitality, namely, customer-centricity, personalisation, individualisation and contextualisation; marketing-driven hospitality excellence and metaverse; as well as operation agility, asset strategy, talent management and supplier interoperation. It also identified the foundations that provide the infostructure for smart hospitality, including ambient intelligence, big data, processes and sustainability, providing the capability blocks to co-create value for all stakeholders in the hospitality ecosystem. Originality/value: This study conceptualises smart hospitality as a disruptive and innovative power that will affect the competitiveness of hospitality and tourism organisations as part of a comprehensive ecosystem. It identifies the key stakeholders and explores how they can take advantage of emerging developments. This paper proposes the drivers and foundation for future research on smart hospitality. The research provides a conceptual synthesis of the literature and the concepts that have been elaborated. The foundations are effectively the infostructure that enables the drivers to add value to different stakeholders. Key issues are identified to stimulate further research on the area to support smart hospitality development and adoption. © 2022, Emerald Publishing Limited.",Hospitality ecosystem; Research directions; Smart hospitality,"Buhalis D., O’Connor P., Leung R.","Bournemouth University Business School, Poole, United Kingdom; UniSA Business, University of South Australia, Adelaide, Australia; Department of International Tourism and Hospitality, I-Shou University, Kaohsiung, Taiwan; School of Hotel and Tourism Management, The Hong Kong Polytechnic University, Hong Kong",2023.0,International Journal of Contemporary Hospitality Management,Emerald Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139956928&doi=10.1108%2fIJCHM-04-2022-0497&partnerID=40&md5=e70359c5729cf0fbac30573d3ddb171d,10.1108/IJCHM-04-2022-0497,20230520-160000,20230521-044735,"['smart', 'hospitality:', 'from', 'smart', 'cities', 'and', 'smart', 'tourism', 'towards', 'agile', 'business', 'ecosystems', 'in', 'networked', 'destinations']",False,20230521-205332,,,,
508,scopus,Lean in industry 4.0 is accelerating manufacturing excellence – A DEMATEL analysis,"Purpose: The purpose of this research paper is to study the digital accelerators in conjunction with lean manufacturing enablers in the technology driven Industry 4.0 (I4.0) and understand their interrelationship dynamics with a goal to accelerate the pace of manufacturing excellence. Design/methodology/approach: Literature review coupled with the focus group approach facilitated to cull the key accelerating enablers to lean in I4.0. Thereafter, application of the multi criteria decision making methodology–DEMATEL (Decision Making Trial and Evaluation Laboratory) was carried out for analysis. Findings: A total of 18 factors from the integration of lean in I4.0 were identified from the focus group approach. The analysis from DEMATEL approach reflected that big data analytics and technology driven talent were the two most important factors in the manufacturing excellence journey. Leadership standard work and continuous improvement culture were the two key cause category factors, while, just in time the critical effect category factor. Practical implications: Analysis from DEMATEL approach has provided useful insights to industry leaders with the details of the degree of importance and type of influencing factors. It has given them direction in areas of investment to face the challenges of smart factories of tomorrow for sustainability. Originality/value: Application of DEMATEL approach for analyzing the dynamics of the 18 factors in the integrated lean systems in I4.0 for manufacturing excellence. © 2022, Emerald Publishing Limited.",Industry 4.0; Lean; Manufacturing,Ojha R.,"Department of Operations, Great Lakes Institute of Management Gurgaon, Gurgaon, India",2023.0,TQM Journal,Emerald Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125950291&doi=10.1108%2fTQM-11-2021-0318&partnerID=40&md5=0636484b99db185b47d646196d017e20,10.1108/TQM-11-2021-0318,20230520-160000,20230521-044735,"['lean', 'in', 'industry', '4.0', 'is', 'accelerating', 'manufacturing', 'excellence', '–', 'a\xa0dematel', 'analysis']",False,20230521-205332,,,,
509,scopus,To achieve sustainability in supply chain with Digital integration: A TISM approach,"Conventional supply chain has been shown to be incapable of meeting the ever-increasing demands of customers as well as the requirements of innovation. Due to various uncertainty volatility, ambiguity, and intricacy, the sustainability of supply chain becomes a major topic for organisations. Now there is need to integrate the digital technologies like cloud computing, internet of things, artificial intelligence, big data analysis etc. which improve the performance of supply chain in efficient and responsiveness manner. Due to this digital integration, the system undergoes various changes at organisational, operational, performance and technological level. This study aims to identify nine major critical factors which are enablers to achieve the sustainability in digitally integrated supply chain. A TISM model is developed to address their interrelationship among them. The factors are classified as dependent and independent factors according to their driving and dependence power through the use of the MICMAC analysis. If is confirmed in MICMAC analysis that the factors Agile Organisational structure, Smart logistics Capabilities, Smart Manufacturing Process and financial planning enhance the sustainability of digitally enabled supply chain. This study provides a comprehensive list of enablers that are necessary to achieve sustainability of digitally integrated supply chains; nevertheless, the list is not exhaustive. This paper was written with the intention of contributing a pool of knowledge on achieving sustainability in digitally integrated supply chain. This study has the potential to make it possible for market specialists and executives to focus on critical elements that lead to tactical decisions and maximise value for companies. It establishes a baseline from which future studies can build. © 2023 The Author(s).",Digital Integration; MICMAC; Sustainability; TISM,"Chauhan N.K., Kumar V., Dixit S.","Department of Mechanical Engineering, JC Bose University of Science & Technology, Haryana, Faridabad, 121006, India",2023.0,International Journal of Experimental Research and Review,International Academic Publishing House (IAPH),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158102959&doi=10.52756%2fijerr.2023.v30.041&partnerID=40&md5=f9660421f8e2559eca692881cc73f67e,10.52756/ijerr.2023.v30.041,20230520-160000,20230521-044735,"['to', 'achieve', 'sustainability', 'in', 'supply', 'chain', 'with', 'digital', 'integration:', 'a', 'tism', 'approach']",False,20230521-205332,,,,
510,scopus,A Cloud-Based Computing Framework for Artificial Intelligence Innovation in Support of Multidomain Operations,"The DoD's artificial intelligence (AI) strategy requires the delivery of transformative and disruptive capabilities that impact the 'character of the future battlefield and the pace of threats' that US forces must be prepared to handle. Candidate frameworks must also address key mission areas while enabling partnerships with the private sector, academia, and global allies. To meet these challenges, a flexible, cost-effective, and scalable computing infrastructure that incorporates cutting edge technologies and complies with stringent information assurance requirements is necessary. The DoD AI strategy mandates the agile employment of innovative AI capabilities that 'rapidly and iteratively' execute experimentation with new operating concepts, and leverage lessons learned in subsequent experiments. Using cloud computing, we present a flexible approach to solve complex systems problems. Promoting 'rapid experimentation' and collaboration on problems such as recursive algorithm implementation, deep learning, and inference in neural networks has enabled inherent advantages over existing computing frameworks. Leveraging the cloud to implement shared responsibility security models, serverless architectures, and high-performance virtual machines, aspects of the AI lifecycle including build, deploy, and monitor have resulted in an adaptable and scalable computing framework that is not only disruptive to the current computing paradigm but also promotes enhanced and productive collaboration. © 1988-2012 IEEE.",Artificial intelligence (AI); artificial intelligence for technology management; cloud computing; collaboration; design of experiments; IS design; new product development process; productivity in software development; RandD management; systems engineering; technology adoption; technology evaluation,"Robertson J., Fossaceca J., Bennett K.","US Army Research Laboratory, Adelphi, MD  20783, United States; Information Sciences, US Army Research Laboratory Ringgold Standard Institution, Adelphi, MD  20783-1138, United States; George Washington University, Ringgold Standard Institution, Washington, DC  20052-0086, United States; Army Research Laboratory, US Army Research Laboratory, Adelphi, MD  20783, United States",2022.0,IEEE Transactions on Engineering Management,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112602767&doi=10.1109%2fTEM.2021.3088382&partnerID=40&md5=9c8f3d052e7e9c4343d1c9a578bdc720,10.1109/TEM.2021.3088382,20230520-160000,20230521-044735,"['a', 'cloud-based', 'computing', 'framework', 'for', 'artificial', 'intelligence', 'innovation', 'in', 'support', 'of', 'multidomain', 'operations']",False,20230521-205332,,,,
511,scopus,Regulatory Considerations on the use of Machine Learning based tools in Clinical Trials,"Background: The widespread increasing use of machine learning (ML) based tools in clinical trials (CTs) impacts the activities of Regulatory Agencies (RAs) that evaluate the development of investigational medicinal products (IMPs) in clinical studies to be carried out through the use of data-driven technologies. The fast progress in this field poses the need to define new approaches and methods to support an agile and structured assessment process. Method: The assessment of key information, characteristics and challenges deriving from the application of ML tools in CTs and their link with the principles for a trustworthy artificial intelligence (AI) that directly affect the decision-making process is investigated. Results: Potential issues are identified during the assessment and areas of greater interaction combining key regulatory points and principles for a trustworthy AI are highlighted. The most impacted areas are those related to technical robustness and safety of the ML tool, in relation to data used and the level of evidence generated. Additional areas of attention emerged, like the ones related to data and algorithm transparency. Conclusion: We evaluate the applicability of a new method to further support the assessment of medicinal products developed using data-driven tools in a CT setting. This is a first step and new paradigms should be adopted to support policy makers and regulatory decisions, capitalizing on technology advancements, considering stakeholders’ feedback and still ensuring a regulatory framework on safety and efficacy. Graphical Abstract: [Figure not available: see fulltext.] © 2022, The Author(s).",Artificial intelligence; Big data; Clinical trials; Digital health; Machine learning; Regulatory,"Massella M., Dri D.A., Gramaglia D.","Clinical Trials Office, Italian Medicines Agency (AIFA), Via del Tritone 181, Rome, 00187, Italy; Department of Drug Chemistry and Technology, Sapienza University of Rome, Piazzale Aldo Moro 5, Rome, 00185, Italy",2022.0,Health and Technology,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141440484&doi=10.1007%2fs12553-022-00708-0&partnerID=40&md5=f4edb5464c3826bed84cd30c8e73e102,10.1007/s12553-022-00708-0,20230520-160000,20230521-044735,"['regulatory', 'considerations', 'on', 'the', 'use', 'of', 'machine', 'learning', 'based', 'tools', 'in', 'clinical', 'trials']",False,20230521-205332,,,,
512,scopus,Infoxication in the Genomic Data Era and Implications in the Development of Information Systems,"We live in an age where data acquisition is no longer a problem and the real challenge is how to determine which information is the right one to take important and sometimes difficult decisions. Infoxication (also known as Infobesity or Information Overload) is a term used to describe the difficulty of adapting to new situations and effectively making decisions when there is too much information to manage. With the advent of the Big Data, infoxication is affecting critical domains such as Health Sciences, where tough decisions for patient's health is being taken every day based on heterogeneous, unconnected and sometimes conflicting information. In order to understand the magnitude of the challenge, based on the information publicly available about the genetic causes of the disease and using data quality assessment techniques, we performed an exhaustive analysis of the DNA variations that have been associated to the risk of suffering migraine headache. The same analysis has been repeated 8 months after, and the results have allowed us to exemplify i) how fragile is the information in this domain, ii) the difficulty of finding repositories of contrasted and reliable data, and iii) the need to have information systems that, far from integrating and storing huge volumes of data, are able to support the decision-making process by providing mechanisms agile and flexible enough to be able to adapt to the changing user needs. © 2019 IEEE.",Genomics; Information Systems; Infoxication; SILE method,"Palacio A.L., Lopez O.P.","Universitat Politècnica de València, Valencia, Spain",2019.0,Proceedings - International Conference on Research Challenges in Information Science,IEEE Computer Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074544176&doi=10.1109%2fRCIS.2019.8877003&partnerID=40&md5=dbf9ab3c7798c7a18c1f180cc732b1b4,10.1109/RCIS.2019.8877003,20230520-160000,20230521-044735,"['infoxication', 'in', 'the', 'genomic', 'data', 'era', 'and', 'implications', 'in', 'the', 'development', 'of', 'information', 'systems']",True,20230521-205332,,,,
513,scopus,Digital supply chain management: An Overview,"Many global supply chains are unequipped to cope with the world we are entering. For that reason, supply chain managers need to shift their attention from cutting costs to enabling new processes, and make corporations more connected and agile to create value across the enterprise. New digital technologies that are emerging everyday are on their way to disrupt nearly all the areas of traditional business processes. The key business priority of almost every industry will find itself in the centre of this upcoming digital era. The process of digitization affects almost everything in today's organizations, including supply chain management and puts huge pressure on organizations to change. Hence it is crucial for managers to understand the implication of digitization on their organization and employees. Current scenario emphasises on the importance of management of people and organization issues in digital transformations. The effect of digitization includes varied impacts on economy as a whole; create tremendous opportunities and challenges for businesses. In the current world of globalization digitization is not a choice but an imperative for all businesses across all industries. Manufacturing processes and work, business model, products and services are the main targets of digitization. The digital transformation enablers and framework discussed in this study-comprised of six techniques of Big data, Cloud services, Unique identification and display innovation, Robotics, Sensors and geolocation, and nanotech and 3D printing-can serve as enablers of digitization. © Published under licence by IOP Publishing Ltd.",,"Agrawal P., Narain R.","Mech. Engg. Dept, Motilal Nehru National Institute of Technology, Allahabad, India",2018.0,IOP Conference Series: Materials Science and Engineering,Institute of Physics Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059389482&doi=10.1088%2f1757-899X%2f455%2f1%2f012074&partnerID=40&md5=3dc5458c777b722adf388c187548ec4f,10.1088/1757-899X/455/1/012074,20230520-160000,20230521-044735,"['digital', 'supply', 'chain', 'management:', 'an', 'overview']",False,20230521-205332,,,,
514,scopus,Training of it-personnel in the interior of “Digital economy”,"Krasnoyarsk Territory is a region of Russia, where the diversified economy of the country is represented. There are mining, metallurgical, petrochemical, timber, woodworking and other industries. Such a developed infrastructure of the economy provides stable needs for qualified specialists-engineers, technologists, power engineering specialists. It is clear that the system of higher and secondary vocational education is aimed at training personnel who are ready to participate in the regional development effectively. The world nowadays lives in the realities of the economy, where digital technologies have already been introduced in both industry and social entrepreneurship. There is enough evidence in the world that the digital economy is one of the most effective tools to increase labor productivity. The economy of any country expects the reduction of costs, the growth of efficiency, the quality of management, the competitiveness from digitalization. Increasingly, we use the terms “big data”, neurotechnology, artificial intelligence, new production technologies, industrial Internet, robotics, sensor technology, wireless communication, virtual and augmented reality in our vocabulary. Moreover, it does not matter whether we are talking about the soil sciences, space research or governmental management. Russia is aimed at the emergence of high-tech enterprises operating in the global market and forming a system of start-ups and research teams that will ensure the development of the economy in the future. Siberian Federal University as one of the largest universities in the country sees its mission in the training of specialists with digital competencies. Understanding the strategy of the state, our university acts as a source of expertise, analytical judgments, scientific discussions, wide dissemination and use of information, information and communication technologies. We have created a team of like-minded people from among the university faculty members, representatives of business and industry, who are ready for change. The purpose of the article is to present the authors’ experience in the development of the project in the form of the concept of a new Master’s educational program for the training of highly qualified specialists in the field of applied Informatics, ready for development, implementation and adaptation of information technologies of various industry directions. The goal is achieved on the basis of competence and system approaches. The research methodology is based on the use of analysis, synthesis, comparison, generalization, including phenomenological description, survey, included observation, Agile-methodology. The result of the team’s activity in the form of the developed concept will have a strong motivational effect both on the labor market and on the university applicants. To the first, it gives the opportunity to feel the involvement in the training of specialists in demand, to understand own value, the importance of it. © 2019, International Multidisciplinary Scientific Geoconference. All rights received.",Big data; Digital economy; IT-specialist,"Bagdasaryan I., Stupina A., Zhanna S., Titiberiya R., Vaitekunene E.","Siberian Federal University, Russian Federation; Reshetnev Siberian State University of Science and Technology, Russian Federation; Krasnoyarsk State Agrarian University, Russian Federation",2019.0,"International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM",International Multidisciplinary Scientific Geoconference,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073334047&doi=10.5593%2fsgem2019%2f5.4%2fS22.052&partnerID=40&md5=718aa0c0037a40b05a3327ec61c7070f,10.5593/sgem2019/5.4/S22.052,20230520-160000,20230521-044735,"['training', 'of', 'it-personnel', 'in', 'the', 'interior', 'of', '“digital', 'economy”']",False,20230521-205332,,,,
515,scopus,AgileChains: Agile supply chains through smart digital twins,"Currently, production and logistics performance of a single organization are only partially dependent on the internal resources, but more and more often, they also depend on the interactions that happen across the so-called supply chain, that is, the interactions between the organization and its customers and suppliers. In particular, the production and logistics coordination between actors in the supply chain is often a difficult activity which draws significant resources. Also, such coordination requires continuous revisions and updates to be performed. In Industry 4.0, the digital twins paradigm is currently adopted to represent, simulate and test the behavior of one or more machines and production plants belonging to an organization. This paper introduces the AgileChains paradigm, extending the digital twin paradigm to supply chains and the dynamics of their participants. This extension also positively affects the reactivity and resilience of the internal processes in case the supply chain has to be reconfigured. We propose a novel conceptual framework that combines Service Oriented Architectures (SOA) with Cyber-Physical Systems (CPS), in order to create service oriented systems suited for exchanging data in a dynamic and adaptive way. In addition, we propose a novel data management mechanism capable of finding the right balance between the internal needs of each organization when handling their data and the need to securely and efficiently export data in the supply chain (cf. smart data movement ). Finally, we plan to define governance tools to model and manage the supply chain that treat agility as a first-class citizen. These tools will allow users to dynamically and predictively change the involved actors, as well as the nature of the exchanged data and the data exchange policies, focusing in particular on adverse, risk-prone events, so to minimize the risk and to optimize the supply chain performance both in terms of efficiency and effectiveness. Copyright © ESREL2020-PSAM15 Organizers.",Big data; Data spaces; Digital twins; Industry 4.0; IoT; Reliability; Resilience,"Pernici B., Plebani P., Mecella M., Leotta F., Mandreoli F., Martoglia R., Cabri G.","DEIB, Politecnico di Milano, Italy; DIAG, Sapienza Università di Roma, Italy; FIM, Università di Modena e Reggio Emilia, Italy",2020.0,"30th European Safety and Reliability Conference, ESREL 2020 and 15th Probabilistic Safety Assessment and Management Conference, PSAM 2020",Research Publishing Services,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110328892&partnerID=40&md5=f83be5e762ea4866c7e824b17a3fd9d8,,20230520-160000,20230521-044735,"['agilechains:', 'agile', 'supply', 'chains', 'through', 'smart', 'digital', 'twins']",False,20230521-205332,,,,
516,scopus,Agilechains: Agile supply chains through smart digital twins,"Currently, production and logistics performance of a single organization are only partially dependent on the internal resources, but more and more often, they also depend on the interactions that happen across the so-called supply chain, that is, the interactions between the organization and its customers and suppliers. In particular, the production and logistics coordination between actors in the supply chain is often a difficult activity which draws significant resources. Also, such coordination requires continuous revisions and updates to be performed. In Industry 4.0, the digital twins paradigm is currently adopted to represent, simulate and test the behavior of one or more machines and production plants belonging to an organization. This paper introduces the AgileChains paradigm, extending the digital twin paradigm to supply chains and the dynamics of their participants. This extension also positively affects the reactivity and resilience of the internal processes in case the supply chain has to be reconfigured. We propose a novel conceptual framework that combines Service Oriented Architectures (SOA) with Cyber-Physical Systems (CPS), in order to create service oriented systems suited for exchanging data in a dynamic and adaptive way. In addition, we propose a novel data management mechanism capable of finding the right balance between the internal needs of each organization when handling their data and the need to securely and efficiently export data in the supply chain (cf. smart data movement ). Finally, we plan to define governance tools to model and manage the supply chain that treat agility as a first-class citizen. These tools will allow users to dynamically and predictively change the involved actors, as well as the nature of the exchanged data and the data exchange policies, focusing in particular on adverse, risk-prone events, so to minimize the risk and to optimize the supply chain performance both in terms of efficiency and effectiveness. © ESREL 2020-PSAM15 Organizers. Published by Research Publishing, Singapore.",Big data; Data spaces; Digital twins; Industry 4.0; IoT; Reliability; Resilience,"Pernici B., Plebani P., Mecella M., Leotta F., Mandreoli F., Martoglia R., Cabri G.","DEIB, Politecnico di Milano, Italy; DIAG, Sapienza Università di Roma, Italy; FIM, Università di Modena e Reggio Emilia, Italy",2020.0,Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference,"Research Publishing, Singapore",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107285147&doi=10.3850%2f978-981-14-8593-0_3697-cd&partnerID=40&md5=570372efcd42849c3ba221e6fcef3101,10.3850/978-981-14-8593-0_3697-cd,20230520-160000,20230521-044735,"['agilechains:', 'agile', 'supply', 'chains', 'through', 'smart', 'digital', 'twins']",True,20230521-205332,,,,
517,scopus,Investigating potential interventions on disruptive impacts of Industry 4.0 technologies in circular supply chains: Evidence from SMEs of an emerging economy,"As a transversal theme, the intertwining of digitalization and sustainability has crossed all Supply Chains (SCs) levels dealing with widespread environmental and societal concerns. This paper investigates the potential interventions and disruptive impacts that Industry 4.0 technologies may have on pharmaceutical Circular SCs (CSCs). To accomplish this, a novel method involving a literature review and Pythagorean fuzzy-Delphi has initially been employed to identify and screen categorized lists of Industry 4.0 Disruptive Technologies (IDTs) and their impacts on pharmaceutical CSC. Subsequently, the weight of finalized impacts and the performance score of finalized IDTs have simultaneously been measured via a novel version of Pythagorean fuzzy SECA (Simultaneously Evaluation of Criteria and Alternatives). Then, the priority of each intervention for disruptive impacts of Industry 4.0 has been determined via the Hanlon method. This is one of the first papers to provide in-depth insights into advancing the study of the disruptive action of Industry 4.0 technologies cross-fertilizing CE throughout pharmaceutical SCs in the emerging economy of Iran. The results indicate that digital technologies such as Big Data Analytics, Global Positioning Systems, Enterprise Resource Planning, and Digital Platforms are quite available in the Irans' pharmaceutical industry. These technologies, along with four available interventions, e.g., environmental regulations, subsidy, fine, and reward, would facilitate moving towards a lean, agile, resilient, and sustainable supply chain through the efficient utilization of resources, optimized waste management, and substituting the human workforce by machines. © 2022 The Author(s)",Hanlon method; Industry 4.0 technologies; Pythagorean fuzzy Delphi; Pythagorean fuzzy SECA,"Amoozad Mahdiraji H., Yaftiyan F., Abbasi-Kamardi A., Garza-Reyes J.A.","School of Business, University of Leicester, Leicester, United Kingdom; Faculty of Management, University of Tehran, Tehran, Iran; Centre for Supply Chain Improvement, The University of Derby, United Kingdom",2022.0,Computers and Industrial Engineering,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140486674&doi=10.1016%2fj.cie.2022.108753&partnerID=40&md5=f03597f78a581831ff8a0c2db2b23f0f,10.1016/j.cie.2022.108753,20230520-160000,20230521-044735,"['investigating', 'potential', 'interventions', 'on', 'disruptive', 'impacts', 'of', 'industry', '4.0', 'technologies', 'in', 'circular', 'supply', 'chains:', 'evidence', 'from', 'smes', 'of', 'an', 'emerging', 'economy']",False,20230521-205332,,,,
518,scopus,Industry 4.0 in Shipbuilding. Application in Autonomous Ships,"Industry 4.0 has favoured the expansion of many technologies where application boundaries are very diffuse. Although some technologies may have very specific applications, there are others much more open. The Shipbuilding Industry is quite traditional, however there are many advantages if the Industry 4.0 technologies could be applied from the beginning of the ship design to autonomous shipping. CAD/CAM tools are used to manage many data that must be considered in advance for the further stages of the ship lifecycle. Augmented Reality, Virtual Reality and Mixed Reality are closely related to the Digital Twin and interlaced with Big Data, which are generated by CAD tools and all surrounding solutions, which applies some cloud/edge/fog computing to these data in a merged technology between finite-state machines and Artificial Intelligence cognitive processes. To perform all these integrations in an agile manner requires a network which support different connections to add specific devices, i.e. Internet of the Things, which can access to the data, creating and modifying them, in a different layer which affects to the basic information layer created by the CAD/PLM tools in the shipyard and later on being used by the autonomous ships. This network should be secure, but also open to allow distributed work, which must be tracked such that all design or process modifications are recorded an open, transparent, trusted and non-modifiable working method for all stakeholders, like shipyard, engineering offices, classification society and ship owner. This paper briefly summarizes how Industry 4.0 technologies may be applied to the shipbuilding, whether through direct integration or in connected periphery applications, and its application to autonomous ships. © 2022 The authors and IOS Press. All rights reserved.",Autonomous Ships; Industry 4.0; Ship Design; Shipbuilding CAD Systems,Fernandez R.P.,"Universidad Politécnica de Madrid, Spain",2022.0,Progress in Marine Science and Technology,IOS Press BV,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138196285&doi=10.3233%2fPMST220005&partnerID=40&md5=49b7d897009cb96bed715218ae4f70ce,10.3233/PMST220005,20230520-160000,20230521-044735,"['industry', '4.0', 'in', 'shipbuilding.', 'application', 'in', 'autonomous', 'ships']",False,20230521-205332,,,,
519,scopus,Digital Transformation Impact Analysis towards Transition in the Role of Information Technology for Organization in New Digital Bank,"The role of Information Technology in the banking industry has been playing an important role in providing better services to customers and open new opportunities. Bank XYZ is a conventional bank that is transforming into a digital bank to improve bank XYZ's position in financial services sector, specifically in the banking industry. In the process of transforming into digital banking, Information Technology leadership in the organization is important. However, publications regarding the impact of digital transformation in Information Technology role and leadership, especially in the banking industry are scarce, so this research is importance. The benefit of this research is to be organization consideration for designing corporate information strategy & management and can be a reference and contribution of ideas that can enrich knowledge and further research about corporate information strategy & management. This study aims to identify digital transformation impact in IT role and leadership specifically in new digital bank. Qualitative approach with data collection from semi-structured interviews and document was used to identify the impact of digital transformation towards transition in the role of information technology and do benchmarking Bank XYZ's case with a few new digital banks in the world. Based on the comparison and benchmarking, learned lesson as an input for Bank XYZ to improve the digital transformation process into a digital bank. Integrated big data, agile team, automation process, cloud computing, machine learning, and artificial intelligence was the common capability of a digital bank. © 2022 IEEE.",Digital Bank; Digital Transformation; Leadership; Role of Information Technology; Strategic,"Sagala Y.P., Juniawan M.A., Effendy V.A., Putrianasari R., Nuraini W., Rahmatika V.A., Shihab M.R., Ranti B.","University of Indonesia, Faculty of Computer Science, Jakarta, Indonesia",2022.0,"2022 7th International Conference on Informatics and Computing, ICIC 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146949820&doi=10.1109%2fICIC56845.2022.10007003&partnerID=40&md5=77a8ee19452cf42a49468344abd99b8e,10.1109/ICIC56845.2022.10007003,20230520-160000,20230521-044735,"['digital', 'transformation', 'impact', 'analysis', 'towards', 'transition', 'in', 'the', 'role', 'of', 'information', 'technology', 'for', 'organization', 'in', 'new', 'digital', 'bank']",True,20230521-205332,,,,
520,scopus,Production Flow Management Based on Industry 4.0 Technologies,"The industry 4.0 technologies are transforming the current industry into a smart industry. While at the same time, the application of the lean manufacturing tools has reduced the wastes and improving efficiency. The technologies of industry 4.0 have facilitated the management of production flows from the raw material to the delivery of the finished product to the final customer. Several technologies have been used to manage the workflow, such as Internet of Things (IoT), artificial intelligence (AI), cloud computing, machine learning, security, Big data, Block chain, Deep learning, Digitization, and Cyber-physical system (CPS), without knowing the best of these technologies are adapted to the management of production flows. Therefore, there is an increased need for automated solutions in the production flow management (PFM) in order to increasing the production efficiency and reduce the lead times by using these industry 4.0 technologies. Such solutions need to replace the manual effort and creating new ways of innovation technologies and development. The aims of this paper is the study the application of industry 4.0 technologies to manage the production flow in automotive industry. The results of this study show that RFID, IoT, CPS and AI are the most technologies of industry 4.0 applied in the production lines in order to minimize the production time, and the on-time delivery. © 2022 IEEE.",Automotive industry; Digitalization; Industry 4.0 technologies; Lean production; RFID; Supply chain management,"Amejwal M., El Jaouhari A., Arif J., Fellaki S., Jawab F.","Higher School of Technology, Sidi Mohamed Ben Abdellah University, Laboratory of Technologies and Industrial Services, Fez, Morocco; National School of Applied Sciences, Laboratory of Modeling and Optimization of Industrial Systems and Logistics, Tetouan, Morocco",2022.0,"2022 IEEE 14th International Conference of Logistics and Supply Chain Management, LOGISTIQUA 2022",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143060646&doi=10.1109%2fLOGISTIQUA55056.2022.9938064&partnerID=40&md5=c2183c9624c1c8a94757f2e3fad56ed8,10.1109/LOGISTIQUA55056.2022.9938064,20230520-160000,20230521-044735,"['production', 'flow', 'management', 'based', 'on', 'industry', '4.0', 'technologies']",False,20230521-205332,,,,
521,scopus,The future of leadership—How is leadership in small and medium-sized enterprises going to change? [Zukunft der Führung – Wie wird sich Führung in kleinen und mittleren Unternehmen verändern?],"This paper in the Journal Gruppe. Interaktion. Organisation. (GIO) addresses changes in leadership through digitalization and their consequences for leaders. For years, digitalization has been heralding changes such as increasing leadership at a distance or use of digital communication media. Small and medium-sized enterprises (SMEs) now face the task of coping with these changes and have to contend with major uncertainties: What are major determining trends for leaders in SMEs? Which changes will shape leadership and how will they change leadership tasks and success-critical behavior? In semi-structured interviews with seven experts from SMEs we have explored these questions. Trends expected by the experts describe changes in the organizational structures and in work within the company. Structurally, companies will become more agile and diverse, hierarchies will play a less strong role and companies will cooperate more closely with each other. Work will become more location-independent, more influenced by Big Data and many tasks will be made easier or taken over by technology. In relation to established models of leadership tasks and behavior, the experts see a clear shift in tasks in favor of managing human resources, including the development of employees through coaching and the transfer of responsibility. In addition to previous tasks, the experts see managing change as a new task area. This area consists of accompanying change, acting flexibly and agilely, communicating openly and transparently and allowing failure. With regard to changes in success-critical behavior, leaders have to show more strategy orientation, communicate clearly and be open to new ideas and further development. © 2021, The Author(s).",Digitalization; Leadership; Leadership behavior; Skills; Tasks,"Ötting S.K., Masjutin L., Maier G.W.","Department of Psychology, Bielefeld University, Universitätsstraße 25, Bielefeld, 33615, Germany",2021.0,Gruppe. Interaktion. Organisation. Zeitschrift fur Angewandte Organisationspsychologie,Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121601664&doi=10.1007%2fs11612-021-00610-9&partnerID=40&md5=d72323f3c14da370a375f444b25d9dc9,10.1007/s11612-021-00610-9,20230520-160000,20230521-044735,"['the', 'future', 'of', 'leadership—how', 'is', 'leadership', 'in', 'small', 'and', 'medium-sized', 'enterprises', 'going', 'to', 'change?', '[zukunft', 'der', 'führung\xa0–', 'wie', 'wird', 'sich', 'führung', 'in', 'kleinen', 'und', 'mittleren', 'unternehmen', 'verändern?]']",False,20230521-205332,,,,
522,scopus,A Framework for Partitioning Support Vector Machine Models on Edge Architectures,"Current IoT applications generate huge volumes of complex data that requires agile analysis in order to obtain deep insights, often by applying Machine Learning (ML) techniques. Support vector machine (SVM) is one such ML technique that has been used in object detection, image classification, text categorization and Pattern Recognition. However, training even a simple SVM model on big data takes a significant amount of computational time. Due to this, the model is unable to react and adapt in real-time. There is an urgent need to speedup the training process. Since organizations typically use the cloud for this data processing, accelerating the training process has the advantage of bringing down costs. In this paper, we propose a model partitioning approach that partitions the tasks of Stochastic Gradient Descent based Support Vector Machines (SGD-SVM) on various edge devices for concurrent computation, thus reducing the training time significantly. The proposed partitioning mechanism not only brings down the training time but also maintains the approximate accuracy over the centralized cloud approach. With a goal of developing a smart objection detection system, we conduct experiments to evaluate the performance of the proposed method using SGD-SVM on an edge based architecture. The results illustrate that the proposed approach significantly reduces the training time by 47%, while decreasing the accuracy by 2%, and offering an optimal number of partitions. © 2021 IEEE.",edge computing; partitioning; SGD-SVM,"Sahi M., Maruf M.A., Azim A., Auluck N.","Indian Institute of Technology, Department of Computer Science and Engineering, Ropar, India; Ontario Tech University, Computer and Software Engineering, Department of Electrical, Ontario, Canada; Ontario Tech University, Computer and Software Engineering, Department of Electrical, Ontario, Canada",2021.0,"Proceedings - 2021 IEEE International Conference on Smart Computing, SMARTCOMP 2021",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117593354&doi=10.1109%2fSMARTCOMP52413.2021.00062&partnerID=40&md5=55ffa5b556a11c1c4e9759981f25b80b,10.1109/SMARTCOMP52413.2021.00062,20230520-160000,20230521-044735,"['a', 'framework', 'for', 'partitioning', 'support', 'vector', 'machine', 'models', 'on', 'edge', 'architectures']",True,20230521-205332,,,,
523,scopus,An approach to build e-health iot reactive multi-services based on technologies around cloud computing for elderly care in smart city homes,"Although there are e-health systems for the care of elderly people, the reactive characteristics to enhance scalability and extensibility, and the use of this type of system in smart cities, have been little explored. To date, some studies have presented healthcare systems for specific purposes without an explicit approach for the development of health services. Moreover, software engineering is hindered by agile management challenges regarding development and deployment processes of new applications. This paper presents an approach to develop health Internet of Things (IoT) reactive applications that can be widely used in smart cities for the care of elderly individuals. The proposed approach is based on the Rozanski and Woods’s iterative architectural design process, the use of architectural patterns, and the Reactive Manifesto Principles. Furthermore, domain-driven design and the characteristics of the emerging fast data architecture are used to adapt the functionalities of services around the IoT, big data, and cloud computing paradigms. In addition, development and deployment processes are proposed as a set of tasks through DevOps techniques. The approach validation was carried out through the implementation of several e-health services, and various workload experiments were performed to measure scalability and performance in certain parts of the architecture. The system obtained is flexible, scalable, and capable of handling the data flow in near real time. Such features are useful for users who work collaboratively in the care of elderly people. With the accomplishment of these results, one can envision using this approach for building other e-health services. © 2021 by the author. Licensee MDPI, Basel, Switzerland.",Cloud computing; Container as a service; DevOps; E-health; Emerging fast data architecture; Internet of Things (IoT); Reactive system,"Pérez L.J., Salvachúa J.","Departamento de Ingeniería de Sistemas Telemáticos, Universidad Politécnica de Madrid, Madrid, 28040, Spain",2021.0,Applied Sciences (Switzerland),MDPI AG,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107743176&doi=10.3390%2fapp11115172&partnerID=40&md5=32c25997c71bea3ab40f5afc4c6906ec,10.3390/app11115172,20230520-160000,20230521-044735,"['an', 'approach', 'to', 'build', 'e-health', 'iot', 'reactive', 'multi-services', 'based', 'on', 'technologies', 'around', 'cloud', 'computing', 'for', 'elderly', 'care', 'in', 'smart', 'city', 'homes']",False,20230521-205332,,,,
524,scopus,Virtual learning: a disruptive service in academic libraries,"Purpose: The purpose of this paper is to present the alignment of disruptive technologies into library and information science (LIS) and libraries as virtual learning spaces during the COVID-19 pandemic lockdown as alternative trajectories to end the disruption caused by the COVID-19; however, the educational systems are still facing challenges in achieving these lofty objectives. Design/methodology/approach: A living-lab methodology was adopted for this paper as an innovative approach, in which technologies that are in the development stages or full deployments are integrated with social research design to test the viability of such technologies for the intended purposes. Findings: The LIS alignment of virtual learning technologies showed that disruptive technology could benefit academic libraries, with minimum training of staff. However, internet bandwidth, digital divide and lack of built-in functionality on the Zoom, compared with Moodle, for assessment and grading are huge setbacks. Nevertheless, library platforms must be mobile-response and agile software algorithm to include voice-over and voice recognition search functionality to access all the databases. Research limitations/implications: For this paper, use of disruptive technology was limited to virtual online learning, Zoom and Moodle; however, the alignment of blockchain and big data and the libraries services was not covered. Practical implications: This paper showed that the LIS could mitigate the COVID-19 global pandemic with disruptive IT alignment with learning management systems (LMS) and for the libraries to remain open during the coronavirus lockdown. Social implications: Academic libraries can deploy disruptive technologies as virtual library spaces. Originality/value: Disruptive technology alignment with LMS as virtual library space was posited for the academic librarians to mitigate the effect of COVID-19 pandemic. © 2020, Emerald Publishing Limited.",Academic librarian; Disruptive technology; Library; LIS; Virtual learning,"Ajibade P., Mutula S.M.","Department of Information Studies Programme, University of KwaZulu-Natal College of Humanities, South Africa; University of KwaZulu-Natal – Pietermaritzburg Campus, Pietermaritzburg, South Africa",2021.0,Library Hi Tech News,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097294323&doi=10.1108%2fLHTN-07-2020-0067&partnerID=40&md5=b11071d8c14b6b10769d7686447a72da,10.1108/LHTN-07-2020-0067,20230520-160000,20230521-044735,"['virtual', 'learning:', 'a', 'disruptive', 'service', 'in', 'academic', 'libraries']",False,20230521-205332,,,,
525,scopus,Data Centered and Usage-Based Security Service,"Protecting Information Systems (IS) relies traditionally on security risk analysis methods. Designed for well-perimetrised environments, these methods rely on a systematic identification of threats and vulnerabilities to identify efficient control-centered protection countermeasures. Unfortunately, this does not fit security challenges carried out by the opened and agile organizations provided by the Social, Mobile, big data Analytics, Cloud and Internet of Things (SMACIT) environment. Due to their inherently collaborative and distributed organization, such multi-tenancy systems require the integration of contextual vulnerabilities, depending on the a priori unknown way of using, storing and exchanging data in opened cloud environment. Moreover, as data can be associated to multiple copies, different protection requirements can be set for each of these copies, which may lead the initial data owner lose control on the data protection. This involves (1) turning the traditional control-centered security vision to a dynamic data-centered protection and even (2) considering that the way a data is used can be a potential threat that may corrupt data protection efficiency. To fit these challenges, we propose a Data-centric Usage-based Protection service (DUP). This service is based on an information system meta-model, used to identify formally data assets and store the processes using copies of these assets. To define a usage-entered protection, we extend the Usage Based Access Control model, which is mostly focused on managing CRUD operations, to more complex operation fitting the SMACIT context. These usage rules are used to generate smart contracts, storing usage consents and managing usage control for cloud services. © 2021, Springer Nature Switzerland AG.",Blockchain; Data-driven organization; GDPR; Privacy; Usage governance,"Yuan J., Biennier F., Benharkat N.","University of Lyon, CNRS, INSA-Lyon, LIRIS, UMR 5205, Lyon, France",2021.0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Springer Science and Business Media Deutschland GmbH,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111363533&doi=10.1007%2f978-3-030-76352-7_42&partnerID=40&md5=9f2820e2ee3760bd2892ae555bca8318,10.1007/978-3-030-76352-7_42,20230520-160000,20230521-044735,"['data', 'centered', 'and', 'usage-based', 'security', 'service']",False,20230521-205332,,,,
526,scopus,Cerebral approach to track malfunction of assets in a smart power grid information system,"Failure of assets at downstream level of Smart Power Grid being barely addressed, subsequently hoarding lots of superfluous human hours, depletion of valuable time and resources, inefficient and untimely rectification of problems leading to concerns of inefficient operations and hefty loss to the power grid organization in all its aspects. There is a need to address such failures in advance, through the use of prevailing information technological inclusion, implicating efficient operations benefiting the entire sector. With Knowledge Management Systems evolving at its growing needs to address critical issues and providing feasible solutions to the digitization of information already at high demand, we propose an analytical approach merged with the concepts of big data, to track historical data of assets and resources, to identify the possibilities of failure of assets in smart power grid infrastructure. The proposed system would identify the possible failure based on the past records of an assets performance and failures, not limited to, but also based on the expected life span of the assets. The issues will be archived for further sharing while in apposite needs and its solutions would be appropriately applied throughout the power business and its subsidiary. The data would be efficiently stored and archived in the form of digitized formats such as audio, video, images, comments, documents, feedback and other visually recognizable and multimedia formats. Various technological related electronics and gadget equipment's such as tablets, mobile phones, laptops and other hand held devices could be easily utilized to support the work force teams towards an agile operation. © 2020 Institute of Physics Publishing. All rights reserved.",,"Sayed B.T., Dekdouk A., Ashraf Y., Chaudhry S.","Department of Computer Science, Dhofar University, PO Box 2509, P. Code 211, Salalah, Oman; Department of Computer Science, Dhofar University, PO Box 2509, P. Code 211, Salalah, Oman; Distribution Planning Department, Dhofar Power Company S.A.O.C, PO Box 2609, P. Code 211, Salalah, Oman; Department of Computer Science, Dhofar University, PO Box 2509, P. Code 211, Salalah, Oman",2020.0,IOP Conference Series: Earth and Environmental Science,IOP Publishing Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094967561&doi=10.1088%2f1755-1315%2f582%2f1%2f012004&partnerID=40&md5=8003138470826d9125fe36b855cd1a1c,10.1088/1755-1315/582/1/012004,20230520-160000,20230521-044735,"['cerebral', 'approach', 'to', 'track', 'malfunction', 'of', 'assets', 'in', 'a', 'smart', 'power', 'grid', 'information', 'system']",False,20230521-205332,,,,
527,scopus,A Cost-Efficient Container Orchestration Strategy in Kubernetes-Based Cloud Computing Infrastructures with Heterogeneous Resources,"Containers, as a lightweight application virtualization technology, have recently gained immense popularity in mainstream cluster management systems like Google Borg and Kubernetes. Prevalently adopted by these systems for task deployments of diverse workloads such as big data, web services, and IoT, they support agile application deployment, environmental consistency, OS distribution portability, application-centric management, and resource isolation. Although most of these systems are mature with advanced features, their optimization strategies are still tailored to the assumption of a static cluster. Elastic compute resources would enable heterogeneous resource management strategies in response to the dynamic business volume for various types of workloads. Hence, we propose a heterogeneous task allocation strategy for cost-efficient container orchestration through resource utilization optimization and elastic instance pricing with three main features. The first one is to support heterogeneous job configurations to optimize the initial placement of containers into existing resources by task packing. The second one is cluster size adjustment to meet the changing workload through autoscaling algorithms. The third one is a rescheduling mechanism to shut down underutilized VM instances for cost saving and reallocate the relevant jobs without losing task progress. We evaluate our approach in terms of cost and performance on the Australian National Cloud Infrastructure (Nectar). Our experiments demonstrate that the proposed strategy could reduce the overall cost by 23% to 32% for different types of cloud workload patterns when compared to the default Kubernetes framework. © 2020 ACM.",Cluster management; container orchestration; cost efficiency; resource heterogeneity,"Zhong Z., Buyya R.","University of Melbourne, Cloud Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and Information System, Parkville Campus, Melbourne, VIC  3010, Australia",2020.0,ACM Transactions on Internet Technology,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085479823&doi=10.1145%2f3378447&partnerID=40&md5=d836b106fff608206434bde56f55841f,10.1145/3378447,20230520-160000,20230521-044735,"['a', 'cost-efficient', 'container', 'orchestration', 'strategy', 'in', 'kubernetes-based', 'cloud', 'computing', 'infrastructures', 'with', 'heterogeneous', 'resources']",True,20230521-205332,,,,
528,scopus,Status quo and quo vadis: Creativity techniques and innovation methods for generating extended innovation processes,"Our working world is on the threshold of a new era: The digital transformation of entire economic sectors and occupational profiles as well as the introduction of new forms of human-machine collaboration through the increased use of big data and cognitive systems require completely new approaches. The key to success in coping with this change, which can be seen in all industries, is to break up old structures and venture something new. The ability to adapt and innovate is becoming a central success-critical factor in entrepreneurial activity. In order to continue to achieve market success and ensure sustainable growth in an extremely dynamic and disruptive environment, enterprises and organisations are called upon to proactively shape change. In addition to the establishment of flexible working models and agile processes, the increased generation and integration of knowledge into and around technical systems in the course of targeted competence development of employees is indispensable. The introduction and use of technical systems thus must go hand in hand with the flexibilisation of innovation and collaboration processes as well as the development of employee skills in order to generate the currently missing socio-technological link - for companieś added value and for the benefit of people. In this paper, the authors present an overview of currently used creativity techniques and innovation methods and work out the promising potentials as well as basic restrictions of the respective tools. Furthermore, the resulting need for action for the optimisation and enhancement of innovation processes in the interaction of established techniques and possibilities of cognitive systems is presented. © 2017 The Authors. Published by Elsevier B.V.",Artificial intelligence; design; human-machine interaction; innovation process,"Vocke C., Constantinescu C., Popescu D.","Fraunhofer IAO, Nobelstr. 12, Stuttgart, 70569, Germany; Technical University of Cluj-Napoca, Strada Memorandumului 28, Cluj-Napoca, 400114, Romania",2020.0,Procedia CIRP,Elsevier B.V.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091693335&doi=10.1016%2fj.procir.2020.02.148&partnerID=40&md5=1c8928e66eba93522220daad9d7efcfa,10.1016/j.procir.2020.02.148,20230520-160000,20230521-044735,"['status', 'quo', 'and', 'quo', 'vadis:', 'creativity', 'techniques', 'and', 'innovation', 'methods', 'for', 'generating', 'extended', 'innovation', 'processes']",False,20230521-205332,,,,
529,scopus,IIot platform for agile manufacturing in plastic and rubber domain,"In recent years, the concept of integration as a key to digital transformation has also been associated with the interconnection of hardware, software, data and information in Industry 4.0. One of the greatest challenges of Industry 4.0 is to be able to ingest massive amounts of data coming out from machines: The eFactory platform enable users to exploit innovative functionalities, experiment with disruptive approaches and develop custom solutions to maximise connectivity, interoperability and efficiency across the supply chains. To achieve this goal, it is necessary to work on standard communication protocols and architectures. By leveraging Industrial Internet of Things (IIoT) technologies, this feasibility study focuses on the design and implementation of an open source platform for plastic and rubber industry, that abstract data and functionalities provided by onboard machinery sensors, exposing relevant services outside the machines to external cloud-based applications. The federation of this new services related to the industrial scenario is supported by an interoperable 'Data Spine' that simplifies cross-platform communication and securely capture information on the multi-tier supply chain. The intent is to make the production process more automated, interconnected and moreover to support a Zero-Defect strategy thanks to digital technologies involved in the project. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Cross-Domain Platforms; Edge Computing; Euromap; Federation of Platforms; Industrial Internet of Things Gateway; Industry 4.0; Interoperability; Kura Framework; OPC UA; Smart Factories; Zero Defect Manufacturing,"Bosi I., Rosso J., Ferrera E., Pastrone C.","LINKS Foundation, Leading Innovation and Knowledge for Society, Turin, Italy",2020.0,"IoTBDS 2020 - Proceedings of the 5th International Conference on Internet of Things, Big Data and Security",SciTePress,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089527177&partnerID=40&md5=3788ab1fee3f2b6b49d22ba5df016391,,20230520-160000,20230521-044735,"['iiot', 'platform', 'for', 'agile', 'manufacturing', 'in', 'plastic', 'and', 'rubber', 'domain']",False,20230521-205332,,,,
530,scopus,A Microservices Platform for Monitoring and Analysis of IoT Traffic Data in Smart Cities,"The ongoing digitization of cities, enabled by the diffusion of interconnected sensors and devices, makes it possible to continuously collect and analyze huge streams of data at extremely large spatio-temporal scales and fine resolutions. These data can be used to monitor, detect and anticipate different kinds of infrastructure vulnerabilities and anomalies, as well as to implement more personalized services that could improve citizens' life. In this new context, full of opportunities, it is difficult to foresee and develop, in advance, the set of applications and services that can be potentially useful for administrators and citizens to solve the manifold compelling needs a city may have to face. Novel ICT paradigms and technologies can help designing agile, general-purpose smart city platforms aimed at supporting the collection and treatment of large-scale, multi-source (streams of) data and the development of novel applications that could fulfill diverse functional requirements under strict non-functional constraints. This paper presents the reference architecture, a prototype implementation and a city-scale case-study evaluation of PROMENADE, a platform that exploits IoT/Fog/Cloud paradigms, microservices and DevOps infrastructures to guarantee continuous development of robust and reliable applications for real-time monitoring and analysis of traffic data generated by IoT devices in large smart cities. The prototype has been evaluated in a case study concerning the quasi real-time detection of road networks vulnerabilities via centrality measures from on-line traffic conditions, emulated from off-line real datasets available for the city of Lyon, France. © 2019 IEEE.",IoT Platform; Microservices; Resilience; Smart cities; Traffic monitoring,"De Iasio A., Futno A., Goglia L., Zimeo E.","University of Sannio, Benevento, Italy; Univ. of Lyon, ENTPE, IFSTTAR LICIT UMR T9401, Lyon, France; University of Sannio, CINI Smart City Lab, Benevento, Italy",2019.0,"Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081406556&doi=10.1109%2fBigData47090.2019.9006025&partnerID=40&md5=1b98b6e5125fe68ddf6d06966a723372,10.1109/BigData47090.2019.9006025,20230520-160000,20230521-044735,"['a', 'microservices', 'platform', 'for', 'monitoring', 'and', 'analysis', 'of', 'iot', 'traffic', 'data', 'in', 'smart', 'cities']",True,20230521-205332,,,,
531,scopus,Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry,"Digital twins, along with the internet of things (IoT), data mining, and machine learning technologies, offer great potential in the transformation of today's manufacturing paradigm toward intelligent manufacturing. Production control in petrochemical industry involves complex circumstances and a high demand for timeliness; therefore, agile and smart controls are important components of intelligent manufacturing in the petrochemical industry. This paper proposes a framework and approaches for constructing a digital twin based on the petrochemical industrial IoT, machine learning and a practice loop for information exchange between the physical factory and a virtual digital twin model to realize production control optimization. Unlike traditional production control approaches, this novel approach integrates machine learning and real-time industrial big data to train and optimize digital twin models. It can support petrochemical and other process manufacturing industries to dynamically adapt to the changing environment, respond in a timely manner to changes in the market due to production optimization, and improve economic benefits. Accounting for environmental characteristics, this paper provides concrete solutions for machine learning difficulties in the petrochemical industry, e.g., high data dimensions, time lags and alignment between time series data, and high demand for immediacy. The approaches were evaluated by applying them in the production unit of a petrochemical factory, and a model was trained via industrial IoT data and used to realize intelligent production control based on real-time data. A case study shows the effectiveness of this approach in the petrochemical industry. © 2019 Elsevier Ltd",digital twin; internet of things; machine learning; petrochemical industry; production control optimization,"Min Q., Lu Y., Liu Z., Su C., Wang B.","School of Economics and Management, Dalian University of Technology, Dalian, 116024, China; China Wanda Group Co. Ltd., Dongying, 257500, China; Big Data & IoT Business Development Unit, Lenovo Capital & Incubator Group, Beijing, 100085, China",2019.0,International Journal of Information Management,Elsevier Ltd,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066307148&doi=10.1016%2fj.ijinfomgt.2019.05.020&partnerID=40&md5=5cc95ab869c2986f2aa7c98a092105ff,10.1016/j.ijinfomgt.2019.05.020,20230520-160000,20230521-044735,"['machine', 'learning', 'based', 'digital', 'twin', 'framework', 'for', 'production', 'optimization', 'in', 'petrochemical', 'industry']",False,20230521-205332,,,,
532,scopus,Deep Learning in Mobile and Wireless Networking: A Survey,"The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research. © 1998-2012 IEEE.",5G systems; Deep learning; machine learning; mobile big data; mobile networking; network management; wireless networking,"Zhang C., Patras P., Haddadi H.","Institute for Computing Systems Architecture, School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Dyson School of Design Engineering, Imperial College London, London, SW7 2AZ, United Kingdom",2019.0,IEEE Communications Surveys and Tutorials,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071685550&doi=10.1109%2fCOMST.2019.2904897&partnerID=40&md5=287774c76fcce0b3fb68d37f50ad974f,10.1109/COMST.2019.2904897,20230520-160000,20230521-044735,"['deep', 'learning', 'in', 'mobile', 'and', 'wireless', 'networking:', 'a', 'survey']",True,20230521-205332,,,,
533,scopus,Enterprise composition architecture for micro-granular digital services and products,"The digitization of our society changes the way we live, work, learn, communicate, and collaborate. This defines the strategical context for composing resilient enterprise architectures for micro-granular digital services and products. The change from a closed-world modeling perspective to more flexible open-world composition and evolution of system architectures defines the moving context for adaptable systems, which are essential to enable the digital transformation. Enterprises are presently transforming their strategy and culture together with their processes and information systems to become more digital. The digital transformation deeply disrupts existing enterprises and economies. Since years a lot of new business opportunities appeared using the potential of the Internet and related digital technologies, like Internet of Things, services computing, cloud computing, big data with analytics, mobile systems, collaboration networks, and cyber physical systems. Digitization fosters the development of IT systems with many rather small and distributed structures, like Internet of Things or mobile systems. In this paper, we are focusing on the continuous bottom-up integration of micro-granular architectures for a huge amount of dynamically growing systems and services, like Internet of Things and Microservices, as part of a new digital enterprise architecture. To integrate micro-granular architecture models to living architectural model versions we are extending more traditional enterprise architecture reference models with state of art elements for agile architectural engineering to support the digitalization of services with related products, and their processes. © Designing Digitalization, ISD 2018. All rights reserved.",Architectural Composition; Digital Transformation; Internet of Things; Microservices; Open-World Architectural Integration; Service-Dominant Digital Products,"Zimmermann A., Schmidt R., Sandkuhl K.","Reutlingen University, Reutlingen, Germany; Munich University of Applied Sciences, Munich, Germany; University of Rostock, Rostock, Germany",2018.0,"Proceedings of the 27th International Conference on Information Systems Development: Designing Digitalization, ISD 2018",Association for Information Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091328776&partnerID=40&md5=5d47b8dca7e1f5a9a4183e822c414c8f,,20230520-160000,20230521-044735,"['enterprise', 'composition', 'architecture', 'for', 'micro-granular', 'digital', 'services', 'and', 'products']",False,20230521-205332,,,,
534,scopus,Brains for Dementia Research: Evolution in a Longitudinal Brain Donation Cohort to Maximize Current and Future Value,"Brain banking has a long and distinguished past, contributing greatly to our understanding of human neurological and psychiatric conditions. Brain banks have been operationally diverse, collecting primarily end stage disease, with variable quality clinical data available, yet it is now recognized the most informative brain donations are from those in longitudinally studied cohorts. The Brains for Dementia Research (BDR) cohort and program was for planned brain donation across five UK brain banks and one donation point, with standardized operating procedures, following longitudinal clinical and psychometric assessments for people with no cognitive impairment as well as those with dementia. Lay representatives with experience of dementia were involved from inception of BDR and 74.5% of all enquiries about participation came through routes that were directly attributable to or influenced by lay representatives. Ten years after inception, this ongoing project has received over 700 brain donations from the recruited cohort of 3,276 potential brain donors. At cohort census for this paper, 72.2% of the living cohort have no cognitive impairment by assessment, whereas only 28.3% of the donated cohort were without cognitive impairment. It is important that brain banks are agile and reflect the changing needs of the research community, given that 'big data', readiness cohorts, and GWAS demand large sample numbers of highly characterized individuals to facilitate new approaches and understanding of pathological processes in dementia. © 2018 - IOS Press and the authors. All rights reserved.",Brain donation; cohort; control; dementia; research tissue bank,"Francis P.T., Costello H., Hayes G.M.","King's College London, Wolfson Centre for Age-Related Diseases, St Thomas Street, London, SE1 1UL, United Kingdom",2018.0,Journal of Alzheimer's Disease,IOS Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058821953&doi=10.3233%2fJAD-180699&partnerID=40&md5=a9a21dde62e91f30dce216baf19bdcde,10.3233/JAD-180699,20230520-160000,20230521-044735,"['brains', 'for', 'dementia', 'research:', 'evolution', 'in', 'a', 'longitudinal', 'brain', 'donation', 'cohort', 'to', 'maximize', 'current', 'and', 'future', 'value']",False,20230521-205332,,,,
535,scopus,Acceleration of 4ir driven digital transformation through open source: Methods and parallel industries knowledge reapplication in the field,"In the age of open source, oil and gas companies that invest in licensing proprietary platforms to build artificial intelligence (AI) solutions will have to closely guard against obsolescence. While the mathematics behind AI has existed for decades, its rapid adoption in virtually all sectors has been powered by open source, where a global community of academicians and data scientists are continuously developing and improving the mathematics behind the predictive and prescriptive solutions of the future. We posit that the existence of AI software development, which we describe as data driven analytical solutions providing predictive and prescriptive answers to questions, is solely due to the academia's focus on research and its pedagogical goals driving the dissemination of the research to the open source community to move the research to development. Indeed, all data science coursework is steeped in training on open source platforms and tools. When models do not depend on platforms, organizations can deploy flexible and agile software that has the ability to leverage better methods that come out in the future. Borrowing ideas from other industries we can see that just as Wordpress and its open source community of designers and developers revolutionized how websites are created, software that can quickly deploy the best available technology (and be mobile) while maintaining the security of the data is poised for user adoption and success where legacy systems and traditional dashboards fail. While the mathematics of physics does not change our confidence in its accuracy, in comparison, the mathematics of an AI algorithm is an approximation. This mathematics is being continuously improved though rarely achieving 100% accuracy. Algorithms are built upon open source AI libraries that are continuously improving. Similarly, the methods and techniques for developing the AI algorithms in oil and gas are continuously improving through two main sources, academia and adjacent industries reapplication of AI methods. We provide examples of open source technologies already part and parcel of all data scientists' repertoire of development, who are currently working in oil and gas. We further showcase reapplication of solutions from other industries, such as, medical image data analysis to seismic data processing and subsurface characterization. © 2020, Offshore Technology Conference.",,"Haroon S.S., Viswanathan A., Alyamkin S., Shenoy R.","AlphaX Decision Sciences, United Arab Emirates",2020.0,Proceedings of the Annual Offshore Technology Conference,Offshore Technology Conference,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086245295&partnerID=40&md5=11cbbbc1c1a9e81bd13b1dd22a0d7e99,,20230520-160000,20230521-044735,"['acceleration', 'of', '4ir', 'driven', 'digital', 'transformation', 'through', 'open', 'source:', 'methods', 'and', 'parallel', 'industries', 'knowledge', 'reapplication', 'in', 'the', 'field']",False,20230521-205332,,,,
536,scopus,How does a (Smart) age-friendly ecosystem look in a post-pandemic society?,"COVID-19 has impacted not only the health of citizens, but also the various factors that make up our society, living environments, and ecosystems. This pandemic has shown that future living will need to be agile and flexible to adapt to the various changes in needs of societal populations. Digital technology has played an integral role during COVID-19, assisting various sectors of the community, and demonstrating that smart cities can provide opportunities to respond to many future societal challenges. In the decades ahead, the rise in aging populations will be one of these challenges, and one in which the needs and requirements between demographic cohorts will vary greatly. Although we need to create future smart age-friendly ecosystems to meet these needs, technology still does not feature in the WHO eight domains of an age-friendly city. This paper extends upon Marston and van Hoof’s ‘Smart Age-friendly Ecosystem’ (SAfE) framework, and explores how digital technology, design hacking, and research approaches can be used to understand a smart age-friendly ecosystem in a post-pandemic society. By exploring a series of case studies and using real-life scenarios from the standpoint of COVID-19, we propose the ‘Concept of Age-friendly Smart Ecologies (CASE)’ framework. We provide an insight into a myriad of contemporary multi-disciplinary research, which are capable to initiate discussions and bring various actors together with a positive impact on future planning and development of age-friendly ecosystems. The strengths and limitations of this framework are outlined, with advantages evident in the opportunity for towns, regions/counties, provinces, and states to take an agile approach and work together in adopting and implement improvements for the greater benefits of residents and citizens. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Age in place; Aging; Community; Coronavirus; COVID-19; Design hacking; Digital; E-health; Gerontechnology; Human-centered design; Internet of things; Older adults; Smart cities; Smart ecosystem; Technology; Urban planning,"Marston H.R., Shore L., White P.J.","Health & Wellbeing Strategic Research Area, School of Health, Wellbeing & Social Care, The Open University, Milton Keynes, Buckinghamshire, MK7 6HH, United Kingdom; MiLab, Department of Design Innovation, Maynooth University, Co. Kildare, W23 F2H6, Ireland; DesignCORE, Humanities, Institute of Technology Carlow, Carlow, R93 V960, Ireland",2020.0,International Journal of Environmental Research and Public Health,MDPI AG,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095842727&doi=10.3390%2fijerph17218276&partnerID=40&md5=08718aa1cadf5e98fe4881b5f085fbda,10.3390/ijerph17218276,20230520-160000,20230521-044735,"['how', 'does', 'a', '(smart)', 'age-friendly', 'ecosystem', 'look', 'in', 'a', 'post-pandemic', 'society?']",False,20230521-205332,,,,
537,scopus,Automatic Control System for Quality Assurance of Clinical Pathology Examination: A Machine Learning Approach,"The object of research is a study on a machine learning-based integrated quality control system to provide accurate test results quickly by improving the accuracy of test results and improving the utilization rate of test equipment by analyzing clinical pathology Examination data. As for the development method for research, IEC 62304, the international standard for medical S/W life cycle used in medical software development, was applied, and the S/W life cycle rule was applied to all processors by integrating agile methodology. Random Forest, XGboost (extreme Gradient Boosting), LightGBM (Light Gradient Boosting Machine), and DNN (Deep Neural Networks) to improve Rule Check accuracy to predict abnormality of inspection results, and to monitor abnormal results in real time by rule check calculation method technique was applied. In addition, to improve user convenience, automatic control and user interface technology using a dashboard function applied with machine learning technology, and automatic interlocking interface technology for various heterogeneous inspection devices were applied. Validation and verification were conducted through a qualified testing body (TTA) to ensure reliability. The following results were found through this study. As a result of implementing a module that applied big data-based machine learning technology to the algorithm used for quality control judgment of the first knowledge-based expert system, it was possible to implement a module with more than 95% accuracy. there was. Second, in order to determine whether a real-time alarm function was provided, the development module was linked to the clinical pathology information system and as a result of the experiment, it was found that it was operating normally. In addition, reliability was secured through certification by an accredited certification body. Third, as a communication support method for the interface of the inspection equipment, stability and various technologies were secured through a number of communication tests and certification tests such as RS232C, TCP/IP, and Serial HL7. Fourth, through multiple database tests (Oracle, MSSQL, MySQL, MS Access, etc.), cost savings were secured by resolving duplicate investment by providing database neutrality and interface with other systems. Fifth, utility and user satisfaction were enhanced by providing program functions for outputting the result report in various formats and configuring the UI settings, and the UI settings were modularized to reduce the program development costs and allow the modules to be reused. Through the results of research, small and medium hospitals can improve the reliability of inspection results through the machine learning-based quality control module, and through real-time monitoring of the inspection equipment, it is possible to quickly determine whether there is a failure and improve the operation rate of the inspection equipment. In addition, by providing a module that can be linked with the existing information system, it was made easy to link, and the convenience of the user was improved by providing various UI environments. As a result, it can be expected that the hospital's competitiveness and medical service will be improved by resolving the difficulties of quality control that small and medium-sized hospitals had and providing prompt and accurate test results. © 2022, Success Culture Press. All rights reserved.",Automatic Control; Big Data; Clinical Pathology Examination; Laboratory Information System (LIS); Machine Learning; Quality Control,"Oh J.-W., Yoo O.-W., Kang J.-K.","Department of Health Management & Education, Kyungdong University, South Korea; Hanwool Information and Communication Technology Corp, South Korea; Department of Industrial and Management Engineering, Hanbat National University, South Korea",2022.0,Journal of System and Management Sciences,Success Culture Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127955798&doi=10.33168%2fJSMS.2022.0103&partnerID=40&md5=4ec1341124854c6994712b4ca5e85b19,10.33168/JSMS.2022.0103,20230520-160000,20230521-044735,"['automatic', 'control', 'system', 'for', 'quality', 'assurance', 'of', 'clinical', 'pathology', 'examination:', 'a', 'machine', 'learning', 'approach']",False,20230521-205332,,,,
538,scopus,Novel Machine Learning and Data Analytics Approach for History Matching Giant Mature Multilayered Oil Field,"This paper discusses an integrated reservoir study utilizing structured and novel machine learning and data analytics approach for history matching a giant mature multilayered oil field in Mahakam Delta of Indonesia. The unique reservoir modeling challenges and novelty of the data science methods will be presented, along with preliminary results and lessons learnt. One of the most important elements in reservoir characterization and history matching process is integration between static and dynamic modeling. With numerous layers as study perimeter, a large number of uncertain parameters is unavoidable, from dynamic uncertainties such as hydrocarbon contacts and communication between regions to static properties like porosity, water saturation, etc. These in turn will create hundreds of possible scenarios during History Matching. Using python scripting embedded in the reservoir simulator and the agile reservoir modeling (ARM) approach, these uncertainties can be handled quickly, and each ensemble can be analyzed easily with Data Analytics and Machine Learning based proxy approaches. The case study presented here is a giant mature oilfield with more than 50 zones and 100 contact regions. With more than 45 years of production and injection history, the conventional reservoir modeling where each zone is modeled individually and independently, assuming no communication between the regions, has been deemed as taking too much time and effort. The integrated approach bypasses this challenge by allowing simultaneous reservoir modeling as well as quick sensitivity analysis and history matching quality checking. Uncertainties were managed early on; for instance, the porosity model was generated through available algorithms and hydrocarbon contacts with Latin-hypercube sampling method. Preliminary results showed that overall time required to perform the modeling has been reduced significantly, while also establishing communication between the regions. Analytical aquifer modeling and communication between the regions were observed as the most sensitive parameters especially when matching the pressure behavior. Moreover, embedded python script and Data Analytics Dashboard have made it possible to perform fast and systematic analysis, thus more effort and time can be allocated to plan the way forward. The Machine Learning results will be further finalized at the next gate review, considering the project was initially proposed into several gates. Static modeling using Machine Learning, coupled with dynamic modeling workflow and data analytics, has created a complete loop of reservoir study and characterization. All of these are conducted in a structured cloud-based platform, ensuring time-efficient process and repeatability while at the same time enabling hybrid approach by combining conventional method and advanced data driven approach. Copyright © 2022, Society of Petroleum Engineers.",,"Suwito E., Dongan Sianturi J.A., Irawan A., Panjaitan P.R., Saeed Y., Priyanto A.D., Elfeel M.A.","PT Pertamina Hulu Mahakam, Indonesia; Schlumberger",2022.0,Society of Petroleum Engineers - ADIPEC 2022,Society of Petroleum Engineers,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143069439&doi=10.2118%2f211398-MS&partnerID=40&md5=10ee102b0c525afb221d2928dddc7ad1,10.2118/211398-MS,20230520-160000,20230521-044735,"['novel', 'machine', 'learning', 'and', 'data', 'analytics', 'approach', 'for', 'history', 'matching', 'giant', 'mature', 'multilayered', 'oil', 'field']",False,20230521-205332,,,,
539,scopus,A Case Study of IIoT Application in Process Manufacturing Management Information Systems in Palm Oil Refinery,"Industrial Internet of Things (IIoT) is providing technology integration of Information Technology (IT) and Operation Technology (OT). While OT is related to operational in shop floor production, IT has become a backbone in corporate management strategic decision making. Both technology are dependent to reliable data, comprehensive analysis from it, and utmost distribution network to related parties. In Industrial Revolution journey, Programmable Logic Controller invention has been part of important part of OT and trigger to the Third Industrial Revolution. The elaboration in Computer Integrated Manufacturing concept has been strengthened by technology providers to deliver reliable solution in manufacturing process. However, these data remain to reside in isolated environment of Industrial Control System. While focusing in process operational automation system, integrated information management become issue in this case study. Manual log sheet in Margarine and Shortening production of Palm Oil Refinery is backbone for process parameter visibility and downside in issues to reliability, distribution, and further analysis. By optimizing available technology in the Fourth Industrial Revolution, this vertical integration from shop floor production to corporate management could be delivered with IIoT-based Information Systems. Methodology from Industrial Internet Consortium (IIC) publication in Industrial Internet Reference Architecture (IIRA) which connected to existing automation system is providing real-time data with historical trending. The velocity and volume of these data has shaped Big Data and presented Management Information System in IT network. This reliable data provide traceability to parameter process in production facilities. © 2022 ACM.",IIoT; Industrial Control System; Industrial Revolution; Information Systems; IT and OT Convergence; Palm Oil,"Koncoro S.T., Lukas, Siregar M.","Universitas Katolik Indonesia Atma Jaya, Indonesia",2022.0,ACM International Conference Proceeding Series,Association for Computing Machinery,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143255778&doi=10.1145%2f3557738.3557865&partnerID=40&md5=6a56eb06b5fba4bc86df363692f4cd7b,10.1145/3557738.3557865,20230520-160000,20230521-044735,"['a', 'case', 'study', 'of', 'iiot', 'application', 'in', 'process', 'manufacturing', 'management', 'information', 'systems', 'in', 'palm', 'oil', 'refinery']",False,20230521-205332,,,,
540,scopus,Artificial Intelligence Potential in Higher Education Institutions Enhanced Learning Environment in Romania and Serbia,"In their struggle to offer a sustainable educational system and transversal competencies for market requests, significant transformations characterise the higher education system in Serbia and Romania. According to EU policy, these transformations are related to educational reforms and the introduction of new technology and methodologies in teaching and learning. They are expected to answer to the PISA requirements and to increase the DESI (Digital Economy and Society Index). They are also likely to mitigate the inequity of HEIs (higher education institutions), empowered by a structured, goal-oriented strategy towards agile management in HEIs that is also appropriate for new market demands. Our study is based on an exploratory survey applied to 139 Romanian and Serbian teachers from the Information Technology School—ITS, Belgrade, and Spiru Haret University, Romania. The survey let them provide their knowledge of AI or their perceptions of the difficulties and opportunities of these technologies in HEIs. Our study discovered how difficulties and opportunities associated with AI impact HEIs. This study aims to see how AI might assist higher education in Romania and Serbia. We also considered how they might be integrated with the educational system, and if instructors would utilise them. Developing creative and transversal skills is required to anticipate future breakthroughs and technological possibilitiesThe new methods of education focuses on ethics, values, problem-solving, and daily activities. Students’ learning material, how they might achieve critical abilities, and their educational changes must be addressed in the future. In this environment, colleges must create new digital skills in IA, machine learning, IoT, 5G, the cloud, big data, blockchain, data analysis, using MS Office and other applications, MOOCs, simulation applications, VR/AR, and gamification. They must also develop cross-disciplinary skills and a long-term mindset. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",artificial intelligence (AI); higher education institutions (HEI); transversal skills,"Bucea-Manea-țoniş R., Kuleto V., Gudei S.C.D., Lianu C., Lianu C., Ilić M.P., Păun D.","Doctoral School, National University of Physical Education and Sport, Bucharest, 060057, Romania; LINK Group Belgrade, Information Technology School ITS-Belgrade, Faculty of Contemporary Arts Belgrade, University Business Academy in Novi Sad, Belgrade, 11000, Serbia; Faculty of Economy and International Affairs, Academy of Economic Studies, Bucharest, 010374, Romania; USH Pro Business, Spiru Haret University, Bucharest, 004021, Romania; Faculty of Physical Education, Spiru Haret University, Bucharest, 004021, Romania",2022.0,Sustainability (Switzerland),MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130542761&doi=10.3390%2fsu14105842&partnerID=40&md5=7b6dfab5016808d954e3ff0c31baf857,10.3390/su14105842,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'potential', 'in', 'higher', 'education', 'institutions', 'enhanced', 'learning', 'environment', 'in', 'romania', 'and', 'serbia']",False,20230521-205332,,,,
541,scopus,The integration of technologies Industry 4.0 technology and Lean Manufacturing: A systematic literature review,"Purpose - Since the development of Lean Manufacturing (LM) in the last century, industry performance has improved. In 2011, when Germany first used the term Industry 4.0 to refer to the fourth industrial revolution, many changes in the way things are done have been discussed and applied. Industry 4.0 involves new technologies such as the Internet of Things (IoT). However, the LM originally does not consider the possibilities of these new information technologies and current research highlights the need for studies on the applications of industry 4.0 technologies in LM environments. Thus, this research aims to identify, select, evaluate, and synthesize the relevant evidence available on the literature around the integration of Industry 4.0 technologies and LM. Design/methodology/approach - The research applied the method of systematic literature review on 107 articles, which were refined by this method. Findings - The creation of value and increase in the company's profit occurs through I4.0 technologies, such as the Internet of Things, Cyber Physical System, use of the Cloud, quality (big) data, Robotics, among others, which provide real-time capability, decentralization, modularity, interoperability, service orientation, and virtualization. Visualizing thus, a support of the industry 4.0 concept to LM and vice versa, where the technologies related to this concept allow improving the flow of information exchanged, guaranteeing the interconnection of machines, things and people. Research limitations/implication - Some important research may not have appeared in the search due to limitations of the systematic literature review method. Practical implications - The findings point insights directions for future research and provide practitioners with insights into the integration of Industry 4.0 technologies and with LM. Originality/value - The literature lacks articles that discuss the relationship of Industry 4.0 technologies with Lean Manufacturing. © 2022 Universidade do Minho. All rights reserved.",Industry 4.0; Lean 4.0; Lean Manufacturing,"Tailise M.M., Mergulhão R.C., Mano A.P., Silva A.A.A.","Federal University of São Carlos, SP, São Carlos, Brazil; Santa Cruz State University, BA, Brazil",2022.0,International Conference on Quality Engineering and Management,Universidade do Minho,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137025336&partnerID=40&md5=e5214dc535ec082710aeaaeb9eaec389,,20230520-160000,20230521-044735,"['the', 'integration', 'of', 'technologies', 'industry', '4.0', 'technology', 'and', 'lean', 'manufacturing:', 'a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
542,scopus,Context and machine learning based trust management framework for internet of vehicles,"Trust is one of the core components of any ad hoc network security system. Trust management (TM) has always been a challenging issue in a vehicular network. One such developing network is the Internet of vehicles (IoV), which is expected to be an essential part of smart cities. IoV originated from the merger of Vehicular ad hoc networks (VANET) and the Internet of things (IoT). Security is one of the main barriers in the on-road IoV implementation. Existing security standards are insufficient to meet the extremely dynamic and rapidly changing IoV requirements. Trust plays a vital role in ensuring security, especially during vehicle to vehicle communication. Vehicular networks, having a unique nature among other wireless ad hoc networks, require dedicated efforts to develop trust protocols. Current TM schemes are inflexible and static. Predefined scenarios and limited parameters are the basis for existing TMmodels that are not suitable for vehicle networks. The vehicular network requires agile and adaptive solutions to ensure security, especially when it comes to critical messages. The vehicle network's wireless nature increases its attack surface and exposes the network to numerous security threats. Moreover, internet involvement makes it more vulnerable to cyberattacks. The proposedTMframework is based on context-based cognition and machine learning to be best suited to IoV dynamics. Machine learning is the best solution to utilize the big data produced by vehicle sensors. To handle the uncertainty Bayesian machine learning statistical model is used. The proposed framework can adapt scenarios dynamically and infer using the maximum possible parameter available. The results indicated better performance than existing TM methods. Furthermore, for future work, a high-level machine learning model is proposed. © 2021 Tech Science Press. All rights reserved.",Bayesian learning; Context awareness; Internet of vehicles (IoV); Machine learning; Trust management (TM); Vehicular ad hoc network (VANET),"Rehman A., Hassan M.F., Hooi Y.K., Qureshi M.A., Chung T.D., Akbar R., Safdar S.","Computer and Information Science Department, Centre for Research and Data Science (CeRDaS), Universiti Teknologi, PETRONAS, Seri Iskandar, Perak Darul Ridzuan, 32610, Malaysia; Department of Computer Science, Bahria University, Pakistan; Computing Fundamental Department, FPT University, Hoa Lac Hi-Tech Park, Hanoi, Viet Nam; Department of Information Systems, Uiversiti Tunku Abdul Rahman, Malaysia; Information Technology Department, College of IT, AHLAI University, Bahrain",2021.0,"Computers, Materials and Continua",Tech Science Press,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105607500&doi=10.32604%2fCMC.2021.017620&partnerID=40&md5=a18901010db67ae00ccea9b9f353d8cc,10.32604/CMC.2021.017620,20230520-160000,20230521-044735,"['context', 'and', 'machine', 'learning', 'based', 'trust', 'management', 'framework', 'for', 'internet', 'of', 'vehicles']",False,20230521-205332,,,,
543,scopus,Disruptive Technologies for Labor Market Information System Implementation Enhancement in the UAE: A Conceptual Perspective,"In December 2019, the world learned about the first outbreak of the novel coronavirus (COVID-19) that first broke out in Wuhan, China. This limited outbreak in a small province of China has rapidly evolved into a global pandemic that has led to a health and economic crisis. As millions of individuals have lost their lives, others have lost their jobs due to the recession of 2020. While the skills and educational mismatch have been a prevalent problem in the UAE labor market, it is logical to assume that the global pandemic has likely increased this problem’s extent. Therefore, there is an urgent need to adopt an agile, innovative solution to address the upcoming challenges in the labor markets due to the lack of skilled resources and the fear of future work amid the COVID-19 pandemic. Since industry and academia have identified skills and educational mismatch as a complex and multivariate problem, the paper builds a conceptual case from a system engineering perspective to solve this problem efficiently. Based on the literature reviewed related to disruptive technologies and labor market management systems, the paper proposes a new implementation approach for an integrated labor market information system enabled by the most widely used disruptive technologies components in the UAE (Machine Learning, AI, Blockchain, Internet of Things, Big Data Analytics, and Cloud Computing). The proposed approach is considered one of the immediate course of actions required to minimize the UAE economy’s negative impact due to the presence of the skills and educational mismatch phenomena. © 2021. All Rights Reserved.",COVID-19; Disruptive technologies; future of work; labor market information systems; skills and educational mismatch; system design thinking; system engineering,"Goher G., Masrom M., Amrin A., Rahim N.A.","Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Malaysia",2021.0,International Journal of Advanced Computer Science and Applications,Science and Information Organization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102031618&doi=10.14569%2fIJACSA.2021.0120247&partnerID=40&md5=628cb14d45b203b53421b5d10adf06ca,10.14569/IJACSA.2021.0120247,20230520-160000,20230521-044735,"['disruptive', 'technologies', 'for', 'labor', 'market', 'information', 'system', 'implementation', 'enhancement', 'in', 'the', 'uae:', 'a', 'conceptual', 'perspective']",False,20230521-205332,,,,
544,scopus,Virginia digital shipbuilding program (VDSP) - Building an agile modern workforce to improve performance in the shipbuilding and ship repair industry,"Industry 4.0 is the latest stage in the Industrial Revolution and is reflected in the digital transformation and use of emergent technologies including the Internet of Things, Big Data, Robotic automation of processes, 3D printing and additive manufacturing, drones and Artificial Intelligence (AI) in the manufacturing industry [15]. The implementation of these technologies in the Shipbuilding and Ship Repair Industry is currently in a nascent stage. Considering this, there is huge potential to produce cost savings, decrease production timelines, and drive down inefficiencies in the lifecycle management of ships. However, the implementation of these Industry 4.0 technologies is hindered by a noticeable gap in workforce capability and capacity. The shipbuilding and ship repair industry is projected to lose approximately 33% of its skilled workforce and 48% of management by 2028 [9]. With an aging workforce and an incoming digital generation that excels in tech savviness, flexibility, global thinking, and multi-tasking, it is crucial to be innovative in workforce development. The Virginia Digital Shipbuilding Program (VDSP) responds to this need by providing a process and platform to address education, training, and adoption of innovative new technology as well as the ability to provide real-time solutions to current and future industry problems. This paper will focus on the three pillars of Digital Shipbuilding - Career Pathway Mapping and Curriculum Development, Outreach and Workforce Development, and Research and Development. Additionally, this paper will address how the team is ensuring that stackable, transferable education and certification processes are implemented between military and industry to facilitate the transition of veterans to the civilian workforce. © American Society for Engineering Education 2020.",,"Kosteczko J.P., Smith K., Johnson J., Diaz R.","Old Dominion University, United States",2020.0,"ASEE Annual Conference and Exposition, Conference Proceedings",American Society for Engineering Education,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095774431&partnerID=40&md5=b8d8f25f2ea90b9e3de5503dc3966e5e,,20230520-160000,20230521-044735,"['virginia', 'digital', 'shipbuilding', 'program', '(vdsp)', '-', 'building', 'an', 'agile', 'modern', 'workforce', 'to', 'improve', 'performance', 'in', 'the', 'shipbuilding', 'and', 'ship', 'repair', 'industry']",False,20230521-205332,,,,
545,scopus,Functional failure diagnosis approach based on Bayesian network for manufacturing systems,"The failure of traditional manufacturing systems mostly refers to the physical failure of the production equipment that constitutes the manufacturing systems. With the advancement of manufacturing technology and the improvement of the level of intelligence, the physical failure of the conventional equipment in the daily operation of the system is rare, but the quality of the work-in-progress (WIP) is unqualified frequently. Especially the hidden functional failures such as reliability degradation of the final product have become increasingly prominent. How to model and characterize the functional failure of manufacturing systems has become a bottleneck restricting the application and development of holistic PHM (Prognostic and Health Management) technology of manufacturing systems. Therefore, a novel functional failure modeling and diagnostic strategy for intelligent manufacturing systems based on RQR chain is proposed in this paper, which includes the manufacturing system reliability (R) data, manufacturing process quality (Q) data and the produced product reliability (R) data. Firstly, the definition of the functional degradation process and principle of manufacturing systems is clarified from the perspective of RQR chain. Secondly, based on the established RQR chain, the functional fault connotation of manufacturing systems is defined, and the KPCs (key product characteristics) in the Bayesian network of integrated manufacturing systems are utilized. Big data are analyzed to model and predict the functional fault state of the running manufacturing systems. Thirdly, based on the relationship of RQR chain from right to left, the holistic functional fault diagnosis strategy is given. Finally, a case study of a manufacturing system for cylinder head is presented to verify the proposed approach. © 2019 IEEE.",Bayesian network (BN); Failure diagnosis; Functional failure; Manufacturing systems; RQR chain,"He Z., He Y., Chen Z., Zhao Y., Lian R.","Beihang University, School of Reliability and Systems Engineering, Beijing, China",2019.0,"2019 Prognostics and System Health Management Conference, PHM-Qingdao 2019",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077999275&doi=10.1109%2fPHM-Qingdao46334.2019.8942813&partnerID=40&md5=555b2f91c9300a12bfdc1a5e9831851a,10.1109/PHM-Qingdao46334.2019.8942813,20230520-160000,20230521-044735,"['functional', 'failure', 'diagnosis', 'approach', 'based', 'on', 'bayesian', 'network', 'for', 'manufacturing', 'systems']",False,20230521-205332,,,,
546,scopus,Human-Technology Centric in Cyber Security Maintenance for Digital Transformation Era,"The development of the digital transformation in the organizations has become more expanding in these present and future years. This is because of the active demand to use the ICT services among all the organizations whether in the government agencies or private sectors. While digital transformation has led manufacturers to incorporate sensors and software analytics into their offerings, the same innovation has also brought pressure to offer clients more accommodating appliance deployment options. So, their needs a well plan to implement the cyber infrastructures and equipment. The cyber security play important role to ensure that the ICT components or infrastructures execute well along the organization's business successful. This paper will present a study of security management models to guideline the security maintenance on existing cyber infrastructures. In order to perform security model for the currently existing cyber infrastructures, combination of the some security workforces and security process of extracting the security maintenance in cyber infrastructures. In the assessment, the focused on the cyber security maintenance within security models in cyber infrastructures and presented a way for the theoretical and practical analysis based on the selected security management models. Then, the proposed model does evaluation for the analysis which can be used to obtain insights into the configuration and to specify desired and undesired configurations. The implemented cyber security maintenance within security management model in a prototype and evaluated it for practical and theoretical scenarios. Furthermore, a framework model is presented which allows the evaluation of configuration changes in the agile and dynamic cyber infrastructure environments with regard to properties like vulnerabilities or expected availability. In case of a security perspective, this evaluation can be used to monitor the security levels of the configuration over its lifetime and to indicate degradations. © 2018 Institute of Physics Publishing. All rights reserved.",cyber security; digital transformation; security maintenance; security management model,"Ali F.A.B.H., Jali M.Z.","Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Johor, Malaysia; Faculty of Science and Technology, Universiti Sains Islam Malaysia, Negeri Sembilan, Malaysia",2018.0,Journal of Physics: Conference Series,Institute of Physics Publishing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048358452&doi=10.1088%2f1742-6596%2f1018%2f1%2f012012&partnerID=40&md5=3b7fb29d4dfa9800bfd4b53208228023,10.1088/1742-6596/1018/1/012012,20230520-160000,20230521-044735,"['human-technology', 'centric', 'in', 'cyber', 'security', 'maintenance', 'for', 'digital', 'transformation', 'era']",False,20230521-205332,,,,
547,scopus,Exploiting page table locality for agile TLB prefetching,"Frequent Translation Lookaside Buffer (TLB) misses incur high performance and energy costs due to page walks required for fetching the corresponding address translations. Prefetching page table entries (PTEs) ahead of demand TLB accesses can mitigate the address translation performance bottleneck, but each prefetch requires traversing the page table, triggering additional accesses to the memory hierarchy. Therefore, TLB prefetching is a costly technique that may undermine performance when the prefetches are not accurate.In this paper we exploit the locality in the last level of the page table to reduce the cost and enhance the effectiveness of TLB prefetching by fetching cache-line adjacent PTEs ""for free"". We propose Sampling-Based Free TLB Prefetching (SBFP), a dynamic scheme that predicts the usefulness of these ""free""PTEs and prefetches only the ones most likely to prevent TLB misses. We demonstrate that combining SBFP with novel and state-of-the-art TLB prefetchers significantly improves miss coverage and reduces most memory accesses due to page walks.Moreover, we propose Agile TLB Prefetcher (ATP), a novel composite TLB prefetcher particularly designed to maximize the benefits of SBFP. ATP efficiently combines three low-cost TLB prefetchers and disables TLB prefetching for those execution phases that do not benefit from it. Unlike state-of-the-art TLB prefetchers that correlate patterns with only one feature (e.g., strides, PC, distances), ATP correlates patterns with multiple features and dynamically enables the most appropriate TLB prefetcher per TLB miss.To alleviate the address translation performance bottleneck, we propose a unified solution that combines ATP and SBFP. Across an extensive set of industrial workloads provided by Qualcomm, ATP coupled with SBFP improves geometric speedup by 16.2%, and eliminates on average 37% of the memory references due to page walks. Considering the SPEC CPU 2006 and SPEC CPU 2017 benchmark suites, ATP with SBFP increases geometric speedup by 11.1%, and eliminates page walk memory references by 26%. Applied to big data workloads (GAP suite, XSBench), ATP with SBFP yields a geometric speedup of 11.8% while reducing page walk memory references by 5%. Over the best state-of-the-art TLB prefetcher for each benchmark suite, ATP with SBFP achieves speedups of 8.7%, 3.4%, and 4.2% for the Qualcomm, SPEC, and GAP+XSBench workloads, respectively. © 2021 IEEE.",Address translation; Page table locality; Prefetching; Translation lookaside buffer; Virtual memory,"Vavouliotis G., Alvarez L., Karakostas V., Nikas K., Koziris N., Jimenez D.A., Casas M.","Barcelona Supercomputing Center, Spain; Universitat Politècnica de Catalunya, Spain; National Technical University of Athens, Greece; Texas AandM University, United States",2021.0,Proceedings - International Symposium on Computer Architecture,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114702846&doi=10.1109%2fISCA52012.2021.00016&partnerID=40&md5=c13394783a9f341d3ebf17b9aed3eb10,10.1109/ISCA52012.2021.00016,20230520-160000,20230521-044735,"['exploiting', 'page', 'table', 'locality', 'for', 'agile', 'tlb', 'prefetching']",True,20230521-205332,,,,
548,scopus,Investment in Research Development or Size Expansion? The Case of Internet of Things Companies,"The Internet of Things (IoT) is at the height of its hype cycle and one can argue that the IoT construct will subsume housing, infrastructures, industrial plants, and other systems in the near future. Big data that is associated with IoT could control systems, affect automation and the process industries require RD support to shape the concept into a functional asset that resolves the problems of users. Hence, investment in research and development (RD) as an integral part of any IoT project could be the first step towards project success. The objective of this study is to examine the effects of an investment in RD and size expansion on the firm value of the top Internet of Things companies. This study examines the top 20 Internet of Things companies in the world spanning the period from 2012 to 2019. By using the panel regression random effect model, this study yields two main conclusions. First, the expansion of size by the companies has a significant impact on promoting the firm value. Second, investment in RD is negatively associated with the firm value of the IoT companies at the initial stage but the lag effect of investment in RD is associated positively with the firm value. The significant size expansion impact on the firm value in the IoT firms suggests that the agile size could lead to more efficient use of resources and easy identification of growth opportunities. The second conclusion demonstrates the need for a budget allocation for the investment in RD for the technological progression and scientific advancement in the IoT companies. Although it takes a few years to observe the significant impacts of investment in RD on IoT firms, in the long term, it could improve the performance of IoT companies in driving the proliferation of connected devices to enhance human productivity and efficiency. © 2020 IEEE.",internet of things; Research and development; return on invested capital; size expansion,"Lee H.S., Sia B.K., Chong S.C., Low C.W.","Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia; Faculty of Accountancy Management and Economics, New Era University College, Kajang, Malaysia",2020.0,"Proceeding - 2020 IEEE 8th Conference on Systems, Process and Control, ICSPC 2020",Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100354733&doi=10.1109%2fICSPC50992.2020.9305758&partnerID=40&md5=bd7513f03266f03a8ec4ee89349cd675,10.1109/ICSPC50992.2020.9305758,20230520-160000,20230521-044735,"['investment', 'in', 'research', 'development', 'or', 'size', 'expansion?', 'the', 'case', 'of', 'internet', 'of', 'things', 'companies']",True,20230521-205332,,,,
549,scopus,Contexts enhance accuracy: On modeling context aware deep factorization machine for web API QoS prediction,"Service-oriented computing (SOC) promises a world of cooperating services loosely connected, constructing agile Web applications in heterogeneous environments conveniently. Web application interface (API) as an emerging technique attracts more and more enterprises and organizations to publish their deep computing functionalities and big data on the Internet, Web API has become the backbone to promote the development of SOC, thus forming the prosperousWeb API economy. However, the number of available Web APIs on the Internet is massive and growing constantly, which causes the Web API overload problem. Quality of service (QoS) as an indicator is able to well differentiate the quality of Web APIs and has been widely applied for high quality Web API selection. Since testing QoS for massive Web APIs is resource-consuming, and the QoS performance depends on contextual information such as network and location, hence accurate QoS prediction has become very crucial for personalizedWeb API recommendation and high quality Web application construction. To address the above issue, this paper presents a context aware deep factorization machine model (CADFM for short) for accurate Web API QoS prediction. Specifically, we first carry out detailed data analysis using real-world QoS dataset and discover a positive relationship between QoS and contextual information, which motivates us to incorporate beneficial contexts for enhancing QoS prediction accuracy. Then, we treat QoS prediction as a regression problem and propose a context aware CADFM framework that integrates the contextual information via embedding technique. Particularly, we adopt MF and MLP for high-order and nonlinear interaction modeling, so as to learn the complex interaction between users andWeb APIs accurately. Finally, the experimental results on real-world QoS dataset demonstrate that CADFM outperforms the classic and the state-of-the-art baselines, thereby generating the most accurate QoS predictions and increasing the revenue of Web APIs recommendation. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Context aware; Deep factorization machine; Quality of service prediction; Service-oriented computing; Web API,"Shen L., Pan M., Liu L., You D., Li F., Chen Z.","Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, 066004, China; National Science Library, Chinese Academy of Sciences, Beijing, 100864, China; College of Computer and Communication Engineering, Northeastern University, Shenyang, 110819, China",2020.0,IEEE Access,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102882872&doi=10.1109%2fACCESS.2020.3022891&partnerID=40&md5=bf3adbb5deff9f7293cf920c9ab52775,10.1109/ACCESS.2020.3022891,20230520-160000,20230521-044735,"['contexts', 'enhance', 'accuracy:', 'on', 'modeling', 'context', 'aware', 'deep', 'factorization', 'machine', 'for', 'web', 'api', 'qos', 'prediction']",True,20230521-205332,,,,
550,scopus,"Transitioning from Legacy Air Traffic Management to Airspace Management through Secure, Cloud-Native Automation Solutions","Advancements in Cloud-native services, Machine-Learning (ML), Artificial Intelligence (AI), and Rapid Application Development (RAD) using the Agile methodology has led countless industries to achieving desirable levels of automation while reducing cost and improving quality software deployments, timely / iterative delivery, and accountability. Coupling this framework with the principle of security as a shared responsibility further enhances the efficacy of an integrated Development, Security, and Operations (DevSecOps) Team within organizations to deliver secured digital solutions. Air Navigation Service Providers (ANSPs) around the world are currently exploring and embracing the digital evolution shifting from monolithic, legacy automation platforms to an application framework of microservices to allow for flexible operations as capabilities and airspace operations evolve. Specific to the US, the ATM automation system of today is comprised of both safety and non-safety critical systems, with mission-essential, efficiency-critical, and mission-support services that are predominately maintained and evolved through multi-year, one contractor-led programs. Although the system has proven resilient, it has not proven to be agile and flexible to allow for advances in capabilities on-board aircraft or in the data integration and sharing with other NAS automation systems. This creates significant overhead in development, sustainability, and operations of the current automation system, and leaves modernization efforts - in terms of new capabilities - in constant investment decision planning cycles, costing agencies not just money, but more time to innovate. To advance aviation into a new generation of interoperability leveraging collaborative frameworks and application specific capabilities, ANSPs must adapt to innovative methods to collect, process, and deliver critical and essential aeronautical, weather, and flight information to air traffic control operators and ultimately to airspace users. Doing so can not only lead to sustaining NAS automation systems while reducing the costs to develop and operate these systems, but it also provides an opportunity to present strategies on how to dramatically reduce the time and integration efforts needed to deploy new capabilities. Leveraging cloud-native technologies and services is a way to realize this automation evolution vision for ANSPs.This paper examines the migration from today's systems to secure, cloud-native platforms to prove that Mission Services and Mission Applications can be rapidly available / deployable to operators who provide separation and flow management services, using a cyber-secured cloud-native environment. Aeronautical data typically used for tactical decision making is now seen as crucial to the decision-making process in Air Traffic Management (ATM). Integrating global and localized datasets into a digital aviation data platform enhances the capabilities of the solutions and opens the possibilities of leveraging big data analytics and microservices to compute trajectory predictions (TP), demand capacity balancing (DCB), arrival and departure sequencing, airspace delay, among others, in real-time to achieve operator-driven mission objectives. Technology has reached a state of maturity, especially in cloud and hybrid cloud solutions, to support safety of life operations, like ATM. This paper identifies approaches that are being considered for that migration to support the integration of new airspace entrants, the use of application services to provide a dynamic, evolutionary ATM platform, and addresses some of the safety and security strategies that must be considered for this evolution. © 2021 IEEE.",ATM; Automation; Cloud-native; Microservices,"Solomon A., Crawford Z.","Digital Aviation Solutions Thales, Arlington, VA, United States",2021.0,AIAA/IEEE Digital Avionics Systems Conference - Proceedings,Institute of Electrical and Electronics Engineers Inc.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122816710&doi=10.1109%2fDASC52595.2021.9594313&partnerID=40&md5=e9f8c629824b3b30dbd840c178e14ff5,10.1109/DASC52595.2021.9594313,20230520-160000,20230521-044735,"['transitioning', 'from', 'legacy', 'air', 'traffic', 'management', 'to', 'airspace', 'management', 'through', 'secure,', 'cloud-native', 'automation', 'solutions']",True,20230521-205332,,,,
551,scopus,Convergence and digital fusion lead to competitive differentiation,"Purpose: Organizations are consistently seeking innovative strategies and novel pathways to enhance business processes and create differentiation. The global business ecosystem is changing and there is growing demand for multi-modal digital technologies, big data consolidation and data analytics to harness a cost-competitive agile system. Technological convergence and integration of digital systems is one of the preferred methodologies that facilitates new and effective workflows and revives business processes. The progressive interlinking of digital technologies with business operations leads to the convergence and blending of management disciplines, devices and applications. The growing inconsistencies in managerial understanding regarding the benefits of convergence prompts a comprehensive examination of digital convergence pathways, identifying the impacts on converging entities and business objectives. The State bank of India (SBI) mega-merger case study was selected to investigate the pragmatic framework of digital convergence and to understand the impacts on interlinked entities such as: business operations, strategic management, project team that support value creation and competitive differentiation. The purpose of this paper is to focus on the phenomena of techno-fusion of emerging technologies creating new opportunities, business models and unique strategies for global banking and financial service organizations. Design/methodology/approach: This study applies the qualitative, inductive research method using critical reflection of before and after the implementation of convergence and digital integration strategies. The SBI case study employs this research strategy based on the premise that banks must stay agile and highly responsive to the changing environment to enhance its value proposition and competitive differentiation objectives. The study methodology incorporates cooperative inquiry and multiple levels of analysis using data collection techniques of exhaustive review of archives, informal interviews, questionnaires and observations to identify the synergistic process improvement pathway. The study is grounded on the concept that the convergence of diverse business pathways involves innovative and interlinked project, strategic and information technology (IT) workflows that results in open innovative systems. Findings: The studies identify that organizational innovation and creative solutions are a result of ecosystem turbulence, environmental force diversity, competitive pressure and the need for differentiation. Organizations that harness the power of digital fusion and convergence of management, systems and data generate a competitive advantage. The technological convergence strategy pulls multiple business and technology processes (project, strategic, IT, Cloud, AI and business process management) at the organizational, divisional or functional level generating new opportunities and threats, new business models and unique growth strategies for global banking and financial services organizations. Organizations that fully integrate techno-fusion of business and digital strategies produce synergistic effects and enhance adaptability, innovation and resiliency in the face of competitive challenges. Research limitations/implications: Additional areas that can be explored further as an extension of this study are listed below: identifying factors to improve the speed of convergence; the current results are limited to large size organizations where formal management and technology functions are distinctive. Similar studies on smaller organizations are warranted. Originality/value: This study focuses on the evolving field of technology innovation, which is increasingly being intertwined with business operations. Innovative digital technology is enabling the convergence of the disciplines of management, digital devices and applications. This facilitates the creation of a pragmatic framework that supports convergence of business operations, strategic management and digital fusion which leads to value creation and competitive differentiation. The techno-fusion of emerging technologies and digital strategies generates new opportunities and threats, new business models and unique growth strategies for organizations. © 2019, Emerald Publishing Limited.",Agile synergistic interaction; Business and technology management; Convergence; Digital fusion; Digital technology; Open innovation,Thomas A.,"Department of Management, Concordia University of Edmonton, Edmonton, Canada",2020.0,Business Process Management Journal,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074672632&doi=10.1108%2fBPMJ-01-2019-0001&partnerID=40&md5=679d997b96a0a62b20fb678812910283,10.1108/BPMJ-01-2019-0001,20230520-160000,20230521-044735,"['convergence', 'and', 'digital', 'fusion', 'lead', 'to', 'competitive', 'differentiation']",False,20230521-205332,,,,
552,scopus,A Blockchain Security Based IoT-Enabled System for Safe and Effective Logistics Management in IR 4.0,"As a result of the revolution brought on by industrial 4.0, the global logistics industry is growing at a rapid rate. Concurrently, logistics operations are undergoing constant change as new technologies such as the internet of things (IoT), cloud computing, and big data are implemented. These Internet of Things devices enhance the functionality of the logistics function by enhancing real-time product tracking, improving data collection, and intelligently storing logistics data, among other things. Because of the centralised database structure of these logistics systems, certain of these new technologies open the door to the possibility of cyberattacks on these systems. The parties involved in the logistics operations must communicate with one another in order to share confidential information about customers and details about products. This is due to the fact that so many logistics stakeholders are being engaged in the process. It is vulnerable to unauthorised access, which may result in fraudulent activity or the production of counterfeit goods by a malicious actor operating within the system. All of these challenges are significant because maintaining the integrity of the logistics data is essential to providing good service to customers. The application of Blockchain's special features, such as immutability, efficient cryptography, and a distributed decentralised storage system, will be used to address these challenges once it is deployed as an innovation. In conclusion, Blockchain has the potential to improve operational efficiency while also ensuring the safety of the data involved in the logistics process. According to the findings of the study, the technologies underlying Industry 4.0 have the potential to make supply chains more agile, transparent, and resilient. In addition, the study demonstrates that despite the fact that the advantages of integrating technologies related to Industry 4.0 into supply chains are widely acknowledged, there is still a dearth of applications, related research, and actual-world use cases. Nevertheless, it is abundantly clear that companies that do not adopt the technologies will eventually go out of business. In the event that the pandemic has revealed bottlenecks in the practises we use for our supply chain, the solution is to integrate advanced technologies from Industry 4.0. © 2023, Ismail Saritas. All rights reserved.",Blockchain; IoT; IR 4.0; Logistics; Security,"Agarwal S., Vinaya Laxmi K., Gupta N.K., Wankhade M.P., Bapat V.","Department of Management Studies (School of Studies in Management and Commerce, Guru Ghasidas Vishwavidyalaya (A Central University), Koni, CG, Bilaspur, India; Vardhaman College of Engineering, Telangana, Kacharam, Shamshabad, Hyderabad, India; Department of IT, Manipal University Jaipur, Rajasthan, India; Department of Computer Engg, Sinhgad College of Engineering, Maharashtra, Pune, India; Department of Electronic Science, PES'S Modern College of Arts, Science and Commerce, Maharashtra, Pune, India",2023.0,International Journal of Intelligent Systems and Applications in Engineering,Ismail Saritas,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158166428&partnerID=40&md5=423f964fe81eb5fcaf49b1aeb5364ee7,,20230520-160000,20230521-044735,"['a', 'blockchain', 'security', 'based', 'iot-enabled', 'system', 'for', 'safe', 'and', 'effective', 'logistics', 'management', 'in', 'ir', '4.0']",False,20230521-205332,,,,
553,scopus,Project management: openings for disruption from AI and advanced analytics,"Purpose: The purpose of this essay is to illustrate how project management “pull” and AI or analytics technology “push” are likely to result in incremental and disruptive evolution of project management capabilities and practices. Design/methodology/approach: This paper is written as a critical essay reflecting the experience and reflections of the author with many ideas drawn from and extending selected items from project management, artificial intelligence (AI) and analytics literatures. Findings: Neither AI nor sophisticated analytics is likely to elicit hands on attention from project managers, other than those producing AI or analytics-based artifacts or using these tools to create their products and services. However, through the conduit of packaged software support for project management, new tools and approaches can be expected to more effectively support current activities, to streamline or eliminate activities that can be automated, to extend current capabilities with the availability of increased data, computing capacity and mathematically based algorithms and to suggest ways to reconceive how projects are done and whether they are needed. Research limitations/implications: This essay includes projections of possible, some likely and some unlikely, events and states that have not yet occurred. Although the hope and purpose are to alert readers to the possibilities of what may occur as logical extensions of current states, it is improbable that all such projections will come to pass at all or in the way described. Nonetheless, consideration of the future ranging from current trends, the interplay among intersecting trends and scenarios of future states can sharpen awareness of the effects of current choices regarding actions, decisions and plans improving the probability that the authors can move toward desired rather than undesired future states. Practical implications: Project managers not involved personally with creating AI or analytics products can avoid mastering detailed skill sets in AI and analytics, but should scan for new software features and affordances that they can use enable new levels of productivity, net benefit creation and ability to sleep well at night. Originality/value: This essay brings together AI, analytics and project management to imagine and anticipate possible directions for the evolution of the project management domain. © 2021, Emerald Publishing Limited.",Agile development; Artificial intelligence; Big data; Business analytics; CRISP-DM; IS project management; Project management,Niederman F.,"Saint Louis University, St. Louis, MO, United States",2021.0,Information Technology and People,Emerald Group Holdings Ltd.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102715757&doi=10.1108%2fITP-09-2020-0639&partnerID=40&md5=99221132bd32c5b677a76ed59b99a188,10.1108/ITP-09-2020-0639,20230520-160000,20230521-044735,"['project', 'management:', 'openings', 'for', 'disruption', 'from', 'ai', 'and', 'advanced', 'analytics']",False,20230521-205332,,,,
554,scopus,Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions,"The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline—no AI can do this. Consequently, human-centered AI (HCAI) is a combination of “artificial intelligence” and “natural intelligence” to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",AI for good; artificial intelligence; cyber-physical systems; human-centered AI; machine learning; precision farming; precision forestry; sensors; smart farming; smart forestry,"Holzinger A., Saranti A., Angerschmid A., Retzlaff C.O., Gronauer A., Pejakovic V., Medel-Jimenez F., Krexner T., Gollob C., Stampfer K.","Human-Centered AI Lab, Institute of Forest Engineering, Department of Forest and Soil Sciences, University of Natural Resources and Life Sciences Vienna, Wien, 1190, Austria; xAI Lab, Alberta Machine Intelligence Institute, University of Alberta, Edmonton, AB  T5J 3B1, Canada; DAI Lab, Technical University Berlin, Berlin, 10623, Germany; Institute of Agricultural Engineering, Department of Sustainable Agricultural Systems, University of Natural Resources and Life Sciences Vienna, Wien, 1180, Austria; Institute of Forest Growth, Department of Forest and Soil Sciences, University of Natural Resources and Life Sciences Vienna, Wien, 1180, Austria; Institute of Forest Engineering, Department of Forest and Soil Sciences, University of Natural Resources and Life Sciences Vienna, Wien, 1180, Austria",2022.0,Sensors,MDPI,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128181274&doi=10.3390%2fs22083043&partnerID=40&md5=f082f34f2e8fd6fc475c4ab30b64ac26,10.3390/s22083043,20230520-160000,20230521-044735,"['digital', 'transformation', 'in', 'smart', 'farm', 'and', 'forest', 'operations', 'needs', 'human-centered', 'ai:', 'challenges', 'and', 'future', 'directions']",False,20230521-205332,,,,
555,scopus,Closed-Loop Data Analytics for Wells Construction Management in Real Time Centre,"The execution phase of the wells technical assurance process is a critical procedure where the drilling operation commences and the well planning program is implemented. During drilling operations, the real-time drilling data are streamed to a real-time centre where it is constantly monitored by a dedicated team of monitoring specialists. If any potential issues or possible opportunities arise, the team will communicate with the operation team on rig for an intervention. This workflow is further enhanced by digital initiatives via big data analytics implementation in PETRONAS. The Digital Standing Instruction to Driller (Digital SID) is a drilling operational procedures documentation tool meant to improve the current process by digitalizing information exchange between office and rig site. Boasting multi-operation usage, it is made fit to context and despite its automated generation, this tool allows flexibility for the operation team to customize the content and more importantly, monitor the execution in real-time. Another tool used in the real-time monitoring platform is the dynamic monitoring drilling system where it allows real-time drilling data to be more intuitive and gives the benefit of foresight. The dynamic nature of the system means that it will update existing roadmaps with extensive real-time data as they come in, hence improving its accuracy as we drill further. Furthermore, an automated drilling key performance indicator (KPI) and performance benchmarking system measures drilling performance to uncover areas of improvement. This will serve as the benchmark for further optimization. On top of that, an artificial intelligence (AI) driven Wells Augmented Stuck Pipe Indicator (WASP) is deployed in the real-time monitoring platform to improve the capability of monitoring specialists to identify stuck pipe symptoms way earlier before the occurrence of the incident. This proactive approach is an improvement to the current process workflow which is less timely and possibly missing the intervention opportunity. These four tools are integrated seamlessly with the real-time monitoring platform hence improving the project management efficiency during the execution phase. The tools are envisioned to offer an agile and efficient process workflow by integrating and tapering down multiple applications in different environments into a single web-based platform which enables better collaboration and faster decision making. Copyright © 2021, International Petroleum Technology Conference.",,"Rosli A., Mak W.J., Richard B., Hakeem Meor Hashim M.M., Arriffin M.F., Mohamad A.","PETRONAS Carigali Sdn Bhd, Malaysia",2021.0,"International Petroleum Technology Conference, IPTC 2021",International Petroleum Technology Conference (IPTC),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150596679&doi=10.2523%2fIPTC-21175-MS&partnerID=40&md5=56f0b73564e7b9e6a14f96c6cfa70983,10.2523/IPTC-21175-MS,20230520-160000,20230521-044735,"['closed-loop', 'data', 'analytics', 'for', 'wells', 'construction', 'management', 'in', 'real', 'time', 'centre']",False,20230521-205332,,,,
556,scopus,MYMARHALAH: A SMART NAVIGATION MOBILE APPLICATION for MUSAFIR in MALAYSIA USING GIS and RELATED TECHNOLOGIES,"Smartphone penetration in Malaysia has exceeded 88% as share of the population and is projected to continue to increase over the coming years. Rapid technological advances open up opportunities to develop Geographical Information System (GIS) based mobile applications using embedded features inherent in mobile devices as well as application framework components and APIs. The evolution in Global Positioning System (GPS) technology has improved the accessibility and navigation accuracy in mobile applications. Islam has set some specific rukhsah (concession) concepts that can be applied by musafir (muslim travellers) including prayers of jama' and qasar (combine and shorten) if the journey exceeds two (2) marhalah which has been decided as 81km by Malaysian Islamic Authority. Currently there aren't any well-defined application available to assist them in fulfilling their obligation in Malaysia. myMarhalah is a mobile GIS application developed to facilitate musafir with their journey by displaying navigation routes, calculating travelled distances, identifying permissible leniency for prayers, locating nearby mosques, showing prayer times and listing the answers for frequently asked questions on related issues. The application uses open source native cross platform development that supports agile software development life cycle (SDLC) and allows DevOps to develop full native application for iOS and android simultaneously. This saves a lot of time in maintenance and upgrades. Equipped with artificial intelligence and machine learning technologies, myMarhalah provides multiple route options to users and dynamically changes active navigation based on user's decision. Integration with mosque location allows users to navigate to the mosque of their choice in the middle of the journey to perform prayer and navigate back to the final destination seamlessly. The application also adopted big data technology in its search and query functions for better user experience (UX). With the absence of distinct application for musafir in Malaysia, myMarhalah is the first one-stop mobile GIS application that provides convenient solution for them to implement the concession concept in their journey. It is also in line with the Malaysian Government's Digitalisation Strategy to improve public service delivery using emerging technologies. © ACRS 2021.All right reserved.",Artificial Intelligence; Geographical Information System (GIS); Machine Learning Technique; Mobile Application,"Ismail A., Yusof M.F.M., Sahlan N.S., Omar S., Rabai S.N.M., Esa S.F.M., Surip A.G., Yazid K.A., Ismail N.A., Awang R.","Malaysian Space Agency (MYSA), Ministry of Science, Technology and Innovation (MOSTI), No.13 Jalan Tun Ismail, Kuala Lumpur, 50480, Malaysia; Jabatan Kemajuan Islam Malaysia, Kompleks Islam Putrajaya, Pusat Pentadbiran Kerajaan Persekutuan, Presint 3, Putrajaya, 62100, Malaysia",2021.0,"42nd Asian Conference on Remote Sensing, ACRS 2021",Asian Association on Remote Sensing,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127412299&partnerID=40&md5=ed321ba431cc3b932eaf8f45b8869f95,,20230520-160000,20230521-044735,"['mymarhalah:', 'a', 'smart', 'navigation', 'mobile', 'application', 'for', 'musafir', 'in', 'malaysia', 'using', 'gis', 'and', 'related', 'technologies']",False,20230521-205332,,,,
557,scopus,The era of digital technology: Analysis of factors contributing to economic growth and sustainability.,"The fourth industrial revolution (4IR) has become the main focus for economic development and competitive advantage for countries and sectors. The advancement of the 4IR technologies introduced the era of digital technology, whereby all sectors, government institutions, small and medium enterprises are seeking these technologies such as the internet of things (IoT), artificial intelligence, and machine learning to name but few. Yet, there is a perception that the South African manufacturing sector is lagging behind with the adoption of these advanced technologies. Moreover, some of these manufacturers are still depending on their traditional methods and conventional machine tools. Meanwhile, the era of digital technology has presented these tools with sectors that had successfully achieved a competitive advantage within the marketplace. As a result, this paper analyses the factors contributing to economic growth and sustainability in relation to the adoption and usage of new technologies. The paper provides some insights into the readiness and adaption of the South African manufacturing sector of the new technologies as well as the global conformity with 4IR. Sectors are being forced to rethink their business processes and the way they conduct business. In response to the challenges deriving from globalization, manufacturing companies today face the need for more flexible and agile manufacturing equipment. Also, the pressure has been posed by their competitors that have taken advantage of these technologies and noted significant improvement in cost reduction, cycle time, productivity, and safety issues. Clearly, the usage of the industry 4.0 tools such as automation, robotics, smart production, artificial intelligence, and big data presents opportunities. From the South African manufacturing perspective, 4IR is challenging a sector that has been in decline for the past decade due to a lack of adopting advanced manufacturing technologies. Whereas this sector is one of the sectors that is expected to strengthen economic growth and job creation. Findings suggest that there is a need to rethink the current production systems in order to develop a manufacturing digital transformation model that enables the conversion to smart factories, automation processes, real-time data of production process, and marketplace. The findings also revealed that there are few component elements that need serious attention, namely, ICT infrastructure, high tech skilled retention, development of the high-tech skilled workforce, particularly digitally skilled workers-which is the main problem in both developed and developing countries. © IEOM Society International.",Digital technology; Economic growth; Industry 4.0; Manufacturing; Sustainability,"Ndou A.T., Madonsela N.S., Twala B.","Department of Quality and Operations Management, University of Johannesburg, Corner Kingsway and University Road, Auckland Park, South Africa; Faculty of Engineering and Built Environment, Durban University of Technology, South Africa 41/43 ML Sultan Rd, Greyville, Durban, South Africa",2020.0,Proceedings of the International Conference on Industrial Engineering and Operations Management,IEOM Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105596104&partnerID=40&md5=d1c0516e8d34b5a0fa6b6dd8fe235184,,20230520-160000,20230521-044735,"['the', 'era', 'of', 'digital', 'technology:', 'analysis', 'of', 'factors', 'contributing', 'to', 'economic', 'growth', 'and', 'sustainability.']",False,20230521-205332,,,,
558,scopus,Knowledge-driven based performance analysis of robotic manufacturing cell for design improvement,"Manufacturing companies must ensure high productivity and low production cost in rapidly changing market conditions. At the same time products and services are evolving permanently. In order to cope with those circumstances, manufacturers should apply the principles of smart manufacturing together with continuous processes improvement. Smart manufacturing is a concept where production is no longer highly labor-intensive and based only on flexible manufacturing systems, but production as a whole process should be monitored and controlled with sophisticated information technology, integrated on all stages of the product life cycle. Process improvements in Smart Manufacturing are heavily reliance on decisions, which can be achieved by using modeling and simulation of systems with different analyzing tools based on Big Data processing and Artificial Intelligence (AI) technologies. This study was performed to automate an estimation process and improve the accuracy for production celĺs performance evaluation. Although there have been researches performed in the same field, the substantial estimation process outcome and accuracy still need to be elaborated further. In this article a robot integrated production cell simulation framework is developed. A developed system is used to simulate production cell parametric models in the real-life situations. A set of rules and constraints are created and inserted into the simulation model. Data for the constraints were acquired by investigating industries' best production cells performance parameters. Information was gathered in four main fields: company profile and strategy, cell layout and equipment, manufactured products process data and shortcomings of goal achievements or improvement necessary to perform. From those parametric case model, a 3D virtual manufacturing simulation model is built and simulated for achieving accurate results. The integration of manufacturing data into decision making process through advanced prescriptive analytics models is a one of the future tasks of this study. The integration makes it possible to use ""best practice""data and obtained Key Performance Indicators (KPIs) results to find the optimal solutions in real manufacturing conditions. The objective is to find the best solution of robot integrated cell for a certain industry using AI enabled simulation model. It also helps to improve situation assessment and deliberated decision-making mechanism.. Copyright © 2020 ASME.",data analytics; digital twins.; Knowledge driven manufacturing; robot-cell performance analysis; simulation applications,"Kangru T., Mahmood K., Otto T., Moor M., Riives J.","Tallinn University of Technology, Tallinn, Estonia; Ttk University of Applied Sciences, Tallinn, Estonia; Innovative Manufacturing Engineering Systems Competence Centre, Tallinn, Estonia",2020.0,"ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)",American Society of Mechanical Engineers (ASME),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101234317&doi=10.1115%2fIMECE2020-23541&partnerID=40&md5=74635bd98dab507102a30d425a8e73a3,10.1115/IMECE2020-23541,20230520-160000,20230521-044735,"['knowledge-driven', 'based', 'performance', 'analysis', 'of', 'robotic', 'manufacturing', 'cell', 'for', 'design', 'improvement']",False,20230521-205332,,,,
559,scopus,GENERATOR HEART FAILURE DataMart: An integrated framework for heart failure research,"Background: Heart failure (HF) is a multifaceted clinical syndrome characterized by different etiologies, risk factors, comorbidities, and a heterogeneous clinical course. The current model, based on data from clinical trials, is limited by the biases related to a highly-selected sample in a protected environment, constraining the applicability of evidence in the real-world scenario. If properly leveraged, the enormous amount of data from real-world may have a groundbreaking impact on clinical care pathways. We present, here, the development of an HF DataMart framework for the management of clinical and research processes. Methods: Within our institution, Fondazione Policlinico Universitario A. Gemelli in Rome (Italy), a digital platform dedicated to HF patients has been envisioned (GENERATOR HF DataMart), based on two building blocks: 1. All retrospective information has been integrated into a multimodal, longitudinal data repository, providing in one single place the description of individual patients with drill-down functionalities in multiple dimensions. This functionality might allow investigators to dynamically filter subsets of patient populations characterized by demographic characteristics, biomarkers, comorbidities, and clinical events (e.g., re-hospitalization), enabling agile analyses of the outcomes by subsets of patients. 2. With respect to expected long-term health status and response to treatments, the use of the disease trajectory toolset and predictive models for the evolution of HF has been implemented. The methodological scaffolding has been constructed in respect of a set of the preferred standards recommended by the CODE-EHR framework. Results: Several examples of GENERATOR HF DataMart utilization are presented as follows: to select a specific retrospective cohort of HF patients within a particular period, along with their clinical and laboratory data, to explore multiple associations between clinical and laboratory data, as well as to identify a potential cohort for enrollment in future studies; to create a multi-parametric predictive models of early re-hospitalization after discharge; to cluster patients according to their ejection fraction (EF) variation, investigating its potential impact on hospital admissions. Conclusion: The GENERATOR HF DataMart has been developed to exploit a large amount of data from patients with HF from our institution and generate evidence from real-world data. The two components of the HF platform might provide the infrastructural basis for a combined patient support program dedicated to continuous monitoring and remote care, assisting patients, caregivers, and healthcare professionals. 2023 D'Amario, Laborante, Delvinoti, Lenkowicz, Iacomini, Masciocchi, Luraschi, Damiani, Rodolico, Restivo, Ciliberti, Paglianiti, Canonico, Paternello, Cesario, Valentini, Scambia and Crea.",artificial intelligence; big data; datamart; heart failure; machine learning,"D’Amario D., Laborante R., Delvinioti A., Lenkowicz J., Iacomini C., Masciocchi C., Luraschi A., Damiani A., Rodolico D., Restivo A., Ciliberti G., Paglianiti D.A., Canonico F., Patarnello S., Cesario A., Valentini V., Scambia G., Crea F.","Department of Cardiovascular and Pulmonary Sciences, Catholic University of the Sacred Heart, Rome, Italy; Department of Cardiovascular Sciences, Fondazione Policlinico Universitario A. Gemelli IRCCS, Rome, Italy; Università del Piemonte Orientale, Dipartimento Medicina Translazionale, Azienda Ospedaliero-Universitaria Maggiore della Carità, Dipartimento Toraco-Cardio-Vascolare, Unità Operativa Complessa di Cardiologia 1, Novara, Italy; Gemelli Generator, Fondazione Policlinico Universitario A. Gemelli IRCCS, Rome, Italy; Department of Bioimaging, Radiation Oncology and Hematology, Fondazione Policlinico Universitario “A. Gemelli” IRCCS, Università Cattolica S. Cuore, Rome, Italy",2023.0,Frontiers in Cardiovascular Medicine,Frontiers Media S.A.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152533503&doi=10.3389%2ffcvm.2023.1104699&partnerID=40&md5=19a0ac80dc8aee78dec6b00ec99b2032,10.3389/fcvm.2023.1104699,20230520-160000,20230521-044735,"['generator', 'heart', 'failure', 'datamart:', 'an', 'integrated', 'framework', 'for', 'heart', 'failure', 'research']",False,20230521-205332,,,,
560,wos,Achieving Agile Big Data Science: The Evolution of a Team Agile Process Methodology,"While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams.",Big Data Science; Agile; Process Methodology,"Saltz, JS; Shamshurin, I",Syracuse University,2019.0,2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,,20230520-160000,20230521-044735,"['achieving', 'agile', 'big', 'data', 'science:', 'the', 'evolution', 'of', 'a', 'team', 'agile', 'process', 'methodology']",False,20230521-205332,,,,
561,wos,Applying Scrum in Data Science Projects,"The rise of big data has led to an increase in data science projects conducted by organizations. Such projects aim to create valuable insights by improving decision making or enhancing an organization's service offering through datadriven services. However, the majority of data science projects still fail to deliver the expected value. To increase the success rate of projects, the use of process models or methodologies is recommended in the literature. Nevertheless, organizations are hardly using them because they are considered too rigid and they do not support the typical iterative and open nature of data science projects. To overcome this problem, this research suggests applying Agile methodologies to data science projects. Agile methodologies were originally developed in the software engineering domain and are characterised by their iterative approach towards software development. In this study, we selected the Scrum approach and integrated it into the CRISP-DM methodology for data science projects using a Design Science Research approach. This new methodology was then evaluated in three different case organizations using expert interviews. Analysis of the expert interviews resulted in a further refinement of the Agile data science methodology proposed by this research.",Data Science; Agile; Scrum,"Baijens, J; Helms, R; Iren, D",Open University Netherlands,2020.0,"2020 IEEE 22ND CONFERENCE ON BUSINESS INFORMATICS (CBI 2020), VOL I - RESEARCH PAPERS",IEEE COMPUTER SOC,,10.1109/CBI49978.2020.00011,20230520-160000,20230521-044735,"['applying', 'scrum', 'in', 'data', 'science', 'projects']",True,20230521-205332,,,,
562,wos,SKI: An Agile Framework for Data Science,"This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrum-like time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus. SKI implements the Kanban process, but with a more repeatable and structured approach.",Data Science; Big Data; Agile; Process Methodology,"Saltz, J; Suthrland, A",Syracuse University,2019.0,2019 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,,20230520-160000,20230521-044735,"['ski:', 'an', 'agile', 'framework', 'for', 'data', 'science']",True,20230521-205332,,,,
563,wos,Adopting Agile Software Development Methodologies in Big Data Projects - a Systematic Literature Review of Experience Reports,"During the last decade, agile software development methodologies have been widely adopted in various project contexts. Big data projects are different from software engineering projects in all three aspects - people, processes and technologies. Recent research has shown that agile approaches are suitable and beneficial when applied in big data projects. The aim of the current study is to investigate which of the agile software development methodologies are currently applied in big data projects and what are the key considerations for their application. As a first step towards achieving this aim, the paper presents a systematic literature review of research articles reporting real-world experience of adopting agile methodologies in different big data science contexts. The findings of the study are beneficial to both practitioners and researchers to define and adopt agile approaches which are well suited for their big data projects.",agile software development; big data science; methodology adoption; real-world experience; systematic literature review,"Krasteva, I; Ilieva, S",,2020.0,2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData50022.2020.9378118,20230520-160000,20230521-044735,"['adopting', 'agile', 'software', 'development', 'methodologies', 'in', 'big', 'data', 'projects', '-', 'a', 'systematic', 'literature', 'review', 'of', 'experience', 'reports']",True,20230521-205332,,,,
564,wos,Web Services-based Report Generation System from Big Data in the Manufacturing Industry based on Agile Software Development,"In the manufacturing industry, there are many information technology (IT) systems and machines connected to different databases with complex big data. In this study, the web service system is developed by using different programming languages consisting of C#, Javascript, HTML, CSS, Ext JS and structured query language (SQL). In addition to these programming languages, model view controller (MVC), a software design pattern is also used for developing a database interface. The development of this system allows the web service system to search for reports that meet the user needs and also has the user interface (UI) for convenience and speed. In this study, agile software development method is used in accordance with scrum framework, which consist of 4 steps: 1) product backlog creation, 2) sprint backlog creation, 3) sprint or the system development and testing and test case writing and 4) daily scrum. Sprint review is held to report the results of unit test, functional test, integration test and user acceptance test (UAT). This sprint review enables the development of an appropriate and comprehensive system and results in collaboration and understanding among stakeholders, including technology adoption among users.",Big Data; Web Services; Agile,"Kattiyawong, P; Tangprasert, S",King Mongkuts University of Technology North Bangkok,2020.0,"PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1",SCITEPRESS,,10.5220/0009459102260232,20230520-160000,20230521-044735,"['web', 'services-based', 'report', 'generation', 'system', 'from', 'big', 'data', 'in', 'the', 'manufacturing', 'industry', 'based', 'on', 'agile', 'software', 'development']",True,20230521-205332,,,,
565,wos,Agile Elastic Desktop Corporate Architecture for Big Data,"New challenges in the dynamically changing business environment require companies to experience digital transformation and more effective use of Big Data generated in their expanding online business activities. A possible solution for solving real business problems concerning Big Data resources is proposed in this paper. The defined Agile Elastic Desktop Corporate Architecture for Big Data is based on virtualizing the unused desktop resources and organizing them in order to serve the needs of Big Data processing, thus saving resources needed for additional infrastructure in an organization. The specific corporate business needs are analyzed within the developed R&D environment and, based on that, the unused desktop resources are customized and configured into required Big Data tools. The R&D environment of the proposed Agile Elastic Desktop Corporate Architecture for Big Data could be implemented on the available unused resources of hundreds desktops.",Agile Elastic Desktop Corporate Architecture; Desktop Virtualization; Big Data; Digital Transformation,"Kisimov, V; Kabakchieva, D; Naydenov, A; Stefanova, K",University of National & World Economics - Bulgaria,2020.0,CYBERNETICS AND INFORMATION TECHNOLOGIES,INST INFORMATION & COMMUNICATION TECHNOLOGIES-BULGARIAN ACAD SCIENCES,,10.2478/cait-2020-0025,20230520-160000,20230521-044735,"['agile', 'elastic', 'desktop', 'corporate', 'architecture', 'for', 'big', 'data']",True,20230521-205332,,,,
566,wos,Current approaches for executing big data science projects-a systematic literature review,"There is an increasing number of big data science projects aiming to create value for organizations by improving decision making, streamlining costs or enhancing business processes. However, many of these projects fail to deliver the expected value. It has been observed that a key reason many data science projects don't succeed is not technical in nature, but rather, the process aspect of the project. The lack of established and mature methodologies for executing data science projects has been frequently noted as a reason for these project failures. To help move the field forward, this study presents a systematic review of research focused on the adoption of big data science process frameworks. The goal of the review was to identify (1) the key themes, with respect to current research on how teams execute data science projects, (2) the most common approaches regarding how data science projects are organized, managed and coordinated, (3) the activities involved in a data science projects life cycle, and (4) the implications for future research in this field. In short, the review identified 68 primary studies thematically classified in six categories. Two of the themes (workflow and agility) accounted for approximately 80% of the identified studies. The findings regarding workflow approaches consist mainly of adaptations to CRISP-DM (vs entirely new proposed methodologies). With respect to agile approaches, most of the studies only explored the conceptual benefits of using an agile approach in a data science project (vs actually evaluating an agile framework being used in a data science context). Hence, one finding from this research is that future research should explore how to best achieve the theorized benefits of agility. Another finding is the need to explore how to efficiently combine workflow and agile frameworks within a data science context to achieve a more comprehensive approach for project execution.",Big data science; Project execution; Process frameworks; Big data science workflows; Agile data science,"Saltz, JS; Krasteva, I",Syracuse University; University of Sofia,2022.0,PEERJ COMPUTER SCIENCE,PEERJ INC,,10.7717/peerj-cs.862,20230520-160000,20230521-044735,"['current', 'approaches', 'for', 'executing', 'big', 'data', 'science', 'projects-a', 'systematic', 'literature', 'review']",False,20230521-205332,,,,
567,wos,Exploring the Challenges of Integrating Data Science Roles in Agile Autonomous Teams,"The notion of autonomous teams is core to agile software development. However, autonomy in agile teams is challenged by increasingly complex software projects, large-scale agile and perhaps increasingly multidisciplinary teams. At the same time, data science roles are making their way into agile teams as companies seek to reap the potential advantages of using data to develop better and more competitive services and products. The consequences of implementing such roles in traditional agile teams are largely unknown. In this paper, we take an exploratory approach to the topic of data science roles in agile teams by a set of interviews with five data scientists as well as three members of an agile software development team. Based on the interviews we identify a set of challenges associated with incorporating the role in agile autonomous teams. Based on these challenges we discuss preliminary recommendations for companies seeking to integrate data science roles in agile teams.",Data science; Agile; Software development; Teams; Autonomy,"Hukkelberg, I; Berntzen, M",University of Oslo,2019.0,AGILE PROCESSES IN SOFTWARE ENGINEERING AND EXTREME PROGRAMMING - WORKSHOPS,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-030-30126-2_5,20230520-160000,20230521-044735,"['exploring', 'the', 'challenges', 'of', 'integrating', 'data', 'science', 'roles', 'in', 'agile', 'autonomous', 'teams']",True,20230521-205332,,,,
568,wos,A Big Data on Private Cloud Agile Provisioning Framework Based on OpenStack,"On the bases of the OpenStack private cloud delivery big data platform, numerous entities yearn for attaining agile and standardized big data delivery platform, reclaiming the resources, managing the total cost of ownership (TCO) and adapting to multiple big data open source or commercial off-the-shelf (COTS) solutions. Nevertheless, as regards the big data platform running on cloud computing, the big data platform is disintegrated from the cloud computing system by virtual machines since neither being based on OpenStack private cloud nor on big data platform can achieve end-to-end resource delivery, together with ensuring that it is quite convenient for the long-term operations. Accordingly, establishing an across framework between private cloud and big data platform is quite essential. The big data on cloud agile provision framework could realize fast resource delivery based on predefined orchestration template of private cloud, operating system, big data platform, monitor, inspection system, etc. Through the deployment of this framework, it is capable of attaining the delivery of agile, low cost, standardized and high adaptability the big data on cloud, as well as the high-quality operation of the big data on cloud with the help of integration configuration management database (CMDB) with the automatic inspection system.",cloud computing; agile resource provisioning; big data platform orchestration; inspection and rule engine,"Lu, M; Zhou, X","Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Legend Holdings; Lenovo; Legend Holdings; Lenovo",2018.0,2018 IEEE 3RD INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA),IEEE,,,20230520-160000,20230521-044735,"['a', 'big', 'data', 'on', 'private', 'cloud', 'agile', 'provisioning', 'framework', 'based', 'on', 'openstack']",True,20230521-205332,,,,
569,wos,Lessons learned to improve the UX practices in agile projects involving data science and process automation,"Context: User-Centered Design (UCD) and Agile methodologies focus on human issues. Nevertheless, agile methodologies focus on contact with contracting customers and generating value for them. Usually, the communication between end users (they use the software and have low decision power) and the agile team is mediated by customers (they have high decision power but do not use the software). However, they do not know the actual problems that end users (may) face in their routine, and they may not be directly affected by software shortcomings. In this context, UX issues are typically identified only after the implementation, during user testing and validation. Objective: Aiming to improve the understanding and definition of the problem in agile projects, this research investigates the practices and difficulties experienced by agile teams during the development of data science and process automation projects. Also, we analyze the benefits and the teams' perceptions regarding user participation in these projects. Method: We collected data from four agile teams, in the context of an academia and industry collaboration focusing on delivering data science and process automation solutions. Therefore, we applied a carefully designed questionnaire answered by developers, scrum masters, and UX designers. In total, 18 subjects answered the questionnaire. Results: From the results, we identify practices used by the teams to define and understand the problem and to represent the solution. The practices most often used are prototypes and meetings with stakeholders. Another practice that helped the team to understand the problem was using Lean Inception (LI) ideation workshops. Also, our results present some specific issues regarding data science projects. Conclusion: We observed that end-user participation can be critical to understanding and defining the problem. They help to define elements of the domain and barriers in the implementation. We identified a need for approaches that facilitate user-team communication in data science projects to understand the data and its value to the users' routine. We also identified insights about the need of more detailed requirements representations to support the development of data science solutions.",Agile; User -centered design; Lean inception; User involvement; User participation; User experience; Data science,"Ferreira, B; Marques, S; Kalinowski, M; Lopes, H; Barbosa, SDJ",,2023.0,INFORMATION AND SOFTWARE TECHNOLOGY,ELSEVIER,,10.1016/j.infsof.2022.107106,20230520-160000,20230521-044735,"['lessons', 'learned', 'to', 'improve', 'the', 'ux', 'practices', 'in', 'agile', 'projects', 'involving', 'data', 'science', 'and', 'process', 'automation']",True,20230521-205332,,,,
570,wos,Agile manufacturing practices: the role of big data and business analytics with multiple case studies,"The purpose of this study was to examine the role of big data and business analytics (BDBA) in agile manufacturing practices. Literature has discussed the benefits and challenges related to the deployment of big data within operations and supply chains, but there has not been a study of the facilitating roles of BDBA in achieving an enhanced level of agile manufacturing practices. As a response to this gap, and drawing upon multiple qualitative case studies undertaken among four UK organisations, we present and validate a framework for the role of BDBA within agile manufacturing. The findings show that market turbulence has negative universal effects and that agile manufacturing enablers are being progressively deployed and aided by BDBA to yield better competitive and business performance objectives. Further, the level of intervention was found to differ across companies depending on the extent of deployment of BDBA, which accounts for variations in outcomes.",big data and business analytics; agile manufacturing; enablers; competitive advantage; performance,"Gunasekaran, A; Yusuf, YY; Adeleye, EO; Papadopoulos, T",California State University System; California State University Bakersfield; University of Central Lancashire; University of Kent,2018.0,INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH,TAYLOR & FRANCIS LTD,,10.1080/00207543.2017.1395488,20230520-160000,20230521-044735,"['agile', 'manufacturing', 'practices:', 'the', 'role', 'of', 'big', 'data', 'and', 'business', 'analytics', 'with', 'multiple', 'case', 'studies']",True,20230521-205332,,,,
571,wos,Application of Methodologies and Process Models in Big Data Projects,"The concept of Big Data is being used in different business sectors; however, it is not certain which methodologies and process models have been used for the development of these kind of projects. This paper presents a systematic literature review of studies reported between 2012 and 2017 related to agile and non-agile methodologies applied in Big Data projects. For validating our review process, a text mining method was used. The results reveal that since 2016 the number of articles that integrate the agile manifesto in Big Data project has increased, being Scrum the agile framework most commonly applied. We also found that 44% of articles obtained from a manual systematic literature review were automatically identified by applying text mining.",Agile Methodologies; Big Data; Systematic Literature Review; Text Mining,"Quelal, R; Mendoza, LE; Villavicencio, M",Escuela Superior Politecnica del Litoral; Simon Bolivar University,2019.0,"PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2019), VOL 2",SCITEPRESS,,10.5220/0007729602770284,20230520-160000,20230521-044735,"['application', 'of', 'methodologies', 'and', 'process', 'models', 'in', 'big', 'data', 'projects']",True,20230521-205332,,,,
572,wos,Enhanced Framework for Big Data Requirement Elicitation,"Requirement engineering is one of the software development life cycle phases; it has been recognized as an important phase for collecting and analyzing a system's goals. However, despite its importance, requirement engineering has several limitations such as incomplete requirements, vague requirements, lack of prioritization, and less user involvement, all of which affect requirement quality. With the emergence of big data technology, the complexity of big data, which is defined by large data volume, high velocity, and large data variety, has gradually increased, affecting the quality of big data software requirements. This study proposes a framework with four sequential phases to improve requirement engineering quality through big data software development. By integrating the proposed framework's phases in which user requirements are collected in a complete vision using traditional requirement elicitation techniques with agile methodology and mind mapping, the collected requirements are displayed via a graphical representation using mind maps to achieve high requirement accuracy with connectivity and modifiability, enabling the accurate prioritization of requirements implemented using agile SCRUM methodology. The proposed framework improves requirement quality in big data software development, which is represented by accuracy, completeness, connectivity, and modifiability to understand the value of the collected requirements and effectively affect the quality of the implementation phase.",Requirement engineering; big data requirement; agile methodology; mind mapping,"Hesham, A; Emam, OE; Salah, M",Egyptian Knowledge Bank (EKB); Helwan University; Egyptian Knowledge Bank (EKB); British University in Egypt,2021.0,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,SCIENCE & INFORMATION SAI ORGANIZATION LTD,,,20230520-160000,20230521-044735,"['enhanced', 'framework', 'for', 'big', 'data', 'requirement', 'elicitation']",True,20230521-205332,,,,
573,wos,A Scalable Methodology to Guide Student Teams Executing Computing Projects,"This article reports on a sequential mixed-methods research study, which compared different approaches on how to guide students through a semester-long data science project. Four different methodologies, ranging from a traditional just assign some intermediate milestones to other more Agile methodologies, were first compared via a controlled experiment. The results of this initial experiment showed that the project methodology used made a significant difference in student outcomes. Surprisingly, the Agile Kanban approach was found to be much more effective than the Agile Scrum methodology. Based on these initial results, in the second semester, we focused on use of the Kanban methodology. The findings in the second, more qualitative phase, confirmed the methodology's usefulness and scalability. A key issue when using the scrum methodology was that the students had a very difficult time estimating what could be completed in each of their two-week sprints. The Kanban board, which visually shows and limits work-in-progress, was found to be an effective way for students to communicate with each other as well as with their instructor. In addition, Agile Kanban also streamlined the work required for instructors to efficiently provide guidance to student teams and to understand each team's status. In summary, a scalable Kanban methodology, which can be applied to a wide variety of student computing projects, was found to an effective methodology to guide and manage student projects, improving student outcomes and minimizing instructor workload.",Project-based learning; scalable methodologies; project methodologies,"Saltz, JS; Heckman, RR",Syracuse University,2018.0,ACM TRANSACTIONS ON COMPUTING EDUCATION,ASSOC COMPUTING MACHINERY,,10.1145/3145477,20230520-160000,20230521-044735,"['a', 'scalable', 'methodology', 'to', 'guide', 'student', 'teams', 'executing', 'computing', 'projects']",True,20230521-205332,,,,
574,wos,Managing and Composing Teams in Data Science: An Empirical Study,"Data science projects have become commonplace over the last decade. During this time, the practices of running such projects, together with the tools used to run them, have evolved considerably. Furthermore, there are various studies on data science workflows and data science project teams. However, studies looking into both workflows and teams are still scarce and comprehensive works to build a holistic view do not exist. This study bases on a prior case study on roles and processes in data science. The goal here is to create a deeper understanding of data science projects and development processes. We conducted a survey targeted at experts working in the field of data science (n=50) to understand data science projects' team structure, roles in the teams, utilized project management practices and the challenges in data science work. Results show little difference between big data projects and other data science. The found differences, however, give pointers for future research on how agile data science projects are, and how important is the role of supporting project management personnel. The current study is work in progress and attempts to spark discussion and new research directions.",Data science; agile practices; teamwork; project management,"Aho, T; Kilamo, T; Lwakatare, L; Mikkonen, T; Sievi-Korte, O; Yaman, S",Tampere University; University of Helsinki; University of Jyvaskyla,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData52589.2021.9671737,20230520-160000,20230521-044735,"['managing', 'and', 'composing', 'teams', 'in', 'data', 'science:', 'an', 'empirical', 'study']",True,20230521-205332,,,,
575,wos,A Review and Future Direction of Business Analytics Project Delivery,"Business analytics is a core competency critical to organizations to stay competitive; however, many organizations are challenged at business analytics delivery, and these projects have a high rate of failure. The volume, variety, and velocity of the big data phenomenon and the lack of current methodologies for delivering business analytics projects are the primary challenges. Applying traditional information technology project methodologies is problematic and has been identified as the largest contributing factor for business analytics project failure. Business analytics projects focus on delivering data insights as well as software delivery. Agile methodologies focus on the ability to respond to change through incremental, iterative processes. Agile methodologies in software delivery have been on the rise, and the dynamic principles align with the discovery nature of business analytics projects. This article explores the big data phenomenon, its impact on business analytics project delivery, and recommends an agile framework for business analytic project delivery using agile methodology principles and practices.",Agile methodologies; Analytics projects; Big data; CRISP-DM; Agile software development,"Larson, D",,2019.0,ALIGNING BUSINESS STRATEGIES AND ANALYTICS: BRIDGING BETWEEN THEORY AND PRACTICE,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-319-93299-6_7,20230520-160000,20230521-044735,"['a', 'review', 'and', 'future', 'direction', 'of', 'business', 'analytics', 'project', 'delivery']",False,20230521-205332,,,,
576,wos,Big Data Analytics on Cyber Attack Graphs for Prioritizing Agile Security Requirements,"In enterprise environments, the amount of managed assets and vulnerabilities that can be exploited is staggering. Hackers' lateral movements between such assets generate a complex big data graph, that contains potential hacking paths. In this vision paper, we enumerate risk-reduction security requirements in large scale environments, then present the Agile Security methodology and technologies for detection, modeling, and constant prioritization of security requirements, agile style. Agile Security models different types of security requirements into the context of an attack graph, containing business process targets and critical assets identification, configuration items, and possible impacts of cyber-attacks. By simulating and analyzing virtual adversary attack paths toward cardinal assets, Agile Security examines the business impact on business processes and prioritizes surgical requirements. Thus, handling these requirements backlog that are constantly evaluated as an outcome of employing Agile Security, gradually increases system hardening, reduces business risks and informs the IT service desk or Security Operation Center what remediation action to perform next. Once remediated, Agile Security constantly recomputes residual risk, assessing risk increase by threat intelligence or infrastructure changes versus defender's remediation actions in order to drive overall attack surface reduction.",Security Requirements; Requirements Prioritization; Agile Security; Attack Graph; Graph Analytics; Attack Path; Remediation Requirements; Attack Surface; Cyber Digital Twin,"Hadar, E; Hassanzadeh, A",Accenture,2019.0,2019 27TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2019),IEEE COMPUTER SOC,,10.1109/RE.2019.00042,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'on', 'cyber', 'attack', 'graphs', 'for', 'prioritizing', 'agile', 'security', 'requirements']",True,20230521-205332,,,,
577,wos,Agile supply chain analytic approach: a case study combining agile and CRISP-DM in an end-to-end supply chain,"In the current competitive environment, Big Data Analytics (BDA) has become a prominent metric to reach an integrated, efficient, and effective supply chain (SC). In the literature, the BDA capabilities have been at the forefront of research in operational supply chain management (SCM), however, there has been a paucity of literature regarding its technical and organisational implementation in the industry. Hence, despite its capabilities and importance, many organisations are reluctant to adopt this promising concept in SC operations management, due to the ambiguity of its practical implementation from a technical and organisational point of view. To address this gap, this paper draws on agile project management, data mining model processing, and case study approaches to propose and test a framework for BDA organisational implementation in SCM. The feasibility of the proposed framework is illustrated and tested by a case study in an end-to-end SC within a large corporation. Our contribution lies in handling the organisational, managerial, and socio-technical challenges of BDA projects implementation in SCM.",Supply chain management; Big Data Analytics; agile methodology; CRISP-DM methodology; Scrum; project management,"Hamdani, FE; Quintero, IAQ; Enjolras, M; Camargo, M; Monticolo, D; Lelong, C",Universite de Lorraine,,SUPPLY CHAIN FORUM,TAYLOR & FRANCIS LTD,,10.1080/16258312.2022.2064721,20230520-160000,20230521-044735,"['agile', 'supply', 'chain', 'analytic', 'approach:', 'a', 'case', 'study', 'combining', 'agile', 'and', 'crisp-dm', 'in', 'an', 'end-to-end', 'supply', 'chain']",False,20230521-205332,,,,
578,wos,Big Data analytics in Agile software development: A systematic mapping study,"Context: Over the last decade, Agile methods have changed the software development process in an unparalleled way and with the increasing popularity of Big Data, optimizing development cycles through data analytics is becoming a commodity. Objective: Although a myriad of research exists on software analytics as well as on Agile software development (ASD) practice on itself, there exists no systematic overview of the research done on ASD from a data analytics perspective. Therefore, the objective of this work is to make progress by linking ASD with Big Data analytics (BDA). Method: As the primary method to find relevant literature on the topic, we performed manual search and snowballing on papers published between 2011 and 2019. Results: In total, 88 primary studies were selected and analyzed. Our results show that BDA is employed throughout the whole ASD lifecycle. The results reveal that data-driven software development is focused on the following areas: code repository analytics, defects/bug fixing, testing, project management analytics, and application usage analytics. Conclusions: As BDA and ASD are fast-developing areas, improving the productivity of software development teams is one of the most important objectives BDA is facing in the industry. This study provides scholars with information about the state of software analytics research and the current trends as well as applications in the business environment. Whereas, thanks to this literature review, practitioners should be able to understand better how to obtain actionable insights from their software artifacts and on which aspects of data analytics to focus when investing in such initiatives.",Agile software development; Software analytics; Data analytics; Machine learning; Artificial intelligence; Literature review,"Biesialska, K; Franch, X; Muntes-Mulero, V",Universitat Politecnica de Catalunya,2021.0,INFORMATION AND SOFTWARE TECHNOLOGY,ELSEVIER,,10.1016/j.infsof.2020.106448,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'in', 'agile', 'software', 'development:', 'a', 'systematic', 'mapping', 'study']",False,20230521-205332,,,,
579,wos,Agile Business Intelligence: Combining Big Data and Business Intelligence to Responsive Decision Model,"Big data and instant information on the external environment of enterprises are critical for decision-making; however, little attention is paid to contemporary business intelligence (BI) theories and practices. This study proposes a new business decision model, agile BI (ABI), which integrates external big data and internal BI to facilitate decision-making for enterprises in a dynamic and rapidly changing environment. This novel model presents two contributions to research in this field: (1) it proposes a new architecture combining external and internal information and (2) it integrates external big data, such as hot searches, social media, news, popular issues, and competitors' information, to increase the accuracy of BI. This study takes international expansion as an example and simulates the international investment decisions of Taiwanese firms by importing data from a search engine, competitors, and firm-specific datasets. The results show that the proposed ABI model not only responds quickly to the external environment but also enhances decision-making efficiently.",Big data; Business intelligence; Decision making,"Chang, BJ",Feng Chia University,2018.0,JOURNAL OF INTERNET TECHNOLOGY,"LIBRARY & INFORMATION CENTER, NAT DONG HWA UNIV",,10.3966/160792642018111906007,20230520-160000,20230521-044735,"['agile', 'business', 'intelligence:', 'combining', 'big', 'data', 'and', 'business', 'intelligence', 'to', 'responsive', 'decision', 'model']",True,20230521-205332,,,,
580,wos,Identifying the most Common Frameworks Data Science Teams Use to Structure and Coordinate their Projects,"This paper presents the results of a study focused on exploring which framework, if any, teams use to execute data science projects. The study consisted of a survey of 109 industry professionals, as well as an evaluation of relevant framework terms searched at Google. Overall, CRISP-DM was the most commonly used framework, with Scrum and Kanban being the second and third most frequently used. We note that CRISP-DM is a life cycle framework, whereas Scrum and Kanban are team coordination frameworks. Hence, this research also notes the potential demand for a framework that integrates both life cycle and team coordination aspects of leading a data science project.",Data Science; Big Data; Process Methodology,"Saltz, JS; Hotz, N",Syracuse University; Indiana University System; Indiana University Bloomington,2020.0,2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData50022.2020.9377813,20230520-160000,20230521-044735,"['identifying', 'the', 'most', 'common', 'frameworks', 'data', 'science', 'teams', 'use', 'to', 'structure', 'and', 'coordinate', 'their', 'projects']",True,20230521-205332,,,,
581,wos,DECIDE: An Agile event-and-data driven design methodology for decisional Big Data projects,"Decision making is the lifeblood of the enterprise - from the mundane to the strategically critical. However, the increasing deluge of data makes it more important than ever to understand and use it effectively in every context. Being data drivenis more aspiration than reality in most organizations due to the complexity, volume, variability and velocity of data streams from every customer and employee interaction. The purpose of this paper is to provide a flexible and adaptable methodology for governing, managing and applying data throughout the enterprise, called DECIDE.",Big Data; Methodology; Decisional systems; Agile; Data governance; Data quality,"Sfaxi, L; Ben Aissa, MM",Universite de Carthage; Universite de Carthage,2020.0,DATA & KNOWLEDGE ENGINEERING,ELSEVIER,,10.1016/j.datak.2020.101862,20230520-160000,20230521-044735,"['decide:', 'an', 'agile', 'event-and-data', 'driven', 'design', 'methodology', 'for', 'decisional', 'big', 'data', 'projects']",True,20230521-205332,,,,
582,wos,An Improved Agile Framework For Implementing Data Science Initiatives in the Government,"Implementing data mining projects in governmental organizations is emerging in the Middle East. The literature has been showing that there is a significant gap between the problems defined by the research in data mining and the problems in real world projects. The gap is to the level of semantics between the data scientists and the business users. Trying to fill this gap, we have developed an improved Agile data mining framework to fulfill the government business objectives and needs. The previous works had been claiming that handling such project is not yet mature in the region. For this an Agile implementation framework is required. We are also proposing a systematic way for identifying business problems as part of the framework. The process is Agile, so it would start from investigating the data set dimensions to identify business problems. It also allows early Business people cooperation with data scientist. We've applied the proposed framework in one of the Middle East government organizations. The business team and the data scientists have been showing their satisfaction regarding the results of using the proposed framework. The proposed framework have helped both business and data scientist to implement their first initiative in data mining. The proposed framework also helped in efficiently mapping the project with the core business objectives and problems using real world dataset.",data mining; data science; agile framework; business problems; business objectives,"Qadadeh, W; Abdallah, S",,2020.0,2020 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2020),IEEE COMPUTER SOC,,10.1109/ICICT50521.2020.00012,20230520-160000,20230521-044735,"['an', 'improved', 'agile', 'framework', 'for', 'implementing', 'data', 'science', 'initiatives', 'in', 'the', 'government']",True,20230521-205332,,,,
583,wos,"Big Data Analytics as a mediator in Lean, Agile, Resilient, and Green (LARG) practices effects on sustainable supply chains","The effect of big data on the lean, agile, resilient, and green (LARG) supply chain has not been explored much in the literature. This study investigates the role of 'Big Data Analytics' (BDA) as a mediator between 'sustainable supply chain business performance' and key factors, namely, lean practices, social practices, environmental practices, organisational practices, supply chain practices, financial practices, and total quality management. A sample of 297 responses from thirtyseven Indian manufacturing firms was collected. The paper is beneficial for managers and practitioners to understand supply chain analytics, and it addresses challenges in the management of LARG practices to contribute to a sustainable supply chain.",Big data analytics; Manufacturing firms; Supply chain and logistics management; LARG; Business performance and innovation; Sustainability,"Raut, RD; Mangla, SK; Narwane, VS; Dora, M; Liu, MQ",National Institute of Industrial Engineering (NITIE); University of Plymouth; Somaiya Vidyavihar University; K J Somaiya College of Engineering; Brunel University; Hunan University,2021.0,TRANSPORTATION RESEARCH PART E-LOGISTICS AND TRANSPORTATION REVIEW,PERGAMON-ELSEVIER SCIENCE LTD,,10.1016/j.tre.2020.102170,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'as', 'a', 'mediator', 'in', 'lean,', 'agile,', 'resilient,', 'and', 'green', '(larg)', 'practices', 'effects', 'on', 'sustainable', 'supply', 'chains']",True,20230521-205332,,,,
584,wos,How big data analytics use improves supply chain performance: considering the role of supply chain and information system strategies,"Purpose Drawing on the dynamic capabilities theory, this paper proposes that supply chain (SC) strategies (i.e. the lean SC and agile SC strategies) will mediate the relationship between big data analytics (BDA) and SC performance. Furthermore, from the perspective of strategic alignment, this study hypothesizes that the effect of the SC strategy on SC performance is differently moderated by the information system (IS) strategy (i.e. the IS innovator and IS conservative strategies). Design/methodology/approach This study used 159 match-paired questionnaires collected from Chinese firms to empirically test the hypotheses. Findings Results show the positive direct and indirect impact of BDA on SC performance. Specifically, the lean and agile SC strategies mediate the relationship between BDA and SC performance. Furthermore, the results indicate that the IS innovator and IS conservative strategies differentially moderate the effect of the lean and agile SC strategies on SC performance. Specifically, the IS innovator strategy positively moderates the effect of the agile SC strategy on SC performance. By contrast, the IS conservative strategy positively moderates the effect of the lean SC strategy on SC performance but negatively moderates the effect of the agile SC strategy on SC performance. Originality/value This study provides a comprehensive understanding of how SC and IS strategies can help firms leverage BDA to improve SC performance.",Big data analytics; Supply chain performance; Lean supply chain strategy; Agile supply chain strategy; IS innovator Strategy; IS conservative Strategy,"Wei, SB; Yin, JM; Chen, W","Hefei University of Technology; Nanjing University of Aeronautics & Astronautics; Chinese Academy of Sciences; University of Science & Technology of China, CAS",2022.0,INTERNATIONAL JOURNAL OF LOGISTICS MANAGEMENT,EMERALD GROUP PUBLISHING LTD,,10.1108/IJLM-06-2020-0255,20230520-160000,20230521-044735,"['how', 'big', 'data', 'analytics', 'use', 'improves', 'supply', 'chain', 'performance:', 'considering', 'the', 'role', 'of', 'supply', 'chain', 'and', 'information', 'system', 'strategies']",True,20230521-205332,,,,
585,wos,IoT Analytics and Agile Optimization for Solving Dynamic Team Orienteering Problems with Mandatory Visits,"Transport activities and citizen mobility have a deep impact on enlarged smart cities. By analyzing Big Data streams generated through Internet of Things (IoT) devices, this paper aims to show the efficiency of using IoT analytics, as an agile optimization input for solving real-time problems in smart cities. IoT analytics has become the main core of large-scale Internet applications, however, its utilization in optimization approaches for real-time configuration and dynamic conditions of a smart city has been less discussed. The challenging research topic is how to reach real-time IoT analytics for use in optimization approaches. In this paper, we consider integrating IoT analytics into agile optimization problems. A realistic waste collection problem is modeled as a dynamic team orienteering problem with mandatory visits. Open data repositories from smart cities are used for extracting the IoT analytics to achieve maximum advantage under the city environment condition. Our developed methodology allows us to process real-time information gathered from IoT systems in order to optimize the vehicle routing decision under dynamic changes of the traffic environments. A series of computational experiments is provided in order to illustrate our approach and discuss its effectiveness. In these experiments, a traditional static approach is compared against a dynamic one. In the former, the solution is calculated only once at the beginning, while in the latter, the solution is re-calculated periodically as new data are obtained. The results of the experiments clearly show that our proposed dynamic approach outperforms the static one in terms of rewards.",IoT analytics; big data streams; agile optimization; smart cities; transport analytics; dynamic team orienteering problem,"Li, YD; Peyman, M; Panadero, J; Juan, AA; Xhafa, F",UOC Universitat Oberta de Catalunya; Universitat Politecnica de Valencia; Universitat Politecnica de Catalunya,2022.0,MATHEMATICS,MDPI,,10.3390/math10060982,20230520-160000,20230521-044735,"['iot', 'analytics', 'and', 'agile', 'optimization', 'for', 'solving', 'dynamic', 'team', 'orienteering', 'problems', 'with', 'mandatory', 'visits']",True,20230521-205332,,,,
586,wos,Analysis of Software Engineering for Agile Machine Learning Projects,"The number of machine learning, artificial intelligence or data science related software engineering projects using Agile methodology is increasing. However, there are very few studies on how such projects work in practice. In this paper, we analyze project issues tracking data taken from Scrum (a popular tool for Agile) for several machine learning projects. We compare this data with corresponding data from non-machine learning projects, in an attempt to analyze how machine learning projects are executed differently from normal software engineering projects. On analysis, we find that machine learning project issues use different kinds of words to describe issues, have higher number of exploratory or research oriented tasks as compared to implementation tasks, and have a higher number of issues in the product backlog after each sprint, denoting that it is more difficult to estimate the duration of machine learning project related tasks in advance. After analyzing this data, we propose a few ways in which Agile machine learning projects can be better logged and executed, given their differences with normal software engineering projects.",scrum; machine learning project; software engineering; agile methodology,"Singla, K; Bose, J; Naik, C",,2018.0,IEEE INDICON: 15TH IEEE INDIA COUNCIL INTERNATIONAL CONFERENCE,IEEE,,,20230520-160000,20230521-044735,"['analysis', 'of', 'software', 'engineering', 'for', 'agile', 'machine', 'learning', 'projects']",True,20230521-205332,,,,
587,wos,Using a coach to improve team performance when the team uses a Kanban process methodology,"Teams are increasing their use of the Kanban process methodology across a range of information system projects, including software development and data science projects. While the use of Kanban is growing, little has been done to explore how to improve team performance for teams that use Kanban. One possibility is to introduce a Kanban Coach (KC). This work reports on exploring the use of a Kanban Coach, with respect to both how the coach could interact with the team as well as how the use of a coach impacts team results. Specifically, this paper reports on an experiment where teams either had, or did not have, a Kanban Coach. A quantitative and qualitative analysis of the data collected during the experiment found that introducing KC led to significant improvement of team performance. Coordination Theory and Shared Mental Models were then employed to provide an explanation as to why a KC leads to better project results. While this experiment was done within a data science project context, the results are likely applicable across a range of information system projects.",project management; process methodology; agile; team performance; Kanban; Kanban process methodology,"Shamshurin, I; Saltz, JS",Syracuse University,2019.0,IJISPM-INTERNATIONAL JOURNAL OF INFORMATION SYSTEMS AND PROJECT MANAGEMENT,SCIKA,,10.12821/ijispm070204,20230520-160000,20230521-044735,"['using', 'a', 'coach', 'to', 'improve', 'team', 'performance', 'when', 'the', 'team', 'uses', 'a', 'kanban', 'process', 'methodology']",True,20230521-205332,,,,
588,wos,Identifying and Addressing 6 Key Questions when Using Data Driven Scrum,"Data Driven Scrum (DDS) enables lean data science project agility and addresses the key challenges that have been identified when using Scrum in a data science context. However, little has been written with respect to the questions or challenges teams might encounter when trying to use DDS. Based on a survey of 18 team leads trying to use DDS, this paper describes six common questions teams might encounter when trying to implement DDS, as well as how to address these challenges.",,"Saltz, JS; Sutherland, A; Jombart, T",Syracuse University; University of London; London School of Hygiene & Tropical Medicine,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData52589.2021.9671930,20230520-160000,20230521-044735,"['identifying', 'and', 'addressing', '6', 'key', 'questions', 'when', 'using', 'data', 'driven', 'scrum']",True,20230521-205332,,,,
589,wos,"CRISP-DM for Data Science: Strengths, Weaknesses and Potential Next Steps","This paper explores the strengths and weaknesses of CRISP-DM when used for data science projects. The paper then explores what key actions data science teams using CRISP-DM should consider that addresses CRISP-DM's weaknesses. In brief, CRISP-DM, which is the most popular framework teams use to execute data science projects, provides an easy to understand description of the data science project workflow (i.e., the data science life cycle). However, CRISP-DM's project phases miss some key aspects of the data science project life cycle. In addition, CRISP-DM's task-focused approach fails to address how a team should prioritize tasks, and in general, collaborate and communicate. Hence, this paper also describes how CRISP-DM could be combined with a team coordination framework, such as Scrum or Data Driven Scrum, which is a newer collaboration framework developed to address the unique data science coordination challenges.",,"Saltz, JS",Syracuse University,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData52589.2021.9671634,20230520-160000,20230521-044735,"['crisp-dm', 'for', 'data', 'science:', 'strengths,', 'weaknesses', 'and', 'potential', 'next', 'steps']",True,20230521-205332,,,,
590,wos,Integration of Lean practices and Industry 4.0 technologies: smart manufacturing for next-generation enterprises,"Industry 4.0 technologies have attempted to transform current industrial settings to a level that we have never seen before. While at the same time, prevailing applications of Lean tools and techniques over the last 20 years have already dramatically reduced wastes ranging from shop floor production to cross-functional enterprise processes. This paper aims to provide a comprehensive review and report on links between Lean tools and Industry 4.0 technologies, and on how simultaneous implementation of these two paradigms affects the operational performance of factories. The existing and potential enhancements of Lean practices enabled by Industry 4.0 technologies such as wireless networks, big data, cloud computing, and virtual reality (VR) will also be explored. A cloud-based Kanban decision support system is also presented as a real-world demonstrator for integration of an Industry 4.0 technology (cloud computing) and a major Lean tool (Kanban).",Industry 4; 0; Lean tools; Smart factory; Cloud Kanban,"Shahin, M; Chen, FF; Bouzary, H; Krishnaiyer, K",University of Texas System; University of Texas at San Antonio (UTSA),2020.0,INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,SPRINGER LONDON LTD,,10.1007/s00170-020-05124-0,20230520-160000,20230521-044735,"['integration', 'of', 'lean', 'practices', 'and', 'industry', '4.0', 'technologies:', 'smart', 'manufacturing', 'for', 'next-generation', 'enterprises']",True,20230521-205332,,,,
591,wos,Data science roadmapping: An architectural framework for facilitating transformation towards a data-driven organization,"Leveraging data science can enable businesses to exploit data for competitive advantage by generating valuable insights. However, many industries cannot effectively incorporate data science into their business processes, as there is no comprehensive approach that allows strategic planning for organization-wide data science efforts and data assets. Accordingly, this study explores the Data Science Roadmapping (DSR) to guide organizations in aligning their business strategies with data-related, technological, and organizational resources. The proposed approach is built on the widely adopted technology roadmapping framework and customizes its context, architecture, and process by synthesizing data science, big data, and data-driven organization literature. Based on industry collaborations, the framework provides a hybrid and agile methodology comprising the recommended steps. We applied DSR with a research group with sector experience to create a comprehensive data science roadmap to validate and refine the framework. The results indicate that the framework facilitates DSR initiatives by creating a comprehensive roadmap capturing strategy, data, technology, and organizational perspectives. The contemporary literature illustrates prebuilt roadmaps to help businesses become data-driven. However, becoming data-driven also necessitates significant social change toward openness and trust. The DSR initiative can facilitate this social change by opening communication channels, aligning perspectives, and generating consensus among stakeholders.",Technology roadmapping; Technology management; Data science; Digital transformation; Data-driven organization; Big data,"Kayabay, K; Gokalp, MO; Gokalp, E; Eren, PE; Kocyigit, A",Middle East Technical University; Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK); RLUK- Research Libraries UK; University of Cambridge; Hacettepe University,2022.0,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,ELSEVIER SCIENCE INC,,10.1016/j.techfore.2021.121264,20230520-160000,20230521-044735,"['data', 'science', 'roadmapping:', 'an', 'architectural', 'framework', 'for', 'facilitating', 'transformation', 'towards', 'a', 'data-driven', 'organization']",True,20230521-205332,,,,
592,wos,Literature Review on Big Data Analytics and Demand Modeling in Supply Chain,"New digital technologies have been introduced into our business and social environments, causing a major change that is recognized as the digital transformation in recent years. While environmental shifts suggest that most of the organization starts using advanced technologies such as Internet of Things (IoT), Mobile applications, Blackchain, Intelligence Things, catboats and many more in their supply chain planning to gain an early competitive advantage and these technologies generates enormous amount of data that the traditional business intelligence system difficult to handle processing of vast data in real-time or nearly real time causes abstraction to the insight discovery, demand modeling and supply chain optimization, Big Data initiatives for demand modeling and supply chain optimization promise to answer these challenges by incorporating various services, methods and tools for more agile and adaptably analytics and decision making, there by this paper focus on reviewing the level of analytics and the forecasting methods being used in the supply chain, understating the fundamentals of supply chain and role of demand modeling, there by proposing a high level framework for supply chain analytics in the context of big data with the knowledge of data science, artificial intelligence, big data echo system and supply chain.",Supply chain; Demand modeling; Big data Analytics; Forecasting methods; supply chain framework,"Kumar, TP; Manjunath, TN; Hegadi, RS",Solapur University,2018.0,"2018 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT - 2018)",IEEE,,,20230520-160000,20230521-044735,"['literature', 'review', 'on', 'big', 'data', 'analytics', 'and', 'demand', 'modeling', 'in', 'supply', 'chain']",True,20230521-205332,,,,
593,wos,"The application framework of big data technology in the COVID-19 epidemic emergency management in local government-a case study of Hainan Province, China","Background As COVID-19 continues to spread globally, traditional emergency management measures are facing many practical limitations. The application of big data analysis technology provides an opportunity for local governments to conduct the COVID-19 epidemic emergency management more scientifically. The present study, based on emergency management lifecycle theory, includes a comprehensive analysis of the application framework of China's SARS epidemic emergency management lacked the support of big data technology in 2003. In contrast, this study first proposes a more agile and efficient application framework, supported by big data technology, for the COVID-19 epidemic emergency management and then analyses the differences between the two frameworks. Methods This study takes Hainan Province, China as its case study by using a file content analysis and semistructured interviews to systematically comprehend the strategy and mechanism of Hainan's application of big data technology in its COVID-19 epidemic emergency management. Results Hainan Province adopted big data technology during the four stages, i.e., migration, preparedness, response, and recovery, of its COVID-19 epidemic emergency management. Hainan Province developed advanced big data management mechanisms and technologies for practical epidemic emergency management, thereby verifying the feasibility and value of the big data technology application framework we propose. Conclusions This study provides empirical evidence for certain aspects of the theory, mechanism, and technology for local governments in different countries and regions to apply, in a precise, agile, and evidence-based manner, big data technology in their formulations of comprehensive COVID-19 epidemic emergency management strategies.",COVID-19; Emergency management; Big data technology; Application framework; Local government; Hainan Province; China,"Mao, ZJ; Zou, Q; Yao, H; Wu, JY",Huazhong University of Science & Technology; Huazhong University of Science & Technology,2021.0,BMC PUBLIC HEALTH,BMC,,10.1186/s12889-021-12065-0,20230520-160000,20230521-044735,"['the', 'application', 'framework', 'of', 'big', 'data', 'technology', 'in', 'the', 'covid-19', 'epidemic', 'emergency', 'management', 'in', 'local', 'government-a', 'case', 'study', 'of', 'hainan', 'province,', 'china']",True,20230521-205332,,,,
594,wos,Reframing business reporting in a Big Data world,"This paper investigates the challenges raised by the datafication of the business environment in the area of performance management. Big Data and its powerful analytics are now essential elements of the business landscape, and the mindset of managers and decision-makers has a crucial impact on how the opportunities offered by these new technologies can be capitalised. Our focus is on how and to what extent business performance management models need to be reviewed and reframed in this era of Big Data. We propose a model, called Balanced ScoreCard System Thinking, that may insure an integrative, highly dynamic and agile construction. This top-down-bottom-up approach assess the way in which every segment of the Balance Score Card is affected by Big Data and Business Analytics. These findings may enable business leaders to develop a more agile and forward-looking approach to performance management, which is only made possible through these new technologies of data analytics.",Business reporting; Big Data; Business Analytics; Balanced Scorecard; System Thinking; Drivers,"Dutescu, A; Pugna, IB; Stanila, GO",Bucharest University of Economic Studies,2019.0,PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BUSINESS EXCELLENCE,SCIENDO,,10.2478/picbe-2019-0062,20230520-160000,20230521-044735,"['reframing', 'business', 'reporting', 'in', 'a', 'big', 'data', 'world']",False,20230521-205332,,,,
595,wos,Agile Construction of Data Science DSLs (Tool Demo),"Domain Specific Languages (DSLs) have proven useful in the domain of data science, as witnessed by the popularity of SQL. However, implementing and maintaining a DSL incurs a significant effort which limits their utility in context of fast-changing data science frameworks and libraries. We propose an approach and a Python-based library/tool NLDSL which simplifies and streamlines implementation of DSLs modeling pipelines of operations. In particular, syntax description and operation implementation are bundled together as annotated and terse Python functions, which simplifies extending and maintaining a DSL. To support ad hoc DSL elements, NLDSL offers a mechanism to define DSL-level functions as first-class DSL elements. Our tool automatically supports each DSL by code completions and in-editor documentation in a multitude of IDEs implementing the Microsoft's Language Server Protocol. To circumvent the problem of a limited expressiveness of a external DSL, our tool allows embedding DSL statements in the source code comments of a general purpose language and to translate the DSL to such a language during editing. We demonstrate and evaluate our approach and tool by implementing a DSL for data tables which is translated to either Pandas or to PySpark code. A preliminary evaluation shows that this DSL can be defined in a concise and maintainable way, and that it can cover a majority of processing steps of popular Spark/Pandas tutorials.",DSL development; Code generation; Assisted editing and IntelliSense; Data analysis frameworks; Apache Spark; Python Pandas,"Andrzejak, A; Kiefer, K; Costa, DE; Wenz, O",Ruprecht Karls University Heidelberg,2019.0,PROCEEDINGS OF THE 18TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON GENERATIVE PROGRAMMING: CONCEPTS AND EXPERIENCES (GPCE '19),ASSOC COMPUTING MACHINERY,,10.1145/3357765.3359516,20230520-160000,20230521-044735,"['agile', 'construction', 'of', 'data', 'science', 'dsls', '(tool', 'demo)']",True,20230521-205332,,,,
596,wos,Big data analytics capability and co-innovation: An empirical study,"There are numerous emerging studies addressing big data and its application in different organizational aspects, especially regarding its impact on the business innovation process. This study in particular aims at analyzing the existing relationship between Big Data Analytics Capabilities and Co-innovation. To test the hypothesis model, structural equations by the partial least squares method were used in a sample of 112 Colombian firms. The main findings allow to positively relate Big Data Analytics Capabilities with better and more agile processes of product and service co-creation and with more robust collaboration networks with stakeholders internal and external to the firm.",Business; Economics; Information science; Big data analytics capabilities; Co-innovation; Big data; Co-creation,"Lozada, N; Arias-Perez, J; Perdomo-Charry, G",Universidad de Antioquia,2019.0,HELIYON,ELSEVIER SCI LTD,,10.1016/j.heliyon.2019.e02541,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'capability', 'and', 'co-innovation:', 'an', 'empirical', 'study']",True,20230521-205332,,,,
597,wos,Agile manufacturing: an evolutionary review of practices,"Academics and practitioners have long acknowledged the importance of agile manufacturing and related supply chains in achieving firm sustainable competitiveness. However, limited, if any, research has focused on the evolution of practices within agile manufacturing supply chains and how these are related to competitive performance objectives. To address this gap, we reviewed the literature on an agile manufacturing drawing on the evolution of manufacturing agility, attributes of agile manufacturing, the drivers of agile manufacturing, and the identification of the enabling competencies deployable for agile manufacturing. Our thesis is that agile manufacturing is at the centre of achieving a sustainable competitive advantage, especially in light of current unprecedented market instability coupled with complex customer requirements. In this regard, the emphasis which agile manufacturing places on responsive adaptability would counter the destabilising influence of competitive pressures on organisations performance criteria. We have identified five enabling competencies as the agility enablers and practices of agile manufacturing, that is, transparent customisation, agile supply chains, intelligent automation, total employee empowerment and technology integration, and further explored their joint deployment to create positive multiplier effects. Future research directions were also provided with respect to the operationalisation of the five identified enablers and the potential for emergent technologies of big data, blockchain, and Internet of Things to shape future agile manufacturing practices.",agile manufacturing; supply chain management; practices; competitive advantage,"Gunasekaran, A; Yusuf, YY; Adeleye, EO; Papadopoulos, T; Kovvuri, D; Geyi, DG",California State University System; California State University Bakersfield; University of Central Lancashire; University of Kent,2019.0,INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH,TAYLOR & FRANCIS LTD,,10.1080/00207543.2018.1530478,20230520-160000,20230521-044735,"['agile', 'manufacturing:', 'an', 'evolutionary', 'review', 'of', 'practices']",False,20230521-205332,,,,
598,wos,Towards the Automation of Industrial Data Science: A Meta-learning based Approach,"In context of the fourth industrial revolution (industry 4.0), the industrial big data is subject to grow rapidly to respond the agile industrial computing and manufacturing technologies. This data evolution can be captured using ubiquitous integrated sensors and multiple smart machines. We believe the use of data science methodologies, for the selection of models and configuration of hyper-parameters, may help to better control such data evolution. But, at the same time, the industrial practitioners and researchers often lack machine-learning expertise to directly retrieve the benefit from valuable manufacturing big data. Such a lack poses the major obstacle to yield value from even-though familiar data. In this case, a collaboration with data scientists may become an exigence along with the extensive machine learning knowledge which presumably may result to pursue further delays and effort. Multiple approaches for automating machine learning (AutoML) have been proposed for the past recent years in order to alleviate this deficiency. These approaches are expected to perform better along with accomplishment of computing resources which are mostly not readily accessible. To address this research challenge, in this paper, we propose a meta-learning based approach that may serve an effective decision support system for the AutoML process.",Automated Machine Learning; Manufacturing Big Data; Industry 4.0; Industrial Data Science; Meta-learning,"Garouani, M; Ahmad, A; Bouneffa, M; Lewandowski, A; Bourguin, G; Hamlich, M",Universite du Littoral-Cote-d'Opale; Hassan II University of Casablanca,2021.0,"PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2021), VOL 1",SCITEPRESS,,10.5220/0010457107090716,20230520-160000,20230521-044735,"['towards', 'the', 'automation', 'of', 'industrial', 'data', 'science:', 'a', 'meta-learning', 'based', 'approach']",True,20230521-205332,,,,
599,wos,Ambidextrous organization and agility in big data era: The role of business process management systems,"Purpose The purpose of this paper is to explore the effect of big data analytics-capable business process management systems (BDA-capable BPMS) on ambidextrous organizations' agility. In particular, how the functionalities of BDA-capable BPMS may improve organizational dynamism and reactiveness to challenges of Big Data era will be explored. Design/methodology/approach A theoretical analysis of the potential of BDA-capable BPMS in increasing organizational agility, with particular attention to the ambidextrous organizations, has been performed. A conceptual framework was subsequently developed. Next, the proposed conceptual framework was applied in a real-world context. Findings The research proposes a framework highlighting the importance of BDA-capable BPMS in increasing ambidextrous organizations' agility. Moreover, the authors apply the framework to the cases of consumer-goods companies that have included BDA in their processes management. Research limitations/implications The principal limitations are linked to the need to validate quantitatively the proposed framework. Practical implications The value of the proposed framework is related to its potential in helping managers to fully understand and exploit the potentiality of BDA-capable BPMS. Moreover, the implications show some guidelines to ease the implementation of such systems within ambidextrous organizations. Originality/value The research offers a model to interpret the effects of BDA-capable BPMS on ambidextrous organizations' agility. In this way, the research addresses a significant gap by exploring the importance of information systems for ambidextrous organizations' agility.",Information systems; Big data; Agile; Agility; Ambidexterity,"Rialti, R; Marzi, G; Silic, M; Ciappei, C",University of Pisa; University of Florence,2018.0,BUSINESS PROCESS MANAGEMENT JOURNAL,EMERALD GROUP PUBLISHING LTD,,10.1108/BPMJ-07-2017-0210,20230520-160000,20230521-044735,"['ambidextrous', 'organization', 'and', 'agility', 'in', 'big', 'data', 'era:', 'the', 'role', 'of', 'business', 'process', 'management', 'systems']",True,20230521-205332,,,,
600,wos,"Big Data Hysteria, Cognizance and Scope","In real time scenario, every second man and machine have been generating a huge amount of data. Social networking sites like Facebook, tweeter, Instagram, search engine google, yahoo and video shearing websites like YouTube and many real time applications generates enormous quantity of data. These data-sets have different attributes (i.e. volume, velocity, complexity etc.) in it, known as `Big Data'. To manage, process and analyze big data, we require advance hardware platform, software stack and analytics techniques. Big data Analytics emerges as a major application for future data-sets, generating by parallel and distributes systems. This paper has discussed about hype on Big Data, its characteristics, different considerations (i.e. Hardware, Software, Platform, NoSql Data Base, Languages). It has summarized the Techniques of Big Data and light up on scope with other technologies (i.e. IoT, Agile, Lean Six Sigma).",Big Data; Volume; Inherent properties; Big Data Management; Analytics techniques,"Harsh, R; Acharya, G; Chaudhary, S",,2018.0,2018 4TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT),IEEE,,,20230520-160000,20230521-044735,"['big', 'data', 'hysteria,', 'cognizance', 'and', 'scope']",True,20230521-205332,,,,
601,wos,Panel: Addressing the Shortage of Big Data Skills with Inter-Disciplinary Big Data Curriculum,"One major challenge faced by enterprises in contemporary era is the shortage of big data and analytics (BDA) professionals. These professionals possess skills to analyze and derive intelligence from big data generated by enterprises. Currently, universities and colleges have not been able to produce sufficient professionals to meet the ever-growing demand for data analytics skill sets. A possible reason for this may be the narrow focus and lack of interdisciplinary approach to big data analytics education. To address this challenge, this panel brings together practitioners, researchers and educators in big data and analytics; to explore the potentials for developing an interdisciplinary curriculum that will deliver data analytics skills to students across all other academic majors. This might help to produce more agile data analytics professionals and close the gap between demand and supply of those professionals.",Analytics; Big Data; Education; Curriculum,"Nwokeji, JC; Stachel, R; Holmes, T; Aglan, F; Udenze, EC; Orji, R",Gannon University; Gannon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Dalhousie University,2019.0,2019 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2019),IEEE,,,20230520-160000,20230521-044735,"['panel:', 'addressing', 'the', 'shortage', 'of', 'big', 'data', 'skills', 'with', 'inter-disciplinary', 'big', 'data', 'curriculum']",True,20230521-205332,,,,
602,wos,Decision Making Analysis in Corporate Sectors Using the Concept of Big Data Analytics,"Big data Analytics is one of the most common technology used by all kind of Organisations Worldwide. It has become a huge problem for all the organisations to store and process the massive data gathered. The main function of big data analytics is to collect, store, examine large amount of data to find the unseen patterns and unknown interrelationships according to the organisations requirement. In this internet era, the data is collected continuously and densely from multiple resources in every department of the organisations. The decision makers requires new methods and techniques to understand and analyse the massive data adequately before taking agile decisions. The achievement of the top management in taking strategic decisions depends on the characteristics of the information used. In this paper the role of big data analytics in decision making, theoretical framework of big data analytics, applications of big data analytics and decisions to data quadrants are discussed.",Big data analytics; Decision making; Structured and unstructured data; Structured and unstructured decisions,"Sheshasaayee, A; Bhargavi, K",,2019.0,"INTERNATIONAL CONFERENCE ON INTELLIGENT DATA COMMUNICATION TECHNOLOGIES AND INTERNET OF THINGS, ICICI 2018",SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-030-03146-6_55,20230520-160000,20230521-044735,"['decision', 'making', 'analysis', 'in', 'corporate', 'sectors', 'using', 'the', 'concept', 'of', 'big', 'data', 'analytics']",False,20230521-205332,,,,
603,wos,A framework to Data Delivery Security for Big Data Annotation Delivery System,"Big data annotation plays an important role in Artificial Intelligence model training. The proliferation of data annotation tasks has brought the issue of security of the big data delivery. This work identifies the security framework associated with encryption and compression procedures that support data delivery safety. In this paper, we propose an agile framework that caters to various types of data under RESTful web services. All the procedures are automatically operated by the server without human intervention. This work assists the company delivers the tagged data products to users with a high-security level avoiding the risk of information disclosure.",Big data; compression; encryption; lightweight framework; data delivery,"Yang, YH; He, HL; Wang, DL; Ding, ZX",,2018.0,2018 IEEE 15TH INTERNATIONAL CONFERENCE ON MOBILE AD HOC AND SENSOR SYSTEMS (MASS),IEEE,,10.1109/MASS.2018.00082,20230520-160000,20230521-044735,"['a', 'framework', 'to', 'data', 'delivery', 'security', 'for', 'big', 'data', 'annotation', 'delivery', 'system']",True,20230521-205332,,,,
604,wos,Intelligent ERP for SCM agility and graph theory technique for adaptation in automotive industry in India,"A supply chain's performance is determined by its capacity to stay market-sensitive while maintaining network integration. The challenges in remaining market sensitive are in designing, analyzing, and maintaining a supply chain to its optimum performance where a few strategic aspects of supply chain control the entire processes. With the emergence of the new business era of Big Data Analytics and its interoperability with ERP as an effective Business Intelligence tool I-ERP (Intelligent ERP) that ensures agility of supply chain as one of its primary qualities for expanding market share and maintaining survival is becoming a need in the volatile and complex supply chain network. The emphasis now is on adaptability of ERP with Big Data Analytics such as Machine Learning and Predictive analysis technique in the supply chain in Automotive industry in India by addressing manufacturing/business needs proactively. This paper is to identify the factors that contribute for the supply chain management to remain agile within the automotive industry through empirical data and an attempt has been made to comprehend the ability of SCM to remain agile with the interoperability between Big Data Analytics and ERP through a review of the literature. Identify the challenges in implementing the interoperability and propose technique based on graph theory for future research, IT and supply chain managers consideration.",Supply chain management; Big data analytics; Intelligent-ERP; Agility,"Jayender, P; Kundu, GK",Vellore Institute of Technology (VIT); VIT Vellore,,INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT,SPRINGER INDIA,,10.1007/s13198-021-01361-y,20230520-160000,20230521-044735,"['intelligent', 'erp', 'for', 'scm', 'agility', 'and', 'graph', 'theory', 'technique', 'for', 'adaptation', 'in', 'automotive', 'industry', 'in', 'india']",False,20230521-205332,,,,
605,wos,Open Data Lake to Support Machine Learning on Arctic Big Data,"The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data.",big data; data management; data lake; open data; reusability; FAIR principle; CARE principle; Arctic data; Arctic expedition; machine learning; data mining,"Olawoyin, AM; Leung, CK; Cuzzocrea, A",University of Manitoba; University of Calabria,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData52589.2021.9671453,20230520-160000,20230521-044735,"['open', 'data', 'lake', 'to', 'support', 'machine', 'learning', 'on', 'arctic', 'big', 'data']",True,20230521-205332,,,,
606,wos,The Era of Big Data and Path towards Sustainability,"This paper is an attempt to throw light on the applications of big data analytics in nurturing sustainable develoment through a descriptive tnetadata study. Big data is widely used in many areas such as hospitality, transporataion, health, governance, e-commerce etc. Common applications of big data include consumer profiling, personalised pricing, marketing, advertising and predictive analysis. One of the formidable challanges confronted by the businesses in the contemporary period is to reconcile the conflicting interests of profit maximisation and fostering sustainability. The unprecedented magnitude of data generated within the organisations do have the potential to bring gainful insights for efficient resource utilisation and waste minimisation. The advent of big data aids in making these conflicting interests complementary by providing efficient and precise predicitions. .A number of studies are going on to explore possible options avialable to leverage big data analytics to create social and environmental value. Novel analytical approaches, enormous amounts of data and new technology would help in gaining insights to frame more agile and efficient policies to protect the environment. This paper discusses how big data is applied in different areas to foster sustainability.",Big data; Sustainability; Gartner's model,"Victor, V; Maria, FF",Hungarian University of Agriculture & Life Sciences,2018.0,"INNOVATION MANAGEMENT AND EDUCATION EXCELLENCE THROUGH VISION 2020, VOLS I -XI",INT BUSINESS INFORMATION MANAGEMENT ASSOC-IBIMA,,,20230520-160000,20230521-044735,"['the', 'era', 'of', 'big', 'data', 'and', 'path', 'towards', 'sustainability']",True,20230521-205332,,,,
607,wos,The future of Artificial Intelligence for the BioTech Big Data landscape,"Recent Industry 4.0 advancements are making available massive amounts of data for the development of innovative BioTech solutions. However, several challenges need to be overcome to correctly use data and novel, non-pharma technologies to greatly speed up discovery, optimization and market delivery of products, and services. In this review, we bring your attention to the important aspects of Big Data and Artificial Intelligence (Al) that have an impact on the future of the field and briefly touch upon how disciplines such as Hyper-Automation, Infrastructure as Code (laC) and DevOps - a set of practices that combines software development with Information Technology (IT) operations (Ops) - can accelerate Big Data and Al adoption in your Agile Digital Transformation journey.",,"Artico, F; Edge, AL; Langham, K",GlaxoSmithKline; AstraZeneca; Medimmune,2022.0,CURRENT OPINION IN BIOTECHNOLOGY,ELSEVIER SCI LTD,,10.1016/j.copbio.2022.102714,20230520-160000,20230521-044735,"['the', 'future', 'of', 'artificial', 'intelligence', 'for', 'the', 'biotech', 'big', 'data', 'landscape']",False,20230521-205332,,,,
608,wos,Batch-based agile program management approach for coordinating IT multi-project concurrent development,"Software development projects have undergone remarkable changes with the arrival of agile development approaches. Many firms are facing a need to use these approaches to manage entities consisting of multiple projects (i.e. programs) simultaneously and efficiently. New technologies such as big data provide a huge power and rich demand for the IT application system of the commercial bank which has the characteristics of multiple sub-projects, strong inter-project correlation, and numerous project participating teams. Hence, taking the IT program management of a bank in China as a case, we explore the methods to solve the problems in multi-project concurrent development practice through integrating the ideas of program and batch management. First, to coordinate the multi-project development process, this paper presents the batch-based agile program management approach that synthesizes concurrent engineering with agile methods. And we compare the application of batch management between software development projects and manufacturing process. Further, we analyze the concurrent multi-project development practice in the batch-based agile program management, including the overlapping between stages, individual project's activities, and multiple projects based on common resources and environment to stimulate the knowledge transfer. Third, to facilitate the communication and coordination of batch-based program management, we present the double-level responsibility organizational structure of batch management.",software development project; program management; batch management; coordination; multi-project management; banking industry,"Yang, Q; Bi, YX; Wang, QR; Yao, T",University of Science & Technology Beijing,2021.0,CONCURRENT ENGINEERING-RESEARCH AND APPLICATIONS,SAGE PUBLICATIONS LTD,,10.1177/1063293X211015236,20230520-160000,20230521-044735,"['batch-based', 'agile', 'program', 'management', 'approach', 'for', 'coordinating', 'it', 'multi-project', 'concurrent', 'development']",True,20230521-205332,,,,
609,wos,What Are the Critical Success Factors for Agile Analytics Projects?,"To get value from BI (Business Intelligence) and Big Data initiatives, organizations need to develop the capability to successfully execute their analytics projects. Via updating Chow and Cao's list of 12 success factors for agile projects, 43 attributes of these potential critical success factors (CSFs) were identified. Data from four case studies of analytics projects suggest that the critical success factors for analytics projects may be Strong Customer Involvement and a Methodical Project Definition Process.",Analytics projects; agile projects; agile project management; project success factors,"Tsoy, M; Staples, DS",Queens University - Canada,2021.0,INFORMATION SYSTEMS MANAGEMENT,TAYLOR & FRANCIS INC,,10.1080/10580530.2020.1818899,20230520-160000,20230521-044735,"['what', 'are', 'the', 'critical', 'success', 'factors', 'for', 'agile', 'analytics', 'projects?']",True,20230521-205332,,,,
610,wos,Discover the Digital Technology Application in Fashion Business Models,"In the last few decades, there has been a surge of interest in the development of fashion business models to assist fashion companies in reducing cost and to efficiently manage the business processes. These business models are developed to manage the internal operations within the company through adopting complex formulae and algorithms to reduce waste at each procedure. However in today's fashion business market, global sourcing and global corporation are much more important than before. The relationship between the fashion company and its suppliers, the relationship between the fashion company and its customers, and the management of these relationships: all of them are critical components of an effective business strategy. The competition between fashion companies is no longer on a company level but instead is subjected to supply chain versus supply chain. Trying to take the massive information into consideration by using traditional digital technology is not a wise decision when developing business strategy. On further thinking, the information flow through the supply chain has the same characteristics 5Vs as big data: Volume, Velocity, Variety, Value and Veracity. In other words, the management of information flow in supply chain is the management of big data. There is no doubt that digital technology under the big data environment will fundamentally change the whole supply chain. The first objective of this paper is to identify the key weakness of lean and agile logistic supply chain models in literature. The second objective is to point out the technological challenges in developing Tomorrow's models to build an agile response with a lean platform: How to set up virtual networks from the early designing stage to the last consuming and feedback stage? How to set up the information standardization and synchronisation process in the system? How to specify the consumer requirements in fitting effects and functional performance of garments? The last objective is to discover the digital technology under big data environment which will enable the information to efficiently flow through the whole supply chain.",Business Model; Supply Chain Logistic; Big Data; Information Flow Management; Digital Technology,"Liu, ZC; Li, Y; Wang, YY",N8 Research Partnership; RLUK- Research Libraries UK; University of Manchester,2018.0,"TEXTILE BIOENGINEERING AND INFORMATICS SYMPOSIUM (TBIS) PROCEEDINGS, 2018",TEXTILE BIOENGINEERING & INFORMATICS SOCIETY LTD,,,20230520-160000,20230521-044735,"['discover', 'the', 'digital', 'technology', 'application', 'in', 'fashion', 'business', 'models']",True,20230521-205332,,,,
611,wos,Guest Editorial Special Issue on Big Data and Computational Intelligence for Agile Wireless IoT,,,"Wu, CLMG; Jin, YC; Li, J; Yau, KLA; Qadir, J",University of Electro-Communications - Japan; University of Surrey; Shanghai Jiao Tong University; Sunway University,2020.0,IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,,10.1109/TETCI.2020.2990757,20230520-160000,20230521-044735,"['guest', 'editorial', 'special', 'issue', 'on', 'big', 'data', 'and', 'computational', 'intelligence', 'for', 'agile', 'wireless', 'iot']",True,20230521-205332,,,,
612,wos,Agile Lossless Compression Algorithm for Big Data of Solar Energy Harvesting Wireless Sensor Network,"Time series data are collected through most of the applications that permeate our lives today. Internet of Things (IoT) sensor data are generated through smart applications and stored in databases. Time series databases require huge storage spaces, as over time they consume a large amount of memory. In this paper, we propose an enhanced compression algorithm for time series data generated by IoT systems that monitor the production of electrical energy by solar panels. The best way to ensure that solar energy systems have high efficiency is to continuously monitor all electrical and environmental factors. However, this requires the collection of enormous quantities of data that can be used to detect defects in the generation of electric energy or in solar panels. As the data must be available for analysis, a lossless compression algorithm is needed. In addition, the compressed data must be in a format that can be queried to perform analysis operations dependent on speed; this means that the decompression of data should not be time-consuming. Our results showed the high speed of the compression process along with good compression rate (16.6%) after applying the proposed compression algorithm.",lossless compression algorithm; solar energy; compressed time series data; wireless sensor network,"El-Hageen, HM; Albalawi, H; Alatwi, AM; Abd Elrahman, WR; Faqeh, STM",University of Tabuk; University of Tabuk; Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA); University of Tabuk; University of Tabuk,2022.0,SENSORS AND MATERIALS,"MYU, SCIENTIFIC PUBLISHING DIVISION",,10.18494/SAM4106,20230520-160000,20230521-044735,"['agile', 'lossless', 'compression', 'algorithm', 'for', 'big', 'data', 'of', 'solar', 'energy', 'harvesting', 'wireless', 'sensor', 'network']",True,20230521-205332,,,,
613,wos,Smart hospitality-Interconnectivity and interoperability towards an ecosystem,"The Internet and cloud computing changed the way business operate. Standardised web-based applications simplify data interchange which allow internal applications and business partners systems to become interconnected and interoperable. This study conceptualises the smart and agile hospitality enterprises of the future, and proposes a smart hospitality ecosystem that adds value to all stakeholders. Internal data from applications among all stakeholders, consolidated with external environment context form the hospitality big data on the cloud that enables members to use business intelligence analysis to generate scenarios that enhance revenue management performance. By connecting to smart tourism network, sensors and content extractors can assist to collect external information, and beacons to deliver context-based promotion messages and add value. The proposed model enables fully integrated applications, using big data to enhance hospitality decision making as well as strengthen competitiveness and improve strategies performance.",Smart hospitality; Interconnectivity and interoperability; Hospitality ecosystem; ICT; Big data; Sensor and beacon,"Buhalis, D; Leung, R",Bournemouth University; I Shou University,2018.0,INTERNATIONAL JOURNAL OF HOSPITALITY MANAGEMENT,ELSEVIER SCI LTD,,10.1016/j.ijhm.2017.11.011,20230520-160000,20230521-044735,"['smart', 'hospitality-interconnectivity', 'and', 'interoperability', 'towards', 'an', 'ecosystem']",True,20230521-205332,,,,
614,wos,Discovering and merging related analytic datasets,"The production of analytic datasets is a significant big data trend and has gone well beyond the scope of traditional IT-governed dataset development. Analytic datasets are now created by data scientists and data analysts using big data frameworks and agile data preparation tools. However, despite the profusion of available datasets, it remains quite difficult for a data analyst to start from a dataset at hand and customize it with additional attributes coming from other existing datasets. This article describes a model and algorithms that exploit automatically extracted and user-defined semantic relationships for extending analytic datasets with new atomic or aggregated attribute values. Our framework is implemented as a REST service in SAP HANA and includes a careful theoretical analysis and practical solutions for several complex data quality issues. (C) 2020 Elsevier Ltd. All rights reserved.",Schema augmentation; Schema complement; Data quality; SAP HANA,"Liu, RT; Simon, E; Amann, B; Gancarski, S",Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Sorbonne Universite,2020.0,INFORMATION SYSTEMS,PERGAMON-ELSEVIER SCIENCE LTD,,10.1016/j.is.2020.101495,20230520-160000,20230521-044735,"['discovering', 'and', 'merging', 'related', 'analytic', 'datasets']",True,20230521-205332,,,,
615,wos,Unlocking the Potential of NextGen Multi-Model Databases for Semantic Big Data Projects,"A new vision in semantic big data processing is to create enterprise data hubs, with a 360 degrees view on all data that matters to a corporation. As we discuss in this paper, a new generation of multi-model database systems seems a promising architectural choice for building such scalable, non-native triple stores. In this paper, we first characterize this new generation of multi-model databases. Then, discussing an example scenario, we show how they allow for agile and flexible schema management, spanning a large design space for creative and incremental data modelling. We identify the challenge of generating sound triple-views from data stored in several, interlinked models, for SPARQL querying. We regard this as one of several appealing research challenges where the semantic big data and the database architecture community may join forces.",Semantic data management; schema evolution; multi-model DBMS,"Holubova, I; Scherzinger, S",Charles University Prague,2019.0,PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON SEMANTIC BIG DATA (SBD 2019),ASSOC COMPUTING MACHINERY,,10.1145/3323878.3325807,20230520-160000,20230521-044735,"['unlocking', 'the', 'potential', 'of', 'nextgen', 'multi-model', 'databases', 'for', 'semantic', 'big', 'data', 'projects']",True,20230521-205332,,,,
616,wos,"Towards DesignOps Design Development, Delivery and Operations for the AECO Industry","The overwhelming success of companies build on top of cloud computing technologies has been driven by their ability to create systems for processing big data at scale and designing high-quality digital products as well as being agile and capable of handling constant changes in the market. This runs somewhat contrary to the AECO industry, which generates an abundance of multidisciplinary data and faces numerous design challenges but is not as prone to agile management. The entire methodology for designing and delivering projects has historically been oriented toward getting all requirements defined and specified in advance. In that context, change of the workflow in AECO is often seen as an exception. Not only this is far from the paradigm or principles of today's business technologies, but today's enterprises are characterized by an opposing set of values. Latest software engineering methodologies, like DevOps and its design incarnation - DesignOps were created solely to tackle those issues in the IT industry. This paperwill present how those methodologies could be successfully implemented in the AECO industry and increase the efficiency of existing design pipelines. We demonstrate a prototype of a software platform, an entire automated ecosystem where design operations are made in the cloud by a collection of automatic or semi-automatic microservices and where data flows seamlessly between various disciplines. The system leverages the potential of distributed computing, performance-driven design, evolutionary optimization, big data, and modern web design.",DesignOps; DevOps; Cloud computing; Performance design; Optimization; High performance computing,"Kosicki, M; Tsiliakos, M; ElAshry, K; Borgstrom, O; Rod, A; Tarabishy, S; Nguyen, C; Davis, A; Tsigkari, M",,2023.0,TOWARDS RADICAL REGENERATION,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-031-13249-0_6,20230520-160000,20230521-044735,"['towards', 'designops', 'design', 'development,', 'delivery', 'and', 'operations', 'for', 'the', 'aeco', 'industry']",False,20230521-205332,,,,
617,wos,manufacturing and Industry 4.0 combinative application: Practices and perceived benefits,"This paper investigates the industry practices regarding the combinative use of Industry 4.0 and lean tools in the manufacturing sector. Following review of the literature, a questionnaire survey was distributed among manufacturing professionals in organizations which have already adopted Industry 4.0 technology and lean manufacturing, with the aim to highlight the popular combinations of tools as seen in manufacturing practice and capture the perceived level of their contribution to operational performance. The survey results show that Real time data, IoT for data exchange, big data analytics, Cyber Physical Systems (CPS), predictive algorithms and robots are among the most popular 14.0 applications used to support lean attributes like continuous flow, Kanban, standardised work, TPM and continuous improvement. It also emerges that although the beneficial impact of lean production across the respondents' organizations is widely accepted, the perceived impact of Industry 4.0 tools is not as clear. Copyright (C) 2021 The Authors.",Lean production; Industry 4.0; production management; information technology; decision making,"Marinelli, M; Deshmukh, AA; Janardhanan, M; Nielsen, I",RLUK- Research Libraries UK; University of Leicester; Aalborg University,2021.0,IFAC PAPERSONLINE,ELSEVIER,,10.1016/j.ifacol.2021.08.034,20230520-160000,20230521-044735,"['manufacturing', 'and', 'industry', '4.0', 'combinative', 'application:', 'practices', 'and', 'perceived', 'benefits']",True,20230521-205332,,,,
618,wos,IoT Agile Framework Enhancement,"Internet of Things (IoT) is considered as a trend nowadays. Devices connected to the internet interact with surrounding; this poses strong challenges in handling big data with a certain level of security. In this paper IoT devices will be divided in to two categories high vulnerability devices and low vulnerability devices. The classification depends on the ease of attacks. In order to ensure the security of IoT devices, an agile approach is used to secure high vulnerability devices as first step and then low vulnerability devices by applying encryption algorithms.",Internet of Things; Agile approach; Encryption algorithms,"Gabr, B; Azer, MA",Egyptian Knowledge Bank (EKB); Nile University; Egyptian Knowledge Bank (EKB); Nile University,2018.0,2018 1ST INTERNATIONAL CONFERENCE ON COMPUTER APPLICATIONS & INFORMATION SECURITY (ICCAIS' 2018),IEEE,,,20230520-160000,20230521-044735,"['iot', 'agile', 'framework', 'enhancement']",True,20230521-205332,,,,
619,wos,Understanding how the Ad Hoc use of Big Data Analytics Impacts Agility: A Sensemaking-based Model,"As business environments become increasingly complex and turbulent, organizations are required to be more agile. Use of big data analytics (BDA) can be a differentiator for organizations seeking to improve agility to quickly sense and respond to novel and complex events. Usage of BDA comprises two types: the routine use and the ad hoc use. The latter is more associated with the unplanned analysis of big data to understand unexpected events, and its effects have not been studied in distinction to the former in the analytics literature. We draw on sensemaking, the organizational theory of the process of understanding novel and complex events, to investigate how the ad hoc use of BDA improves agility of organizations. Analysis of a survey of 107 business executives and senior managers demonstrated the positive effects of the ad hoc use of BDA on agility, through mediation by sensemaking.",big data; analytics; ad hoc use; sensemaking; agility,"Hosoya, R; Kamioka, T",Hitotsubashi University; Hitotsubashi University,2018.0,"2018 INTERNATIONAL CONFERENCE ON ADVANCES IN BIG DATA, COMPUTING AND DATA COMMUNICATION SYSTEMS (ICABCD)",IEEE,,,20230520-160000,20230521-044735,"['understanding', 'how', 'the', 'ad', 'hoc', 'use', 'of', 'big', 'data', 'analytics', 'impacts', 'agility:', 'a', 'sensemaking-based', 'model']",True,20230521-205332,,,,
620,wos,Modelling the relationship of digital technologies with lean and agile strategies,"As the world becomes globalised, companies fight for survival by connecting their in-house processes with external suppliers/customers. To remain competitive, companies must integrate innovative capabilities like 'industry-4.0 technologies' with their operation and supply chain (SC) strategies. The integration of various strategies has been investigated with the associated effect on performance; however, studies on how industry 4.0 technologies might support integrated strategies are still incipient. This work investigates the hierarchical relationships of 'industry 4.0 technologies' with lean and agile strategies. Adopting the 'Interpretive Structural Modelling (ISM)' technique to present a model depicting the linkage, the work also classifies the technologies and practices according to their 'driving' and 'dependency' powers. The findings revealed that the technologies have a high affinity to enable the implementation of lean and agile strategies. Among the nine technologies included in the study, 'Cyber-Physical-System', 'Internet-of-Things', 'Cloud-Computing', and 'Big-Data-Analytics' have the highest driving powers, signifying their higher affinity with the practices. Meanwhile, all the practices have a high enough affinity to be influenced by the technologies, except for a few (3/16 of lean and 2/9 of agile) that possess affinities too low to be driven by these technologies. The theoretical and managerial impacts of the research are also emphasised.",Lean SCM; agile SCM; digital technologies; interpretive structural modelling; industry 4; 0,"Raji, IO; Shevtshenko, E; Rossi, T; Strozzi, F",Universita Carlo Cattaneo - Liuc,2021.0,SUPPLY CHAIN FORUM,TAYLOR & FRANCIS LTD,,10.1080/16258312.2021.1925583,20230520-160000,20230521-044735,"['modelling', 'the', 'relationship', 'of', 'digital', 'technologies', 'with', 'lean', 'and', 'agile', 'strategies']",True,20230521-205332,,,,
621,wos,Exploring the Digital Transformation Based on Big Data with Ubiquitous Internet of Everything,"Digital technologies present both game-changing opportunities for and existential threats to companies. Digital services in consumer-facing organizations offer novelty value propositions, closer consumer relationships and higher automation of consumer-facing processes. Facing big digital data streams generated by ubiquitous Internet of Everything(IoE) and savvy customers with mobile computing and social media, this paper focuses on digital transformation journeys seeking digital capabilities and digital leadership to upgrade organizational performance, one is discovering big data value, the other is dual methods with agile. The finding provides practical implications that can help guide practitioners in digital transformation.",Internet of Everything(IoE); big data; analytics capabilities,"Wang, XX",Beijing Jiaotong University,2020.0,PROCEEDINGS OF NINETEENTH WUHAN INTERNATIONAL CONFERENCE ON E-BUSINESS,UNIV CALGARY PRESS,,,20230520-160000,20230521-044735,"['exploring', 'the', 'digital', 'transformation', 'based', 'on', 'big', 'data', 'with', 'ubiquitous', 'internet', 'of', 'everything']",False,20230521-205332,,,,
622,wos,An Overview of Fashion Business Models in Big Data Environment,"The competitive pressure in the fashion industry not only exist between companies, they also exist between the networks of linked partners (known as supply chains). Consumers' needs are changing faster than ever before. Textile and garment manufactures are forced to lower the production costs and increase the efficiency so that they can respond quickly when there is a new trend in the market. Big data (BD) has been a hot topic for the last decade; this concept is mainly about extracting valuable information from voluminous data. In the fashion business, big data is playing a more and more important role in trend forecasting, consumer behavior studying etc. This paper reviews the history of conducting business in different developing stages of information technology. The basic garment supply chain in the traditional business era and in e-business era, as well as the development in fashion industry has been critically viewed.",Fast Fashion; Supply Chain Management; Agile; Fashion Management; Fashion Big Data,"Wang, YY; Li, Y; Perry, P; Liu, ZC",N8 Research Partnership; RLUK- Research Libraries UK; University of Manchester,2018.0,"TEXTILE BIOENGINEERING AND INFORMATICS SYMPOSIUM (TBIS) PROCEEDINGS, 2018",TEXTILE BIOENGINEERING & INFORMATICS SOCIETY LTD,,,20230520-160000,20230521-044735,"['an', 'overview', 'of', 'fashion', 'business', 'models', 'in', 'big', 'data', 'environment']",True,20230521-205332,,,,
623,wos,"Work-in-progress: Data Science Challenge-X: self-directed, competence-based, project-based learning","We discuss in this paper the implementation of a project-based self-direct learning competency-based project module in our Bachelor Data Science programme. The goal of the course is to integrate in a later stage all project modules, which are now divided in two: one with and one without external industry partners, treating different aspects of data science with a pre-defined goal and clear objectives for the project. Switching for a competency-based learner-based paradigm with agile aspects and intrinsic focus, we define the core project goals as secondary and develop core data science competences which are acquired by the students and reflected in a learning journal.",project-based learning; intrinsic motivation; self-directed learning,"Benites, F; Schlatter, M; Messerli, M; Custer, R",FHNW University of Applied Sciences & Arts Northwestern Switzerland,2022.0,PROCEEDINGS OF THE 2022 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE (EDUCON 2022),IEEE,,10.1109/EDUCON52537.2022.9766710,20230520-160000,20230521-044735,"['work-in-progress:', 'data', 'science', 'challenge-x:', 'self-directed,', 'competence-based,', 'project-based', 'learning']",True,20230521-205332,,,,
624,wos,Advanced Customer Analytics: Strategic Value Through Integration of Relationship-Oriented Big Data,"As more firms adopt big data analytics to better understand their customers and differentiate their offerings from competitors, it becomes increasingly difficult to generate strategic value from isolated and unfocused ad hoc initiatives. To attain sustainable competitive advantage from big data, firms must achieve agility in combining rich data across the organization to deploy analytics that sense and respond to customers in a dynamic environment. A key challenge in achieving this agility lies in the identification, collection, and integration of data across functional silos both within and outside the organization. Because it is infeasible to systematically integrate all available data, managers need guidance in finding which data can provide valuable and actionable insights about customers. Leveraging relationship marketing theory, we develop a framework for identifying and evaluating various sources of big data in order to create a value-justified data infrastructure that enables focused and agile deployment of advanced customer analytics. Such analytics move beyond siloed transactional customer analytics approaches of the past and incorporate a variety of rich, relationship-oriented constructs to provide actionable and valuable insights. We develop a customized kernel-based learning method to take advantage of these rich constructs and instantiate the framework in a novel prototype system that accurately predicts a variety of customer behaviors in a challenging environment, demonstrating the framework's ability to drive significant value.",big data; customer acquisition; customer analytics; customer expansion; data integration; data management; design science; IT strategic value; relationship marketing; customer retention,"Kitchens, B; Dobolyi, D; Li, JJ; Abbasi, A",University of Virginia; University of Virginia; University of Virginia,2018.0,JOURNAL OF MANAGEMENT INFORMATION SYSTEMS,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD",,10.1080/07421222.2018.1451957,20230520-160000,20230521-044735,"['advanced', 'customer', 'analytics:', 'strategic', 'value', 'through', 'integration', 'of', 'relationship-oriented', 'big', 'data']",True,20230521-205332,,,,
625,wos,Why we need a small data paradigm,"BackgroundThere is great interest in and excitement about the concept of personalized or precision medicine and, in particular, advancing this vision via various big data' efforts. While these methods are necessary, they are insufficient to achieve the full personalized medicine promise. A rigorous, complementary small data' paradigm that can function both autonomously from and in collaboration with big data is also needed. By small data' we build on Estrin's formulation and refer to the rigorous use of data by and for a specific N-of-1 unit (i.e., a single person, clinic, hospital, healthcare system, community, city, etc.) to facilitate improved individual-level description, prediction and, ultimately, control for that specific unit.Main bodyThe purpose of this piece is to articulate why a small data paradigm is needed and is valuable in itself, and to provide initial directions for future work that can advance study designs and data analytic techniques for a small data approach to precision health. Scientifically, the central value of a small data approach is that it can uniquely manage complex, dynamic, multi-causal, idiosyncratically manifesting phenomena, such as chronic diseases, in comparison to big data. Beyond this, a small data approach better aligns the goals of science and practice, which can result in more rapid agile learning with less data. There is also, feasibly, a unique pathway towards transportable knowledge from a small data approach, which is complementary to a big data approach. Future work should (1) further refine appropriate methods for a small data approach; (2) advance strategies for better integrating a small data approach into real-world practices; and (3) advance ways of actively integrating the strengths and limitations from both small and big data approaches into a unified scientific knowledge base that is linked via a robust science of causality.ConclusionSmall data is valuable in its own right. That said, small and big data paradigms can and should be combined via a foundational science of causality. With these approaches combined, the vision of precision health can be achieved.",Precision medicine; Personalized medicine; Precision health; Small data; Artificial intelligence; Data science,"Hekler, EB; Klasnja, P; Chevance, G; Golaszewski, NM; Lewis, D; Sim, I",University of California System; University of California San Diego; University of California System; University of California San Diego; University of Michigan System; University of Michigan; University of California System; University of California San Francisco,2019.0,BMC MEDICINE,BMC,,10.1186/s12916-019-1366-x,20230520-160000,20230521-044735,"['why', 'we', 'need', 'a', 'small', 'data', 'paradigm']",True,20230521-205332,,,,
626,wos,Hacking marketing: how do firms develop marketers' expertise and practices in a digital era?,"PurposeDigital technologies, digitalised consumers and the torrent of customer data have been transforming marketing practice. In discussing such trends, existing research has either focussed on the skills marketers need or broad-based approaches such as agile methods but has given less consideration to just how such skills or approaches might be developed and used in marketers' day-to-day activities and in the organisation of marketing in the firm. This is what the authors address in this paper.Design/methodology/approachThis paper adopts an in-depth case study approach to examine an exemplary digital enterprise in transformation of their digital marketing. The insights were gathered from 25 interviews, netnography and document analysis of the case organisation in addition to 10 interviews with independent experts.FindingsDrawing on practice-oriented approach, the authors show how organisations respond to the emerging trends of digital consumers and big data by taking a 'hacking marketing' approach and developing novel marketing expertise at disciplinary boundaries. The authors put forward three sets of practices that enable and shape the hacking marketing approach. These include spanning the expertise boundary, making value measurable and experimenting through which their adaptive, iterative and multidisciplinary work occurs. This explains how managing digital consumers and big data is not within the realm of information technology (IT) functions but marketing and how marketing professionals are changing their practice and moving their disciplinary boundaries.Practical implicationsThis study offers practical contributions for firms in terms of identifying new work practices and expertise that marketing specialists need in managing digital platforms, digitalised consumers and big data. This study's results show that enterprises need to design and implement strong training programmes to prepare their marketing workforce in adopting experimentations of agile approach and data-driven decision making. In addition, Marketing education should be changed so that programmes consider a review of their courses and include the novel marketing models and approaches into their curriculum.Originality/valueThis study contributes to the nascent discussions by unpacking how enterprises can develop new marketing expertise and practices beyond skillsets and how such practices form new hacking marketing approach which addresses the problem of the inability of the conventional marketing approach to show its value within the firm.",Digitalised consumers; Practice; Expertise; Digital marketing; Digital organisation; Occupations; Hacking,"Hafezieh, N; Pollock, N; Ryan, A",RLUK- Research Libraries UK; University of London; Royal Holloway University London; RLUK- Research Libraries UK; University of Edinburgh; University of Limerick,2023.0,JOURNAL OF ENTERPRISE INFORMATION MANAGEMENT,EMERALD GROUP PUBLISHING LTD,,10.1108/JEIM-12-2021-0530,20230520-160000,20230521-044735,"['hacking', 'marketing:', 'how', 'do', 'firms', 'develop', ""marketers'"", 'expertise', 'and', 'practices', 'in', 'a', 'digital', 'era?']",True,20230521-205332,,,,
627,wos,Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure,"Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a big data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP? In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better. The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI.",,"Wang, C; Kim, B",,2020.0,2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData50022.2020.9378045,20230520-160000,20230521-044735,"['automotive', 'big', 'data', 'pipeline:', 'disaggregated', 'hyper-converged', 'infrastructure', 'vs', 'hyper-converged', 'infrastructure']",True,20230521-205332,,,,
628,wos,Towards Microservice Identification Approaches for Architecting Data Science Workflows,"In order to support fast development cycles and deploying software components in productive environments, there are three crucial trends in data science. These are agile process models, development of many technologies and increasing usage of cloud platforms. Therefore, effective architectures are needed to support this trend in data science context. This paper explores and evaluates first approaches for, why and how microservice architecture style can support fast development cycles for data science workflows. Microservices are becoming a popular architectural style for designing modern applications due to several advantages like scalability, reliability and maintainability. First, this paper points out the research gap on why microservices could be a suitable way to design data science workflows. Second, it defines relevant research questions for future research that addresses challenges of the microservice architectural style in the data science context. An essential prerequisite for this architecture style is to identify the right context of a microservice for data science workflows. (C) 2021 The Authors. Published by Elsevier B.V.",Microservice; Microservice Identification; Data Science Workflows; Software Architecture,"Schroer, C",Volkswagen; Carl von Ossietzky Universitat Oldenburg,2021.0,INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS / INTERNATIONAL CONFERENCE ON PROJECT MANAGEMENT / INTERNATIONAL CONFERENCE ON HEALTH AND SOCIAL CARE INFORMATION SYSTEMS AND TECHNOLOGIES 2020 (CENTERIS/PROJMAN/HCIST 2020),ELSEVIER SCIENCE BV,,10.1016/j.procs.2021.01.198,20230520-160000,20230521-044735,"['towards', 'microservice', 'identification', 'approaches', 'for', 'architecting', 'data', 'science', 'workflows']",True,20230521-205332,,,,
629,wos,A Methodology to Manage Structured and Semi-structured Data in Knowledge Oriented Graph,"Data has become fundamental to every business process and research area like never before. To date, one of the main open points of research activities is to manage the data acquired in the field by sensors, logs etc. by modeling the data structures according to the analyzes that will be carried out. In fact, with the advent of Big Data, the need to have a single reference data structure has been reduced, but with modern architectures there is a tendency to generate specific and optimized data structures for the analyzes that will be carried out. In this work we propose an agile data modeling methodology guided by analytics focused on the management of structured and semi-structured data sources.",Events graphs; Graph rewriting; Data management,"Bellandi, V; Ceravolo, P; D'Andrea, GA; Maghool, S; Siccardi, S",University of Milan,2022.0,"ENGINEERING APPLICATIONS OF NEURAL NETWORKS, EAAAI/EANN 2022",SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-031-08223-8_18,20230520-160000,20230521-044735,"['a', 'methodology', 'to', 'manage', 'structured', 'and', 'semi-structured', 'data', 'in', 'knowledge', 'oriented', 'graph']",True,20230521-205332,,,,
630,wos,Importance of Project Management in Business Analytics: Academia and Real World,"Project management constitutes a powerful lever as organizations face increasing pressure to manage projects to budget, on time, and deliver more insights, in less time and with rapidly increasing amounts of data. This is critical especially in business analytics, with more than75% of organizations planning big data investments over the next several years. But the manipulation of massive amounts of data presents challenges - budgetary, time constraints, execution, proper manager skillsets, and such like. These challenges have cramped recent project rollouts, as only 37% of organizations have deployed big data projects in the past year; this suggests that filling the gap between data and insight remains a substantial hurdle as well as evolving need of project management for such projects. This chapter offers real-world examples of how project management professionals tackle big data challenges in a rapidly evolving, data-rich environment. Simultaneously, it establishes a bridge between business and academia as they both recognize the joint necessity to develop highly trained project managers to utilize the powerful and cutting edge analytical tools available to create value.",Analytics; Project management; Business analytics; Data science; Business intelligence; Agile methods,"Shah, S; Gochtovtt, A; Baldini, G",Drexel University,2019.0,ALIGNING BUSINESS STRATEGIES AND ANALYTICS: BRIDGING BETWEEN THEORY AND PRACTICE,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-319-93299-6_6,20230520-160000,20230521-044735,"['importance', 'of', 'project', 'management', 'in', 'business', 'analytics:', 'academia', 'and', 'real', 'world']",False,20230521-205332,,,,
631,wos,Machine Learning-based Estimation of Story Points in Agile Development: Industrial Experience and Lessons Learned,"Estimating story points is an important activity in agile software engineering. Story-point estimation enables software development teams to, among other things, better scope products, prioritize requirements, allocate resources and measure progress. Several machine learning techniques have been proposed for automated story-point estimation. However, most of these techniques use open-source projects for evaluation. There are important differences between open-source and commercial projects with respect to story authoring. The goal of this paper is to evaluate a state-of-the-art machine learning technique, known as Deep-SE [3], for estimating story points in a commercial project. Our dataset is comprised of 4,727 stories for a data anonymization product developed by a 27-member agile team at a healthcare data science company, IQVIA. Over this dataset, Deep-SE achieved a mean absolute error of 1.46, significantly better than three different baselines. Model performance nonetheless varied across stories, with the estimation error being larger for stories that had higher points. Our results further indicate that model performance is correlated with certain story characteristics such as the level of detail and the frequency of vague terms in the stories. An important take-away from our study is that, before organizations attempt to introduce machine learning-based estimation into agile development, they need to better embrace agile best practices, particularly in relation to story authoring and expert-based estimation.",Agile Development; Story-point Estimation; Machine Learning,"Abadeer, M; Sabetzadeh, M",University of Ottawa,2021.0,29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021),IEEE COMPUTER SOC,,10.1109/REW53955.2021.00022,20230520-160000,20230521-044735,"['machine', 'learning-based', 'estimation', 'of', 'story', 'points', 'in', 'agile', 'development:', 'industrial', 'experience', 'and', 'lessons', 'learned']",True,20230521-205332,,,,
632,wos,Interdisciplinarity in Data Science Pedagogy: A Foundational Design,"Data science is an interdisciplinary field that generates insights in data to aid decision-making. Recognizing that data scientists must be interdisciplinary, agile, and able to adapt to data analysis across many domains, both academia and the industry are striving to integrate interdisciplinary learning and transferable skills into data science curriculum. This paper introduces an interdisciplinary approach to teaching the foundations of data science. We evaluate two different interdisciplinary formats. The first format considers collaborative efforts among instructors with different academic disciplines. The second involves a sole instructor that discusses data science concepts from different disciplines and related to business processes, computer science, and programming. We demonstrate that interdisciplinarity ensures favorable learning experiences and produces high learning outcomes. We also show that our course design maintains and promotes interdisciplinarity even in situations where logistical constraints would not support the use of multiple instructors to deliver one course.",Data science; interdisciplinarity; pedagogy; analytics; curriculum design,"Asamoah, DA; Doran, D; Schiller, S",University System of Ohio; Wright State University Dayton,2020.0,JOURNAL OF COMPUTER INFORMATION SYSTEMS,TAYLOR & FRANCIS INC,,10.1080/08874417.2018.1496803,20230520-160000,20230521-044735,"['interdisciplinarity', 'in', 'data', 'science', 'pedagogy:', 'a', 'foundational', 'design']",True,20230521-205332,,,,
633,wos,The concept and competitiveness of agile organization in the fourth industrial revolution's drift,"Corporate competitiveness is constantly being shaped by the Fourth Industrial Revolution, the explosive development of technology, the globalization and the hyper-competition. The VUCA status has now become a permanent reality: volatility and complexity cannot be traced to traditional corporate operations. The Industry 4.0 projects a physical, a digital and a biological megatrend such as advanced robotics, artificial intelligence, new materials, personalized healing, self-driving cars. Through usage of the resources and knowledge sharing, the global economy is experiencing mutations such as the sharing economy, the peer to peer economy, the gig economy in the labor market and the Big Data in planning. Meanwhile, the disruptive innovations are transforming industries and gaining exponentially competitive advantage. The special business concepts were born and whom cannot be handled by models of classic macro and micro economics: the largest taxi company in the world does not own any taxicab (Uber), the largest accommodation company does not own any property (Airbnb), the largest telecommunication company has no infrastructure (Skype), the world's most valuable retailer has no inventory (Alibaba), the most popular media doesn't create its own content (Facebook), the world's largest cinema doesn't have its own movie (Netflix). In the meantime, those are treasuring huge profits, business influence and information capital. The competitiveness of their agile way of working can be proved. These call for changes not only in the market, but also in organizational and individual terms. An adaptive corporate structure and leadership, a self-organizing group, an agile working method hold companies in the direction of growing track and changes in the future. My research about discovering some aspects of agile way of working versus traditional organization work. My hypothesis is that employees are more motivated, effective and committed in an agile team than in a classic hierarchy or matrix. I added own business and project-based worker as their flexible, effective work is a must. My hypotheses are partially fulfilled.",agile; Industry 4.0; VUCA; sharing economy; competitiveness,"Balog, K",Hungarian University of Agriculture & Life Sciences,2020.0,STRATEGIC MANAGEMENT,"UNIV NOVI SAD, FAC ECONOMICS SUBOTICA",,10.5937/StraMan2003014B,20230520-160000,20230521-044735,"['the', 'concept', 'and', 'competitiveness', 'of', 'agile', 'organization', 'in', 'the', 'fourth', 'industrial', ""revolution's"", 'drift']",False,20230521-205332,,,,
634,wos,A survey study of success factors in data science projects,"In recent years, the data science community has pursued excellence and made significant research efforts to develop advanced analytics, focusing on solving technical problems at the expense of organizational and socio-technical challenges. According to previous surveys on the state of data science project management, there is a significant gap between technical and organizational processes. In this article we present new empirical data from a survey to 237 data science professionals on the use of project management methodologies for data science. We provide additional profiling of the survey respondents' roles and their priorities when executing data science projects. Based on this survey study, the main findings are: (1) Agile data science lifecycle is the most widely used framework, but only 25% of the survey participants state to follow a data science project methodology. (2) The most important success factors are precisely describing stakeholders' needs, communicating the results to end-users, and team collaboration and coordination. (3) Professionals who adhere to a project methodology place greater emphasis on the project's potential risks and pitfalls, version control, the deployment pipeline to production, and data security and privacy.",data science; survey; project management; factor analysis; success factors,"Martinez, I; Viles, E; Olaizola, IG",University of Navarra,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,10.1109/BigData52589.2021.9671588,20230520-160000,20230521-044735,"['a', 'survey', 'study', 'of', 'success', 'factors', 'in', 'data', 'science', 'projects']",True,20230521-205332,,,,
635,wos,"Artificial Intelligence in Surveillance, Diagnosis, Drug Discovery and Vaccine Development against COVID-19","As of August 6th, 2021, the World Health Organization has notified 200.8 million laboratory-confirmed infections and 4.26 million deaths from COVID-19, making it the worst pandemic since the 1918 flu. The main challenges in mitigating COVID-19 are effective vaccination, treatment, and agile containment strategies. In this review, we focus on the potential of Artificial Intelligence (AI) in COVID-19 surveillance, diagnosis, outcome prediction, drug discovery and vaccine development. With the help of big data, AI tries to mimic the cognitive capabilities of a human brain, such as problem-solving and learning abilities. Machine Learning (ML), a subset of AI, holds special promise for solving problems based on experiences gained from the curated data. Advances in AI methods have created an unprecedented opportunity for building agile surveillance systems using the deluge of real-time data generated within a short span of time. During the COVID-19 pandemic, many reports have discussed the utility of AI approaches in prioritization, delivery, surveillance, and supply chain of drugs, vaccines, and non-pharmaceutical interventions. This review will discuss the clinical utility of AI-based models and will also discuss limitations and challenges faced by AI systems, such as model generalizability, explainability, and trust as pillars for real-life deployment in healthcare.",COVID-19; machine learning; artificial intelligence; drug discovery; SARS-CoV-2; pandemic; diagnosis; prediction; surveillance; vaccine,"Arora, G; Joshi, J; Mandal, RS; Shrivastava, N; Virmani, R; Sethi, T",Yale University; Cleveland Clinic Foundation; University of Pennsylvania; Pennsylvania Medicine; Montefiore Medical Center; Yeshiva University; Albert Einstein College of Medicine; Indraprastha Institute of Information Technology Delhi,2021.0,PATHOGENS,MDPI,,10.3390/pathogens10081048,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'in', 'surveillance,', 'diagnosis,', 'drug', 'discovery', 'and', 'vaccine', 'development', 'against', 'covid-19']",False,20230521-205332,,,,
636,wos,What more than a hundred project groups reveal about teaching visualization,"The growing number of students can be a challenge for teaching visualization lectures, supervision, evaluation, and grading. Moreover, designing visualization courses by matching the different experiences and skills of the students is a major goal in order to find a common solvable task for all of them. Particularly, the given task is important to follow a common project goal, to collaborate in small project groups, but also to further experience, learn, or extend programming skills. In this article, we survey our experiences from teaching 116 student project groups of 6 bachelor courses on information visualization with varying topics. Moreover, two teaching strategies were tried: 2 courses were held without lectures and assignments but with weekly scrum sessions (further denoted by TS1) and 4 courses were guided by weekly lectures and assignments (further denoted by TS2). A total number of 687 students took part in all of these 6 courses. Managing the ever growing number of students in computer and data science is a big challenge in these days, i.e., the students typically apply a design-based active learning scenario while being supported by weekly lectures, assignments, or scrum sessions. As a major outcome, we identified a regular supervision either by lectures and assignments or by regular scrum sessions as important due to the fact that the students were relatively unexperienced bachelor students with a wide range of programming skills, but nearly no visualization background. In this article, we explain different subsequent stages to successfully handle the upcoming problems and describe how much supervision was involved in the development of the visualization project. The project task description is given in a way that it has a minimal number of requirements but can be extended in many directions while most of the decisions are up to the students like programming languages, visualization approaches, or interaction techniques. Finally, we discuss the benefits and drawbacks of both teaching strategies.",Information visualization; Interaction; Education; Teaching,"Burch, M; Melby, E",Eindhoven University of Technology,2020.0,JOURNAL OF VISUALIZATION,SPRINGER,,10.1007/s12650-020-00659-6,20230520-160000,20230521-044735,"['what', 'more', 'than', 'a', 'hundred', 'project', 'groups', 'reveal', 'about', 'teaching', 'visualization']",True,20230521-205332,,,,
637,wos,What is Good Feedback in Big Data Projects for Cyberinfrastructure Diffusion in e-Science?,"This paper investigates the role of feedback in big data projects for cyberinfrastructure (CI) diffusion in e-science. For many of these projects, large-scale and heterogeneous datasets, multidisciplinary and dispersed experts, and advanced technologies are brought together to harness analytic insights. However, without effective CI and computational tools, the accuracy and meaningfulness of analytics results are compromised. In fact, without CI tools, raw data remain raw with hidden insights, as data analytics cannot be executed at all. In order to improve such tools for meaningful results, we argue to conceptualize the communication mechanism of 'feedback' in agile software development, with the goal of producing CI tools that are responsive to users. Based on a grounded analysis of interview data, we concluded that feedback helps developers in big data projects understand users' needs, makes tools user-friendly, prevents emergencies, and is better for developers than no feedback. Furthermore, good feedback is often structured, specific, actionable, timely, generalizable, and delivered in a tactful way. Despite the limitation of the findings being exploratory and yet to be evaluated experimentally, we argued that they still can motivate developers to be proactive seekers of feedback for their tools, productively guide developers' communication with users, and ultimately promote further adoption and diffusion of CI tools in e-science.",feedback; agile software development; e-science; cyberinfrastructure; technology adoption; diffusion of innovations,"Kee, KF; McCain, JC",Chapman University System; Chapman University,2018.0,2018 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,,20230520-160000,20230521-044735,"['what', 'is', 'good', 'feedback', 'in', 'big', 'data', 'projects', 'for', 'cyberinfrastructure', 'diffusion', 'in', 'e-science?']",True,20230521-205332,,,,
638,wos,INFORMED: an incubator at the US FDA for driving innovations in data science and agile technology,"Information Exchange and Data Transformation (INFORMED), a multidisciplinary initiative anchored in the FDA Oncology Center of Excellence, is a decentralized science and technology incubator designed to harness the power of big data and advanced analytics to improve disease outcomes.",,"Khozin, S; Pazdur, R; Shah, A",US Food & Drug Administration (FDA); Centers for Medicare & Medicaid Services,2018.0,NATURE REVIEWS DRUG DISCOVERY,NATURE PUBLISHING GROUP,,10.1038/nrd.2018.34,20230520-160000,20230521-044735,"['informed:', 'an', 'incubator', 'at', 'the', 'us', 'fda', 'for', 'driving', 'innovations', 'in', 'data', 'science', 'and', 'agile', 'technology']",False,20230521-205332,,,,
639,wos,To Offload or Not? An Analysis of Big Data Offloading Strategies from Edge to Cloud,"Large reductions in completion times can result from transfer of Big Data tasks from edge nodes to cloud resources, which can reduce the completion times by up to 97% and meet client deadlines for computational tasks with responsive and agile solutions. Using scientific programs of varying computational complexity to model resource-intensive tasks, we demonstrate that the task complexity of the computational jobs, the Wide Area Network (WAN) speed and the potential overload of edge servers (as reflected by CPU workloads) are crucial for achieving total reductions in task completion time edge-cloud orchestrators are situated in edge nodes. With continuous access to the parameters ofWireless Local Area Network (WLAN) speed (for data exchanges between client and edge resources), WAN speed (for data exchanges between edge and cloud resources) edge server CPU workload and the complexities in Big Data analytics requirements, accurate edge-to-cloud offloading decisions can be made to minimise total task completion time by the use of cloud computing resources. This work supports the major research efforts have been recently made to develop novel resource orchestration solutions to flexibly link edge nodes with centralised cloud resources so as to maximise the efficiency with which such a continuum of resources can be accessed by users.",Application-level orchestration; Cloud-to-Edge continuum; Big Data analytics; WLAN; WAN; Computational complexity; Server workload,"Singh, R; Kovacs, J; Kiss, T",University of Westminster,2022.0,2022 IEEE WORLD AI IOT CONGRESS (AIIOT),IEEE,,10.1109/AIIOT54504.2022.9817276,20230520-160000,20230521-044735,"['to', 'offload', 'or', 'not?', 'an', 'analysis', 'of', 'big', 'data', 'offloading', 'strategies', 'from', 'edge', 'to', 'cloud']",True,20230521-205332,,,,
640,wos,Internet of Things and Other E-Solutions in Supply Chain Management May Generate Threats in the Energy Sector-The Quest for Preventive Measures,"Energy firms are the beneficiaries and initiators of innovation, and energy investments are a crucial area of business activity that is specially protected in any country. This is no wonder, as energy security is the basis for the functioning of states and economies. The Internet of Things and Big Data create both new challenges and new threats. This study aimed to identify the potential threats and determine preventive measures, as well as to establish the agile principles related to energy firms' logistics. The method of the narrative summary in combination with the literature searching method was used. Two conclusions emerged: first, research serves to develop the discipline of management science; second, the identification of risks associated with innovation serves practitioners. In addition, the study defined further research directions.",energy; risk; Internet of Things; bid data; industry 4; 0; supply chain management; logistics; agile; framing,"Dobrowolski, Z",Jagiellonian University,2021.0,ENERGIES,MDPI,,10.3390/en14175381,20230520-160000,20230521-044735,"['internet', 'of', 'things', 'and', 'other', 'e-solutions', 'in', 'supply', 'chain', 'management', 'may', 'generate', 'threats', 'in', 'the', 'energy', 'sector-the', 'quest', 'for', 'preventive', 'measures']",True,20230521-205332,,,,
641,wos,"Big data, industry 4.0 and cyber-physical systems integration: A smart industry context","The advancements in the industries have paved the way for the distributed establishment of the big data volumes, cyber-physical systems, and industrie 4.0. The perspectives of modules are integrated with the shop-floor monitoring and controlled by computational paradigms, and digital computational spaces. The performance rises after introducing an intelligent and automated manufacturing industry into the nextgeneration industry. The scope of this paper is to address the state-of-the-art technologies and phases such as digital twins, big data analytics, artificial intelligence, and internet-of-things. The research challenges are examined with attention on data integrity, data quality, data privacy, data availability, data scalability, data transformation, legitimate and monitoring issues, and governance. Lastly, potential research issues that need considerable research efforts are summarized. We believe that this paper is presenting the research directions for researchers in the area of smart industry towards its integration for the advancements of the industrial sector, and agile management. Some surprising development as industry 4.0 integration with socio-technical systems was found in designing the architecture of vertical, horizontal, and end-to-end integration mechanisms. (c) 2021 Elsevier Ltd. All rights reserved. Selection and peer-review under responsibility of the scientific committee of the 2nd International Conference on Manufacturing Material Science and Engineering.",Agile management; Heterogeneity; Internet-of-things; Smart factory; Smart manufacturing,"Singh, H",Lovely Professional University,2021.0,MATERIALS TODAY-PROCEEDINGS,ELSEVIER,,10.1016/j.matpr.2020.07.170,20230520-160000,20230521-044735,"['big', 'data,', 'industry', '4.0', 'and', 'cyber-physical', 'systems', 'integration:', 'a', 'smart', 'industry', 'context']",True,20230521-205332,,,,
642,wos,Robotics in the Modern World of Work - Results From an Empirical Study Regarding Business Ethics,"The digital revolution is changing the world. Robots, big data and artificial intelligence are the key technologies of the future and the basis of important innovations for the future development of the economy and society. In companies, this fact requires strategic rethinking and adjustments in ever-shorter time cycles. The creation of an agile and collaborative production to achieve the goals is often a basic requirement. With adaptation to technical progress, requirements and goals change continuously. To be and remain competitive, companies are forced to have at least the same technological standard as their competitors. In order to meet these challenges today, the use of highly efficient mechatronic systems such as robots is necessary. The paper analyses business ethics relevant aspects of robotics by using a survey with 88 respondents.",business ethics; digitalization; ethics; robotics; sustainability,"Ludin, D; Wellbrock, W; Muller, E; Gerstlberger, W; Gray, L; Salat, S",Tallinn University of Technology,2021.0,TEHNICKI GLASNIK-TECHNICAL JOURNAL,UNIV NORTH,,10.31803/tg-20210517201926,20230520-160000,20230521-044735,"['robotics', 'in', 'the', 'modern', 'world', 'of', 'work', '-', 'results', 'from', 'an', 'empirical', 'study', 'regarding', 'business', 'ethics']",False,20230521-205332,,,,
643,wos,Big Data Analytics Capability Ecosystem Model for SMEs,"The unprecedented COVID-19 pandemic, together with globalization and advanced technologies, has drastically changed the business environment and forced companies to become more innovative and agile in the way they run their business and respond to the needs and wants of customers. Survival highly depends on the adaptability of SMEs to this ever-changing complex dynamic environment by taking steps in implementing Big Data Analytics as the next frontier for innovation, competition, productivity, and value creation. Based on the grounded theory, this study employed a qualitative method via focus group discussion. Focus groups were conducted with 14 government agencies, SMEs associations, business owners, Chief Operating Officers (CEOs), academic and industrial experts and directors of SMEs in Malaysia. The study revealed the challenges of Malaysian SMEs in adopting Big Data Analytics Capability, presents the criticality of Big Data Analytics Capability to overcome the identified challenges, and develops a BDA Capability Ecosystem Model that integrates the internal enablers, external barriers and support to explain the adoption of BDA Capability for value creation and support the decision-making process. This paper is followed by some policy suggestions for companies' owners, policymakers, government agencies, universities, and SMEs. This study directly impacts Malaysia's economy as a whole by addressing Malaysia's Shared Prosperity Vision 2030. This research contributes to industries that are still in the low value added category with low adoption of technology. Furthermore, it will ultimately lead to the realization of SMEs as 'game changers' to transition the economy to a high-income nation. This study proposes a model that could help SMEs improve their value creation performance, directly influencing the country's GDP and employability.",Big Data Analytics; value creation; capability; competencies; business model; SMEs,"Falahat, M; Cheah, PK; Jayabalan, J; Lee, CMJ; Kai, SB",,2023.0,SUSTAINABILITY,MDPI,,10.3390/su15010360,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'capability', 'ecosystem', 'model', 'for', 'smes']",True,20230521-205332,,,,
644,wos,The role of artificial intelligence in shaping the future of Agile fashion industry,"Artificial intelligence (AI) has become an integral part of every industry. With the emergence of big data, the industries, and more especially textile and apparel (T&A) industry, are on the brink of relationships with consumers, suppliers, and competitors. They need to handle different scenarios with a multitude of complex correlations and dependencies between them and uncertainties arising from human interaction. It has become imperative for them to manage huge amounts of data for the optimization of decision-making processes. In such circumstances, AI techniques have shown promise in every segment of the T&A value chain, from product discovery to robotic manufacturing. The potential wide-ranging applications of AI in T&A industry have found their ways into design support systems to T&A recommendation systems, intelligent tracking systems, quality control, T&A forecasting, predictive analytics in supply chain management or social networks and T&A e-commerce. The research recourses to the qualitative method in the form of systematic literature review and in-depth interviews from senior management people and industry experts. Findings identify the dimensions of AI to develop dynamic capability along with its potential impact and probable challenges. As such, the findings contribute to relevant literature and offer useful insights for academia and practitioners.",Artificial intelligence; dynamic capability; big data analytics; apparel; textile and fashion industry; Agile manufacturing,"Babu, MM; Akter, S; Rahman, M; Billah, MM; Hack-Polay, D",Coventry University; University of Wollongong; University of Lincoln; Khulna University,,PRODUCTION PLANNING & CONTROL,TAYLOR & FRANCIS LTD,,10.1080/09537287.2022.2060858,20230520-160000,20230521-044735,"['the', 'role', 'of', 'artificial', 'intelligence', 'in', 'shaping', 'the', 'future', 'of', 'agile', 'fashion', 'industry']",False,20230521-205332,,,,
645,wos,Nursing Value User Stories A Value Measurement Method for Linking Nurse Contribution to Patient Outcomes,"The use of nursing big data sets for value-based measurement is novel. Nursing value measurement depends on the availability of essential data attributes in the electronic health record related to nursing care delivered (what happened, when, and the result seen). Key in measuring value is a standardized structure and format of these attributes for enabling uniform consistent analysis, along with data sets that are sharable and comparable across individuals and groups, time, organization, and practice focus. The foundation of such sharable and comparable data sets would represent at a minimum individual essential nurse care actions and the resulting patient outcome(s). While nurses generate an extraordinary amount of health-related data, healthcare information systems are not designed to collect structured data that reflect the unique attributes of nursing care or support nursing analytic activities that would measure value. More important, the multidimensional features of the nursing process are difficult to untangle and differentiate from other healthcare workers and nonnursing care activities. The complexity of nursing knowledge work has limited the development of nursing data science methods like value measurement and discouraged value versus cost discussions. This article sets out to describe nursing value measurement and an approach that nurse scientists are maximizing through methods adapted from agile project management, including user stories, and business analysis processes to recognize nurses as primary contributors to patient outcomes and value generation. Nursing Value User Story methods deconstruct complex nursing scenarios into user stories that capture nursing actions as standardized data that can be mapped to a common nursing data model. Methods described here are being used in pilot research at Los Angeles Children's Hospital, and results will be available in 2019.",Clinical data model; Hospital administration; Nurse cost models; Nurse value; Nursing administration; Nursing user stories; Risk-sharing arrangements; Value-based care,"Moon, LA; Clancy, G; Welton, J; Harper, E",University of Minnesota System; University of Minnesota Twin Cities; University of Colorado System; University of Colorado Denver; University of Kansas,2019.0,CIN-COMPUTERS INFORMATICS NURSING,LIPPINCOTT WILLIAMS & WILKINS,,10.1097/CIN.0000000000000520,20230520-160000,20230521-044735,"['nursing', 'value', 'user', 'stories', 'a', 'value', 'measurement', 'method', 'for', 'linking', 'nurse', 'contribution', 'to', 'patient', 'outcomes']",True,20230521-205332,,,,
646,wos,Failure Prediction Approach in Agile Software Development,"Software failure prediction is an important activity during agile software development as it can help managers to identify the failure modules. Thus, it can reduce the test time, cost, and assign testing resources efficiently. RapidMiner Studio9.4 has been used to perform all the required steps from preparing the primary data to visualizing the results and evaluating the outputs, as well as verifying and improving them in a unified environment. Two datasets are used in this work. The results for the first one indicate that the percentage of failure to predict the time used in the test for all 181 rows, for all test times recorded, is 3% for mean time between failures (MTBF). SVM achieved a 97% success in predicting compared to previous work whose results indicated that the use of administrative delay time (ADT) achieved a statistically significant overall success rate of 93.5%. At the same time, the second dataset result indicates that the percentage of failure to predict the time used is 1.5% for MTBF; SVM achieved 98.5% prediction.",Agile; Big Data; Correlation Coefficient; Decision Making; Software Failure; Software Testing; Support Vector Machine,"Alajaleen, B; Alhroob, A",Isra University,2022.0,INTERNATIONAL JOURNAL OF SOFTWARE INNOVATION,IGI GLOBAL,,10.4018/IJSI.292025,20230520-160000,20230521-044735,"['failure', 'prediction', 'approach', 'in', 'agile', 'software', 'development']",True,20230521-205332,,,,
647,wos,"Understand, develop and enhance the learning process with big data","Purpose With the advent of the internet and communication technology, the penetration of e-learning has increased. The digital data being created by the educational and research institutions is also on the ascent. The growing interest in recent years toward big data, educational data mining and learning analytics has motivated the development of new analytical ways and approaches and advancements in learning settings. The need for using big data to handle, analyze this large amount of data is prime. This trend has started attracting the interest of educational institutions which have an important role in the development skills process and the preparation of a new generation of learners. A real revolution for education, it is based on this kind of terms that many articles have paid attention to big data for learning. How can analytics techniques and tools be so efficient and become a great prospect for the learning process? Big data analytics, when applied into teaching and learning processes, might help to improvise as well as to develop new paradigms. In this perspective, this paper aims to investigate the most promising applications and issues of big data for the design of the next-generation of massive e-learning. Specifically, it addresses the analytical tools and approaches for enhancing the future of e-learning, pitfalls arising from the usage of large data sets. Globally, this paper focuses on the possible application of big data techniques on learning developments, to show the power of analytics and why integrating big data is so important for the learning context. Design/methodology/approach Big data has in the recent years been an area of interest among innovative sectors and has become a major priority for many industries, and learning sector cannot escape to this deluge. This paper focuses on the different methods of big data able to be used in learning context to understand the benefits it can bring both to teaching and learning process, and identify its possible impact on the future of this sector in general. This paper investigates the connection between big data and the learning context. This connection can be illustrated by identifying the several main analytics approaches, methods and tools for improving the learning process. This can be clearer by the examination of the different ways and solutions that contribute to making a learning process more agile and dynamic. The methods that were used in this research are mainly of a descriptive and analytical nature, to establish how big data and analytics methods develop the learning process, and understand their contributions and impacts in addressing learning issues. To this end, authors have collected and reviewed existing literature related to big data in education and the technology application in the learning context. Authors then have done the same process with dynamic and operational examples of big data for learning. In this context, the authors noticed that there are jigsaw bits that contained important knowledge on the different parts of the research area. The process concludes by outlining the role and benefit of the related actors and highlighting the several directions relating to the development and implementation of an efficient learning process based on big data analytics. Findings Big data analytics, its techniques, tools and algorithms are important to improve the learning context. The findings in this paper suggest that the incorporation of an approach based on big data is of crucial importance. This approach can improve the learning process, for this, its implementation must be correctly aligned with educational strategies and learning needs. Research limitations/implications This research represents a reference to better understanding the influence and the role of big data in educational dynamic. In addition, it leads to improve existing literature about big data for learning. The limitations of the paper are given by its nature derived from a theoretical perspective, and the discussed ideas can be empirically validated by identifying how big data helps in addressing learning issues. Originality/value Over the time, the process that leads to the acquisition of the knowledge uses and receives more technological tools and components; this approach has contributed to the development of information communication and the interactive learning context. Technology applications continue to expand the boundaries of education into an anytime/anywhere experience. This technology and its wide use in the learning system produce a vast amount of different kinds of data. These data are still rarely exploited by educational practitioners. Its successful exploitation conducts educational actors to achieve their full potential in a complex and uncertain environment. The general motivation for this research is assisting higher educational institutions to better understand the impact of the big data as a success factor to develop their learning process and achieve their educational strategy and goals. This study contributes to better understand how big data analytics solutions are turned into operational actions and will be particularly valuable to improve learning in educational institutions.",E-learning; Higher education; Big data; Learning analytics; Learning process; Algorithm,"Sedkaoui, S; Khelfaoui, M",Universite de Khemis Miliana,2019.0,INFORMATION DISCOVERY AND DELIVERY,EMERALD GROUP PUBLISHING LTD,,10.1108/IDD-09-2018-0043,20230520-160000,20230521-044735,"['understand,', 'develop', 'and', 'enhance', 'the', 'learning', 'process', 'with', 'big', 'data']",True,20230521-205332,,,,
648,wos,Lean 4.0: A New Holistic Approach for the Integration of Lean Manufacturing Tools and Digital Technologies,"Due to the highly dynamic and competitive environment, organizations are led to rethink their processes and strategies. In the industrial field, Lean Manufacturing (LM) is widely recognized as a traditional approach to eliminate waste in the value stream and ensure the efficiency of production processes. On the other hand, Industry 4.0 has recently emerged, incurring disruptive changes in manufacturing processes based on a technology-driven approach. The integration of these two philosophies to achieve organizational goals is interesting in order to guarantee competitiveness, especially for manufacturing companies. This paper proposed an integration of LM tools and technologies 4.0, considering the perspectives of the industrial field in the digital era. Based on a three-step methodology, which included technological and industrial mapping, it was identified 25 synergy points. From interactions of LM tools mainly with Big Data Analytics, The Cloud, Virtual Simulation and Augmented Reality, multi-level circular diagrams pointed out the main contributions of Just in Time 4.0 (JIT 4.0), Kaizen 4.0, Kanban 4.0, Poka-Yoke 4.0, Value Stream Mapping 4.0 (VSM 4.0) and Total Productive Maintenance 4.0 (TPM 4.0). Also, five attributes of Lean 4.0 were identified, highlighting the integration between processes, devices and stakeholders; waste minimization; and autonomous, pointing to gains for the organization from this holistic integration approach.",Lean manufacturing; Industry 4.0; Lean 4.0; Digital technologies; Value chain,"Valamede, LS; Akkari, ACS",Universidade Presbiteriana Mackenzie,2020.0,INTERNATIONAL JOURNAL OF MATHEMATICAL ENGINEERING AND MANAGEMENT SCIENCES,INT JOURNAL MATHEMATICAL ENGINEERING & MANAGEMENT SCIENCES-IJMEMS,,10.33889/IJMEMS.2020.5.5.066,20230520-160000,20230521-044735,"['lean', '4.0:', 'a', 'new', 'holistic', 'approach', 'for', 'the', 'integration', 'of', 'lean', 'manufacturing', 'tools', 'and', 'digital', 'technologies']",True,20230521-205332,,,,
649,wos,Reproducible research and GIScience: an evaluation using AGILE conference papers,"The demand for reproducible research is on the rise in disciplines concerned with data analysis and computational methods. Therefore, we reviewed current recommendations for reproducible research and translated them into criteria for assessing the reproducibility of articles in the field of geographic information science (GIScience). Using this criteria, we assessed a sample of GIScience studies from the Association of Geographic Information Laboratories in Europe (AGILE) conference series, and we collected feedback about the assessment from the study authors. Results from the author feedback indicate that although authors support the concept of performing reproducible research, the incentives for doi ng this in practice are too small. Therefore, we propose concrete actions for individual researchers and the GIScience conference series to improve transparency and reproducibility. For example, to support researchers in producing reproducible work, the GIScience conference series could offer awards and paper badges, provide author guidelines for computational research, and publish articles in Open Access formats.",GIScience; Open science; Reproducible research; Data science; AGILE; Reproducible conference publications; Open access,"Nust, D; Granell, C; Hofer, B; Konkol, M; Ostermann, FO; Sileryte, R; Cerutti, V",University of Munster; Universitat Jaume I; Salzburg University; University of Twente; Delft University of Technology,2018.0,PEERJ,PEERJ INC,,10.7717/peerj.5072,20230520-160000,20230521-044735,"['reproducible', 'research', 'and', 'giscience:', 'an', 'evaluation', 'using', 'agile', 'conference', 'papers']",True,20230521-205332,,,,
650,wos,Data agility through clustered edge computing and stream processing,"The Internet of Things is underpinned by the global penetration of network-connected smart devices continuously generating extreme amounts of raw data to be processed in a timely manner. Supported by Cloud and Fog/Edge infrastructures - on the one hand, and Big Data processing techniques - on the other, existing approaches, however, primarily adopt a vertical offloading model that is heavily dependent on the underlying network bandwidth. That is, (constrained) network communication remains the main limitation to achieve truly agile IoT data management and processing. This paper aims to bridge this gap by defining Clustered Edge Computing - a new approach to enable rapid data processing at the very edge of the IoT network by clustering edge devices into fully functional decentralized ensembles, capable of workload distribution and balancing to accomplish relatively complex computational tasks. This paper also proposes ECStream Processing that implements Clustered Edge Computing using Stream Processing techniques to enable dynamic in-memory computation close to the data source. By spreading the workload among a cluster of collocated edge devices to process data in parallel, the proposed approach aims to improve performance, thereby supporting agile data management. The experimental results confirm that such a distributed in-memory approach to data processing at the very edge of an IoT network can outperform currently adopted Cloud-enabled architectures, and has the potential to address a wide range of IoT-related data-intensive time-critical scenarios.",cloud computing; clustered edge computing; data agility; edge computing; internet of things; stream processing,"Dautov, R; Distefano, S; Bruneo, D; Longo, F; Merlino, G; Puliafito, A",Kazan Federal University; University of Messina,2021.0,CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE,WILEY,,10.1002/cpe.5093,20230520-160000,20230521-044735,"['data', 'agility', 'through', 'clustered', 'edge', 'computing', 'and', 'stream', 'processing']",True,20230521-205332,,,,
651,wos,Advancing Design and Runtime Management of AI Applications with AI-SPRINT (Position Paper),"The adoption of Artificial intelligence (AI) technologies is steadily increasing. However, to become fully pervasive, AI needs resources at the edge of the network. The cloud can provide the processing power needed for big data, but edge computing is close to where data are produced and therefore crucial to their timely, flexible, and secure management. In this paper, we introduce the AI-SPRINT project, which will provide solutions to seamlessly design, partition, and run AI applications in computing continuum environments. AI-SPRINT will offer novel tools for AI applications development, secure execution, easy deployment, as well as runtime management and optimization: AI-SPRINT design tools will allow trading-off application performance (in terms of end-to-end latency or throughput), energy efficiency, and AI models accuracy while providing security and privacy guarantees. The runtime environment will support live data protection, architecture enhancement, agile delivery, runtime optimization, and continuous adaptation.",Cloud computing; fog computing; edge computing; AI and machine learning; Cloud trust security & privacy,"Sedghani, H; Ardagna, D; Matteucci, M; Fontana, GA; Verticale, G; Amarilli, F; Badia, R; Lezzi, D; Blanquer, I; Martin, A; Wawruch, K",Polytechnic University of Milan; Universitat Politecnica de Valencia; Technische Universitat Dresden,2021.0,"2021 IEEE 45TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2021)",IEEE COMPUTER SOC,,10.1109/COMPSAC51774.2021.00216,20230520-160000,20230521-044735,"['advancing', 'design', 'and', 'runtime', 'management', 'of', 'ai', 'applications', 'with', 'ai-sprint', '(position', 'paper)']",True,20230521-205332,,,,
652,wos,Smart Cities Semantics and Data Models,"Data models and semantics are a key aspect for the valorization of data in cross-domain applications and to obtain knowledge/insights beyond the original applications (vertical use cases). An important role of Big Data and a key fundament of its success is this capacity to discover and extract new knowledge beyond the original use of data, in order to learn, optimize processes and understand the hidden rules of our world. This works presents the different data models from standardization bodies such as IEEE PAR2530, ITU-T FG DPM, ETSI ISG CIM and oneM2M, W3C SSN, OMA LwM2M etc. An analysis and comparative among all of them and also the opportunities to link them in order to guarantee that we can obtain the major value through co-operation among cities and different departments. This work is contextualized in the principles from the Open and Agile Smart Cites (OASC) and linked initiatives focused on data management cross-cities and large scale pilots.",Smart cities; Data models; Internet of things; Semantics; ETSI ISG CIM; ITU-T; oneM2M; FIWARE; Open and agile smart cities; OASC,"Jara, AJ; Serrano, M; Gomez, A; Fernandez, D; Molina, G; Bocchi, Y; Alcarria, R",University of Applied Sciences & Arts Western Switzerland; Ollscoil na Gaillimhe-University of Galway; Universidad Politecnica de Madrid,2018.0,PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY & SYSTEMS (ICITS 2018),SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-319-73450-7_8,20230520-160000,20230521-044735,"['smart', 'cities', 'semantics', 'and', 'data', 'models']",True,20230521-205332,,,,
653,wos,Harnessing The Power of the Internet of Things (IoT) to Achieve an Agile Business Education Model: A Visionary Paper,"The emergence of artificial intelligence, big data, and the Internet of Things (IoT) has shifted human-human, human-machine, and machine-machine interaction to a new level. This shift is affecting all aspects of society's behavior toward the adoption of technology. One important pillar of society that is especially impacted by this radical change is that of education. The advancement of new technologies as well as the occurrence of unexpected global events has forced education systems in many countries to look differently at traditional educational issues and work toward becoming a more agile education system. This means being responsive to any unpredicted changes that may occur in the education environment. Indeed, the agility of business schools and technological adaptability is one of the standards required by program accreditation organizations (i.e., AACSB). This paper discusses the application of IoT in business education, focusing on the opportunities, challenges, and paths forward this presents.",IoT; Business Education; Education Agility; Higher Education,"Qasim, A; El Refae, GA; Eletter, S; Al-Chahadah, AR",,2021.0,"2021 EIGHTH INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, SYSTEMS, MANAGEMENT AND SECURITY (IOTSMS)",IEEE,,10.1109/IOTSMS53705.2021.9704939,20230520-160000,20230521-044735,"['harnessing', 'the', 'power', 'of', 'the', 'internet', 'of', 'things', '(iot)', 'to', 'achieve', 'an', 'agile', 'business', 'education', 'model:', 'a', 'visionary', 'paper']",True,20230521-205332,,,,
654,wos,Let's DO - Automotive Platform for Interoperability,"Developing automotive software applications is one of the most challenging and time-consuming activities in the automotive product development cycle. As of today, classical automotive software applications communicate exclusively using vehicle-specific communication protocols such as Controller Area Network (CAN) and FlexRay communication buses. Automotive applications communicate using transport layer messages that are defined and configured for each vehicle system (car model). This hard-wired design makes out-of-the box integrations between heterogeneous automotive products virtually impossible. It also renders automotive integration projects to digital world (smart devices, cloud, big data, IoT gadgets) hard to develop and maintain. We present in this paper Let's DO, a novel platform for interoperability and data exchange between different noncoherent products, systems and devices (both automotive and nonautomotive). Let's DO platform abstracts automotive communication protocol messages in a unified message standard transported over IP-based Ethernet networks enabling interoperability, quick prototyping, code reuse, and allowing more agile and efficient automotive software development cycles.",Automotive Software; Prototyping; Digital Transformation,"ElHakim, R; Elqadi, A; Torky, M; Zayed, M; Farag, I; Agamawi, M",,2021.0,2021 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2021),IEEE,,10.1109/ICICT52872.2021.00054,20230520-160000,20230521-044735,"[""let's"", 'do', '-', 'automotive', 'platform', 'for', 'interoperability']",True,20230521-205332,,,,
655,wos,Project management: openings for disruption from AI and advanced analytics,"Purpose The purpose of this essay is to illustrate how project management pull and AI or analytics technology push are likely to result in incremental and disruptive evolution of project management capabilities and practices. Design/methodology/approach This paper is written as a critical essay reflecting the experience and reflections of the author with many ideas drawn from and extending selected items from project management, artificial intelligence (AI) and analytics literatures. Findings Neither AI nor sophisticated analytics is likely to elicit hands on attention from project managers, other than those producing AI or analytics-based artifacts or using these tools to create their products and services. However, through the conduit of packaged software support for project management, new tools and approaches can be expected to more effectively support current activities, to streamline or eliminate activities that can be automated, to extend current capabilities with the availability of increased data, computing capacity and mathematically based algorithms and to suggest ways to reconceive how projects are done and whether they are needed. Research limitations/implications This essay includes projections of possible, some likely and some unlikely, events and states that have not yet occurred. Although the hope and purpose are to alert readers to the possibilities of what may occur as logical extensions of current states, it is improbable that all such projections will come to pass at all or in the way described. Nonetheless, consideration of the future ranging from current trends, the interplay among intersecting trends and scenarios of future states can sharpen awareness of the effects of current choices regarding actions, decisions and plans improving the probability that the authors can move toward desired rather than undesired future states. Practical implications Project managers not involved personally with creating AI or analytics products can avoid mastering detailed skill sets in AI and analytics, but should scan for new software features and affordances that they can use enable new levels of productivity, net benefit creation and ability to sleep well at night. Originality/value This essay brings together AI, analytics and project management to imagine and anticipate possible directions for the evolution of the project management domain.",Project management; IS project management; Artificial intelligence; Business analytics; Big data; Agile development; CRISP-DM,"Niederman, F",Saint Louis University,2021.0,INFORMATION TECHNOLOGY & PEOPLE,EMERALD GROUP PUBLISHING LTD,,10.1108/ITP-09-2020-0639,20230520-160000,20230521-044735,"['project', 'management:', 'openings', 'for', 'disruption', 'from', 'ai', 'and', 'advanced', 'analytics']",True,20230521-205332,,,,
656,wos,"The adoption of Design Thinking, Agile Software Development and Co-creation concepts A case study of Digital Banking innovation","Acceleration of technology, especially the mobile internet, causes changes all aspects of human life, including in the banking sector. New emerging technology such as Artificial Intelligence, Blockchain, Big Data, and Cloud computing change the business and operation of the bank. The bank's services have become more personalized, furthermore change customers' lifestyles. Banks are competing to create innovations and breakthroughs to create added value and building a digital ecosystem with fintech and big tech companies in the era of sharing economy. This case study explores the process of creating digital innovation in banking institutions by focusing on adopting design thinking (DT), agile software development (ASD), and co-creation concepts for building digital banking platforms. The case study involved IT executives from four banks in Indonesia. Data were taken through semi-structured interviews and analyzed using NVIVO12. The implication of this research is to accelerate the process of digital banking innovation and produce high-quality digital banking platforms in terms of features and technology.",Digital Innovation; Digital Banking; Agile Software Development; Design Thinking; Co-creation,"Indriasari, E; Prabowo, H; Gaol, FL; Purwandari, B",Universitas Bina Nusantara; University of Indonesia,2021.0,2021 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON),IEEE,,10.1109/PlatCon53246.2021.9680763,20230520-160000,20230521-044735,"['the', 'adoption', 'of', 'design', 'thinking,', 'agile', 'software', 'development', 'and', 'co-creation', 'concepts', 'a', 'case', 'study', 'of', 'digital', 'banking', 'innovation']",True,20230521-205332,,,,
657,wos,Transformational shifts through digital servitization,"Manufacturers increasingly look to digitalization to drive service growth. However, success is far from guaranteed, and many firms focus too much on technology. Adopting a discovery-oriented, theories-in-use approach, this study examines the strategic organizational shifts that underpin digital servitization. Notwithstanding strong managerial and academic interest, this link between digitalization and servitization is still under-investigated. Depth interviews with senior executives and managers from a global market leader revealed that to achieve digital service-led growth, a firm and its network need to make three interconnected shifts: (1) from planning to discovery, (2) from scarcity to abundance, and (3) from hierarchy to partnership. Organizational identity, dematerialization, and collaboration play a key role in this transformation. For managers, the study identifies a comprehensive set of strategic change initiatives needed to ensure successful digital servitization.",Digital servitization; Digital transformation; Organizational culture; Agile mindset; Data-centric business model; Big data monetization,"Tronvoll, B; Sklyar, A; Sorhammar, D; Kowalkowski, C",Inland Norway University of Applied Sciences; Karlstad University; Linkoping University; Stockholm University; Hanken School of Economics,2020.0,INDUSTRIAL MARKETING MANAGEMENT,ELSEVIER SCIENCE INC,,10.1016/j.indmarman.2020.02.005,20230520-160000,20230521-044735,"['transformational', 'shifts', 'through', 'digital', 'servitization']",True,20230521-205332,,,,
658,wos,An Agile Governance of Big Data Analytics (BDA) Capabilities and Strategic Alignment to Support Malaysian Public Sector Performance: A Concept Paper,"The 11th Malaysia Plan has emphasized leverage on data (data-driven) that can contribute to the strategic organizational values and be critical to the national transformation agenda. Hence, the government has announced the implementation of the Big Data Analytics (BDA) to support in making accurate decisions; innovation in government services and strategic priorities; system delivery of responsive services; greater agility and performance management. However, BDA still poses a lot of expostulation due to the unsubstantial link between analytics capabilities and core strategic performance. Furthermore, most BDA is incapable to rigorously analyze data since big datasets are generally asymmetrical to performance. Thus, this paper aims to uncover how government agencies should acquire BDA capabilities to succeed in their BD investment to advocate performance. This paper includes a review of secondary sources on Malaysia's economy, social aspects, and technology; BDA, organization performance, government agencies; and Resource based Theory. The paper will contribute: theoretically, an empirically based framework and practically, recognizing the main areas of focus for BDA capability and OP and explaining the mechanisms through which they should be leveraged. The paper also attempts to add to literature on how more effective data-driven analytics strategies to align the performance of government agencies can be adopted. Notably, it can provide ideas to improve performance in government agencies involved in implementing national development strategies, including strengthening administrative functions, social infrastructure and also superior performance of the economy in line with the National Key Result Areas and Industrial Revolution 4.0.",Big Data; Big Data Analytics; Malaysian Public Sector; Performance Management,"Sani, MKJA; Zaini, MK; Sahid, NZ; Noordin, SA; Baba, J",Universiti Teknologi MARA; Universiti Teknologi MARA,2019.0,VISION 2025: EDUCATION EXCELLENCE AND MANAGEMENT OF INNOVATIONS THROUGH SUSTAINABLE ECONOMIC COMPETITIVE ADVANTAGE,INT BUSINESS INFORMATION MANAGEMENT ASSOC-IBIMA,,,20230520-160000,20230521-044735,"['an', 'agile', 'governance', 'of', 'big', 'data', 'analytics', '(bda)', 'capabilities', 'and', 'strategic', 'alignment', 'to', 'support', 'malaysian', 'public', 'sector', 'performance:', 'a', 'concept', 'paper']",False,20230521-205332,,,,
659,wos,ICSSP 2018-Special issue introduction,"The International Conference on Software and System Processes (ICSSP) provides a leading forum for the exchange of research outcomes and industrial best practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, May 26 to 27, 2018, colocated with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand by recognizing the demands on processes that include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. This special issue includes the revised and extended versions of the five highest ranked full research papers and industry experience papers of ICSSP 2018, including the two award-winning papers.",agile methods; continuous development; data science; deployment; hybrid systems development; product duality; project management,"O'Connor, RV; Houston, D; Hebig, R; Kuhrmann, M",Dublin City University; Aerospace Corporation - USA; Chalmers University of Technology; TU Clausthal,2019.0,JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS,WILEY,,10.1002/smr.2174,20230520-160000,20230521-044735,"['icssp', '2018-special', 'issue', 'introduction']",False,20230521-205332,,,,
660,wos,Seven Principles for Rapid-Response Data Science: Lessons Learned from Covid-19 Forecasting,"In this article, we take a step back to distill seven principles out of our experience in the spring of 2020, when our 12-person rapid-response team used skills of data science and beyond to help distribute 340,000+ units of Covid PPE. This process included tapping into domain knowledge of epidemiology and medical logistics chains, curating a relevant data repository, developing models for short-term county-level death forecasting in the US, and building a website for sharing visualization (an automated AI machine). The principles are described in the context of working with Response4Life, a then-new nonprofit organization, to illustrate their necessity. Many of these principles overlap with those in standard data-science teams, but an emphasis is put on dealing with problems that require rapid response, often resembling agile software development. The technical work from this rapid response project resulted in a paper (Altieri et al. (2021)); see also this interview for more background (Yu and Meng (2021)).",Coronavirus; forecasting; county-level; data-science,"Yu, B; Singh, C",University of California System; University of California Berkeley; University of California System; University of California Berkeley,2022.0,STATISTICAL SCIENCE,INST MATHEMATICAL STATISTICS-IMS,,10.1214/22-STS855,20230520-160000,20230521-044735,"['seven', 'principles', 'for', 'rapid-response', 'data', 'science:', 'lessons', 'learned', 'from', 'covid-19', 'forecasting']",True,20230521-205332,,,,
661,wos,"iOntoBioethics: A Framework for the Agile Development of Bioethics Ontologies in Pandemics, Applied to COVID-19","Background: Few ontological attempts have been reported for conceptualizing the bioethics domain. In addition to limited scope representativeness and lack of robust methodological approaches in driving research design and evaluation of bioethics ontologies, no bioethics ontologies exist for pandemics and COVID-19. This research attempted to investigate whether studying the bioethics research literature, from the inception of bioethics research publications, facilitates developing highly agile, and representative computational bioethics ontology as a foundation for the automatic governance of bioethics processes in general and the COVID-19 pandemic in particular. Research Design: The iOntoBioethics agile research framework adopted the Design Science Research Methodology. Using systematic literature mapping, the search space resulted in 26,170 Scopus indexed bioethics articles, published since 1971. iOntoBioethics underwent two distinctive stages: (1) Manually Constructing Bioethics (MCB) ontology from selected bioethics sources, and (2) Automatically generating bioethics ontological topic models with all 26,170 sources and using special-purpose developed Text Mining and Machine-Learning (TM&ML) engine. Bioethics domain experts validated these ontologies, and further extended to construct and validate the Bioethics COVID-19 Pandemic Ontology. Results: Cross-validation of the MCB and TM&ML bioethics ontologies confirmed that the latter provided higher-level abstraction for bioethics entities with well-structured bioethics ontology class hierarchy compared to the MCB ontology. However, both bioethics ontologies were found to complement each other forming a highly comprehensive Bioethics Ontology with around 700 concepts and associations COVID-19 inclusive. Conclusion: The iOntoBioethics framework yielded the first agile, semi-automatically generated, literature-based, and domain experts validated General Bioethics and Bioethics Pandemic Ontologies Operable in COVID-19 context with readiness for automatic governance of bioethics processes. These ontologies will be regularly and semi-automatically enriched as iOntoBioethics is proposed as an open platform for scientific and healthcare communities, in their infancy COVID-19 learning stage. iOntoBioethics not only it contributes to better understanding of bioethics processes, but also serves as a bridge linking these processes to healthcare systems. Such big data analytics platform has the potential to automatically inform bioethics governance adherence given the plethora of developing bioethics and COVID-19 pandemic knowledge. Finally, iOntoBioethics contributes toward setting the first building block for forming the field of Bioethics Informatics.",bioethics; COVID-19; pandemic; bioethics ontology; bioethics informatics; iOntoBioethics; agile framework; design science research methodology,"Odeh, M; Kharbat, FF; Yousef, R; Odeh, Y; Tbaishat, D; Hakooz, N; Dajani, R; Mansour, A",King Hussein Cancer Center; University of West England; University of Jordan; University of Jordan; University of Jordan; Hashemite University; University of Richmond,2021.0,FRONTIERS IN MEDICINE,FRONTIERS MEDIA SA,,10.3389/fmed.2021.619978,20230520-160000,20230521-044735,"['iontobioethics:', 'a', 'framework', 'for', 'the', 'agile', 'development', 'of', 'bioethics', 'ontologies', 'in', 'pandemics,', 'applied', 'to', 'covid-19']",True,20230521-205332,,,,
662,wos,Value creation from analytics with limited data: a case study on the retailing of durably consumer goods,"Companies are pinning high hopes on competitive advantages through data analytics. So far, value gains through analytics have been demonstrated for IT-heavy and data-rich business areas. Yet, research has paid little attention to value creation through data analytics in the plethora of companies with limited data (Le. having transactions in the hundreds and attributes in the tens). Building on the literature of big data value creation and the resource-based view, we carried out an in-depth analytics case study with a retailer of renewable energy systems. Firms in this business area operate with expensive but few sales, so their available data are notoriously limited. Our findings demonstrate that data analytics capabilities and value creation mechanisms (democratise, contextualise, experiment with data, and execute data insights) are also effective in situations with limited data. Practice and research should therefore put not only emphasis on the volume and the variety of data but also on contextual factors related to managers (e.g. dear strategy, vision, leadership) and all employees (e.g. openness for agile working mode, data awareness).",data analytics; information systems (IS) value creation; resource theory; value creation mechanisms; machine learning(ML); retail; renewable energy systems (RES),"Hopf, K; Weigert, A; Staake, T",Otto Friedrich University Bamberg,,JOURNAL OF DECISION SYSTEMS,TAYLOR & FRANCIS LTD,,10.1080/12460125.2022.2059172,20230520-160000,20230521-044735,"['value', 'creation', 'from', 'analytics', 'with', 'limited', 'data:', 'a', 'case', 'study', 'on', 'the', 'retailing', 'of', 'durably', 'consumer', 'goods']",False,20230521-205332,,,,
663,wos,An End-to-End Recommendation System for Urban Traffic Controls and Management Under a Parallel Learning Framework,"A paradigm shift towards agile and adaptive traffic signal control empowered with the massive growth of Big Data and Internet of Things (IoT) technologies is emerging rapidly for Intelligent Transportation Systems. Generally, an adaptive signal control system fine-tunes signal timing parameters based on pre-defined control hyperparameters using instantaneous traffic detection information. Once traffic pattern changes, those hyperparameters (e.g., maximum and minimum green times) need to be adjusted according to the evolution of traffic dynamics over a very short-term period. Such adjustment processes are usually conducted by professional and experienced traffic engineers. Here we present a human-in-the-loop parallel learning framework and its utilization in an end-to-end recommendation system that mimics and enhances professional signal control engineers' behaviors. The system has been deployed into a real-world application for an extended period in Hangzhou, China, where signal control hyperparameters are recommended based on large-scale multidimensional traffic datasets. Experimental evaluations demonstrate significant improvements in traffic efficiency through the use of our signal recommendation system.",Control systems; Urban areas; Timing; Adaptive systems; Real-time systems; Recurrent neural networks; Process control; Intelligent traffic control; traffic signal control; parallel learning; recommendation systems; deep neural networks,"Jin, JC; Guo, HF; Xu, J; Wang, X; Wang, FY","Chinese Academy of Sciences; Institute of Automation, CAS; Zhejiang University of Technology; Zhejiang University",2021.0,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,,10.1109/TITS.2020.2973736,20230520-160000,20230521-044735,"['an', 'end-to-end', 'recommendation', 'system', 'for', 'urban', 'traffic', 'controls', 'and', 'management', 'under', 'a', 'parallel', 'learning', 'framework']",True,20230521-205332,,,,
664,wos,Applications of Machine Learning for Electronic Warfare Emitter Identification and Resource Management,"Electronic warfare (EW) operators face a multitude of challenges when performing single-and distributed-platform sensing and jamming tasks in increasingly dense and agile threat environ-ments. During an engagement timeline, actions often must be taken quickly and based on the partial information available. Recently, the world has observed a boom in artificial intelligence, a suite of data-driven lateral technologies that has already disrupted multiple fields where autonomy and big data are key elements. Although it is not the solution to all EW tasks, artificial intelligence shows promise in offering potential solutions to improve EW efficiency and effectiveness through informed decision-making beyond the capability of a human operator. The Johns Hopkins Uni-versity Applied Physics Laboratory (APL) Precision Strike Mission Area has invested in research and development in the specific EW tasks of emitter identification and autonomous resource alloca-tion. This article presents promising results from these projects and describes recommended future work in these areas, as well as additional EW applications that may benefit from research in arti-ficial intelligence.",,"Casterline, KA; Watkins, NJ; Ward, JR; Li, WL; Thommana, MJ",Johns Hopkins University; Johns Hopkins University Applied Physics Laboratory,2022.0,JOHNS HOPKINS APL TECHNICAL DIGEST,JOHNS HOPKINS UNIV APPLIED PHYSICS LABORATORY LLC,,,20230520-160000,20230521-044735,"['applications', 'of', 'machine', 'learning', 'for', 'electronic', 'warfare', 'emitter', 'identification', 'and', 'resource', 'management']",True,20230521-205332,,,,
665,wos,SMVS: A Web-based Application for Graphical Visualization of Malay Text Corpus,"Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur'an corpus.",Big data; data visualization; knowledge representation; Qur'an knowledge; natural language processing,"Baseri, NBA; Abu Bakar, J; Ahmad, A; Jafferi, H; Zamri, MF",Universiti Utara Malaysia,2020.0,IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020),IEEE,,,20230520-160000,20230521-044735,"['smvs:', 'a', 'web-based', 'application', 'for', 'graphical', 'visualization', 'of', 'malay', 'text', 'corpus']",True,20230521-205332,,,,
666,wos,Digital twin framework for reconfigurable manufacturing systems (RMSs): design and simulation,"Faced with the global crisis of COVID-19 and the strong increase in customer demands, competition is becoming more intense between companies, on the one hand, and supply chains on the other. This competition has led to the development of new strategies to manage demand and increase market share. Among these strategies are the growing interest in sustainable manufacturing and the need for customizable products that create an increasingly complex manufacturing environment. Sustainable manufacturing and the need for customizable products create an environment of increased competition and constant change. Indeed, companies are trying to establish more flexible and agile manufacturing systems through several systems of reconfiguration. Reconfiguration contributes to an extension of the manufacturing system's life cycle by modifying its physical, organizational and IT characteristics according to the changing market conditions. Due to the rapid development of new information technology (such as IoT, Big Data analytics, cyber-physical systems, cloud computing and artificial intelligence), digital twins have become intensively used in smart manufacturing. This paper proposes a digital twin design and simulation model for reconfigurable manufacturing systems (RMSs).",Reconfigurable manufacturing system (RMS); Modular framework; Generic model; Digital twin (DT); SysML,"Touckia, JK; Hamani, N; Kermad, L",Universite Paris-VIII; Picardie Universites; Universite de Picardie Jules Verne (UPJV),2022.0,INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,SPRINGER LONDON LTD,,10.1007/s00170-022-09118-y,20230520-160000,20230521-044735,"['digital', 'twin', 'framework', 'for', 'reconfigurable', 'manufacturing', 'systems', '(rmss):', 'design', 'and', 'simulation']",True,20230521-205332,,,,
667,wos,Internet of Vehicles and Real-Time Optimization Algorithms: Concepts for Vehicle Networking in Smart Cities,"Achieving sustainable freight transport and citizens' mobility operations in modern cities are becoming critical issues for many governments. By analyzing big data streams generated through IoT devices, city planners now have the possibility to optimize traffic and mobility patterns. IoT combined with innovative transport concepts as well as emerging mobility modes (e.g., ridesharing and carsharing) constitute a new paradigm in sustainable and optimized traffic operations in smart cities. Still, these are highly dynamic scenarios, which are also subject to a high uncertainty degree. Hence, factors such as real-time optimization and re-optimization of routes, stochastic travel times, and evolving customers' requirements and traffic status also have to be considered. This paper discusses the main challenges associated with Internet of Vehicles (IoV) and vehicle networking scenarios, identifies the underlying optimization problems that need to be solved in real time, and proposes an approach to combine the use of IoV with parallelization approaches. To this aim, agile optimization and distributed machine learning are envisaged as the best candidate algorithms to develop efficient transport and mobility systems.",vehicle networking; Internet of Vehicles; IoT analytics; data analytics; agile optimization; distributed machine learning; smart cities,"Adelantado, F; Ammouriova, M; Herrera, E; Juan, AA; Shinde, SS; Tarchi, D",UOC Universitat Oberta de Catalunya; Universitat Politecnica de Valencia; University of Bologna,2022.0,VEHICLES,MDPI,,10.3390/vehicles4040065,20230520-160000,20230521-044735,"['internet', 'of', 'vehicles', 'and', 'real-time', 'optimization', 'algorithms:', 'concepts', 'for', 'vehicle', 'networking', 'in', 'smart', 'cities']",True,20230521-205332,,,,
668,wos,Management Perspectives towards the Data-Driven Organization in the Energy Sector,"This paper explores the current attitudes of managers and executives working in the energy sector towards the Data-Driven Organizational Model implied by Big Data. The aim is to explore and understand the current mindset of senior decision makers, since their success depends as much on cognitive and behavioral processes as on their technical competences. We adopt a grounded-theory approach, developing models of understanding and belief abductively, driven by the data obtained from participants through a reflection guide. We find that managers differ significantly in their understanding and engagement with their challenges; they display interest but differ in their commitment and enthusiasm; they identify a lack of strategy and skills as current barriers; and they are currently unwilling to trust data, treating evidence according to their own prior commitments. This is a significant barrier to establishing the Data-Driven Organizational Model. These findings raise concerns, and the paper concludes that by considering initiatives for implementing more agile and forward-looking approaches, establishing a data-driven organizational culture, and managing such changes effectively.",data-driven organizational model; big data; big data analytics; digitalization; energy; EU Green Deal,"Pugna, IB; Boldeanu, DM; Gheorghe, M; Cozgarea, G; Cozgarea, AN",Bucharest University of Economic Studies,2022.0,ENERGIES,MDPI,,10.3390/en15165775,20230520-160000,20230521-044735,"['management', 'perspectives', 'towards', 'the', 'data-driven', 'organization', 'in', 'the', 'energy', 'sector']",True,20230521-205332,,,,
669,wos,Applications of Machine Learning for Electronic Warfare Emitter Identification and Resource Management,"Electronic warfare (EW) operators face a multitude of challenges when performing single- and distributed-platform sensing and jamming tasks in increasingly dense and agile threat environments. During an engagement timeline, actions often must be taken quickly and based on the partial information available. Recently, the world has observed a boom in artificial intelligence, a suite of data-driven lateral technologies that has already disrupted multiple fields where autonomy and big data are key elements. Although it is not the solution to all EW tasks, artificial intelligence shows promise in offering potential solutions to improve EW efficiency and effectiveness through informed decision-making beyond the capability of a human operator. The Johns Hopkins University Applied Physics Laboratory (APL) Precision Strike Mission Area has invested in research and development in the specific EW tasks of emitter identification and autonomous resource allocation. This article presents promising results from these projects and describes recommended future work in these areas, as well as additional EW applications that may benefit from research in artificial intelligence.",,"Casterline, KA; Watkins, NJ; Ward, JR; Li, WL; Thommana, MJ",Johns Hopkins University; Johns Hopkins University Applied Physics Laboratory,2022.0,JOHNS HOPKINS APL TECHNICAL DIGEST,JOHNS HOPKINS UNIV APPLIED PHYSICS LABORATORY LLC,,,20230520-160000,20230521-044735,"['applications', 'of', 'machine', 'learning', 'for', 'electronic', 'warfare', 'emitter', 'identification', 'and', 'resource', 'management']",True,20230521-205332,,,,
670,wos,Requirements capture and comparative analysis of open source versus proprietary service oriented architecture,"Service Oriented Architecture (SOA) integrates information systems towards an agile and reusable service-based connectivity. It is an approach amalgamating large scale private/public computer systems and other resources with continuous phenomenal advent evolution and leveraging of the World Wide Web (WWW, commonly referred to as the Web) social media, mobile communications, Big Data (BD), data analytics, Machine Learning (ML) based optimisation, Cloud Computing (CC) and Internet of Things (IoT), commonly known as Advanced Technologies (AT). Implementing SOA, whether Open Source Software (OSS) or proprietary or absolute freeware is a choice to be made which depends on the organisation's requirements in light of AT as well as a host of delivery and security concerns. In this paper, a comparative analysis of an open source vs. proprietary SOA for large scale computer systems servicing AT is presented by examining their main efficacies, features, advantages and disadvantages and capturing their generic technical functional and non-functional requirements in a unified manner. Furthermore, the SOA evaluation criteria, recommendations and conclusions are also presented.",SOA; Open source; Closed source proprietary; Requirements capture; Advanced technologies; Web services access; Web 1.0/2.0/3.0/4./5.0/6.0,"Bamhdi, A",Umm Al Qura University,2021.0,COMPUTER STANDARDS & INTERFACES,ELSEVIER,,10.1016/j.csi.2020.103468,20230520-160000,20230521-044735,"['requirements', 'capture', 'and', 'comparative', 'analysis', 'of', 'open', 'source', 'versus', 'proprietary', 'service', 'oriented', 'architecture']",True,20230521-205332,,,,
671,wos,Developing a Virtual Smart Total Learning Environment for Future Teaching-Learning System,"The world of education system after this COVID-19 pandemic will have to change its dimension to map the needs of learners. The proposed framework is focused on transforming the learning experience into two possible ways like online and on-campus learning through groundbreaking & agile methodologies. The new interfaces for learners will be included like Gamification, animated tutorial etc. The framework designed here is the outcome of the e-learning experiences of the authors and it tries to add all relevant technologies with cutting-edge research to provide inspirational and transformative knowledge to learners of all ages, social status, communities who form worldwide communities of special-learners. It will rise to the occasion to use its open source technology along with the emerged technologies like IoT, 5G etc, to transcend physical and social borders. This framework is a total learning environment as it will incorporate all possible latest technologies like big data and machine learning. The e-learning system possesses features like personalized e-learning, anomaly detection, student performance monitoring, dynamic content preparations, students' satisfaction monitoring etc. The new framework will include big data, cloud applications, machine learning and artificial intelligence to make the system faster, efficient and smart. The new features will make the e-learning system based on Virtual Smart Total Learning Environment (VSTLE) more technologically sound and efficient in processing, predicting, evaluating and making storage backup. This framework is designed in such a way that the minimum human intervention will be needed for its functioning. As a result, the final output will be more accurate as compared to other e-learning systems available.",smart; virtual; learning-environment; machine learning; big data; adaptive learning,"Akour, MA; Das, A",,2020.0,"PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (IEEE TALE 2020)",IEEE,,10.1109/TALE48869.2020.9368373,20230520-160000,20230521-044735,"['developing', 'a', 'virtual', 'smart', 'total', 'learning', 'environment', 'for', 'future', 'teaching-learning', 'system']",True,20230521-205332,,,,
672,wos,An Agile Sample Maintenance Approach for Agile Analytics,"Agile analytics can help organizations to gain and sustain a competitive advantage by making timely decisions. Approximate query processing (AQP) is one of the useful approaches in agile analytics, which facilitates fast queries on big data by leveraging a pre-computed sample. One problem such a sample faces is that when new data is being imported, re-sampling is most likely needed to keep the sample fresh and AQP results accurate enough. Re-sampling from scratch for every batch of new data, called the full re-sampling method and adopted by many existing AQP works, is obviously a very costly process, and a much quicker incremental sampling process, such as reservoir sampling, may be used to cover the newly arrived data. However, incremental update methods suffer from the fact that the sample size cannot be increased, which is a problem when the underlying data distribution dramatically changes and the sample needs to be enlarged to maintain the AQP accuracy. This paper proposes an adaptive sample update (ASU) approach that avoids re-sampling from scratch as much as possible by monitoring the data distribution, and uses instead an incremental update method before a re-sampling becomes necessary. The paper also proposes an enhanced approach (T-ASU), which tries to enlarge the sample size without re-sampling from scratch when a bit of query inaccuracy is tolerable to further reduce the sample update cost. These two approaches are integrated into a state-of-the-art AQP engine for an extensive experimental study. Experimental results on both real-world and synthetic datasets show that the two approaches are faster than the full re-sampling method while achieving almost the same AQP accuracy when the underlying data distribution continuously changes.",,"Zhang, HB; Zhang, YZ; He, ZY; Jing, YA; Zhang, K; Wang, XS",Fudan University,2020.0,2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2020),IEEE COMPUTER SOC,,10.1109/ICDE48307.2020.00071,20230520-160000,20230521-044735,"['an', 'agile', 'sample', 'maintenance', 'approach', 'for', 'agile', 'analytics']",True,20230521-205332,,,,
673,wos,Digital Contact Tracing Based on a Graph Database Algorithm for Emergency Management During the COVID-19 Epidemic: Case Study,"Background: The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. Objective: Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. Methods: A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. Results: An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government's big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. Conclusions: During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing.",COVID-19; digital contact tracing; emergency management; graph database; big data; visualization; China,"Mao, ZJ; Yao, H; Zou, Q; Zhang, WT; Dong, Y",Huazhong University of Science & Technology; Huazhong University of Science & Technology; China University of Mining & Technology,2021.0,JMIR MHEALTH AND UHEALTH,"JMIR PUBLICATIONS, INC",,10.2196/26836,20230520-160000,20230521-044735,"['digital', 'contact', 'tracing', 'based', 'on', 'a', 'graph', 'database', 'algorithm', 'for', 'emergency', 'management', 'during', 'the', 'covid-19', 'epidemic:', 'case', 'study']",True,20230521-205332,,,,
674,wos,Energy Efficient Double Critic Deep Deterministic Policy Gradient Framework for Fog Computing,"Nowadays the data is growing at a faster pace and the big data applications are required to be more agile and flexible. There is a need for a decentralized model to carry out the required substantial amount of computation across edge devices as they has led to the innovation of fog computing. Energy consumption among the edge devices is one of the potential threatening issues in fog computing. Their high energy demand also contributes to higher computation cost. In this paper Double Critic (DC) approach is enforced over the Deep Deterministic Policy Gradient (DDPG) technique to design the DC-DDPG framework which formulates high quality energy efficiency policies for fog computing. The performance of the proposed framework is outstanding compared to existing works based on the metrics like energy consumption, response time, total cost, and throughput. They are measured under two different fog computing scenarios i.e., fog layer with multiple entities in a region and fog layer with multiple entities in multiple regions. Mathematical modeling reveals that the energy efficiency policies formulated are of high quality as they satisfy the quality assurance metrics, such as empirical correctness, robustness, model relevance, and data privacy.",Deterministic Policy Gradient; Fog computing; Energy; Q-learning; Double Critic,"Krishnamurthy, B; Shiva, SG",Siddaganga Institute of Technology; University of Memphis,2022.0,2022 IEEE WORLD AI IOT CONGRESS (AIIOT),IEEE,,10.1109/AIIoT54504.2022.9817157,20230520-160000,20230521-044735,"['energy', 'efficient', 'double', 'critic', 'deep', 'deterministic', 'policy', 'gradient', 'framework', 'for', 'fog', 'computing']",True,20230521-205332,,,,
675,wos,CHALLENGES OF LOGISTICS IN THE CONCEPT OF INDUSTRY 4.0,"Concerns about the marginalization of Europe in world production prompted the development of the concept of Industry 4.0, which will allow highly developed countries to regain the status of leaders in industrialization. As part of the proposed concept, which is to form the basis of the fourth industrial revolution, it is planned to closely connect physical objects with the information network. The application of new production strategies, such as Agile Manufacturing and Mass Customization, are causing manufacturing companies to be transformed into integrated networks in which they combine their core competencies. The idea of Industry 4.0 is to create sophisticated business networks, connected by intelligent resources communicating via the internet, using well-known and already used technologies, including the Internet of Things (IoT), big data, cloud computing, etc. As a result of applying these solutions, autonomous systems exchange data between themselves and the boundaries between enterprises are disappearing more and more. Therefore, the aim of the article is to identify key challenges of today's logistics (called Logistics 4.0) in the perspective of the development of the industry concept 4.0.",Industry 4.0; Logistics 4.0; production networks management; Internet of Things (IoT),"Saniuk, S; Graczyk, M; Kulyk, P",University of Zielona Gora,2019.0,8TH CARPATHIAN LOGISTICS CONGRESS (CLC 2018),TANGER LTD,,,20230520-160000,20230521-044735,"['challenges', 'of', 'logistics', 'in', 'the', 'concept', 'of', 'industry', '4.0']",False,20230521-205332,,,,
676,wos,Reimagining the Fashion Retail Industry Through the Implications of COVID-19 in the Gulf Cooperation Council (GCC) Countries,"The COVID-19 pandemic has disrupted the fashion retail industry. The Gulf Cooperation Council Countries (GCC) is the home of family-centric shopping malls and brick and mortar stores (B&M). This article aims to provide a critical look at the business strategies which the fashion retail companies need to adopt to provide consumers with an integrated online and B&M service which will be essential to survive in the post-pandemic business environment. This article is based on the rich industry experience of the authors and extensive secondary research on the business strategies being employed by the leading fashion retailers in the GCC region to combat the pandemic disruption. The study highlights the importance of a comprehensive rethink on business strategy for the GCC fashion retailers with adoption of digitalization technologies and an adaptive supply chain as the pillars to survive the post-pandemic normal of business environments. The study concludes with a look to the future strategies for fashion retailers in developing a digitalization blueprint, using cloud technologies and big data analytics, leveraging social media, building an agile and adaptive supply chain with omnichannel capability, and ensuring that future products and services are sustainable and socially responsible.",COVID-19; fashion retail; GCC; e-commerce; business strategy; B&M stores,"Rao, PHN; Vihari, NS; Jabeen, SS",,2021.0,FIIB BUSINESS REVIEW,SAGE PUBLICATIONS INDIA  PVT LTD,,10.1177/23197145211039580,20230520-160000,20230521-044735,"['reimagining', 'the', 'fashion', 'retail', 'industry', 'through', 'the', 'implications', 'of', 'covid-19', 'in', 'the', 'gulf', 'cooperation', 'council', '(gcc)', 'countries']",True,20230521-205332,,,,
677,wos,Collective Intelligence Systems from an Organizational Perspective,"In this talk, we consider Collective Intelligence (CI) systems [11-13, 15] from an organizational perspective. CI systems offer a solution to problems that need cognitive skills, problem-solving capabilities, knowledge, know-how or experience at large scale. They help to facilitate and streamline large-scale problem-solving endeavours. The organizational perspective on CI systems offers us two strands of discussion. On the one hand, it can be about understanding the potential of CI systems for today's organizations. On the other hand, CI systems can be considered as organizations themselves and can be investigated as such. We start by reviewing the state-of-the art of CI frameworks [19, 20]. What are the essential building blocks of a CI system? Who uses them? For what, how and why? We come up with a generalized framework [19] that serves us as a basis for further investigations. From a governance perspective, today's organizations are recursive-feedback control systems, usually expressed in the form of process-oriented management [5, 9, 10], see also [6, 7]. A deeper look reveals a plethora of different styles of organizational culture [14, 18]. Still, viable organizations have in common certain essential sub systems, which are policy making, external and internal steering, the primary activities and an informational backbone [13]. How can we exploit CI systems to support these organizational building blocks? Can CI systems be made an integral part of organizations to make them more stable towards distortions; more adaptive towards an ever changing environment; more agile towards the organization's innovative potential? Answers to such questions would free CI systems from being niche players in certain large-scale problem-solving initiatives. Reflecting back from the potential of CI systems in today's organizations, we ask: what can be learned with respect to the design and implementation of future CI systems; and: how to break the silos, i.e., how to integrate CI systems with related paradigms such as knowledge management systems, compare also with [4, 8, 16, 17] and latest computing resources such as big data and the data science toolkit?",collective intelligence; crowdsourcing; human computer interaction; Web 2.0,"Draheim, D",Tallinn University of Technology,2019.0,IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES,ASSOC COMPUTING MACHINERY,,10.1145/3366030.3368457,20230520-160000,20230521-044735,"['collective', 'intelligence', 'systems', 'from', 'an', 'organizational', 'perspective']",False,20230521-205332,,,,
678,wos,Big Data Analytics APIs Architecture for Formative Assessors,"This Research to Practice Full Paper is driven by the question: Within limited time resources available to trainers in projects for Big Data Analytics (BDA) problems, how can they define project requirements for Formative Assessment (FA) actions? The paper suggests BDA APIs architecture as helping tool for formative assessors. It helps them effectively produce and adapt visual diagnostic reports for FA-actions in agile based requirements (i.e. features) definition. The paper presents two core architectures: Architecture for a parametrized feature-descriptor-system to define/refine a BDA API feature and its visual diagnostic reports, and an initial resources architecture for BDA API to initialize an analytics algorithm with its input big data sets. Clarifying visually the trainee's challenges (i.e. incremental features in a BDA API) is our main FA action. The FA action is designed based on Csikszentmihalyi's flow model to support a trainee in matching balance between his/her challenges and his/her skills. To test the architecture's functions, the paper has test setups for two formal projects (each has 1 to 6 trainees) and two informal projects (each has 1 to 3 trainees). The projects are to attack BDA problems in learning analytics and in image automatic classification. The test results show that the visual diagnostic reports produced by the trainers are very effective in clarifying visually incremental BDA API features not only for simple classifiers (i.e. classical data mining algorithms) but also for complex classifiers (i.e. deep learning algorithms). The results show also how visual diagnostic reports are easily produced for comparing the algorithm performances using different input big data sets, whereas other reports are produced for comparing performances between different algorithms, using one input data set. Related works are also discussed to show the architecture's differences and advantages. Its main advantages are: 1) it enables the trainers to use deep learning algorithms beside classical data mining algorithms in its BDA API parameterizable feature descriptors for visual diagnostic reports. 2) The descriptors can be extended, reused, shared, and scaled out to help trainers in other universities providing flow model based FA actions. 3) Finally, it has extensions to integrate other theoretical frameworks like Buckingham Shum and Deakin Crick's framework for dispositional learning analytics instead of the used flow model.",assessment in engineering education; planning for formative assessment; Big Data Analytics,"Mahfouz, W; Wuttke, HD",Technische Universitat Ilmenau,2021.0,2021 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2021),IEEE,,10.1109/FIE49875.2021.9637431,20230520-160000,20230521-044735,"['big', 'data', 'analytics', 'apis', 'architecture', 'for', 'formative', 'assessors']",True,20230521-205332,,,,
679,wos,Key Considerations in Optimizing the Deployment of Big Data Analytics-as-a-Service Utilizing Cloud Architecture and Machine Learning,"Cloud computing is usually associated with storage and processing on a back-end server that is accessible over the Internet. Increasingly the Cloud has transcended the boundaries of storage and retrieval and moved into the realms of offering services, performing analytics, undertaking collaborations and much more while ensuring security and privacy of data for the user applications. As a result, deployment of any application or service on the Cloud requires a carefully constructed strategy - especially with respect to managing the dynamicity and balancing of that deployment. This strategic need for Cloud Architecture is further important because of the advent of Big Data and Analytics-as-a-Service (AaaS). The Analytical services utilizing Big Data are not limited to a specific Cloud server. Instead, Big Data Analytics are carried out across the entire spectrum of Internet-based nodes ranging from the back-end Cloud server through to the End-user Internet of Things (IoT) devices and everything in between. The time, location and granularity of Big Data Analytics on and off the Cloud is a crucial strategic question. The Quality of Service (QoS) and security of deployment of Analytics-as-a-Service depends on the key considerations in answering this question. This strategic question relates to the dynamic decision making required to deploy a Cloud-based Big Data Analytics solution - which, in turn, is based on understanding the current conditions security, volume, performance, criticality, among others - of Cloud-based deployment. The need for automation and intelligence with the dynamic optimization of Analytics on the Cloud requires the application of Machine Learning. This paper explores these key considerations of the strategic aspects of deploying Big Data Analytics using a Cloud Architecture. The practical application of these key considerations is demonstrated through the education domain. Finally, this paper proposes areas of research emanating from the study of Cloud Architecture and Machine Learning for Big Data Analytics.",Data Analytics; Analytics-as-a-Service; Big data strategies; IoT; Cloud Architecture; Cloud deployment; Machine Learning; Agile business,"Unhelkar, B; Rao, VT",State University System of Florida; University of South Florida,2020.0,PROCEEDINGS OF ICETIT 2019: EMERGING TRENDS IN INFORMATION TECHNOLOGY,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-030-30577-2_73,20230520-160000,20230521-044735,"['key', 'considerations', 'in', 'optimizing', 'the', 'deployment', 'of', 'big', 'data', 'analytics-as-a-service', 'utilizing', 'cloud', 'architecture', 'and', 'machine', 'learning']",True,20230521-205332,,,,
680,wos,Rethinking data-driven decision support in flood risk management for a big data age,"Decision-making in flood risk management is increasingly dependent on access to data, with the availability of data increasing dramatically in recent years. We are therefore moving towards an era of big data, with the added challenges that, in this area, data sources are highly heterogeneous, at a variety of scales, and include a mix of structured and unstructured data. The key requirement is therefore one of integration and subsequent analyses of this complex web of data. This paper examines the potential of a data-driven approach to support decision-making in flood risk management, with the goal of investigating a suitable software architecture and associated set of techniques to support a more data-centric approach. The key contribution of the paper is a cloud-based data hypercube that achieves the desired level of integration of highly complex data. This hypercube builds on innovations in cloud services for data storage, semantic enrichment and querying, and also features the use of notebook technologies to support open and collaborative scenario analyses in support of decision making. The paper also highlights the success of our agile methodology in weaving together cross-disciplinary perspectives and in engaging a wide range of stakeholders in exploring possible technological futures for flood risk management.",big data; cloud computing; data hypercube; data science; flexible querying; semantic web; uncertainty,"Towe, R; Dean, G; Edwards, L; Nundloll, V; Blair, G; Lamb, R; Hankin, B; Manson, S",N8 Research Partnership; RLUK- Research Libraries UK; Lancaster University; Royal Dutch Shell; UK Centre for Ecology & Hydrology (UKCEH); N8 Research Partnership; RLUK- Research Libraries UK; Lancaster University,2020.0,JOURNAL OF FLOOD RISK MANAGEMENT,WILEY,,10.1111/jfr3.12652,20230520-160000,20230521-044735,"['rethinking', 'data-driven', 'decision', 'support', 'in', 'flood', 'risk', 'management', 'for', 'a', 'big', 'data', 'age']",True,20230521-205332,,,,
681,wos,Large scale quality transformation in hybrid development organizations - A case study,"As the software industry transitions to a subscription-based software-as-a-service (SaaS) model, soft-ware development companies are transforming to hybrid development organizations with increased adoption of Agile and Continuous Integration/ Continuous Delivery (CI/CD) development practices for newer products while continuing to use Waterfall methods for older products. This transformation is a huge undertaking impacting all aspects of the software development life cycle (SDLC), including the quality management system. This paper presents a case study of a large-scale transformation of a legacy quality management system to a modern system developed and implemented at Cisco Systems. The framework for this transformation is defined by six distinct areas: metrics, process, measurement, reporting, quality analytics, and culture & leadership. Our implementation leveraged recent advances in Machine Learning (ML), Artificial Intelligence (AI), connected data, integrated operations, and big data technologies to solve the challenges created by a hybrid software development organization. We believe this case study will help researchers and industry leaders understand the benefits and potential challenges of such sizeable transformations. (c) 2020 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",Quality transformation; Quality management system; Agile; Waterfall; Hybrid development organization,"Pradhan, S; Nanniyur, V",Cisco Systems Inc,2021.0,JOURNAL OF SYSTEMS AND SOFTWARE,ELSEVIER SCIENCE INC,,10.1016/j.jss.2020.110836,20230520-160000,20230521-044735,"['large', 'scale', 'quality', 'transformation', 'in', 'hybrid', 'development', 'organizations', '-', 'a', 'case', 'study']",True,20230521-205332,,,,
682,wos,Management Consulting Business Models: Operations through and for Digital Transformation,"Management consulting as a service has become part of almost every company's daily business. The growth is being exponential, even with all the non-consensual issues and controversies in the industry. However, the market is increasingly competitive, with new competitors coming from everywhere. At the same time, the world is changing at a speed never seen before, and the challenges are several: automatization, scarcity of resources, democratization of the information, big data, and regulation are some examples. Thus, it's not possible for consulting firms to keep providing the market needs without adapting continuously their own business models. The companies that can outperform these challenges more efficiently will win against the competitors. Investigate which strategies and mechanisms adopt to be agile and flexible enough, in which sectors invest the most, and how reinvent their business model in order to be resilient in a fast changing and technological world are the main objectives of this research. Several interviews with the top management of fifteen of the biggest consulting companies in Portugal were conducted. The results suggested that companies are now trying to differentiate by the services delivered, and these business models' adaptation to the digital transformation is rather than a reality, a need.",Management Consulting; Digital Transformation; Business Models,"Jeronimo, C; Pereira, L; Sousa, H",Instituto Universitario de Lisboa,2019.0,"2019 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING, TECHNOLOGY AND INNOVATION (ICE/ITMC)",IEEE,,,20230520-160000,20230521-044735,"['management', 'consulting', 'business', 'models:', 'operations', 'through', 'and', 'for', 'digital', 'transformation']",True,20230521-205332,,,,
683,wos,Evolving profiles of financial risk management in the era of digitization: The tomorrow that began in the past,"The initial phases of digitization have automatized the front-end of banks and financial institutions (FIs). This paper documents the automation of the back-end in the current wave of digitization. In particular, it highlights the use of technology in streamlining risk management and its potential to provide competitive advantage to the FIs embracing digitization. For instance, automated big data credit scoring tools built on predictive analytics and machine learning algorithms are employed to examine several credit propositions. This can accurately construct the credit worthiness and risk profile of public, even without any credit history. These developments can widen the access of credit and other financial services to the society. However, on a cautionary note, this study emphasizes that although digitization of back-end financial transactions carries substantive advantages, the FIs must be guarded against cyber, outsourcing, financial exclusion, and macrofinance risks that can manifest with this automation. In this backdrop, the need for robust yet agile regulations and supervisory counsel to control and exploit the digitization towards optimal benefits for banks and FIs and society at large, acquires salience. Furthermore, regulators and supervisory authorities can mitigate the digitization risks and prevent any public fallout by leveraging the use of digitization itself.",,"Chakraborty, G",KREA University; IFMR - Graduate School of Business (GSB); University of Madras,2020.0,JOURNAL OF PUBLIC AFFAIRS,WILEY,,10.1002/pa.2034,20230520-160000,20230521-044735,"['evolving', 'profiles', 'of', 'financial', 'risk', 'management', 'in', 'the', 'era', 'of', 'digitization:', 'the', 'tomorrow', 'that', 'began', 'in', 'the', 'past']",True,20230521-205332,,,,
684,wos,Cyber-Physical Systems in Smart City: Challenges and Future Trends for Strategic Research,"Modern cities today compete with each other to be smarter, maintain a more sustainable with high-quality living, acquire talents, and provide jobs. This digital transformation through agile drivers will help address the increasing challenges of urbanization in a couple of decades. The Cyber-Physical System (CPS) is becoming pervasive in every aspect of smart city daily life and considered as one of the four fundamental conceptual approaches of the fourth generation industrial revolution (Industry 4.0). CPS used to describe the next generation of a diverse spectrum of complicated, multidisciplinary, physically comprehending engineered systems that integrates embedded cyber aspects into the physical world. It implants computation technologies, communication control, the convergence of information, and physical processes together with strategic importance internationally. CPS is still a vast research area. As a result, it opens venues for applications across multiple scales. This paper presents an in-depth survey of the related works, focusing on the design and how it relates to different research fields, current concepts, and real-life applications to understand CPS more precisely. Further, it enumerates an extensive set of CPS challenges and opportunities, introducing visionary ideas, research strategies, and future trends expected for future-oriented technological solutions, like cloud computing, Internet of Things, and Big Data. These technological solutions are to play a critical role in CPS research and have significant impacts on the smart city.",Cyber-physical systems; Smart city; Industry 4.0; Big Data; Cloud computing; Internet of Things; Research strategies; Future trends,"Juma, M; Shaalan, K",,2020.0,PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ADVANCED INTELLIGENT SYSTEMS AND INFORMATICS 2019,SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-030-31129-2_78,20230520-160000,20230521-044735,"['cyber-physical', 'systems', 'in', 'smart', 'city:', 'challenges', 'and', 'future', 'trends', 'for', 'strategic', 'research']",True,20230521-205332,,,,
685,wos,Infoxication in the Genomic Data Era and Implications in the Development of Information Systems,"We live in an age where data acquisition is no longer a problem and the real challenge is how to determine which information is the right one to take important and sometimes difficult decisions. Infoxication (also known as Infobesity or Information Overload) is a term used to describe the difficulty of adapting to new situations and effectively making decisions when there is too much information to manage. With the advent of the Big Data, infoxication is affecting critical domains such as Health Sciences, where tough decisions for patient's health is being taken every day based on heterogeneous, unconnected and sometimes conflicting information. In order to understand the magnitude of the challenge, based on the information publicly available about the genetic causes of the disease and using data quality assessment techniques, we performed an exhaustive analysis of the DNA variations that have been associated to the risk of suffering migraine headache. The same analysis has been repeated 8 months after, and the results have allowed us to exemplify i) how fragile is the information in this domain, ii) the difficulty of finding repositories of contrasted and reliable data, and iii) the need to have information systems that, far from integrating and storing huge volumes of data, are able to support the decision-making process by providing mechanisms agile and flexible enough to be able to adapt to the changing user needs.",Infoxication; Genomics; Information Systems; SILE method,"Palacio, AL; Lopez, OP",Universitat Politecnica de Valencia,2019.0,2019 13TH INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN INFORMATION SCIENCE (RCIS),IEEE,,,20230520-160000,20230521-044735,"['infoxication', 'in', 'the', 'genomic', 'data', 'era', 'and', 'implications', 'in', 'the', 'development', 'of', 'information', 'systems']",True,20230521-205332,,,,
686,wos,Smart hospitality: from smart cities and smart tourism towards agile business ecosystems in networked destinations,"Purpose Building on recent smart hospitality systematic reviews and extensive literature analyses, this paper aims to explore recent developments, themes and issues within smart hospitality. It synthesises existing knowledge, extrapolating forward and contributes to the future development of smart hospitality by serving as a reference to enrich academic/industry discussions and stimulate future research. Design/methodology/approach The research examined 8 recent review articles on smart hospitality and tourism and extracted 145 articles in peer-reviewed sources from Web of Science focussed on smart hospitality. These publications supported in-depth analysis to explore the body of knowledge and develop foresight for the future of smart hospitality within business ecosystems at tourism destinations. It synthesises knowledge and provides the basis for the development of a comprehensive in-depth research agenda in smart hospitality innovations as well as the formulation of agile hospitality ecosystems. Findings This paper illustrates that smart hospitality introduces disruptive innovations that affect the entire hospitality ecosystem. Smart hospitality takes advantage of smart cities and smart tourism towards establishing agile business ecosystems in networked destinations. Having reviewed the existing literature, the study developed a conceptual framework and introduced a comprehensive future research agenda. This includes the drivers of smart hospitality, namely, customer-centricity, personalisation, individualisation and contextualisation; marketing-driven hospitality excellence and metaverse; as well as operation agility, asset strategy, talent management and supplier interoperation. It also identified the foundations that provide the infostructure for smart hospitality, including ambient intelligence, big data, processes and sustainability, providing the capability blocks to co-create value for all stakeholders in the hospitality ecosystem. Originality/value This study conceptualises smart hospitality as a disruptive and innovative power that will affect the competitiveness of hospitality and tourism organisations as part of a comprehensive ecosystem. It identifies the key stakeholders and explores how they can take advantage of emerging developments. This paper proposes the drivers and foundation for future research on smart hospitality. The research provides a conceptual synthesis of the literature and the concepts that have been elaborated. The foundations are effectively the infostructure that enables the drivers to add value to different stakeholders. Key issues are identified to stimulate further research on the area to support smart hospitality development and adoption.",Smart hospitality; Hospitality ecosystem; Research directions,"Buhalis, DT; O'Connor, P; Leung, R",Bournemouth University; Hong Kong Polytechnic University; University of South Australia; I Shou University,2023.0,INTERNATIONAL JOURNAL OF CONTEMPORARY HOSPITALITY MANAGEMENT,EMERALD GROUP PUBLISHING LTD,,10.1108/IJCHM-04-2022-0497,20230520-160000,20230521-044735,"['smart', 'hospitality:', 'from', 'smart', 'cities', 'and', 'smart', 'tourism', 'towards', 'agile', 'business', 'ecosystems', 'in', 'networked', 'destinations']",True,20230521-205332,,,,
687,wos,A Framework for Partitioning Support Vector Machine Models on Edge Architectures,"Current IoT applications generate huge volumes of complex data that requires agile analysis in order to obtain deep insights, often by applying Machine Learning (ML) techniques. Support vector machine (SVM) is one such ML technique that has been used in object detection, image classification, text categorization and Pattern Recognition. However, training even a simple SVM model on big data takes a significant amount of computational time. Due to this, the model is unable to react and adapt in real-time. There is an urgent need to speedup the training process. Since organizations typically use the cloud for this data processing, accelerating the training process has the advantage of bringing down costs. In this paper, we propose a model partitioning approach that partitions the tasks of Stochastic Gradient Descent based Support Vector Machines (SGD-SVM) on various edge devices for concurrent computation, thus reducing the training time significantly. The proposed partitioning mechanism not only brings down the training time but also maintains the approximate accuracy over the centralized cloud approach. With a goal of developing a smart objection detection system, we conduct experiments to evaluate the performance of the proposed method using SGD-SVM on an edge based architecture. The results illustrate that the proposed approach significantly reduces the training time by 47%, while decreasing the accuracy by 2%, and offering an optimal number of partitions.",partitioning; edge computing; SGD-SVM,"Sahi, M; Al Maruf, M; Azim, A; Auluck, N",Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Ropar,2021.0,2021 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2021),IEEE,,10.1109/SMARTCOMP52413.2021.00062,20230520-160000,20230521-044735,"['a', 'framework', 'for', 'partitioning', 'support', 'vector', 'machine', 'models', 'on', 'edge', 'architectures']",True,20230521-205332,,,,
688,wos,"Operational Data-Driven Intelligent Modelling and Visualization System for Real-World, On-Road Vehicle Emissions-A Case Study in Hangzhou City, China","On-road vehicle emissions play a crucial role in affecting air quality and human exposure, particularly in megacities. In the absence of comprehensive traffic monitoring networks with the general lack of intelligent transportation systems (ITSs) and big-data-driven, high-performance-computing (HPC) platforms, it remains challenging to constrain on-road vehicle emissions and capture their hotspots. Here, we established an intelligent modelling and visualization system driven by ITS traffic data for real-world, on-road vehicle emissions. Based on the HPC platform (named City Brain) and an agile Web Geographic Information System (WebGISs), this system can map real-time (hourly), hyperfine (10 similar to 1000 m) vehicle emissions (e.g., PM2.5, NOx, CO, and HC) and associated traffic states (e.g., vehicle-specific categories and traffic fluxes) over the Xiaoshan District in Hangzhou. Our results show sharp variations in on-road vehicle emissions on small scales, which even fluctuated up to 31.2 times within adjacent road links. Frequent and widespread emission hotspots were also exposed. Over custom spatiotemporal scopes, we virtually investigated and visualized the impacts of traffic control policies on the traffic states and on-road vehicle emissions. Such results have important implications for how traffic control policies should be optimized. Integrating this system with chemical transport models and air quality measurements would bridge the technical gap between air pollutant emissions, concentrations, and human exposure.",big-data intelligent system; on-road vehicle emissions; traffic monitoring; hyperfine modelling; real-time visualization,"Wang, L; Chen, X; Xia, Y; Jiang, LH; Ye, JJ; Hou, TY; Wang, LQ; Zhang, YB; Li, MY; Li, Z; Song, Z; Jiang, YP; Liu, WP; Li, PF; Zhang, XY; Yu, SC",Zhejiang University; Hebei Agricultural University; China Meteorological Administration; Chinese Academy of Meteorological Sciences (CAMS),2022.0,SUSTAINABILITY,MDPI,,10.3390/su14095434,20230520-160000,20230521-044735,"['operational', 'data-driven', 'intelligent', 'modelling', 'and', 'visualization', 'system', 'for', 'real-world,', 'on-road', 'vehicle', 'emissions-a', 'case', 'study', 'in', 'hangzhou', 'city,', 'china']",True,20230521-205332,,,,
689,wos,Brains for Dementia Research: Evolution in a Longitudinal Brain Donation Cohort to Maximize Current and Future Value,"Brain banking has a long and distinguished past, contributing greatly to our understanding of human neurological and psychiatric conditions. Brain banks have been operationally diverse, collecting primarily end stage disease, with variable quality clinical data available, yet it is now recognized the most informative brain donations are from those in longitudinally studied cohorts. The Brains for Dementia Research (BDR) cohort and program was for planned brain donation across five UK brain banks and one donation point, with standardized operating procedures, following longitudinal clinical and psychometric assessments for people with no cognitive impairment as well as those with dementia. Lay representatives with experience of dementia were involved from inception of BDR and 74.5% of all enquiries about participation came through routes that were directly attributable to or influenced by lay representatives. Ten years after inception, this ongoing project has received over 700 brain donations from the recruited cohort of 3,276 potential brain donors. At cohort census for this paper, 72.2% of the living cohort have no cognitive impairment by assessment, whereas only 28.3% of the donated cohort were without cognitive impairment. It is important that brain banks are agile and reflect the changing needs of the research community, given that `big data', readiness cohorts, and GWAS demand large sample numbers of highly characterized individuals to facilitate new approaches and understanding of pathological processes in dementia.",Brain donation; cohort; control; dementia; research tissue bank,"Francis, PT; Costello, H; Hayes, GM",RLUK- Research Libraries UK; University of London; King's College London,2018.0,JOURNAL OF ALZHEIMERS DISEASE,IOS PRESS,,10.3233/JAD-180699,20230520-160000,20230521-044735,"['brains', 'for', 'dementia', 'research:', 'evolution', 'in', 'a', 'longitudinal', 'brain', 'donation', 'cohort', 'to', 'maximize', 'current', 'and', 'future', 'value']",True,20230521-205332,,,,
690,wos,A Simulator and Compiler Framework for Agile Hardware-Software Co-design Evaluation and Exploration,"As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and hardware-software co-design. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support heterogeneous combinations of general-purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we describe our compiler and simulator pair: DEC++ and MosaicSim. Together, they provide a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. The simulator and corresponding compiler were developed as part of the DECADES project, a multi-team effort to design and tape out a new heterogeneous architecture. We will present two case-studies in important data-science applications where DEC++ and MosaicSim enable straightforward design space explorations for emerging full-stack systems.",performance modeling; heterogeneous systems; hardware-software co-design; LLVM simulation,"Sorensen, T; Manocha, A; Tureci, E; Orenes-Vera, M; Aragon, JL; Martonosi, M",University of California System; University of California Santa Cruz; Princeton University; University of Murcia,2020.0,2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD),IEEE,,10.1145/3400302.3415751,20230520-160000,20230521-044735,"['a', 'simulator', 'and', 'compiler', 'framework', 'for', 'agile', 'hardware-software', 'co-design', 'evaluation', 'and', 'exploration']",True,20230521-205332,,,,
691,wos,E-monitoring the nature of water,"The critical need for hydrological observations in support of water resources management, particularly during extreme events, has transformed traditional methods of hydrological data management. This transformation has given rise to a framework of e-monitoring the hydrological cycle, the aim of which is to improve understanding of the nature of water. New trends in data science, coupled with increasing technological evolution, make the new generation of data systems more agile and responsive to the needs and expectations for efficient and effective data sharing and service delivery. The WMO Hydrological Observing System was designed around the integration of observations, data exchange, research, data processing, modelling and forecasting, in such a way that societal needs for disaster risk reduction, improved sustainability of environmental resources, climate resilience and economic growth can be effectively met. With its implementation of conceptual functionalities for sustainable data management, the WHOS operational architecture is hydrology's system for the future.",hydrological observations; data discovery and access; interoperability,"Pecora, S; Lins, HF",,2020.0,HYDROLOGICAL SCIENCES JOURNAL-JOURNAL DES SCIENCES HYDROLOGIQUES,TAYLOR & FRANCIS LTD,,10.1080/02626667.2020.1724296,20230520-160000,20230521-044735,"['e-monitoring', 'the', 'nature', 'of', 'water']",True,20230521-205332,,,,
692,wos,Software packaging and distribution for LHCb using Nix,"Software is an essential and rapidly evolving component of modern high energy physics research. The ability to be agile and take advantage of new and updated packages from the wider data science community is allowing physicists to efficiently utilise the data available to them. However, these packages often introduce complex dependency chains and evolve rapidly introducing specific, and sometimes conflicting, version requirements which can make managing environments challenging. Additionally, there is a need to replicate old environments when generating simulated data and to utilise pre-existing datasets. Nix is a purely functional package manager which allows for software to be built and distributed with fully specified dependencies, making packages independent from those available on the host. Builds are reproducible and multiple versions/configurations of each package can coexist with the build configuration of each perfectly preserved. Here we will give an overview of Nix followed by the work that has been done to use Nix in LHCb and the advantages and challenges that this brings.",,"Burr, C; Clemencic, M; Couturier, B",N8 Research Partnership; RLUK- Research Libraries UK; University of Manchester; European Organization for Nuclear Research (CERN),2019.0,23RD INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY AND NUCLEAR PHYSICS (CHEP 2018),E D P SCIENCES,,10.1051/epjconf/201921405005,20230520-160000,20230521-044735,"['software', 'packaging', 'and', 'distribution', 'for', 'lhcb', 'using', 'nix']",False,20230521-205332,,,,
693,wos,Information Resilience: the nexus of responsible and agile approaches to information use,"The appetite for effective use of information assets has been steadily rising in both public and private sector organisations. However, whether the information is used for social good or commercial gain, there is a growing recognition of the complex socio-technical challenges associated with balancing the diverse demands of regulatory compliance and data privacy, social expectations and ethical use, business process agility and value creation, and scarcity of data science talent. In this vision paper, we present a series of case studies that highlight these interconnected challenges, across a range of application areas. We use the insights from the case studies to introduce Information Resilience, as a scaffold within which the competing requirements of responsible and agile approaches to information use can be positioned. The aim of this paper is to develop and present a manifesto for Information Resilience that can serve as a reference for future research and development in relevant areas of responsible data management.",Information Resilience; Data quality; Responsible data science; Effective information use; Value creation,"Sadiq, S; Aryani, A; Demartini, G; Hua, W; Indulska, M; Burton-Jones, A; Khosravi, H; Benavides-Prado, D; Sellis, T; Someh, I; Vaithianathan, R; Wang, S; Zhou, XF",University of Queensland; Swinburne University of Technology; Auckland University of Technology; Facebook Inc; Hong Kong University of Science & Technology,2022.0,VLDB JOURNAL,SPRINGER,,10.1007/s00778-021-00720-2,20230520-160000,20230521-044735,"['information', 'resilience:', 'the', 'nexus', 'of', 'responsible', 'and', 'agile', 'approaches', 'to', 'information', 'use']",True,20230521-205332,,,,
694,wos,Structured Data for Product Performance Improvement,"Aftermarket reliability data is a cornerstone to understand the performance of one's products against requirements. A successful aftermarket data system goes beyond the basics of supplying reliability figures. Its attributes also include additional metrics for an effective alerting and reporting system to enable proactive response to aftermarket issues. While these system features are key, the implementation and maintenance methodology of the system is crucial to its success. This is because these systems involve big data. In the case presented, it is data which spans several years, for a variety of model numbers on a variety of aircraft platforms or applications. Each set of circumstances yields different reliability figures and associated metrics. With this big data, it is equally crucial to its success to have a methodology to address data integrity, the speed of data, and the portability of data. Our solution with this successful methodology of these features is called Structured Data. A good aftermarket data system is a backbone for any successful organization. A good system in the aerospace industry goes beyond ATA Spec 2000 [1] formatted data and standard reliability figures such as MTBUR (Mean Time Between Unscheduled Removal) and MTBF (Mean Time Between Failure). It is also beyond implementing a Failure Reporting and Corrective Action System (FRACAS). A comprehensive system in the aerospace industry includes several additional measures (i.e. frequency, severity, risk) to represent the Voice of the Customer. And with a built-in mechanism for proactive response to the data, the system can then be considered World-Class. While designing a system with these features is important, its success also hinges upon the methodology of implementation and maintenance. As stated earlier, aftermarket data is considered big data due to the volume of highly specific data. With this big data, it is critical to success to address data integrity, the speed of data, and the portability of data all within a user-friendly experience. For data integrity, do we trust the data? This takes on many forms from cross referencing input and output data to determining an accurate mixed fleet factor. For speed of data, do we have a system in place to handle the cadence of data efficiently? For portability, do we structure our data in such a way where we can be agile to serve potential changes to our system or new systems as our company evolves? For a user-friendly experience, can we structure the data for intuitive analysis for all stakeholders? Thus in the proposed system, all of these aspects of data integrity, the speed of data, the portability of data, and formatting the data per stakeholders are addressed. Our solution with this successful methodology of these features is called Structured Data. The benefits of this newly developed Structured Data extend beyond ATA Spec 2000 in which it is based. The data is structured in a dynamic and interactive environment. This environment includes intuitive analysis and a system of prioritization for corrective action. The key benefit of this Structured Data system is proactive response to aftermarket data analysis.",Product performance; Reliability metrics; MTBUR / MTBF; FRACAS; Voice of Customer; Big data; Data integrity Speed of data; Portability of data; Natural Language Programming (NLP),"Peter, P; Parendo, C",Raytheon Technologies; Collins Aerospace,2021.0,67TH ANNUAL RELIABILITY & MAINTAINABILITY SYMPOSIUM (RAMS 2021),IEEE,,10.1109/RAMS48097.2021.9605770,20230520-160000,20230521-044735,"['structured', 'data', 'for', 'product', 'performance', 'improvement']",True,20230521-205332,,,,
695,wos,Using Big Data Analytics to Create a Predictive Model for Joint Strike Fighter,"The amount of information needed to acquire knowledge on today's acquisition systems is growing exponentially due to more complex, higher resolution, software-intensive acquisition systems that need to operate in System-of-Systems (SoS), Family-of-Systems (FoS), Joint, and Coalition environments. Unfortunately, the tools and methods necessary to rapidly collect, aggregate, and analyze this information have not evolved as a whole in conjunction with this increased system complexity and, therefore, has made analysis and evaluation increasingly deficient and ineffective. The Test Resource Management Center's (TRMC's) vision is to build a DoD test and evaluation (T&E) knowledge management (KM) and analysis capability that leverages commercial big data analysis and cloud computing technologies to improve evaluation quality and reduce decision-making time. An evaluation revolution, starting with the Joint Strike Fighter (JSF) program, is underway to ensure the T&E community can support the demands of next-generation weapon systems. The true product of T&E is knowledge ascertained through the collection of information about a system or item under test. However, the T&E community's ability to provide this knowledge is hampered by more complex systems, more complex environments, and the need to be more agile in support of strategic initiatives, such as agile acquisition and the 3rd Offset Strategy. This increased complexity and need for speed cause delayed analysis and problems that go undetected during T&E. The primary reason for these shortfalls is antiquated tools and processes that make data hard to locate, aggregate, and convert into knowledge. In short, DoD has not evolved its evaluation infrastructure as its weapon systems have evolved. Conversely, commercial entities, such as medical observation and diagnosis, electric power distribution, retail, and industrial manufacturing, have embraced agility in their methodologies while modernizing analytics capabilities to keep up with the massive influx of data. Raw physical sensors could provide data, higher-quality image or video cameras, radio frequency identification (RFID) devices, faster data collectors, more detailed point-of-sale information or digitized records, and ultimately is providing more data to analysts in size and complexity than ever before. As more data has become available, an interrelated phenomenon is the desire of analysts to ask more detailed questions about their consumers and their business infrastructure. To drive the process of implementing big data analytics, businesses have begun establishing analytics centers which either take pre-defined business cases and apply methods to address them or implement existing knowledge within the data architecture to create a higher level of awareness to business groups or the company at-large. To meet these demands, data storage and computation architectures have become more sophisticated, dozens of technologies were developed for large-scale processing (such as Apache Hadoop or GreenPlum), and streaming architectures which allow data to be processed and actioned on in real-time as it is collected have become commonplace. The net result of these commercial best practices is a solid foundation for the DoD to transform how it uses data to achieve faster, better, and smarter decisions throughout the acquisition lifecycle.",Big Data; Data Analytics; Knowledge Management; Data Management; Virtualization; Cloud Computing; Predictive Maintainance; Department of Defense; Test and Evaluation,"Norman, R; Bolin, J; Powell, ET; Amin, S; Nacker, J",,2018.0,2018 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,,20230520-160000,20230521-044735,"['using', 'big', 'data', 'analytics', 'to', 'create', 'a', 'predictive', 'model', 'for', 'joint', 'strike', 'fighter']",True,20230521-205332,,,,
696,wos,LEADERSHIP DECISION-MAKING PROCESSES IN THE CONTEXT OF DATA DRIVEN TOOLS,"Digital economy vast streams of data have created a new paradigm for the business intelligence processes, increasing the potential of advanced analytics and cognitive data tools. Big data structures are used in business intelligence to work with massive amount of dataset to extract value for effective business decision. The current research seeks to address the following question: how can leaders integrate new technology in their decision process to achieve business goals? Emerging technologies directly created organizational power shift and internal bureaucracy adjustments as a result of data transparency trend and decision-making levels changes. A new type of organizational culture and the leadership role in the organizational development becomes necessary. The significant impact over the organizational systems and business goals requires a strategic approach in implementing data driven decision-making processes.",Big Data; Advanced analytics; Machine learning; Artificial intelligence; Organization culture; Data management; Technology; Digital Economy; Business Intelligence; Agile; Continuous Development,"Bratasanu, V",,2018.0,QUALITY-ACCESS TO SUCCESS,SOC ROMANA PENTRU ASIGURAREA CALITATII,,,20230520-160000,20230521-044735,"['leadership', 'decision-making', 'processes', 'in', 'the', 'context', 'of', 'data', 'driven', 'tools']",True,20230521-205332,,,,
697,wos,Towards Prediction of Security Attacks on Software Defined Networks: A Big Data Analytic Approach,"Cyber-physical systems (CPS) tightly integrate physical and computing processes by monitoring and control data interacting between them via underlying networks. Software Defined Network (SDN) Technology has increasingly become essential in many advanced computer networks, including those in modern CPS, to provide flexible and agile network development. Despite many benefits that SDN offers, malicious attacks that can eventually prevent network services are unavoidable. Among the most predominant attacks on SDN controller layer, Link Discovery Attack and ARP (Address Resolution Protocol) Spoofing Attack are fundamental in that they are the gateways of many other SDN threats and attacks. To defend these attacks, most existing techniques either rely on relatively complex data validation techniques or use thresholds that can be subjective and unable to detect more than one type of attacks at a time if one deciding factor is used. While Big data technology, particularly machine learning, has been widely used for intrusion/anomaly detection, little has been done in SDN. This paper explores how well this technology can be used to predict these SDN attacks. By employing typical machine learning algorithms on simulated data of routing in SDN when attacks occur, preliminary results, obtained from four machine learning models, show the average area under ROC curve of over 96% and 92% for sample size 50,970 (12 switches) and 60,000 (20 switches), respectively. Further experiments show near-linear scaling in training time for the best performing algorithm when sample size grows up to 100,000.",Software-Defined Networking; SDN-specific security; Link Discovery attack; ARP Spoofing attack; Machine Learning; Data Analytic Applications,"Unal, E; Sen-Baidya, S; Hewett, R",Texas Tech University System; Texas Tech University,2018.0,2018 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA),IEEE,,,20230520-160000,20230521-044735,"['towards', 'prediction', 'of', 'security', 'attacks', 'on', 'software', 'defined', 'networks:', 'a', 'big', 'data', 'analytic', 'approach']",True,20230521-205332,,,,
698,wos,A Cost-Efficient Container Orchestration Strategy in Kubernetes-Based Cloud Computing Infrastructures with Heterogeneous Resources,"Containers, as a lightweight application virtualization technology, have recently gained immense popularity in mainstream cluster management systems like Google Borg and Kubernetes. Prevalently adopted by these systems for task deployments of diverse workloads such as big data, web services, and loT, they support agile application deployment, environmental consistency, OS distribution portability, application-centric management, and resource isolation. Although most of these systems are mature with advanced features, their optimization strategies are still tailored to the assumption of a static cluster. Elastic compute resources would enable heterogeneous resource management strategies in response to the dynamic business volume for various types of workloads. Hence, we propose a heterogeneous task allocation strategy for cost-efficient container orchestration through resource utilization optimization and elastic instance pricing with three main features. The first one is to support heterogeneous job configurations to optimize the initial placement of containers into existing resources by task packing. The second one is cluster size adjustment to meet the changing workload through autoscaling algorithms. The third one is a rescheduling mechanism to shut down underutilized VM instances for cost saving and reallocate the relevant jobs without losing task progress. We evaluate our approach in terms of cost and performance on the Australian National Cloud Infrastructure (Nectar). Our experiments demonstrate that the proposed strategy could reduce the overall cost by 23% to 32% for different types of cloud workload patterns when compared to the default Kubernetes framework.",Cluster management; container orchestration; resource heterogeneity; cost efficiency,"Zhong, ZH; Buyya, R",University of Melbourne,2020.0,ACM TRANSACTIONS ON INTERNET TECHNOLOGY,ASSOC COMPUTING MACHINERY,,10.1145/3378447,20230520-160000,20230521-044735,"['a', 'cost-efficient', 'container', 'orchestration', 'strategy', 'in', 'kubernetes-based', 'cloud', 'computing', 'infrastructures', 'with', 'heterogeneous', 'resources']",True,20230521-205332,,,,
699,wos,Machine Learning based Digital Twin Framework for Production Optimization in Petrochemical Industry,"Digital twins, along with the internet of things (IoT), data mining, and machine learning technologies, offer great potential in the transformation of today's manufacturing paradigm toward intelligent manufacturing. Production control in petrochemical industry involves complex circumstances and a high demand for timeliness; therefore, agile and smart controls are important components of intelligent manufacturing in the petrochemical industry. This paper proposes a framework and approaches for constructing a digital twin based on the petrochemical industrial IoT, machine learning and a practice loop for information exchange between the physical factory and a virtual digital twin model to realize production control optimization. Unlike traditional production control approaches, this novel approach integrates machine learning and real-time industrial big data to train and optimize digital twin models. It can support petrochemical and other process manufacturing industries to dynamically adapt to the changing environment, respond in a timely manner to changes in the market due to production optimization, and improve economic benefits. Accounting for environmental characteristics, this paper provides concrete solutions for machine learning difficulties in the petrochemical industry, e.g., high data dimensions, time lags and alignment between time series data, and high demand for immediacy. The approaches were evaluated by applying them in the production unit of a petrochemical factory, and a model was trained via industrial IoT data and used to realize intelligent production control based on real-time data. A case study shows the effectiveness of this approach in the petrochemical industry.",digital twin; machine learning; internet of things; petrochemical industry; production control optimization,"Min, QF; Lu, YG; Liu, ZY; Su, C; Wang, B",Dalian University of Technology,2019.0,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,ELSEVIER SCI LTD,,10.1016/j.ijinfomgt.2019.05.020,20230520-160000,20230521-044735,"['machine', 'learning', 'based', 'digital', 'twin', 'framework', 'for', 'production', 'optimization', 'in', 'petrochemical', 'industry']",True,20230521-205332,,,,
700,wos,Di-ANFIS: an integrated blockchain-IoT-big data-enabled framework for evaluating service supply chain performance,"Service supply chain management is a complex process because of its intangibility, high diversity of services, trustless settings, and uncertain conditions. However, the traditional evaluating models mostly consider the historical performance data and fail to predict and diagnose the problems' root. This paper proposes a distributed, trustworthy, tamper-proof, and learning framework for evaluating service supply chain performance based on blockchain and adaptive network-based fuzzy inference systems (ANFIS) techniques, named Di-ANFIS. The main objectives of this research are as follows: (1) presenting hierarchical criteria of service supply chain performance to cope with the diagnosis of the problems' root; (2) proposing a smart learning model to deal with the uncertainty conditions by a combination of neural network and fuzzy logic; and (3) introducing a distributed blockchain-based framework due to the dependence of ANFIS on big data and the lack of trust and security in the supply chain. Furthermore, the proposed six-layer conceptual framework consists of the data layer, connection layer, blockchain layer, smart layer, ANFIS layer, and application layer. This architecture creates a performance management system using the Internet of Things, smart contracts, and ANFIS based on the blockchain platform. The Di-ANFIS model provides a performance evaluation system without needing a third party and a reliable intermediary that provides an agile and diagnostic model in a smart and learning process. It also saves computing time and speeds up information flow.",blockchain; industry 4.0; Internet of Things (IoT); big data; service supply chain; performance evaluation,"Bamakan, SMH; Faregh, N; ZareRavasan, A",University of Yazd; University of Yazd; Masaryk University Brno,2021.0,JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING,OXFORD UNIV PRESS,,10.1093/jcde/qwab007,20230520-160000,20230521-044735,"['di-anfis:', 'an', 'integrated', 'blockchain-iot-big', 'data-enabled', 'framework', 'for', 'evaluating', 'service', 'supply', 'chain', 'performance']",True,20230521-205332,,,,
701,wos,Bean counter to value-adding business partner: the changing role of the accountant and situated rationality in a multinational firm,"Purpose This paper aims to explore the changing role of the accountant amid multiple drivers, responses of accountants and situated rationality in a multinational firm, Max-choice Lanka. Design/methodology/approach It adopts the single-site case study approach under the qualitative methodology and leans on institutional theory, specifically Ter Bogt and Scapens (2019) framework. Findings The case study findings reveal that the role of the accountant has undergone change amid local and broader institutions linked to organizational culture/norms, the influence of the parent company, global trends and technological advancements. Based on evolving situated rationalities, the contemporary accountant performs an agile role as a value-adding business partner; data scientist; strategic decision-maker; and a cross-functional team member. Practical implications At the practice level, identifying drivers influencing the changing role of accountants enables organizations to shape their accounting functions attuned to evolving needs by implementing appropriate strategies and recruiting competent personnel. In the realm of education, it calls for incorporating areas such as big data analytics, artificial intelligence, reporting nonfinancial information and integrated accounting software to the accounting curricular and upskill students based on industry expectations catering to changing roles. Originality/value This paper adds to the ongoing debate on the contemporary role of the accountant. Capitalizing on case study data, this research illuminates the influence of multiplicity of institutions, different forms and situated rationality within this changing role and extends the Ter Bogt and Scapens (2019) framework.",Accountant; Case study; Situated rationality; Changing role; Forms of rationality; Multiplicity of institutions,"Samanthi, D; Gooneratne, T",University of Colombo,,JOURNAL OF ACCOUNTING AND ORGANIZATIONAL CHANGE,EMERALD GROUP PUBLISHING LTD,,10.1108/JAOC-04-2022-0063,20230520-160000,20230521-044735,"['bean', 'counter', 'to', 'value-adding', 'business', 'partner:', 'the', 'changing', 'role', 'of', 'the', 'accountant', 'and', 'situated', 'rationality', 'in', 'a', 'multinational', 'firm']",False,20230521-205332,,,,
702,wos,Investigating potential interventions on disruptive impacts of Industry 4.0 technologies in circular supply chains: Evidence from SMEs of an emerging economy,"As a transversal theme, the intertwining of digitalization and sustainability has crossed all Supply Chains (SCs) levels dealing with widespread environmental and societal concerns. This paper investigates the potential in-terventions and disruptive impacts that Industry 4.0 technologies may have on pharmaceutical Circular SCs (CSCs). To accomplish this, a novel method involving a literature review and Pythagorean fuzzy-Delphi has initially been employed to identify and screen categorized lists of Industry 4.0 Disruptive Technologies (IDTs) and their impacts on pharmaceutical CSC. Subsequently, the weight of finalized impacts and the performance score of finalized IDTs have simultaneously been measured via a novel version of Pythagorean fuzzy SECA (Simultaneously Evaluation of Criteria and Alternatives). Then, the priority of each intervention for disruptive impacts of Industry 4.0 has been determined via the Hanlon method. This is one of the first papers to provide in-depth insights into advancing the study of the disruptive action of Industry 4.0 technologies cross-fertilizing CE throughout pharmaceutical SCs in the emerging economy of Iran. The results indicate that digital technologies such as Big Data Analytics, Global Positioning Systems, Enterprise Resource Planning, and Digital Platforms are quite available in the Irans' pharmaceutical industry. These technologies, along with four available in-terventions, e.g., environmental regulations, subsidy, fine, and reward, would facilitate moving towards a lean, agile, resilient, and sustainable supply chain through the efficient utilization of resources, optimized waste management, and substituting the human workforce by machines.",Industry 4; 0 technologies; Pythagorean fuzzy Delphi; Pythagorean fuzzy SECA; Hanlon method,"Mahdiraji, HA; Yaftiyan, F; Abbasi-Kamardi, A; Garza-Reyes, JA",RLUK- Research Libraries UK; University of Leicester; University of Tehran; University of Derby,2022.0,COMPUTERS & INDUSTRIAL ENGINEERING,PERGAMON-ELSEVIER SCIENCE LTD,,10.1016/j.cie.2022.108753,20230520-160000,20230521-044735,"['investigating', 'potential', 'interventions', 'on', 'disruptive', 'impacts', 'of', 'industry', '4.0', 'technologies', 'in', 'circular', 'supply', 'chains:', 'evidence', 'from', 'smes', 'of', 'an', 'emerging', 'economy']",True,20230521-205332,,,,
703,wos,Combining Terrier with Apache Spark to create Agile Experimental Information Retrieval Pipelines,"Experimentation using information retrieval (IR) systems has traditionally been a procedural and laborious process. Queries must be run on an index, with any parameters of the retrieval models suitably tuned. With the advent of learning-to-rank, such experimental processes (including the appropriate folding of queries to achieve cross-fold validation) have resulted in complicated experimental designs and hence scripting. At the same time, machine learning platforms such as Scikit Learn and Apache Spark have pioneered the notion of an experimental pipeline, which naturally allows a supervised classification experiment to be expressed as a series of stages, which can be learned or transformed. In this demonstration, we detail Terrier-Spark, a recent adaptation to the Terrier IR platform which permits it to be used within the experimental pipelines of Spark. We argue that this (1) provides an agile experimental platform for information retrieval, comparable to that enjoyed by other branches of data science; (2) aids research reproducibility in information retrieval by facilitating easily-distributable notebooks containing conducted experiments; and (3) facilitates the teaching of information retrieval experiments in educational environments.",,"Macdonald, C",RLUK- Research Libraries UK; University of Glasgow,2018.0,ACM/SIGIR PROCEEDINGS 2018,ASSOC COMPUTING MACHINERY,,10.1145/3209978.3210174,20230520-160000,20230521-044735,"['combining', 'terrier', 'with', 'apache', 'spark', 'to', 'create', 'agile', 'experimental', 'information', 'retrieval', 'pipelines']",True,20230521-205332,,,,
704,wos,Working Life Within a Hybrid World - How Digital Transformation and Agile Structures Affect Human Functions and Increase Quality of Work and Business Performance,"Digitization is dramatically changing economy and society. With current developments in the field of e.g. artificial intelligence and machine learning, big data and data analytics, cloud computing, conversational systems and adaptive architectures, robotics as well as virtual and augmented reality work life is facing huge challenges. On the other side the networking over the internet, more effective handling and sharing of data and new forms of human-machine-collaboration offer a great variety of potentials for designing even more flexible business processes, agile working structures and even smarter working setups and environments. Technique, organizational aspects and humans in the future are going to be within a new triad. Instead of taking the role of a dominator or captain as in former times, humans now more and more have to fulfill tasks as a conductor. The role of building up and interacting within new hybrid networks and holistic systems is gaining higher importance - leading to massive changes with reference to all dimensions of work. Total new requirements concerning work objectives, working tasks, work equipment, workspace as well as new challenges for organization, qualification, employment and leadership arise. Work is becoming more and more digitally and going to look quite different than expected today. Combining the physical and virtual world is representing the key success factor for future work. The study examines how digitization is going to penetrate working life further on displaying central measures and selected solutions for resulting organizational structures, human qualification needs and optimized working conditions in a hybrid world.",Agility; Collaboration; Data; Digitization; Industry 4.0; Organization; Performance; Qualifications; Requirements; Technology,"Bauer, W; Schlund, S; Vocke, C",Fraunhofer Gesellschaft,2018.0,"ADVANCES IN HUMAN FACTORS, BUSINESS MANAGEMENT AND LEADERSHIP, AHFE 2017",SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-319-60372-8_1,20230520-160000,20230521-044735,"['working', 'life', 'within', 'a', 'hybrid', 'world', '-', 'how', 'digital', 'transformation', 'and', 'agile', 'structures', 'affect', 'human', 'functions', 'and', 'increase', 'quality', 'of', 'work', 'and', 'business', 'performance']",True,20230521-205332,,,,
705,wos,"Big data empowered agility for dynamic, volatile, and time-sensitive service industries: the case of tourism sector","Purpose Dynamic, volatile, and time-sensitive industries, such as tourism, travel and hospitality require agility and market intelligence to create value and achieve competitive advantage. The aim of the current study is to examine the influence of big data (BD) on the performance of service organizations and to probe for a deeper understanding of implementing BD, based on available technologies. Design/methodology/approach An ethnographic study was conducted following an abductive approach. A primary qualitative research scheme was used with 35 information technology and database professionals participating in five online focus groups of seven participants each. Analytical themes were developed simultaneously with the literature being revisited throughout the study to ultimately create sets of common themes and dimensions. Findings BD can help organizations build agility, especially within dynamic industries, to better predict customer behavioral patterns and make tailor-made propositions from the BD. An integrated BD-specific framework is proposed to address value according to the dimensions of need, value, time and utility. Research limitations/implications Little research exists on the key drivers of BD use for dynamic, real-time and agile businesses. This research adds to the developing literature on BD applications to support organizational decision-making and business performance in the tourism industry. Originality/value This study responds to scholars' recent calls for more empirical research with contextual understanding of the use of BD to add value in marketing intelligence within business ecosystems. It delineates factors contributing to BD value creation and explores the impacts on the respective service encounters.",Big data; IT experts; Online focus groups; Tourism organizations; BD-specific framework,"Stylos, N; Zwiegelaar, J; Buhalis, D",RLUK- Research Libraries UK; University of Bristol; Oxford Brookes University; Bournemouth University,2021.0,INTERNATIONAL JOURNAL OF CONTEMPORARY HOSPITALITY MANAGEMENT,EMERALD GROUP PUBLISHING LTD,,10.1108/IJCHM-07-2020-0644,20230520-160000,20230521-044735,"['big', 'data', 'empowered', 'agility', 'for', 'dynamic,', 'volatile,', 'and', 'time-sensitive', 'service', 'industries:', 'the', 'case', 'of', 'tourism', 'sector']",True,20230521-205332,,,,
706,wos,Data Centered and Usage-Based Security Service,"Protecting Information Systems (IS) relies traditionally on security risk analysis methods. Designed for well-perimetrised environments, these methods rely on a systematic identification of threats and vulnerabilities to identify efficient control-centered protection countermeasures. Unfortunately, this does not fit security challenges carried out by the opened and agile organizations provided by the Social, Mobile, big data Analytics, Cloud and Internet of Things (SMACIT) environment. Due to their inherently collaborative and distributed organization, such multi-tenancy systems require the integration of contextual vulnerabilities, depending on the a priori unknown way of using, storing and exchanging data in opened cloud environment. Moreover, as data can be associated to multiple copies, different protection requirements can be set for each of these copies, which may lead the initial data owner lose control on the data protection. This involves (1) turning the traditional control-centered security vision to a dynamic data-centered protection and even (2) considering that the way a data is used can be a potential threat that may corrupt data protection efficiency. To fit these challenges, we propose a Data-centric Usage-based Protection service (DUP). This service is based on an information system meta-model, used to identify formally data assets and store the processes using copies of these assets. To define a usage-entered protection, we extend the Usage Based Access Control model, which is mostly focused on managing CRUD operations, to more complex operation fitting the SMACIT context. These usage rules are used to generate smart contracts, storing usage consents and managing usage control for cloud services.",Privacy; Data-driven organization; Blockchain; GDPR; Usage governance,"Yuan, JY; Biennier, F; Benharkat, N",Centre National de la Recherche Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon - INSA Lyon,2021.0,"SERVICE-ORIENTED COMPUTING, ICSOC 2020",SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-030-76352-7_42,20230520-160000,20230521-044735,"['data', 'centered', 'and', 'usage-based', 'security', 'service']",True,20230521-205332,,,,
707,wos,An Approach to Build e-Health IoT Reactive Multi-Services Based on Technologies around Cloud Computing for Elderly Care in Smart City Homes,"Although there are e-health systems for the care of elderly people, the reactive characteristics to enhance scalability and extensibility, and the use of this type of system in smart cities, have been little explored. To date, some studies have presented healthcare systems for specific purposes without an explicit approach for the development of health services. Moreover, software engineering is hindered by agile management challenges regarding development and deployment processes of new applications. This paper presents an approach to develop health Internet of Things (IoT) reactive applications that can be widely used in smart cities for the care of elderly individuals. The proposed approach is based on the Rozanski and Woods's iterative architectural design process, the use of architectural patterns, and the Reactive Manifesto Principles. Furthermore, domain-driven design and the characteristics of the emerging fast data architecture are used to adapt the functionalities of services around the IoT, big data, and cloud computing paradigms. In addition, development and deployment processes are proposed as a set of tasks through DevOps techniques. The approach validation was carried out through the implementation of several e-health services, and various workload experiments were performed to measure scalability and performance in certain parts of the architecture. The system obtained is flexible, scalable, and capable of handling the data flow in near real time. Such features are useful for users who work collaboratively in the care of elderly people. With the accomplishment of these results, one can envision using this approach for building other e-health services.",cloud computing; container as a service; DevOps; e-health; emerging fast data architecture; Internet of Things (IoT); reactive system,"Perez, LJ; Salvachua, J",Universidad Politecnica de Madrid,2021.0,APPLIED SCIENCES-BASEL,MDPI,,10.3390/app11115172,20230520-160000,20230521-044735,"['an', 'approach', 'to', 'build', 'e-health', 'iot', 'reactive', 'multi-services', 'based', 'on', 'technologies', 'around', 'cloud', 'computing', 'for', 'elderly', 'care', 'in', 'smart', 'city', 'homes']",True,20230521-205332,,,,
708,wos,"Enterprise Meta-architecture for Megacorps of Unmanageably Great Size, Speed, and Technological Complexity","The discipline of enterprise architecture (EA) provides valuable tools for aligning an organization's business strategy and processes, IT strategy and systems, personnel structures, and organizational culture, with the goal of enhancing organizational agility, adaptability, and efficiency. However, the centralized and exhaustively detailed approach of conventional EA is susceptible to failure when employed in organizations demonstrating exceedingly great size, speed of operation and change, and IT complexity - a combination of traits that characterizes, for example, some emerging types of technologized oligopolistic megacorps reflecting the Industry 4.0 paradigm. This text develops the conceptual basis for a variant form of enterprise architecture that can be used to enact improved target architectures for organizations whose characteristics would otherwise render them unmanageable from the perspective of conventional EA. The proposed approach of enterprise meta-architecture (or EMA) disengages human enterprise architects from the fine-grained details of architectural analysis, design, and implementation, which are handled by artificially intelligent systems functioning as active agents rather than passive tools. The role of the human enterprise architect becomes one of determining the types of performance improvements a target architecture should ideally generate, establishing the operating parameters for an EMA system, and monitoring and optimizing its functioning. Advances in Big Data and parametric design provide models for enterprise meta-architecture, which is distinct from other new approaches like agile and adaptive EA. Deployment of EMA systems should become feasible as ongoing advances in AI result in an increasing share of organizational agency and decision-making responsibility being shifted to artificial agents.",Enterprise Architecture; Organizational complexity; Unmanageability; Industry 4.0; Megacorps; Parametric design,"Gladden, ME",Polish Academy of Sciences; Institute of Computer Science of the Polish Academy of Sciences,2019.0,"INFORMATION SYSTEMS ARCHITECTURE AND TECHNOLOGY, ISAT 2018, PT III",SPRINGER INTERNATIONAL PUBLISHING AG,,10.1007/978-3-319-99993-7_22,20230520-160000,20230521-044735,"['enterprise', 'meta-architecture', 'for', 'megacorps', 'of', 'unmanageably', 'great', 'size,', 'speed,', 'and', 'technological', 'complexity']",True,20230521-205332,,,,
709,wos,Impact of artificial intelligence-driven big data analytics culture on agility and resilience in humanitarian supply chain: A practice-based view,"This study attempts to understand the role of artificial intelligence-driven big data analytics capability in hu-manitarian relief operations. These disasters play an important role in mobilizing several organizations to counteract them, but the organizations often find it hard to strike a fine balance between agility and resilience. Operations Management Scholars' opinion remains divided between responsiveness and efficiency. However, to manage unexpected events like disasters, organizations need to be agile and resilient. In previous studies, scholars have adopted the resource-based view or dynamic capability view to explain the combination of re-sources and capabilities (i.e., technology, agility, and resilience) to explain their performance. However, following some recent scholarly debates, we argue that organizational theories like the resource-based view or dynamic capability view are not suitable enough to explain humanitarian supply chain performance. As the underlying assumptions of the commercial supply chain do not hold true in the case of the humanitarian supply chain. We note this as a potential research gap in the existing literature. Moreover, humanitarian organizations remain sceptical regarding the adoption of artificial intelligence-driven big data analytics capability (AI-BDAC) in the decision-making process. To address these potential gaps, we grounded our theoretical model in the practice-based view which is proposed as an appropriate lens to examine the role of practices that are not rare and are easy to imitate in performance. We used Partial Least Squares (PLS) to test our theoretical model and research hypotheses, using 171 useable responses gathered through a web survey of international non-governmental organizations (NGOs). The findings of our study suggest that AI-BDAC is a significant determi-nant of agility, resilience, and performance of the humanitarian supply chain. Furthermore, the reduction of the level of information complexity (IC) on the paths joining agility, resilience, and performance in the humanitarian supply chain. These results offer some useful theoretical contributions to the contingent view of the practice -based view. In a way, we have tried to establish empirically that the humanitarian supply chain designs are quite different from their commercial counterparts. Hence, the use of a resource-based view or dynamic capa-bility view as theoretical lenses may not help capture true perspectives. Thus, the use of a practice-based view as an alternative theoretical lens provides a better understanding of humanitarian supply chains. We have further outlined the limitations and the future research directions of the study.",Artificial intelligence; Big data analytics; Culture; Supply chain agility; Supply chain resilience; Humanitarian supply chain; Practice-based view; Humanitarian operations management; PLS-SEM,"Dubey, R; Bryde, DJ; Dwivedi, YK; Graham, G; Foropon, C",Montpellier Business School; Liverpool John Moores University; Swansea University; Symbiosis International University; Symbiosis Institute of Business Management (SIBM) Pune; N8 Research Partnership; RLUK- Research Libraries UK; White Rose University Consortium; University of Leeds,2022.0,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,ELSEVIER,,10.1016/j.ijpe.2022.108618,20230520-160000,20230521-044735,"['impact', 'of', 'artificial', 'intelligence-driven', 'big', 'data', 'analytics', 'culture', 'on', 'agility', 'and', 'resilience', 'in', 'humanitarian', 'supply', 'chain:', 'a', 'practice-based', 'view']",True,20230521-205332,,,,
710,wos,The future of leadership-How is leadership in small and medium-sized enterprises going to change?,"This paper in the Journal Gruppe. Interaktion. Organisation. (GIO) addresses changes in leadership through digitalization and their consequences for leaders. For years, digitalization has been heralding changes such as increasing leadership at a distance or use of digital communication media. Small and medium-sized enterprises (SMEs) now face the task of coping with these changes and have to contend with major uncertainties: What are major determining trends for leaders in SMEs? Which changes will shape leadership and how will they change leadership tasks and success-critical behavior? In semi-structured interviews with seven experts from SMEs we have explored these questions. Trends expected by the experts describe changes in the organizational structures and in work within the company. Structurally, companies will become more agile and diverse, hierarchies will play a less strong role and companies will cooperate more closely with each other. Work will become more location-independent, more influenced by Big Data and many tasks will be made easier or taken over by technology. In relation to established models of leadership tasks and behavior, the experts see a clear shift in tasks in favor of managing human resources, including the development of employees through coaching and the transfer of responsibility. In addition to previous tasks, the experts see managing change as a new task area. This area consists of accompanying change, acting flexibly and agilely, communicating openly and transparently and allowing failure. With regard to changes in success-critical behavior, leaders have to show more strategy orientation, communicate clearly and be open to new ideas and further development.",Leadership; Digitalization; Tasks; Skills; Leadership behavior,"Otting, SK; Masjutin, L; Maier, GW",University of Bielefeld,2021.0,GIO-GRUPPE-INTERAKTION-ORGANISATION-ZEITSCHRIFT FUER ANGEWANDTE ORGANISATIONSPSYCHOLOGIE,SPRINGER VIEWEG-SPRINGER FACHMEDIEN WIESBADEN GMBH,,10.1007/s11612-021-00610-9,20230520-160000,20230521-044735,"['the', 'future', 'of', 'leadership-how', 'is', 'leadership', 'in', 'small', 'and', 'medium-sized', 'enterprises', 'going', 'to', 'change?']",True,20230521-205332,,,,
711,wos,Disruptive Technologies for Labor Market Information System Implementation Enhancement in the UAE: A Conceptual Perspective,"In December 2019, the world learned about the first outbreak of the novel coronavirus (COVID-19) that first broke out in Wuhan, China. This limited outbreak in a small province of China has rapidly evolved into a global pandemic that has led to a health and economic crisis. As millions of individuals have lost their lives, others have lost their jobs due to the recession of 2020. While the skills and educational mismatch have been a prevalent problem in the UAE labor market, it is logical to assume that the global pandemic has likely increased this problem's extent. Therefore, there is an urgent need to adopt an agile, innovative solution to address the upcoming challenges in the labor markets due to the lack of skilled resources and the fear of future work amid the COVID-19 pandemic. Since industry and academia have identified skills and educational mismatch as a complex and multivariate problem, the paper builds a conceptual case from a system engineering perspective to solve this problem efficiently. Based on the literature reviewed related to disruptive technologies and labor market management systems, the paper proposes a new implementation approach for an integrated labor market information system enabled by the most widely used disruptive technologies components in the UAE (Machine Learning, AI, Blockchain, Internet of Things, Big Data Analytics, and Cloud Computing). The proposed approach is considered one of the immediate course of actions required to minimize the UAE economy's negative impact due to the presence of the skills and educational mismatch phenomena.",Disruptive technologies; labor market information systems; skills and educational mismatch; future of work; system engineering; system design thinking; COVID-19,"Goher, G; Masrom, M; Amrin, A; Abd Rahim, N",Universiti Teknologi Malaysia,2021.0,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,SCIENCE & INFORMATION SAI ORGANIZATION LTD,,,20230520-160000,20230521-044735,"['disruptive', 'technologies', 'for', 'labor', 'market', 'information', 'system', 'implementation', 'enhancement', 'in', 'the', 'uae:', 'a', 'conceptual', 'perspective']",True,20230521-205332,,,,
712,wos,"MosaicSim: A Lightweight, Modular Simulator for Heterogeneous Systems","As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and domain-specific hardware-software co-designs. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support rich heterogeneous combinations of general purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we introduce MosaicSim, a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. By integrating the LLVM toolchain, MosaicSim enables efficient modeling of instruction dependencies and flexible additions across the stack. Its modularity also allows the composition and integration of different hardware components. We first demonstrate that MosaicSim captures architectural bottlenecks in applications, and accurately models both scaling trends in a multicore setting and accelerator behavior. We then present two case-studies where MosaicSim enables straightforward design space explorations for emerging systems, i.e. data science application acceleration and heterogeneous parallel architectures.",heterogeneity; hardware-software co-design; performance modeling; multi-core architectures; accelerators,"Matthews, O; Manocha, A; Giri, D; Orenes-Vera, M; Tureci, E; Sorensen, T; Ham, TJ; Aragon, JL; Carloni, LP; Martonosi, M",Princeton University; Columbia University; University of California System; University of California Santa Cruz; Seoul National University (SNU); University of Murcia,2020.0,2020 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND SOFTWARE (ISPASS),IEEE,,10.1109/ISPASS48437.2020.00029,20230520-160000,20230521-044735,"['mosaicsim:', 'a', 'lightweight,', 'modular', 'simulator', 'for', 'heterogeneous', 'systems']",True,20230521-205332,,,,
713,wos,Context and Machine Learning Based Trust Management Framework for Internet of Vehicles,"Trust is one of the core components of any ad hoc network security system. Trust management (TM) has always been a challenging issue in a vehicular network. One such developing network is the Internet of vehicles (IoV), which is expected to be an essential part of smart cities. IoV originated from the merger of Vehicular ad hoc networks (VANET) and the Internet of things (IoT). Security is one of the main barriers in the on-road IoV implementation. Existing security standards are insufficient to meet the extremely dynamic and rapidly changing IoV requirements. Trust plays a vital role in ensuring security, especially during vehicle to vehicle communication. Vehicular networks, having a unique nature among other wireless ad hoc networks, require dedicated efforts to develop trust protocols. Current TM schemes are inflexible and static. Predefined scenarios and limited parameters are the basis for existing TM models that are not suitable for vehicle networks. The vehicular network requires agile and adaptive solutions to ensure security, especially when it comes to critical messages. The vehicle network's wireless nature increases its attack surface and exposes the network to numerous security threats. Moreover, internet involvement makes it more vulnerable to cyberattacks. The proposed TM framework is based on context-based cognition and machine learning to be best suited to IoV dynamics. Machine learning is the best solution to utilize the big data produced by vehicle sensors. To handle the uncertainty Bayesian machine learning statistical model is used. The proposed framework can adapt scenarios dynamically and infer using the maximum possible parameter available. The results indicated better performance than existing TM methods. Furthermore, for future work, a high-level machine learning model is proposed.",Internet of vehicles (IoV); trust management (TM); vehicular ad hoc network (VANET); machine learning; context awareness; bayesian learning,"Rehman, A; Hassan, MF; Hooi, YK; Qureshi, MA; Chung, TD; Akbar, R; Safdar, S",Universiti Teknologi Petronas; FPT University,2021.0,CMC-COMPUTERS MATERIALS & CONTINUA,TECH SCIENCE PRESS,,10.32604/CMC.2021.017620,20230520-160000,20230521-044735,"['context', 'and', 'machine', 'learning', 'based', 'trust', 'management', 'framework', 'for', 'internet', 'of', 'vehicles']",True,20230521-205332,,,,
714,wos,The mediating role of knowledge management and information systems selection management capability on Big Data Analytics quality and firm performance,"This study draws on organizational learning and strategic decision-making theory to develop a conceptual framework to explore how the selection measures of BDA systems and external support partners are linked to BDA system quality, and how these influence firms' competitive position. Through a cross-sectional survey of 523 IT professionals from the US, UK, and India, using path analysis and structural equation modeling, we found that the information systems selection process, enhanced by knowledge management capabilities, is positively related to the BDA system quality and firms' performance. However, inconsistent with prior studies on transactional systems, we found no support for the hypothesis that software vendor criteria influence BDA quality. Also, in selecting systems and external facilitators, organizations appear to be pivoting towards parameters that are considered emerging, such as cloud computing, DevOps, and agile experiences, as they increase the likelihood of unlocking business value from BDA.",Big data analytics; cloud computing; DevOps; agile; information system criteria; knowledge management; third-party consultant; software vendor criteria; business values and competitive advantage,"Obitade, OP",University of North Texas System; University of North Texas Denton,,JOURNAL OF DECISION SYSTEMS,TAYLOR & FRANCIS LTD,,10.1080/12460125.2021.1966162,20230520-160000,20230521-044735,"['the', 'mediating', 'role', 'of', 'knowledge', 'management', 'and', 'information', 'systems', 'selection', 'management', 'capability', 'on', 'big', 'data', 'analytics', 'quality', 'and', 'firm', 'performance']",False,20230521-205332,,,,
715,wos,DMISTA: Conceptual Data Model for Interactions in Support Ticket Administration,"Changing business models and dynamic markets in the globally connected world results in more and more complex system environments. The IT service infrastructure as enabler of innovative business models has to support these innovations by providing agile methods to quickly adapt to new use-cases. This underlines the need to manage the digitized environment systematically in order to foster efficiency. IT Service Management (ITSM) as a discipline evolved and now provides the framework to orchestrate the complexity in Information Technology. The activities, processes, and capabilities to maintain the portfolio are served by individuals, who interact with each other. There is an emphasized need for identifying, acquiring, organizing, storing, retrieving, and analyzing data related to human interaction processes to support finally the business processes. This paper proposes a conceptual data model to capture information about human interactions during support ticket administration (DMISTA). The presented model-structure and -requirements allow for efficient selection of appropriate data for various data science use-cases to understand and optimize business processes. The DMISTA supports different types of relationships (based on causality, joint cases, and joint activities) to enable efficient processing of specific analysis methods. The applicability of the model is shown based on a typical use-case.",IT Service Management; Enterprise Information System; Conceptual Data Model; Data Mining; Data Flow Architectures; Requirements Engineering; Support Ticket Administration,"Mertens, C; Nurnberger, A",Otto von Guericke University,2022.0,ICEIS: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS - VOL 1,SCITEPRESS,,10.5220/0010999100003179,20230520-160000,20230521-044735,"['dmista:', 'conceptual', 'data', 'model', 'for', 'interactions', 'in', 'support', 'ticket', 'administration']",True,20230521-205332,,,,
716,wos,IBM Z development transformation,"This article discusses how the product development cycle is being transformed with Artificial Intelligence (AI) for the first time in zSeries history. This new era of AI, under the project name IBM Z Development Transformation (zDT), has allowed the team to grow and learn new skills in data science. This transformation forces change structurally in how data is prepared and stored. In z14, there were incremental productivity gains with enhancements to automation with eServer Automation Test Solution and a technology data analysis engine called zDataAssist. However, in z15, AI will significantly accelerate our efficiency. This article explains how Design Thinking and Agile principles were used to identify areas that are of high impact and feasible to implement: 1) what and how data is collected via System Test Event Logging and Analysis engine, Problem ticket management system (Jupitr), and Processor data analysis engine (Xrings); 2) problem identification, analysis, and management (AutoJup) along with Intelligent Recovery Verification Assistant; 3) product design documentation search engine (AskiheMachine); and 4) prototype microprocessor allocation processes Intelligent Commodity Fulfillment System using Machine Learning. This article details the approach of these areas for z15, the implementation of these solutions under the zDT project, as well as the results and future work.",,"McCain, EC; Bastien, P; Belmar, BF; Bhattacharya, B; Cheruiyot, KK; Coq, M; Dartey, R; Deekaram, K; Ghadai, K; Lalima, LD; Nettey, J; Owolabi, AW; Phillips, K; Shiling, TM; Schroeder, DT; Slegel, C; Steen, B; Thorne, DA; Venuto, E; Willoughby, JD; Yaniv, D; Ziemis, N",International Business Machines (IBM); International Business Machines (IBM),2020.0,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,IBM CORP,,10.1147/JRD.2020.3008122,20230520-160000,20230521-044735,"['ibm', 'z', 'development', 'transformation']",True,20230521-205332,,,,
717,wos,Testing a Generalizable Machine Learning Workflow for Aquatic Invasive Species on Rainbow Trout (Oncorhynchus mykiss) in Northwest Montana,"Biological invasions are accelerating worldwide, causing major ecological and economic impacts in aquatic ecosystems. The urgent decision-making needs of invasive species managers can be better met by the integration of biodiversity big data with large-domain models and data-driven products. Remotely sensed data products can be combined with existing invasive species occurrence data via machine learning models to provide the proactive spatial risk analysis necessary for implementing coordinated and agile management paradigms across large scales. We present a workflow that generates rapid spatial risk assessments on aquatic invasive species using occurrence data, spatially explicit environmental data, and an ensemble approach to species distribution modeling using five machine learning algorithms. For proof of concept and validation, we tested this workflow using extensive spatial and temporal hybridization and occurrence data from a well-studied, ongoing, and climate-driven species invasion in the upper Flathead River system in northwestern Montana, USA. Rainbow Trout (RBT; Oncorhynchus mykiss), an introduced species in the Flathead River basin, compete and readily hybridize with native Westslope Cutthroat Trout (WCT; O. clarkii lewisii), and the spread of RBT individuals and their alleles has been tracked for decades. We used remotely sensed and other geospatial data as key environmental predictors for projecting resultant habitat suitability to geographic space. The ensemble modeling technique yielded high accuracy predictions relative to 30-fold cross-validated datasets (87% 30-fold cross-validated accuracy score). Both top predictors and model performance relative to these predictors matched current understanding of the drivers of RBT invasion and habitat suitability, indicating that temperature is a major factor influencing the spread of invasive RBT and hybridization with native WCT. The congruence between more time-consuming modeling approaches and our rapid machine-learning approach suggest that this workflow could be applied more broadly to provide data-driven management information for early detection of potential invaders.",invasive species; machine learning; species distribution modeling; remote sensing; big data analytics; early detection and rapid response,"Carter, S; van Rees, CB; Hand, BK; Muhlfeld, CC; Luikart, G; Kimball, JS",University of Montana System; University of Montana; University of Montana System; University of Montana; United States Department of the Interior; United States Geological Survey; University of Montana System; University of Montana; University System of Georgia; University of Georgia; University System of Georgia; University of Georgia,2021.0,FRONTIERS IN BIG DATA,FRONTIERS MEDIA SA,,10.3389/fdata.2021.734990,20230520-160000,20230521-044735,"['testing', 'a', 'generalizable', 'machine', 'learning', 'workflow', 'for', 'aquatic', 'invasive', 'species', 'on', 'rainbow', 'trout', '(oncorhynchus', 'mykiss)', 'in', 'northwest', 'montana']",True,20230521-205332,,,,
718,wos,Diaspore: Diagnosing Performance Interference in Apache Spark,"Apache Spark is being increasingly used to execute big data applications on cluster computing platforms. To increase system utilization, cluster operators often configure their clusters such that multiple co-located applications can simultaneously share the resources of a cluster node. With resource sharing, applications can compete with each other for shared node resources thereby interfering with each other's performance. Many Spark applications take a long time to execute. Performance interference from other applications can thus cause a Spark application to fail or take even longer time to execute thereby wasting cluster resources and frustrating users. This motivates the need for an automated technique that can detect interference quickly and also diagnose the root cause of the interference to facilitate mitigation of the problem. Most existing approaches are not designed to offer quick interference detection and diagnosis. For example, they typically require extensive training data for every application of interest under various possible input data sizes and resource allocations. In this paper, we systematically investigate the design of a Machine Learning (ML) based technique that addresses this open problem. We implement a tool called Diaspore that integrates our findings. We evaluate the tool with a diverse set of 13 Spark applications executing on a real cluster. Experimental results show that Diaspore requires only small scale training data, i.e., executions under small input sizes and resource allocations. Furthermore, our results show that the tool can offer accurate predictions for applications not present in the training data. Consequently, Diaspore reduces the training time needed to offer predictions. Finally, the feature engineering underlying Diaspore ensures that the tool can detect and diagnose interference quickly in an online manner by sampling only a small fraction of a long running application's execution. This can allow cluster operators to mitigate interference in an agile manner.",Interference; Sparks; Task analysis; Measurement; Training; Resource management; Training data; Interference detection; big data; machine learning,"Shah, SR; Amannejad, Y; Krishnamurthy, D",University of Calgary; Mount Royal University,2021.0,IEEE ACCESS,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,,10.1109/ACCESS.2021.3098426,20230520-160000,20230521-044735,"['diaspore:', 'diagnosing', 'performance', 'interference', 'in', 'apache', 'spark']",True,20230521-205332,,,,
719,wos,Contexts Enhance Accuracy: On Modeling Context Aware Deep Factorization Machine for Web API QoS Prediction,"Service-oriented computing (SOC) promises a world of cooperating services loosely connected, constructing agile Web applications in heterogeneous environments conveniently. Web application interface (API) as an emerging technique attracts more and more enterprises and organizations to publish their deep computing functionalities and big data on the Internet, Web API has become the backbone to promote the development of SOC, thus forming the prosperous Web API economy. However, the number of available Web APIs on the Internet is massive and growing constantly, which causes the Web API overload problem. Quality of service (QoS) as an indicator is able to well differentiate the quality of Web APIs and has been widely applied for high quality Web API selection. Since testing QoS for massive Web APIs is resource-consuming, and the QoS performance depends on contextual information such as network and location, hence accurate QoS prediction has become very crucial for personalized Web API recommendation and high quality Web application construction. To address the above issue, this paper presents a context aware deep factorization machine model (CADFM for short) for accurate Web API QoS prediction. Specifically, we first carry out detailed data analysis using real-world QoS dataset and discover a positive relationship between QoS and contextual information, which motivates us to incorporate beneficial contexts for enhancing QoS prediction accuracy. Then, we treat QoS prediction as a regression problem and propose a context aware CADFM framework that integrates the contextual information via embedding technique. Particularly, we adopt MF and MLP for high-order and nonlinear interaction modeling, so as to learn the complex interaction between users and Web APIs accurately. Finally, the experimental results on real-world QoS dataset demonstrate that CADFM outperforms the classic and the state-of-the-art baselines, thereby generating the most accurate QoS predictions and increasing the revenue of Web APIs recommendation.",Quality of service; Context modeling; Predictive models; Context-aware services; Internet; Organizations; Software; Service-oriented computing; Web API; quality of service prediction; context aware; deep factorization machine,"Shen, LM; Pan, MS; Liu, LL; You, DL; Li, F; Chen, Z","Yanshan University; Chinese Academy of Sciences; National Science Library, CAS; Northeastern University - China",2020.0,IEEE ACCESS,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,,10.1109/ACCESS.2020.3022891,20230520-160000,20230521-044735,"['contexts', 'enhance', 'accuracy:', 'on', 'modeling', 'context', 'aware', 'deep', 'factorization', 'machine', 'for', 'web', 'api', 'qos', 'prediction']",True,20230521-205332,,,,
720,wos,Agile Deep Learning UAVs Operating in Smart Spaces: Collective Intelligence Versus Mission-Impossible,"The environments, in which we all live, are known to be complex and unpredictable. The complete discovery of these environments aiming to take full control over them is a mission-impossible, however, still in our common agenda. People intend to make their living spaces smarter utilizing innovations from the Internet of Things and Artificial Intelligence. Unmanned aerial vehicles (UAVs) as very dynamic, autonomous and intelligent things capable to discover and control large areas are becoming important inhabitants within existing and future smart cities. Our concern in this paper is to challenge the potential of UAVs in situations, which are evolving fast in a way unseen before, e.g., emergency situations. To address such challenges, UAVs have to be intelligent enough to be capable to autonomously and in near real-time evaluate the situation and its dynamics. Then, they have to discover their own missions and set-up suitable own configurations to perform it. This configuration is the result of flexible plans which are created in mutual collaboration. Finally, the UAVs execute the plans and learn from the new experiences for future reuse. However, if to take into account also the Big Data challenge, which is naturally associated with the smart cities, UAVs must be also wise in a sense that the process of making autonomous and responsible real-time decisions must include continuous search for a compromise between efficiency (acceptable time frame to get the decision and reasonable resources spent for that) and effectiveness (processing as much of important input information as possible and to improve the quality of the decisions). To address such a skill we propose to perform the required computations using Cloud Computing enhanced with Semantic Web technologies and potential tools (agile deep learning) for compromising, such as, e.g., focusing, filtering, forgetting, contextualizing, compressing and connecting.",,"Cochez, M; Periaux, J; Terziyan, V; Tuovinen, T",University of Jyvaskyla; Fraunhofer Gesellschaft; RWTH Aachen University; Universitat Politecnica de Catalunya; Centre Internacional de Metodes Numerics en Enginyeria (CIMNE),2018.0,COMPUTATIONAL METHODS AND MODELS FOR TRANSPORT: NEW CHALLENGES FOR THE GREENING OF TRANSPORT SYSTEMS,SPRINGER-VERLAG BERLIN,,10.1007/978-3-319-54490-8_3,20230520-160000,20230521-044735,"['agile', 'deep', 'learning', 'uavs', 'operating', 'in', 'smart', 'spaces:', 'collective', 'intelligence', 'versus', 'mission-impossible']",False,20230521-205332,,,,
721,wos,Artificial Intelligence Potential in Higher Education Institutions Enhanced Learning Environment in Romania and Serbia,"In their struggle to offer a sustainable educational system and transversal competencies for market requests, significant transformations characterise the higher education system in Serbia and Romania. According to EU policy, these transformations are related to educational reforms and the introduction of new technology and methodologies in teaching and learning. They are expected to answer to the PISA requirements and to increase the DESI (Digital Economy and Society Index). They are also likely to mitigate the inequity of HEIs (higher education institutions), empowered by a structured, goal-oriented strategy towards agile management in HEIs that is also appropriate for new market demands. Our study is based on an exploratory survey applied to 139 Romanian and Serbian teachers from the Information Technology School-ITS, Belgrade, and Spiru Haret University, Romania. The survey let them provide their knowledge of AI or their perceptions of the difficulties and opportunities of these technologies in HEIs. Our study discovered how difficulties and opportunities associated with AI impact HEIs. This study aims to see how AI might assist higher education in Romania and Serbia. We also considered how they might be integrated with the educational system, and if instructors would utilise them. Developing creative and transversal skills is required to anticipate future breakthroughs and technological possibilitiesThe new methods of education focuses on ethics, values, problem-solving, and daily activities. Students' learning material, how they might achieve critical abilities, and their educational changes must be addressed in the future. In this environment, colleges must create new digital skills in IA, machine learning, IoT, 5G, the cloud, big data, blockchain, data analysis, using MS Office and other applications, MOOCs, simulation applications, VR/AR, and gamification. They must also develop cross-disciplinary skills and a long-term mindset.",higher education institutions (HEI); artificial intelligence (AI); transversal skills,"Bucea-Manea-Tonis, R; Kuleto, V; Gudei, SCD; Lianu, C; Lianu, C; Ilic, MP; Paun, D",National University of Physical Education & Sport; Bucharest University of Economic Studies; Spiru Haret University; Spiru Haret University,2022.0,SUSTAINABILITY,MDPI,,10.3390/su14105842,20230520-160000,20230521-044735,"['artificial', 'intelligence', 'potential', 'in', 'higher', 'education', 'institutions', 'enhanced', 'learning', 'environment', 'in', 'romania', 'and', 'serbia']",True,20230521-205332,,,,
722,wos,Impact of the worldwide trends on the development of the digital economy,"The aim of the article is to develop a new model of the digital economy as a new scientific direction of the philosophy of economics. Analysis methodology is the use of methods such as cross-cultural, systemic, synergetic, informational, axiological, cybernetic to develop a new model of the digital economy as a new scientific direction, in the context of which a new information space is being formed. The problems of solving the digital economy are taking place against the backdrop of new trends - globalization 4.0, Industry 4.0, Enlightenment 2.0, Agile management, in the context of which there is a transition from simple interconnection to hyperconnection and the spread of Moore's law, according to which there is a doubling of information. The results of the study. 1) The development of the digital economy as a new scientific field, which is based on a combination of concepts of informatization, digitalization, robotics, developing under the influence of global trends is studied. 2) It has been established that the digital economy contributes to technological progress and, under the pressure of global trends, develops a variety of economic models of scientific, technical and digital progress, which are based on the solution of problems of man, science, society. 3) The problematic issues of the digital economy and the conditions for its solution are identified. Conclusions. The prospects that the digital economy opens up thanks to modern technologies representing a technological breakthrough are analyzed. The digital technology network is designed so that it moves with the least loss and the smallest pieces of calculus are at the heart of this new constant flow system. All this indicates that in the context of globalization and the BIG DATA era, humanity is entering a new stage of calculus, when information doubles in accordance with Moore's law.",global trends; digital economy; information-digital technologies; philosophy of economics,"Voronkova, HV; Nikitenko, AV; Teslenko, VT; Bilohur, EV",Ministry of Education & Science of Ukraine; Zaporizhzhia National University; Ministry of Education & Science of Ukraine; Ukrainian State University of Science & Technologies; Bogdan Khmelnitsky Melitopol State Pedagogical University,2020.0,AMAZONIA INVESTIGA,UNIV AMAZONIA,,10.34069/AI/2020.32.08.9,20230520-160000,20230521-044735,"['impact', 'of', 'the', 'worldwide', 'trends', 'on', 'the', 'development', 'of', 'the', 'digital', 'economy']",False,20230521-205332,,,,
723,wos,The ecology of open innovation units: adhocracy and competing values in public service systems,"There have been concerted efforts to encourage innovation and to foster a more innovative and open culture to government and public service institutions. Policy and service innovation labs constitute one part of a broader open innovation movement which also includes open data, behavioral insights, digital services, data science units, visualization capabilities, and agile and lean methods. This article argues that we need to step back and better understand these ecologies of innovation capabilities that have emerged across public service institutions, and to recognize that as fellow innovation traveling companions they collectively seek to transform the culture of government and public service institutions, producing more effective, efficient and tailored policies and services. This article introduces analytic frameworks that should help locate policy and innovation labs amidst these other innovating entities. First, it delineates the various units and initiatives which can be seen as committed to new ways of working and innovating in public service institutions, often relying on open innovation rhetoric and approaches. Second, it shows how - despite the diversity among these entities - they nevertheless share similar attributes as adhocracies and are located as part of a broader movement and class of organizations. Third, we locate these diverse OI entities amidst broader public service systems using the Competing Values Framework. Fourth, this article situates the challenges confronting OI units developing and sustaining or broadening niches in public service systems. Finally, it identifies future research questions to take up.",Open innovation; public service; adhocracies; competing values framework; policy labs; innovation labs; service labs,"Lindquist, EA; Buttazzoni, M",University of Victoria,2021.0,POLICY DESIGN AND PRACTICE,TAYLOR & FRANCIS LTD,,10.1080/25741292.2021.1941569,20230520-160000,20230521-044735,"['the', 'ecology', 'of', 'open', 'innovation', 'units:', 'adhocracy', 'and', 'competing', 'values', 'in', 'public', 'service', 'systems']",True,20230521-205332,,,,
724,wos,Software Engineering for Machine Learning: A Case Study,"Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be entangled in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",AI; Software engineering; process; data,"Amershi, S; Begel, A; Bird, C; DeLine, R; Gall, H; Kamar, E; Nagappan, N; Nushi, B; Zimmermann, T",Microsoft; University of Zurich,2019.0,2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019),IEEE,,10.1109/ICSE-SEIP.2019.00042,20230520-160000,20230521-044735,"['software', 'engineering', 'for', 'machine', 'learning:', 'a', 'case', 'study']",True,20230521-205332,,,,
725,wos,A Mathematics Pipeline to Student Success in Data Analytics through Course-Based Undergraduate Research,"This paper reports on Data Analytics Research (DAR), a course-based undergraduate research experience (CURE) in which undergraduate students conduct data analysis research on open real-world problems for industry, university, and community clients. We describe how DAR, offered by the Mathematical Sciences Department at Rensselaer Polytechnic Institute (RPI), is an essential part of an early low-barrier pipeline into data analytics studies and careers for diverse students. Students first take a foundational course, typically Introduction to Data Mathematics, that teaches linear algebra, data analytics, and R programming simultaneously using a project-based learning (PBL) approach. Then in DAR, students work in teams on open applied data analytics research problems provided by the clients. We describe the DAR organization which is inspired in part by agile software development practices. Students meet for coaching sessions with instructors multiple times a week and present to clients frequently. In a fully remote format during the pandemic, the students continued to be highly successful and engaged in COVID-19 research producing significant results as indicated by deployed online applications, refereed papers, and conference presentations. Formal evaluation shows that the pipeline of the single on-ramp course followed by DAR addressing real-world problems with societal benefits is highly effective at developing students' data analytics skills, advancing creative problem solvers who can work both independently and in teams, and attracting students to further studies and careers in data science.",undergraduate education; data analytics; course-based undergraduate research; linear algebra; project-based learning; data visualization; machine learning,"Bennett, KP; Erickson, JS; Svirsky, A; Seddon, JC",Rensselaer Polytechnic Institute; University of Rochester,2022.0,MATHEMATICS ENTHUSIAST,"UNIV MONTANA, DEPT MATHEMATICAL SCIENCES",,,20230520-160000,20230521-044735,"['a', 'mathematics', 'pipeline', 'to', 'student', 'success', 'in', 'data', 'analytics', 'through', 'course-based', 'undergraduate', 'research']",True,20230521-205332,,,,
726,wos,"Transitioning from Legacy Air Traffic Management to Airspace Management through Secure, Cloud-Native Automation Solutions","Advancements in Cloud-native services, Machine-Learning (ML), Artificial Intelligence (AI), and Rapid Application Development (RAD) using the Agile methodology has led countless industries to achieving desirable levels of automation while reducing cost and improving quality software deployments, timely / iterative delivery, and accountability. Coupling this framework with the principle of security as a shared responsibility further enhances the efficacy of an integrated Development, Security, and Operations (DevSecOps) Team within organizations to deliver secured digital solutions. Air Navigation Service Providers (ANSPs) around the world are currently exploring and embracing the digital evolution shifting from monolithic, legacy automation platforms to an application framework of microservices to allow for flexible operations as capabilities and airspace operations evolve. Specific to the US, the ATM automation system of today is comprised of both safety and non-safety critical systems, with mission-essential, efficiency-critical, and mission-support services that are predominately maintained and evolved through multiyear, one contractor-led programs. Although the system has proven resilient, it has not proven to be agile and flexible to allow for advances in capabilities on-board aircraft or in the data integration and sharing with other NAS automation systems. This creates significant overhead in development, sustainability, and operations of the current automation system, and leaves modernization efforts-in terms of new capabilities-in constant investment decision planning cycles, costing agencies not just money, but more time to innovate. To advance aviation into a new generation of interoperability leveraging collaborative frameworks and application specific capabilities, ANSPs must adapt to innovative methods to collect, process, and deliver critical and essential aeronautical, weather, and flight information to air traffic control operators and ultimately to airspace users. Doing so can not only lead to sustaining NAS automation systems while reducing the costs to develop and operate these systems, but it also provides an opportunity to present strategies on how to dramatically reduce the time and integration efforts needed to deploy new capabilities. Leveraging cloud-native technologies and services is a way to realize this automation evolution vision for ANSPs. This paper examines the migration from today's systems to secure, cloud-native platforms to prove that Mission Services and Mission Applications can be rapidly available / deployable to operators who provide separation and flow management services, using a cyber-secured cloud-native environment. Aeronautical data typically used for tactical decision making is now seen as crucial to the decision-making process in Air Traffic Management (ATM). Integrating global and localized datasets into a digital aviation data platform enhances the capabilities of the solutions and opens the possibilities of leveraging big data analytics and microservices to compute trajectory predictions (TP), demand capacity balancing (DCB), arrival and departure sequencing, airspace delay, among others, in real-time to achieve operator-driven mission objectives. Technology has reached a state of maturity, especially in cloud and hybrid cloud solutions, to support safety of life operations, like ATM. This paper identifies approaches that are being considered for that migration to support the integration of new airspace entrants, the use of application services to provide a dynamic, evolutionary ATM platform, and addresses some of the safety and security strategies that must be considered for this evolution.",Automation; ATM; Cloud-native; Microservices,"Solomon, A; Crawford, Z",Thales Group,2021.0,2021 IEEE/AIAA 40TH DIGITAL AVIONICS SYSTEMS CONFERENCE (DASC),IEEE,,10.1109/DASC52595.2021.9594313,20230520-160000,20230521-044735,"['transitioning', 'from', 'legacy', 'air', 'traffic', 'management', 'to', 'airspace', 'management', 'through', 'secure,', 'cloud-native', 'automation', 'solutions']",True,20230521-205332,,,,
727,wos,Convergence and digital fusion lead to competitive differentiation,"Purpose Organizations are consistently seeking innovative strategies and novel pathways to enhance business processes and create differentiation. The global business ecosystem is changing and there is growing demand for multi-modal digital technologies, big data consolidation and data analytics to harness a cost-competitive agile system. Technological convergence and integration of digital systems is one of the preferred methodologies that facilitates new and effective workflows and revives business processes. The progressive interlinking of digital technologies with business operations leads to the convergence and blending of management disciplines, devices and applications. The growing inconsistencies in managerial understanding regarding the benefits of convergence prompts a comprehensive examination of digital convergence pathways, identifying the impacts on converging entities and business objectives. The State bank of India (SBI) mega-merger case study was selected to investigate the pragmatic framework of digital convergence and to understand the impacts on interlinked entities such as: business operations, strategic management, project team that support value creation and competitive differentiation. The purpose of this paper is to focus on the phenomena of techno-fusion of emerging technologies creating new opportunities, business models and unique strategies for global banking and financial service organizations. Design/methodology/approach This study applies the qualitative, inductive research method using critical reflection of before and after the implementation of convergence and digital integration strategies. The SBI case study employs this research strategy based on the premise that banks must stay agile and highly responsive to the changing environment to enhance its value proposition and competitive differentiation objectives. The study methodology incorporates cooperative inquiry and multiple levels of analysis using data collection techniques of exhaustive review of archives, informal interviews, questionnaires and observations to identify the synergistic process improvement pathway. The study is grounded on the concept that the convergence of diverse business pathways involves innovative and interlinked project, strategic and information technology (IT) workflows that results in open innovative systems. Findings The studies identify that organizational innovation and creative solutions are a result of ecosystem turbulence, environmental force diversity, competitive pressure and the need for differentiation. Organizations that harness the power of digital fusion and convergence of management, systems and data generate a competitive advantage. The technological convergence strategy pulls multiple business and technology processes (project, strategic, IT, Cloud, AI and business process management) at the organizational, divisional or functional level generating new opportunities and threats, new business models and unique growth strategies for global banking and financial services organizations. Organizations that fully integrate techno-fusion of business and digital strategies produce synergistic effects and enhance adaptability, innovation and resiliency in the face of competitive challenges. Research limitations/implications Additional areas that can be explored further as an extension of this study are listed below: identifying factors to improve the speed of convergence; the current results are limited to large size organizations where formal management and technology functions are distinctive. Similar studies on smaller organizations are warranted. Originality/value This study focuses on the evolving field of technology innovation, which is increasingly being intertwined with business operations. Innovative digital technology is enabling the convergence of the disciplines of management, digital devices and applications. This facilitates the creation of a pragmatic framework that supports convergence of business operations, strategic management and digital fusion which leads to value creation and competitive differentiation. The techno-fusion of emerging technologies and digital strategies generates new opportunities and threats, new business models and unique growth strategies for organizations.",Convergence; Open innovation; Digital technology; Agile synergistic interaction; Business and technology management; Digital fusion,"Thomas, A",,2020.0,BUSINESS PROCESS MANAGEMENT JOURNAL,EMERALD GROUP PUBLISHING LTD,,10.1108/BPMJ-01-2019-0001,20230520-160000,20230521-044735,"['convergence', 'and', 'digital', 'fusion', 'lead', 'to', 'competitive', 'differentiation']",True,20230521-205332,,,,
728,wos,Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions,"The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline-no AI can do this. Consequently, human-centered AI (HCAI) is a combination of artificial intelligence and natural intelligence to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art.",sensors; cyber-physical systems; machine learning; artificial intelligence; human-centered AI; smart farming; smart forestry; precision farming; precision forestry; AI for good,"Holzinger, A; Saranti, A; Angerschmid, A; Retzlaff, CO; Gronauer, A; Pejakovic, V; Medel-Jimenez, F; Krexner, T; Gollob, C; Stampfer, K","University of Natural Resources & Life Sciences, Vienna; University of Alberta; Technical University of Berlin; University of Natural Resources & Life Sciences, Vienna; University of Natural Resources & Life Sciences, Vienna; University of Natural Resources & Life Sciences, Vienna",2022.0,SENSORS,MDPI,,10.3390/s22083043,20230520-160000,20230521-044735,"['digital', 'transformation', 'in', 'smart', 'farm', 'and', 'forest', 'operations', 'needs', 'human-centered', 'ai:', 'challenges', 'and', 'future', 'directions']",True,20230521-205332,,,,
729,wos,GELAB - The Cutting Edge of Grammatical Evolution,"The advent of cloud-based super-computing platforms has given rise to a Data Science (DS) boom. Many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration. Machine Learning (ML) tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike. Coupled with modern-day computing power, ML tools can be looked at as hammers that can deal with even the most stubborn nails. ML tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly. In order to keep pace with these requirements, a new enterprise, referred to as MLOps has blossomed in recent years. MLOps combines the process of ML and DS with an agile software engineering technique to develop and deliver solutions in a fast and iterative way. One of the key challenges to this is that ML and DS tools should be efficient and have better usability characteristics than were traditionally offered. In this paper, we present a novel software for Grammatical Evolution (GE) that meets both of these expectations. Our tool, GELAB, is a toolbox for GE in Matlab which has numerous features that distinguish it from existing contemporary GE software. Firstly, it is user-friendly and its development was aimed for use by non-specialists. Secondly, it is capable of hybrid optimization, in which standard numerical optimization techniques can be added to GE. We have shown experimentally that when hybridized with meta-heuristics GELAB has an overall better performance as compared with standard GE.",Germanium; Matlab; Software; Optimization; Grammar; Statistics; Sociology; Grammatical evolution; diversity; hybrid optimization,"Gupt, KK; Youssef, A; Murphy, A; Raja, MA; Ryan, C",University of Limerick; University of Limerick; University College Dublin; Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI); University of Limerick,2022.0,IEEE ACCESS,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,,10.1109/ACCESS.2022.3166115,20230520-160000,20230521-044735,"['gelab', '-', 'the', 'cutting', 'edge', 'of', 'grammatical', 'evolution']",True,20230521-205332,,,,
730,wos,Role of chemical reaction engineering for sustainable growth: One industrial perspective from India,"Chemical reaction engineering (CRE) is vital to solve many of the pressing societal challenges-energy and energy transition, materials, food, mobility, and so forth, to meet the aspirational goals of developing country population in the face of climate change, changing demographics, and geopolitical challenges. Application of the core principles of CRE to the emerging societal challenges is creating new technologies and cost-effective solutions by integrating the widely varied CRE activities into broad, powerful, systems descriptions with the help of interdisciplinary teams with broad expertise including chemistry, catalysis, chemical kinetics, transport phenomena, biology, applied mathematics and modeling, emerging data science technologies to design and optimize chemical/biochemical reactors. Such developments will be critical for CRE to play an important role in the emerging fourth industrial revolution-amalgamation of physical, digital, and biological worlds, where the velocity of disruption and acceleration of innovation are hard to comprehend or anticipate and such broadening of CRE discipline will be critical for the field to remain agile and relevant. This article describes some latest technical advances in Reliance Industries Ltd. using this philosophy to help achieve sustainable growth and Net Zero business targets. We will broadly discuss renewable hydrogen from novel biomass catalytic gasification, multizone catalytic cracking process to convert crude oil and low value hydrocarbon streams to petrochemical building blocks, an adsorption/desorption process for CO2 concentration and monetization from industrial flue gases. Furthermore, biotechnology advances in leveraging photosynthesis kinetics, synthetic biology, and genetic modifications for converting solar energy and carbon dioxide through algae production will be discussed to produce proteins, biomaterials, renewable biocrude, and so forth. We will also discuss new catalytic technologies to convert mixed plastic waste to stable oil and organic waste such as agri and municipal solid waste, and so forth, to biocrude for circular economy, and biodegradable plastics production to manage plastics pollution.",,"Sapre, A",Reliance Industries,2023.0,AICHE JOURNAL,WILEY,,10.1002/aic.17685,20230520-160000,20230521-044735,"['role', 'of', 'chemical', 'reaction', 'engineering', 'for', 'sustainable', 'growth:', 'one', 'industrial', 'perspective', 'from', 'india']",False,20230521-205332,,,,
731,wos,Exploiting Page Table Locality for Agile TLB Prefetching,"Frequent Translation Lookaside Buffer (TLB) misses incur high performance and energy costs due to page walks required for fetching the corresponding address translations. Prefetching page table entries (PTEs) ahead of demand TLB accesses can mitigate the address translation performance bottleneck, but each prefetch requires traversing the page table, triggering additional accesses to the memory hierarchy. Therefore, TLB prefetching is a costly technique that may undermine performance when the prefetches are not accurate. In this paper we exploit the locality in the last level of the page table to reduce the cost and enhance the effectiveness of TLB prefetching by fetching cache-line adjacent PTEs for free. We propose Sampling-Based Free TLB Prefetching (SBFP), a dynamic scheme that predicts the usefulness of these free PTEs and prefetches only the ones most likely to prevent TLB misses We demonstrate that combining SBFP with novel and state-of-the-art TLB prefetchers significantly improves miss coverage and reduces most memory accesses due to page walks. Moreover, we propose Agile TLB Prefetcher (ATP), a novel composite TLB prefetcher particularly designed to maximize the benefits of SBFP. ATP efficiently combines three low-cost TLB prefetchers and disables TLB prefetching for those execution phases that do not benefit from it. Unlike state-of-the-art TLB prefetchers that correlate patterns with only one feature (e.g., strides, PC, distances), ATP correlates patterns with multiple features and dynamically enables the most appropriate TLB prefetcher per TLB miss. To alleviate the address translation performance bottleneck, we propose a unified solution that combines ATP and SBFP. Across an extensive set of industrial workloads provided by Qualcomm, ATP coupled with SBFP improves geometric speedup by 16.2%, and eliminates on average 37% of the memory references due to page walks. Considering the SPEC CPU 2006 and SPEC CPU 2017 benchmark suites, ATP with SBFP increases geometric speedup by 11.1%, and eliminates page walk memory references by 26%. Applied to big data workloads (GAP suite, XSBench), ATP with SBFP yields a geometric speedup of 11.8% while reducing page walk memory references by 5%. Over the best state-of-the-art TLB prefetcher for each benchmark suite, ATP with SBFP achieves speedups of 8.7%, 3.4%, and 4.2% for the Qualcomm, SPEC, and GAP+XSBench workloads, respectively.",,"Vavouliotis, G; Alvarez, L; Karakostas, V; Nikas, K; Koziris, N; Jimenez, DA; Casas, M",Universitat Politecnica de Catalunya; Barcelona Supercomputer Center (BSC-CNS); Universitat Politecnica de Catalunya; National Technical University of Athens; Texas A&M University System; Texas A&M University College Station,2021.0,2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2021),IEEE COMPUTER SOC,,10.1109/ISCA52012.2021.00016,20230520-160000,20230521-044735,"['exploiting', 'page', 'table', 'locality', 'for', 'agile', 'tlb', 'prefetching']",True,20230521-205332,,,,
732,wos,CONSOLIDATING THE DIGITAL EDUCATIONAL TRANSFORMATION IN ANDALUSIA,"This paper presents the project for the implementation of the Virtual Learning Environment for non university education in Andalusia, a Spanish region with more than 8 million inhabitants, which educational community consists of over 2 million people (teachers, students and families), in a very heterogeneous scenario, encompassing geography, socio-economy and technology. The project is led by the General Directorate for Teacher Training and Educational Innovation (DGFPIE) of the Ministry of Education and Sports (CED), and its main objective is the consolidation of the Digital Educational Transformation in Andalusia (TDE), focusing on the optimisation of services to grant the best use of the resources. The project' strategy is fully aligned with the EU's Digital Education Action Plan, upon a global, collaborative and inclusive approach, making emphasis in granting universal access to resources and services to all the groups of the Educational Community. Once high connectivity is provided to schools, the project is defined around three action lines that consolidate the TDE ecosystem of the DGFPIE: Improving the use of digital technology in teaching-learning processes Developing digital competencies and skills relevant to the educational community Promoting the improvement of school results and reduction of dropout through Big Data (BD), Learning Analytics (LA) and Artificial Intelligence (AI). The project methodologies cover technological, implementation and dissemination aspects, and consist of adaptations of gap analysis, design thinking, Lean IT, BPM and TOGAF for the definition phase, scrum for the development and ITIL, PMP and OPPM services provision and project management. Regarding implementation and dissemination, any new service provided is tested in a piloting phase prior to its go alive, with a defined piloting methodology. The result, the Andalusian Digital Education Ecosystem is a personalized teaching-learning environment that provides access to a digital classroom, integrated with the backoffice management system, which allows class organization and planning, connected with the digital content of publishers and with an open educational resources banks (LOR). This pedagogical support is complemented with services to promote the digital training of students, families and teachers through a MOOC, MoocEdu, fully aligned with the DigCompX frameworks. A Digital Proficiency Test is included to diagnose the user skills and stablish a starting point, recommending training actions to achieve the defined objectives. Through this single access point, schools benefit from facilities to collaborate which include a vast community of school blogs and classroom spaces, BlogsAverroes, ever growing to support communication needs for different decision-making bodies within the CED. AI allows the provision of a Pedagogical Assessment Service, a personalized and contextualized educational reinforcement of the students through recommendations of itineraries, contents, tasks and/or readings adapted to their academic situation, which take into account information related to the characteristics of their teachers, their socioeconomic context and their academic performance, among others. The project results are measured by means of access and use indicators, which together with the user's satisfaction, checked by the change management service, establish the conclusions and the basis for the continuous improvement of the TDE ecosystem.",New projects and innovations; APP for education; Identity Management; Learning Analytics; Open Educational Resources; LOR; Digital Education; Collaboration,"Segura, A; Agromayor, JA; Conde, A",,2020.0,"14TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT CONFERENCE (INTED2020)",IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT,,,20230520-160000,20230521-044735,"['consolidating', 'the', 'digital', 'educational', 'transformation', 'in', 'andalusia']",False,20230521-205332,,,,
733,wos,Successful operational integration of healthcare analytics at Seattle Children's,"Introduction: As the quantity and complexity of health data grows, it is critical for healthcare organizations to devise analytic strategies that power data innovation so they can take advantage of new opportunities and improve outcomes. Seattle Children's Healthcare System (Seattle Children's) is an example of an organization that has built an operating model that integrates analytics into their business and daily operations. We present a roadmap for how Seattle Children's consolidated its fragmented analytics operations into a unified cohesive ecosystem capable of supporting advanced analytics capabilities and operational integration to transform care and accelerate research. Methods: In-depth interviews were conducted with ten leaders at Seattle Children's who have been instrumental in developing their enterprise analytics program. Interviews included the following leadership roles: Chief Data & Analytics Officer, Director of Research Informatics, Principal Systems Architect, Manager of Bioinformatics and High Throughput Analytics, Director of Neurocritical Care, Strategic Program Manager & Neuron Product Development Lead, Director of Dev Ops,Director of Clinical Analytics, Data Science Manager, and Advance Analytics Product Engineer. The interviews were unstructured and consisted of conversations intended to gather information from leadership about their experiences in building out Enterprise Analytics at Seattle Children's. Results: Seattle Children's has built an advanced enterprise analytics ecosystem that is integrated into its daily operations by applying an entrepreneurial mindset and agile development practices that are common in a startup environment. Analytics efforts were approached iteratively by selecting high-value projects that were delivered through Multidisciplinary Delivery Teams that were integrated into service lines. Service line leadership, in partnership with the Delivery Team leads, were responsible for the success of the team by setting project priorities, determining project budgets, and maintaining overall governance of their analytics endeavors. This organizational structure has led to the development of a wide range of analytic products that have been used to improve both operations and clinical care at Seattle Children's. Conclusions: Seattle Children's has demonstrated how a leading healthcare system can successfully create a robust, scalable, near real-time analytics ecosystem- one that delivers significant value to the organization from the ever-expanding volume of health data we see today.",analytics operating model; data ecosystems; healthcare analytics; organizational innovation; scientific computing,"Frisbee, KL; Sousa, R",Seattle Children's Hospital,2023.0,LEARNING HEALTH SYSTEMS,WILEY,,10.1002/lrh2.10331,20230520-160000,20230521-044735,"['successful', 'operational', 'integration', 'of', 'healthcare', 'analytics', 'at', 'seattle', ""children's""]",True,20230521-205332,,,,
734,wos,Characterization and Identification of Variations in Types of Primary Care Visits Before and During the COVID-19 Pandemic in Catalonia: Big Data Analysis Study,"Background: The COVID-19 pandemic has turned the care model of health systems around the world upside down, causing the abrupt cancellation of face-to-face visits and redirection of the model toward telemedicine. Digital transformation boosts information systems-the more robust they are, the easier it is to monitor the health care system in a highly complex state and allow for more agile and reliable analysis. Objective: The purpose of this study was to analyze diagnoses from primary care visits and distinguish between those that had higher and lower variations, relative to the 2019 and 2020 periods (roughly before and during COVID-19), to identify clinical profiles that may have been most impaired from the least-used diagnostic codes for visits during the pandemic. Methods: We used a database from the Primary Care Services Information Technologies Information System of Catalonia. We analyzed the register of visits (n=2,824,185) and their International Classification of Diseases (ICD-10) diagnostic codes (n=3,921,974; mean 1.38 per visit), as approximations of the reasons for consultations, at 3 different grouping levels. The data were represented by a term frequency matrix and analyzed recursively in different partitions aggregated according to date. Results: The increase in non-face-to-face visits (+267%) did not counterbalance the decrease in face-to-face visits (-47%), with an overall reduction in the total number of visits of 1.36%, despite the notable increase in nursing visits (10.54%). The largest increases in 2020 were visits with diagnoses related to COVID-19 (ICD-10 codes Z20-Z29: 2.540%), along with codes related to economic and housing problems (ICD-10 codes Z55-Z65: 44.40%). Visits with most of the other diagnostic codes decreased in 2020 relative to those in 2019. The largest reductions were chronic pathologies such as arterial hypertension (ICD-10 codes I10-I16: -32.73%) or diabetes (ICD-10 codes E08-E13: -21.13%), but also obesity (E65-E68: -48.58%) and bodily injuries (ICD-10 code T14: -33.70%). Visits with mental health-related diagnostic codes decreased, but the decrease was less than the average decrease. There was a decrease in consultations-for children, adolescents, and adults-for respiratory infections (ICD-10 codes J00-J06: -40.96%). The results show large year-on-year variations (in absolute terms, an average of 12%), which is representative of the strong shock to the health system. Conclusions: The disruption in the primary care model in Catalonia has led to an explosive increase in the number of non-face-to-face visits. There has been a reduction in the number of visits for diagnoses related to chronic pathologies, respiratory infections, obesity, and bodily injuries. Instead, visits for diagnoses related to socioeconomic and housing problems have increased, which emphasizes the importance of social determinants of health in the context of this pandemic. Big data analytics with routine care data yield findings that are consistent with those derived from intuition in everyday clinical practice and can help inform decision making by health planners in order to use the next few years to focus on the least-treated diseases during the COVID-19 pandemic.",COVID-19; primary care; diagnose variations; big data; ICD10; health system; big data; primary care; healthcare system,"Segui, FL; Guillamet, GH; Arolas, HP; Marin-Gomez, FX; Comellas, AR; Morros, AMR; Mas, CA; Vidal-Alaball, J",Pompeu Fabra University; Universitat de Vic - Universitat Central de Catalunya (UVic-UCC),2021.0,JOURNAL OF MEDICAL INTERNET RESEARCH,"JMIR PUBLICATIONS, INC",,10.2196/29622,20230520-160000,20230521-044735,"['characterization', 'and', 'identification', 'of', 'variations', 'in', 'types', 'of', 'primary', 'care', 'visits', 'before', 'and', 'during', 'the', 'covid-19', 'pandemic', 'in', 'catalonia:', 'big', 'data', 'analysis', 'study']",True,20230521-205332,,,,
