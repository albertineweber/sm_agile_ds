"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Achieving Agile Big Data Science: The Evolution of a Team’s Agile Process Methodology","J. S. Saltz; I. Shamshurin","School of Information Studies Syracuse University, Syracuse, NY, USA; School of Information Studies Syracuse University, Syracuse, NY, USA","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","3477","3485","While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005493","Big Data Science;Agile;Process Methodology","Big Data;Data science;Task analysis;Software;Data models;Limiting;Estimation","Big Data;kanban;project management;software management;software prototyping;team working","Agile Kanban methodology;team agile process methodology;Big Data science team;Big Data science project;agile Big Data science","","5","","38","IEEE","24 Feb 2020","","","IEEE","IEEE Conferences"
"SKI: An Agile Framework for Data Science","J. Saltz; A. Suthrland",Syracuse University; Scrum Inc.,"2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","3468","3476","This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrumlike time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus, SKI implements the Kanban process, but with a more repeatable and structured approach.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005591","Data Science;Big Data;Agile;Process Methodology","Data science;Big Data;Task analysis;Project management;Data mining;Data models","data handling;iterative methods;kanban;project management","agile framework;data science project management;process management framework;data science team;lean Kanban philosophy;structured iteration process;lean hypothesis testing;capability-based iterations;Kanban process;SKI;Scrum best practices;structured Kanban iteration framework","","7","","40","IEEE","24 Feb 2020","","","IEEE","IEEE Conferences"
"On the Application of SCRUM in Data Science Projects","N. Kraut; F. Transchel","Faculty of Business Studies, Harz University of Applied Sciences, Wernigerode, Germany; Faculty of Automation & Computer Science, Harz University of Applied Sciences, Wernigerode, Germany","2022 7th International Conference on Big Data Analytics (ICBDA)","21 Apr 2022","2022","","","1","9","The emerging discipline of Data Science poses several challenges for teams conducting projects in the field as notably, the majority of Data Science teams fail to deliver the expected outcomes. To improve the results, researchers tried to adapt agile project methodologies like Scrum for Data Science projects. Scrum in particular is often implemented due its success in software engineering. However, the basic Scrum framework has proven itself to be too strict for Data Science, due to frequent unpredictabilities of Data Science tasks. Consequently, adaptions were made to traditional Scrum to make it more suitable for the new challenges. This article discusses further adaptations and suggests that Scrum in itself is usable in Data Science, however, additional adaptations of the core concepts need to be envisioned.","","978-1-6654-7938-7","10.1109/ICBDA55095.2022.9760341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760341","SCRUM;data science;project management","Data science;Big Data;Task analysis;Scrum (Software development);Software engineering","project management;software development management;software engineering;software prototyping","Data Science tasks;basic Scrum framework;agile project methodologies;Data Science teams;Data Science projects;traditional Scrum","","","","43","IEEE","21 Apr 2022","","","IEEE","IEEE Conferences"
"The Waterfall Model with Agile Scrum as the Hybrid Agile Model for the Software Engineering Team","N. Yahya; S. S. Maidin","Department of Computer Science, Kulliyyah of Information and Communication Technology, International Islamic University Malaysia (IIUM), Malaysia; Faculty of Data Science and Information Technology (FDSIT), INTI International University, Malaysia","2022 10th International Conference on Cyber and IT Service Management (CITSM)","11 Nov 2022","2022","","","1","5","Hybrid agile is a software development model that combines the agile approach with a non-agile development strategy. A software engineering team chooses the hybrid agile to best fit the development process based on project needs; some projects require a plan-driven approach, and at the same time, agility is a must. However, among many agile methodologies and plan-driven development models, which methodologies or models adopted by a software engineering team lead to hybrid agile. This research aims to identify the software engineering team's approach and model that resulted in the emergence of a hybrid agile model. Data for this research were acquired through a qualitative study using interviews as the data collection instrument and thematic analysis is used to analyze the data and identify the theme. In the context of this paper, we focus on only one (1) theme, which is “models used in a software project”. According to the research findings, the agile Scrum and Waterfall models are the models that have been practised in software projects that have resulted in the hybrid agile model. In the near future, further research will be conducted to determine which process model is employed in certain software process phases of a software project.","2770-159X","978-1-6654-6074-3","10.1109/CITSM56380.2022.9936036","Ministry of Education (MOE)(grant numbers:FRGS/1/2019/ICT01/UIAM/03/2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9936036","Hybrid agile;Scrum;Waterfall model;Software engineering team","Instruments;Data collection;Software;Scrum (Software development);Interviews;Software engineering;Context modeling","project management;software development management;software prototyping;team working","agile methodologies;agile scrum;hybrid agile model;nonagile development strategy;plan-driven development models;process model;software engineering team;software project;waterfall model","","","","25","IEEE","11 Nov 2022","","","IEEE","IEEE Conferences"
"Identifying the most Common Frameworks Data Science Teams Use to Structure and Coordinate their Projects","J. S. Saltz; N. Hotz",Syracuse University; Indiana University,"2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","2038","2042","This paper presents the results of a study focused on exploring which framework, if any, teams use to execute data science projects. The study consisted of a survey of 109 industry professionals, as well as an evaluation of relevant framework terms searched at Google. Overall, CRISP-DM was the most commonly used framework, with Scrum and Kanban being the second and third most frequently used. We note that CRISP-DM is a life cycle framework, whereas Scrum and Kanban are team coordination frameworks. Hence, this research also notes the potential demand for a framework that integrates both life cycle and team coordination aspects of leading a data science project.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377813","Data Science;Big Data;Process Methodology","Industries;Conferences;Project management;Organizations;Data science;Big Data;Internet","data mining;project management","relevant framework terms;CRISP-DM;life cycle framework;team coordination frameworks;team coordination aspects;data science project;common frameworks data science teams use;industry professionals;Scrum;Kanban","","4","","32","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Adopting Agile Software Development Methodologies in Big Data Projects – a Systematic Literature Review of Experience Reports","I. Krasteva; S. Ilieva","GATE Institute, Software University ""St. Kliment Ohridski"", Sofia, Bulgaria; GATE Institute, Software University ""St. Kliment Ohridski"", Sofia, Bulgaria","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","2028","2033","During the last decade, agile software development methodologies have been widely adopted in various project contexts. Big data projects are different from software engineering projects in all three aspects - people, processes and technologies. Recent research has shown that agile approaches are suitable and beneficial when applied in big data projects. The aim of the current study is to investigate which of the agile software development methodologies are currently applied in big data projects and what are the key considerations for their application. As a first step towards achieving this aim, the paper presents a systematic literature review of research articles reporting real-world experience of adopting agile methodologies in different big data science contexts. The findings of the study are beneficial to both practitioners and researchers to define and adopt agile approaches which are well suited for their big data projects.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378118","agile software development;big data science;methodology adoption;real-world experience;systematic literature review","Systematics;Bibliographies;Agile software development;Big Data;Libraries;Software;Software engineering","Big Data;project management;software development management;software prototyping","agile software development methodologies;systematic literature review;software engineering projects;Big Data projects;Big Data science contexts;experience reports","","1","","18","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Applying Scrum in Data Science Projects","J. Baijens; R. Helms; D. Iren","Department of Information Science, Open University, Heerlen, The Netherlands; Department of Information Science, Open University, Heerlen, The Netherlands; Department of Information Science, Open University, Heerlen, The Netherlands","2020 IEEE 22nd Conference on Business Informatics (CBI)","15 Jul 2020","2020","1","","30","38","The rise of big data has led to an increase in data science projects conducted by organizations. Such projects aim to create valuable insights by improving decision making or enhancing an organization's service offering through data-driven services. However, the majority of data science projects still fail to deliver the expected value. To increase the success rate of projects, the use of process models or methodologies is recommended in the literature. Nevertheless, organizations are hardly using them because they are considered too rigid and they do not support the typical iterative and open nature of data science projects. To overcome this problem, this research suggests applying Agile methodologies to data science projects. Agile methodologies were originally developed in the software engineering domain and are characterised by their iterative approach towards software development. In this study, we selected the Scrum approach and integrated it into the CRISP-DM methodology for data science projects using a Design Science Research approach. This new methodology was then evaluated in three different case organizations using expert interviews. Analysis of the expert interviews resulted in a further refinement of the Agile data science methodology proposed by this research.","2378-1971","978-1-7281-9926-9","10.1109/CBI49978.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140255","Data Science;Agile;Scrum","Data science;Biological system modeling;Data models;Organizations;Task analysis;Software","Big Data;decision making;project management;software prototyping","data science projects;agile data science methodology;Scrum;big data;decision making;software engineering;software development;CRISP-DM methodology","","9","","43","IEEE","15 Jul 2020","","","IEEE","IEEE Conferences"
"Managing and Composing Teams in Data Science: An Empirical Study","T. Aho; T. Kilamo; L. Lwakatare; T. Mikkonen; O. Sievi-Korte; S. Yaman","TietoEvry, Tampere, Finland; Computing Sciences, Tampere University, Tampere, Finland; Computer Science, University of Helsinki, Helsinki, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Computing Sciences, Tampere University, Tampere, Finland; KPMG Finland, Helsinki, Finland","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","2291","2300","Data science projects have become commonplace over the last decade. During this time, the practices of running such projects, together with the tools used to run them, have evolved considerably. Furthermore, there are various studies on data science workflows and data science project teams. However, studies looking into both workflows and teams are still scarce and comprehensive works to build a holistic view do not exist. This study bases on a prior case study on roles and processes in data science. The goal here is to create a deeper understanding of data science projects and development processes. We conducted a survey targeted at experts working in the field of data science (n=50) to understand data science projects’ team structure, roles in the teams, utilized project management practices and the challenges in data science work. Results show little difference between big data projects and other data science. The found differences, however, give pointers for future research on how agile data science projects are, and how important is the role of supporting project management personnel. The current study is work in progress and attempts to spark discussion and new research directions.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671737","Data science;agile practices;teamwork;project management","Conferences;Project management;Data science;Big Data;Data models;Sparks;Personnel","Big Data;project management","data science workflows;agile data science projects;Big Data projects;project management practices","","","","23","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Using Agile Frameworks in Big Data projects","K. Kolesnikova; O. Mezentseva; O. Kolesnikov; D. J. Obenewaa","Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine; Taras Shevchenko National University of Kyiv, Kyiv, Ukraine","2021 IEEE 16th International Conference on Computer Sciences and Information Technologies (CSIT)","27 Dec 2021","2021","2","","415","418","Considering the main problems of Big Data projects - huge amounts of data, uncertainty and the need to take into account constant changes, the study decided to investigate the process of managing Big Data projects using Agile. The problem of choosing Agile techniques is complicated by the fact that each of the known frameworks has its own advantages and disadvantages. Depending on the type of project, a particular tool can influence various criteria for the success of the project. In addition, research has shown that some enterprises use separate elements of a particular framework. Therefore, the scientific novelty of the article lies in the study of the influence of individual elements of Agile techniques on the success of the project and its course. With the help of expert assessment in the work, a quantity of separate elements of Agile were formed. These techniques are the most common among practicing managers of Big Data project. The data were prepared to create a regression model.","2766-3639","978-1-6654-4257-2","10.1109/CSIT52700.2021.9648622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648622","Agile;project management;Big Data;statistics;questionnaire;expert assessment","Uncertainty;Conferences;Customer satisfaction;Project management;Companies;Big Data;Data models","Big Data;data analysis;regression analysis;software prototyping","agile frameworks;Big Data project;agile techniques;expert assessment;practicing managers;regression model","","","","20","IEEE","27 Dec 2021","","","IEEE","IEEE Conferences"
"Scrum Best Practices Recommendation: a Media and Community Startup Case Study","A. Kurniawan; E. K. Budiardjo; K. Mahatma","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia","2021 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS)","9 Feb 2022","2021","","","1","5","XYZ Company is a media and community company that applies Scrum in the process of developing key business support applications. The results of problem identification through interviews with the Chief Technology Officer (CTO) and Chief Product Officer (CPO) showed that one of the root causes of the problem was the Scrum team did not implement the Scrum guidelines strictly. This research evaluates the maturity level of Scrum implementation using the Standard CMMI Appraisal Method for Process Improvement (SCAMPI C). Researchers used the Scrum Maturity Model (SMM) as a model for calculating maturity. This SMM has been updated by following the Scrum Guide 2020 and best practices in 2020-2021 obtained from the literature study. To affirm the appraisal result, This research also distributed questionnaires to 33 respondents from the product team and the technology team. This research recommends implementation improvements using the Plan, Do, Check, Act (PDCA) Cycle approach. The results of the Scrum implementation maturity assessment are on Level 2. This research recommends some practices to be implemented and improved in the objectives: (a) Scrum Role Exist; (b) Scrum Meetings Occur and are Participated, and (c) Daily Scrum Succeed. If applied consistently, XYZ will have a quality improvement in Scrum implementation.","","978-1-6654-3709-7","10.1109/ICADEIS52521.2021.9701958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701958","Evaluation;Best practices;SCAMPI C;Scrum;Scrum maturity model","Electronic learning;Companies;Media;Data science;Appraisal;Interviews;Best practices","business data processing;Capability Maturity Model;organisational aspects;project management;software development management","community company;business support applications;problem identification;chief technology officer;standard CMMI appraisal method;process improvement;SMM;chief product officer;Scrum meetings occur;Scrum role exist;daily scrum succeed;XYZ company;CTO;CPO;SCAMPI C;plan, do, check, act cycle approach;PDCA;Scrum implementation maturity assessment","","","","24","IEEE","9 Feb 2022","","","IEEE","IEEE Conferences"
"Story and Task Issue Analysis for Agile Machine Learning Projects","K. Singla; T. M. Vinayak; A. S. Arpitha; C. Naik; J. Bose","Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India","2020 IEEE-HYDCON","3 Nov 2020","2020","","","1","4","The usage of Agile methodology in planning and executing machine learning (ML) and data science related software engineering projects is increasing. However, there are very few studies using real data on how effective such planning is or guidelines on how to plan such projects. In this paper, we analyze data taken from several software projects using Scrum tools. We compare the data for data science/ML and non-ML projects, in an attempt to understand if data science and ML projects are planned or executed any differently compared to normal software engineering projects. We also perform a story classification task using machine learning to analyze story logs for agile tasks for several teams. We find there are differences in what makes a good ML story as opposed to a non ML story. After analyzing this data, we propose a few ways in which software projects, whether machine learning related or not, can be better logged and executed using Scrum tools like Jira.","","978-1-7281-4994-3","10.1109/HYDCON48903.2020.9242803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9242803","scrum;machine learning project;software engineering;agile methodology","Machine learning;Tools;Software;Planning;Task analysis;Scrum (Software development);Software engineering","learning (artificial intelligence);software engineering","nonML story;agile tasks;story classification task;normal software engineering projects;nonML projects;Scrum tools;software projects;agile methodology;agile machine learning projects;task issue analysis","","1","","16","IEEE","3 Nov 2020","","","IEEE","IEEE Conferences"
"A Typical Practical Team Structure and Setup in Agile Software Development","M. Afshari; T. J. Gandomani","Data Science Research Center, Shahrekord University, Shahrekord, Iran; Department of Computer Science, Data Science Research Center, Shahrekord University, Shahrekord, Iran","2021 7th International Conference on Electrical, Electronics and Information Engineering (ICEEIE)","30 Nov 2021","2021","","","483","487","Agile software development provides a different approach to Agile projects. This approach emphasizes employing experienced and committed individuals. In this approach, team management is different from what the disciplined methods defined. In this condition, team organization, team members’ roles, and responsibilities, and project control methods need to be defined in a new form. Although some Agile methods define particular roles, it seems that team structure in Agile projects in real projects is different from what is expected. This paper aimed to propose a common team structure and setup for Agile teams in practice. Differences in the Agile and plan-driven approaches in software development lead to define new concepts such as team self-organization, on-site customer, leadership, and collaboration in Agile teams. Also, some new roles and responsibilities have been defined in Agile teams, including Technical Lead, Product Owner, Architecture Owner, Developer, etc.","","978-1-6654-3232-0","10.1109/ICEEIE52663.2021.9616743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616743","Agile software development;Agile methods;Agile team;Agile team setup;Agile team structure","Leadership;Force;Agile software development;Collaboration;Computer architecture;Companies;Lead","project management;software development management;software prototyping;team working","agile software development;agile projects;agile team management;team structure;plan-driven approaches;team self-organization;on-site customer;leadership;collaboration","","","","31","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"A big data on private cloud agile provisioning framework based on OpenStack","M. Lu; X. Zhou","Infrastructure as a Service, BT/IT, Lenovo, Beijing, China; Infrastructure as a Service, BT/IT, Lenovo, Beijing, China","2018 IEEE 3rd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)","18 Jun 2018","2018","","","253","260","On the bases of the OpenStack private cloud delivery big data platform, numerous entities yearn for attaining agile and standardized big data delivery platform, reclaiming the resources, managing the total cost of ownership (TCO) and adapting to multiple big data open source or commercial off-the-shelf (COTS) solutions. Nevertheless, as regards the big data platform running on cloud computing, the big data platform is disintegrated from the cloud computing system by virtual machines since neither being based on OpenStack private cloud nor on big data platform can achieve end-to-end resource delivery, together with ensuring that it is quite convenient for the long-term operations. Accordingly, establishing an across framework between private cloud and big data platform is quite essential. The big data on cloud agile provision framework could realize fast resource delivery based on predefined orchestration template of private cloud, operating system, big data platform, monitor, inspection system, etc. Through the deployment of this framework, it is capable of attaining the delivery of agile, low cost, standardized and high adaptability the big data on cloud, as well as the high-quality operation of the big data on cloud with the help of integration configuration management database (CMDB) with the automatic inspection system.","","978-1-5386-4301-3","10.1109/ICCCBDA.2018.8386522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386522","cloud computing;agile resource provisioning;big data platform orchestration;inspection and rule engine","Big Data;Cloud computing;Virtual machining;Technological innovation;Testing;Inspection","Big Data;cloud computing;configuration management;virtual machines","OpenStack private cloud delivery big data platform;agile data delivery platform;private cloud agile provisioning framework;total cost of ownership;TCO management;commercial off-the-shelf solutions;COTS solutions;Big Data open source;virtual machines;end-to-end resource delivery;integration configuration management database;CMDB;automatic inspection system","","1","","12","IEEE","18 Jun 2018","","","IEEE","IEEE Conferences"
"Research on Enterprise Agile High Potential Talent Identification System Based on Big Data Technology","M. Yang; W. Wang","School of Management, Shanghai Sanda University, Shanghai, China; School of Economics and Management, Harbin University of Science and Technology, Harbin, China","2021 9th International Conference on Orange Technology (ICOT)","21 Jan 2022","2021","","","1","4","In the era of VUCA, enterprises need to quickly and accurately identify high-potential talents to achieve enterprise development and transformation. This article will talent radar, data, image, big data technologies, such as tendency analysis and Merce post evaluation methods, behavioral event interview, evaluation center technology and so on to carry on the organic combination, build agile high latent talent identification system, to establish high latent talent ability quality model, establish other agile high dive into the well path and the specification, as to provide theoretical basis for enterprise agile high latent talent identification.","","978-1-6654-7842-7","10.1109/ICOT54518.2021.9680668","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680668","VUCA agile;high potential talents;talent recognition system;competency model","Analytical models;Radar;Big Data;Radar imaging;Data models;Social implications of technology;Interviews","Big Data;business data processing;human resource management","enterprise agile high potential talent identification system;Big Data;high-potential talents;enterprise development;Merce post evaluation methods;behavioral event interview;evaluation center technology;high latent talent ability quality model;tendency analysis","","","","9","IEEE","21 Jan 2022","","","IEEE","IEEE Conferences"
"CRISP-DM for Data Science: Strengths, Weaknesses and Potential Next Steps","J. S. Saltz",Syracuse University,"2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","2337","2344","This paper explores the strengths and weaknesses of CRISP-DM when used for data science projects. The paper then explores what key actions data science teams using CRISP-DM should consider that addresses CRISP-DM’s weaknesses. In brief, CRISP-DM, which is the most popular framework teams use to execute data science projects, provides an easy to understand description of the data science project workflow (i.e., the data science life cycle). However, CRISP-DM’s project phases miss some key aspects of the data science project life cycle. In addition, CRISP-DM’s task-focused approach fails to address how a team should prioritize tasks, and in general, collaborate and communicate. Hence, this paper also describes how CRISP-DM could be combined with a team coordination framework, such as Scrum or Data Driven Scrum, which is a newer collaboration framework developed to address the unique data science coordination challenges.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671634","","Conferences;Collaboration;Data science;Big Data;Task analysis","data handling;data mining;groupware;organisational aspects;project management;software prototyping","data science project workflow;data science life cycle;CRISP-DM's project phases;data science project life cycle;CRISP-DM's task-focused approach;Data Driven Scrum;data science projects;key actions data science teams","","6","","21","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Identifying and Addressing 6 Key Questions when Using Data Driven Scrum","J. S. Saltz; A. Sutherland; T. Jombart",Syracuse University; Scrum Inc; London School of Hygiene & Tropical Medicine,"2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","2345","2352","Data Driven Scrum (DDS) enables lean data science project agility and addresses the key challenges that have been identified when using Scrum in a data science context. However, little has been written with respect to the questions or challenges teams might encounter when trying to use DDS. Based on a survey of 18 team leads trying to use DDS, this paper describes six common questions teams might encounter when trying to implement DDS, as well as how to address these challenges.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671930","","Conferences;Data science;Big Data","business data processing;data handling;team working","common questions teams;DDS;lean data science project agility;data science context;data driven scrum","","","","13","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Analysis of Software Engineering for Agile Machine Learning Projects","K. Singla; J. Bose; C. Naik","Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India; Samsung R&D Institute, Bangalore, India","2018 15th IEEE India Council International Conference (INDICON)","16 Mar 2020","2018","","","1","5","The number of machine learning, artificial intelligence or data science related software engineering projects using Agile methodology is increasing. However, there are very few studies on how such projects work in practice. In this paper, we analyze project issues tracking data taken from Scrum (a popular tool for Agile) for several machine learning projects. We compare this data with corresponding data from non-machine learning projects, in an attempt to analyze how machine learning projects are executed differently from normal software engineering projects. On analysis, we find that machine learning project issues use different kinds of words to describe issues, have higher number of exploratory or research oriented tasks as compared to implementation tasks, and have a higher number of issues in the product backlog after each sprint, denoting that it is more difficult to estimate the duration of machine learning project related tasks in advance. After analyzing this data, we propose a few ways in which Agile machine learning projects can be better logged and executed, given their differences with normal software engineering projects.","2325-9418","978-1-5386-8235-7","10.1109/INDICON45594.2018.8987154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987154","scrum;machine learning project;software engineering;agile methodology","Machine learning;Task analysis;Software;Maximum likelihood estimation;Software engineering;Tag clouds;Data science","learning (artificial intelligence);project management;software engineering","nonmachine learning projects;normal software engineering projects;agile machine learning projects;Scrum;product backlog","","1","","14","IEEE","16 Mar 2020","","","IEEE","IEEE Conferences"
"When Edge Computing Meets Agile Software Development","L. Zhu; S. Song; Z. Xu; W. Wang; S. Peng; S. Hu","Institute of Software Chinese Academy of Sciences, Beijing, China; Alibaba Cloud Big Data Application College, Zhuhai College of Science and Technology, Zhuhai, China; Academy of Management, Guangdong University of Science and Technology, Dongguan, China; Alibaba Cloud Big Data Application College, Zhuhai College of Science and Technology, Zhuhai, China; Zhuhai Yingying Technology Co., Ltd., Zhuhai, China; Institute of Data Science, City University of Macau, Macau, China","2022 4th International Conference on Communications, Information System and Computer Engineering (CISCE)","17 Aug 2022","2022","","","156","159","Agile development has been a common methodology in software development. In response to the covid-19, most software development teams choose to work remotely. As a result of the different network environments, the company cloud center network load cannot meet the requirements of remote development and fault tolerance requirements of the agile development process. We designed a mixed-method called the Edge Development approach for improving Agile software development during the decision-making process. The extensive literature review provided us with three categories of challenges as well as solutions to support Edge Development's decision-support process. In the light of the survey, Five main software development decision-making challenges were identified in this study. In addition, we made a series of recommendations to improve the decision-making process of Edge Development from a variety of perspectives.","","978-1-6654-9848-7","10.1109/CISCE55963.2022.9851104","Zhuhai Industry University-Research Cooperation(grant numbers:ZH22017002200011PWC); FDCT-NSFC(grant numbers:0066/2019/AFJ); MOST-FDCT(grant numbers:0058/2019/AMJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851104","Agile development;Edge computing;Edge development;Decision-making","COVID-19;Fault tolerance;Bibliographies;Decision making;Fault tolerant systems;Agile software development;Companies","decision making;decision support systems;software development management;software engineering;software prototyping","main software development decision-making challenges;Edge Development's decision-support process;Edge Development approach;agile development process;fault tolerance requirements;remote development;company cloud center network load;different network environments;software development teams;common methodology;Edge computing meets Agile software Development;decision-making process","","","","16","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"A survey study of success factors in data science projects","I. Martinez; E. Viles; I. G. Olaizola","Vicomtech Foundation, Basque Research and Technology Alliance, Donostia-San Sebastián, Spain; TECNUN School of Engineering, University of Navarra, Donostia-San Sebastián, Spain; Vicomtech Foundation, Basque Research and Technology Alliance, Donostia-San Sebastián, Spain","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","2313","2318","In recent years, the data science community has pursued excellence and made significant research efforts to develop advanced analytics, focusing on solving technical problems at the expense of organizational and socio-technical challenges. According to previous surveys on the state of data science project management, there is a significant gap between technical and organizational processes. In this article we present new empirical data from a survey to 237 data science professionals on the use of project management methodologies for data science. We provide additional profiling of the survey respondents’ roles and their priorities when executing data science projects. Based on this survey study, the main findings are: (1) Agile data science lifecycle is the most widely used framework, but only 25% of the survey participants state to follow a data science project methodology. (2) The most important success factors are precisely describing stakeholders’ needs, communicating the results to end-users, and team collaboration and coordination. (3) Professionals who adhere to a project methodology place greater emphasis on the project’s potential risks and pitfalls, version control, the deployment pipeline to production, and data security and privacy.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671588","data science;survey;project management;factor analysis;success factors","Data privacy;Statistical analysis;Data security;Pipelines;Project management;Focusing;Production","data privacy;organisational aspects;project management;security of data","empirical data;project management methodologies;survey respondents;data science projects;survey study;data science lifecycle;survey participants state;data science project methodology;project methodology;data security;privacy;data science community;socio-technical challenges;data science project management","","","","23","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Using Big Data Analytics to Create a Predictive Model for Joint Strike Fighter","R. Norman; J. Bolin; E. T. Powell; S. Amin; J. Nacker","Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Big Data and Knowledge Management, Test Resource Management Center (TRMC), Alexandria, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA; Joint Strike Fighter Program Office (JPO), Naval Air Systems Command (NAVAIR), Arlington, VA","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","3590","3596","The amount of information needed to acquire knowledge on today's acquisition systems is growing exponentially due to more complex, higher resolution, software-intensive acquisition systems that need to operate in System-of-Systems (SoS), Family-of-Systems (FoS), Joint, and Coalition environments. Unfortunately, the tools and methods necessary to rapidly collect, aggregate, and analyze this information have not evolved as a whole in conjunction with this increased system complexity and, therefore, has made analysis and evaluation increasingly deficient and ineffective. The Test Resource Management Center's (TRMC's) vision is to build a DoD test and evaluation (T&E) knowledge management (KM) and analysis capability that leverages commercial big data analysis and cloud computing technologies to improve evaluation quality and reduce decision-making time. An evaluation revolution, starting with the Joint Strike Fighter (JSF) program, is underway to ensure the T&E community can support the demands of next-generation weapon systems.The true product of T&E is knowledge ascertained through the collection of information about a system or item under test. However, the T&E community's ability to provide this knowledge is hampered by more complex systems, more complex environments, and the need to be more agile in support of strategic initiatives, such as agile acquisition and the 3rd Offset Strategy. This increased complexity and need for speed cause delayed analysis and problems that go undetected during T&E. The primary reason for these shortfalls is antiquated tools and processes that make data hard to locate, aggregate, and convert into knowledge. In short, DoD has not evolved its evaluation infrastructure as its weapon systems have evolved.Conversely, commercial entities, such as medical observation and diagnosis, electric power distribution, retail, and industrial manufacturing, have embraced agility in their methodologies while modernizing analytics capabilities to keep up with the massive influx of data. Raw physical sensors could provide data, higher-quality image or video cameras, radio frequency identification (RFID) devices, faster data collectors, more detailed point-of-sale information or digitized records, and ultimately is providing more data to analysts in size and complexity than ever before. As more data has become available, an interrelated phenomenon is the desire of analysts to ask more detailed questions about their consumers and their business infrastructure. To drive the process of implementing big data analytics, businesses have begun establishing analytics centers which either take pre-defined business cases and apply methods to address them or implement existing knowledge within the data architecture to create a higher level of awareness to business groups or the company at-large. To meet these demands, data storage and computation architectures have become more sophisticated, dozens of technologies were developed for large-scale processing (such as Apache Hadoop or GreenPlum), and streaming architectures which allow data to be processed and actioned on in real-time as it is collected have become commonplace. The net result of these commercial best practices is a solid foundation for the DoD to transform how it uses data to achieve faster, better, and smarter decisions throughout the acquisition lifecycle.","","978-1-5386-5035-6","10.1109/BigData.2018.8622388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622388","Big Data;Data Analytics;Knowledge Management;Data Management;Virtualization;Cloud Computing;Predictive Maintainance;Department of Defense;Test and Evaluation","Big Data;Knowledge management;Tools;US Department of Defense;Cloud computing;Computer architecture;Data analysis","Big Data;data analysis;decision making;knowledge management;military aircraft;military computing;weapons","data analytics centers;Test Resource Management Center;data collectors;3rd Offset Strategy;Joint Strike Fighter program;commercial Big Data analysis;system-of-systems;higher-quality image;evaluation infrastructure;agile acquisition;complex systems;T&E community;next-generation weapon systems;decision-making time;evaluation quality;cloud computing technologies;DoD test;software-intensive acquisition systems;predictive model;acquisition lifecycle;computation architectures;data storage;data architecture","","3","","0","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure","C. J. Wang; B. Kim","R&D InfoTech Labs, Toyota Motor North America (TMNA), U.S.A; R&D InfoTech Labs, Toyota Motor North America (TMNA), U.S.A","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","1784","1787","Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a Big Data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP?In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better.The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378045","","Human computer interaction;Pipelines;Memory management;Big Data;Throughput;Standards;Automotive engineering","Big Data;computer centres;data analysis;microprocessor chips;storage management","automotive use case;agile performance;infrastructure design;HCI;DHCI;data center hardware;disaggregated hyper-converged infrastructure;automotive Big Data pipeline;CPU utilization;IOPs;network consumption;memory consumption","","","","13","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"An Improved Agile Framework For Implementing Data Science Initiatives in the Government","W. Qadadeh; S. Abdallah","Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, UAE; Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, UAE","2020 3rd International Conference on Information and Computer Technologies (ICICT)","14 May 2020","2020","","","24","30","Implementing data mining projects in governmental organizations is emerging in the Middle East. The literature has been showing that there is a significant gap between the problems defined by the research in data mining and the problems in real world projects. The gap is to the level of semantics between the data scientists and the business users. Trying to fill this gap, we have developed an improved Agile data mining framework to fulfill the government business objectives and needs. The previous works had been claiming that handling such project is not yet mature in the region. For this an Agile implementation framework is required. We are also proposing a systematic way for identifying business problems as part of the framework. The process is Agile, so it would start from investigating the data set dimensions to identify business problems. It also allows early Business people cooperation with data scientist. We've applied the proposed framework in one of the Middle East government organizations. The business team and the data scientists have been showing their satisfaction regarding the results of using the proposed framework. The proposed framework have helped both business and data scientist to implement their first initiative in data mining. The proposed framework also helped in efficiently mapping the project with the core business objectives and problems using real world dataset.","","978-1-7281-7283-5","10.1109/ICICT50521.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092078","data mining, data science, agile framework, business problems, business objectives","Data mining;Organizations;Data science;Task analysis;Tools","business data processing;business process re-engineering;data mining;government data processing;public administration","agile implementation framework;improved agile data mining framework;early business people cooperation;improved agile framework;government business objectives;business users;data mining projects;data science initiatives;core business objectives;business team;Middle East government organizations;data scientist;business problems","","4","","23","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Building the federation of cloud service for big data","J. Shu; C. Liang; B. Wang; J. Xu","School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Management, Hefei University of Technology, Hefei, Anhui, China; School of Statistics and Applied Mathematics, Anhui University of Finance and Economics, Bengbu, Anhui, China","2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA)","28 May 2018","2018","","","166","169","The demand for agile and flexible business application for big data has sparked interest in using cloud computing technology. Due to the limitation of provider's capability and the magnanimity of task quantity for big data, a single cloud provider may not offer enough service resources. However, a service federation among multiple providers can effectively solve this problem. This paper proposes the framework of cloud federation and introduces the basic processes of building service federation among multiple cloud providers. Moreover, we propose a multi-objectives task assigning model in the federation. A genetic algorithm based heuristic approach is developed as the optimization method. Eventually, some simulation experiments are conducted to illustrate the effectiveness of the model.","","978-1-5386-4794-3","10.1109/ICBDA.2018.8367670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367670","cloud service;cloud federation;multiple objectives optimization;task assignment;genetic algorithm","Task analysis;Cloud computing;Reliability;Big Data;Organizations;Measurement","Big Data;cloud computing;genetic algorithms","cloud service;big data;agile business application;flexible business application;cloud computing technology;task quantity;single cloud provider;service resources;multiple providers;cloud federation;building service federation;multiple cloud providers;multiobjectives task assigning model","","2","","10","IEEE","28 May 2018","","","IEEE","IEEE Conferences"
"Improving Agile Development from Perspective of Design-Informing Model","Z. Zhang","University of Toronto, Toronto, Canada","2020 International Conference on Computing and Data Science (CDS)","9 Dec 2020","2020","","","23","26","Agile development is usually used to solve the problem of inflexibility which the other project management models, like the Waterfall model and the V model, may meet. However, conventional agile development still faces many problems under rapid iterations. Frequent iteration lacks efficient communication a large community, resources to share information, and quality of product. For better project management, this article describes a method, called the design-informing model (DIM), to improve the agile development. The design-informing model consists of four parts, user mental mode, developer mental model, system model, and environmental model. At the end of the paper, some discussions will be conducted to evaluate DIM in practice.","","978-1-7281-7106-7","10.1109/CDS49703.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275950","project management;agile development;software engineering;model optimization","Data science","iterative methods;knowledge based systems;software prototyping","environmental model;design-informing model;project management models;Waterfall model;V model;conventional agile development;developer mental model;system model","","","","15","IEEE","9 Dec 2020","","","IEEE","IEEE Conferences"
"What is Good Feedback in Big Data Projects for Cyberinfrastructure Diffusion in e-Science?","K. F. Kee; J. C. McCain","School of Communication, Chapman University, Orange, CA, USA; School of Communication, Chapman University, Orange, CA, USA","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","2804","2812","This paper investigates the role of feedback in big data projects for cyberinfrastructure (CI) diffusion in e-science. For many of these projects, large-scale and heterogeneous datasets, multidisciplinary and dispersed experts, and advanced technologies are brought together to harness analytic insights. However, without effective CI and computational tools, the accuracy and meaningfulness of analytics results are compromised. In fact, without CI tools, raw data remain raw with hidden insights, as data analytics cannot be executed at all. In order to improve such tools for meaningful results, we argue to conceptualize the communication mechanism of `feedback' in agile software development, with the goal of producing CI tools that are responsive to users. Based on a grounded analysis of interview data, we concluded that feedback helps developers in big data projects understand users' needs, makes tools user-friendly, prevents emergencies, and is better for developers than no feedback. Furthermore, good feedback is often structured, specific, actionable, timely, generalizable, and delivered in a tactful way. Despite the limitation of the findings being exploratory and yet to be evaluated experimentally, we argued that they still can motivate developers to be proactive seekers of feedback for their tools, productively guide developers' communication with users, and ultimately promote further adoption and diffusion of CI tools in e-science.","","978-1-5386-5035-6","10.1109/BigData.2018.8622573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622573","feedback;agile software development;e-science;cyberinfrastructure;technology adoption;diffusion of innovations","Big Data;Tools;Receivers;Agile software development;Standards organizations;Organizations;Feedback communications","Big Data;data analysis;decision making;natural sciences computing","good feedback;big data projects;cyberinfrastructure diffusion;computational tools;CI tools;raw data;data analytics;interview data;e-scienc;grounded analysis","","","","28","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"A Framework to Data Delivery Security for Big Data Annotation Delivery System","Y. Yang; H. He; D. Wang; Z. Ding","Information School, Beijing Institute of Graphic Communication, Beijing, China; Datatang (Beijing) Technology Company, Limited, Beijing, China; Datatang (Beijing) Technology Company, Limited, Beijing, China; Information School, Beijing Institute of Graphic Communication, Beijing, China","2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)","9 Dec 2018","2018","","","532","536","Big data annotation plays an important role in Artificial Intelligence model training. The proliferation of data annotation tasks has brought the issue of security of the big data delivery. This work identifies the security framework associated with encryption and compression procedures that support data delivery safety. In this paper, we propose an agile framework that caters to various types of data under RESTful web services. All the procedures are automatically operated by the server without human intervention. This work assists the company delivers the tagged data products to users with a high-security level avoiding the risk of information disclosure.","2155-6814","978-1-5386-5580-1","10.1109/MASS.2018.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567604","Big data;compression;encryption;lightweight framework;data delivery","Encryption;Servers;Task analysis;Image coding;Companies;Big Data","Big Data;cryptography;data compression;data handling;Web services","data delivery security;delivery system;big data annotation;data annotation tasks;big data delivery;security framework;encryption;compression procedures;data delivery safety;agile framework;tagged data products;high-security level;artificial intelligence model training;RESTful web services","","1","","7","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"Designing Knowledge Management System with Big Data for Hospital Inpatient Services : (Case Study at Islamic Hospital XYZ Pekanbaru)","T. R. Perdana; S. Mujiatun; S. Sfenrianto; E. R. Kaburuan","Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia; Information System Management, Bina Nusantara University, Jakarta, Indonesia","2019 International Conference on Information and Communications Technology (ICOIACT)","23 Dec 2019","2019","","","851","856","The quality of health services is an important indicator in the health business and industry, especially for the XYZ ISLAMIC HOSPITAL in Pekanbaru. The need for performance improvements that can directly improve the quality of inpatient health services is a major problem. The role of doctors and nurses' knowledge becomes a benchmark in determining the performance and quality of services, in this case the Knowledge Management System (KMS) can be a solution in supporting the knowledge management process. However, the growth of innovation in knowledge management is also needed in practice. So Big Data as a large data processing technology and various types of data will be a supporter in the process of increasing and accelerating the growth of knowledge of doctors and nurses at the XYZ ISLAMIC HOSPITAL by providing relevant information as needed. Then it is necessary to design a KMS that uses Big data as one of the enablers in the process of creating knowledge for doctors and nurses and then can be stored and shared. This design is done by using the Knowledge Management System Agile Implementation Methodology (KMSAIM) which prioritizes the initiation process in each problem domain so that each component has the right and relevant solutions. The KMS design results are in the form of site-based applications that have file sharing features, discussion forums for sharing medical experiences and there are search features needed by doctors and nurses for inpatient services at XYZ ISLAMIC HOSPITAL.","","978-1-7281-1655-6","10.1109/ICOIACT46704.2019.8938469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938469","Inpatient Medical Service;Knowledge Management;Knowledge Management System;Big Data.","Hospitals;Big Data;Knowledge management;Technological innovation","Big Data;health care;hospitals;knowledge management;medical information systems;patient care;peer-to-peer computing;software prototyping","nurses;XYZ ISLAMIC HOSPITAL;designing knowledge management system;big data;hospital inpatient services;Islamic Hospital XYZ Pekanbaru;health business;performance improvements;inpatient health services;doctors;knowledge management process;data processing technology;initiation process;KMS design results;knowledge management system agile implementation methodology;KMSAIM","","2","","10","IEEE","23 Dec 2019","","","IEEE","IEEE Conferences"
"On the Appropriate Methodologies for Data Science Projects","A. Karimi Dastgerdi; T. Javdani Gandomani","Faculty of Business and Economics, Leuphana University of Luneburg, Luneburg, Germany; Department of Computer Science, Shahrekord University, Shahrekord, Iran","2021 International Conference on Information Technology (ICIT)","26 Jul 2021","2021","","","667","673","Data science is an emerging discipline with a particular research focus on improving the available techniques for data analysis. While the number of data science projects is growing, unfortunately, there is a slight consideration of how a team performs a data science project. Although the existence of a repeatable well-defined process could deal with many challenges of data science projects, researches conducted in recent years indicate a convergence of the results to agile methodologies as the appropriate ones for the projects. In this paper, first, the tasks and roles of individuals in data science projects are addressed; then, some research conducted for the methodologies used in the projects are studied. The study shows that agile methodologies could resolve many issues of data science projects by increasing the communications and cooperation of the team members and investors.","","978-1-6654-2870-5","10.1109/ICIT52682.2021.9491712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491712","agile software methodologies;data science;big data;business intelligence","Training;Software algorithms;Project management;Data science;Predictive models;Tools;Software","data analysis;project management;team working","data science project;data analysis;agile methodologies","","1","","31","IEEE","26 Jul 2021","","","IEEE","IEEE Conferences"
"Big Data Analytics on Cyber Attack Graphs for Prioritizing Agile Security Requirements","E. Hadar; A. Hassanzadeh","Accenture Labs, Accenture; Accenture Labs, Accenture","2019 IEEE 27th International Requirements Engineering Conference (RE)","5 Dec 2019","2019","","","330","339","In enterprise environments, the amount of managed assets and vulnerabilities that can be exploited is staggering. Hackers' lateral movements between such assets generate a complex big data graph, that contains potential hacking paths. In this vision paper, we enumerate risk-reduction security requirements in large scale environments, then present the Agile Security methodology and technologies for detection, modeling, and constant prioritization of security requirements, agile style. Agile Security models different types of security requirements into the context of an attack graph, containing business process targets and critical assets identification, configuration items, and possible impacts of cyber-attacks. By simulating and analyzing virtual adversary attack paths toward cardinal assets, Agile Security examines the business impact on business processes and prioritizes surgical requirements. Thus, handling these requirements backlog that are constantly evaluated as an outcome of employing Agile Security, gradually increases system hardening, reduces business risks and informs the IT service desk or Security Operation Center what remediation action to perform next. Once remediated, Agile Security constantly recomputes residual risk, assessing risk increase by threat intelligence or infrastructure changes versus defender's remediation actions in order to drive overall attack surface reduction.","2332-6441","978-1-7281-3912-8","10.1109/RE.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920695","Security Requirements;Requirements Prioritization;Agile Security;Attack Graph;Graph Analytics;Attack Path;Remediation Requirements;Attack Surface;Cyber Digital Twin","Security;Organizations;Risk management;Process control;Scalability;Standards organizations","Big Data;business data processing;computer crime;data analysis;graph theory;risk analysis;risk management;software prototyping","requirements backlog;business risks;Security Operation Center;attack surface reduction;big data analytics;cyber attack graphs;prioritizing Agile Security requirements;managed assets;complex big data graph;potential hacking paths;risk-reduction security requirements;constant prioritization;agile style;Agile Security models different types;attack graph;business process targets;critical assets identification;cyber-attacks;virtual adversary attack paths;cardinal assets;business processes;prioritizes surgical requirements","","29","","18","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Agility Measurement of Agile Supply Chain Network Based on Complex Network Theory","Y. Yao; L. Li","Anhui Finance & Trade Vocational College, Hefei, China; School of Management Hefei University of Technology, Anhui Finance & Trade Vocational College, Hefei, China","2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS)","2 Apr 2020","2019","","","757","762","With the development of information technology, the supply chain has developed into a new stage of intelligent supply chain which is deeply integrated with the Internet and the Internet of Objects. In order to give full play to the characteristics of innovation, collaboration, win-win, openness and greenness in supply chain, and to build a smart supply chain system with big data support, network sharing and intelligent collaboration, the agility measurement of supply chain has become an urgent and important topic. This paper presents an agile metric based on complex network theory for agile supply chain network. Firstly, the mathematical expression of agile supply chain network and its agility measurement method are defined, and the constraints of complex network theory are also defined. Secondly, to facilitate the calculation of agility metrics, complex network theory is introduced into agile supply chain network. In addition, a large number of experiments have been designed and implemented to verify the accuracy of the proposed complex network theory in agile supply chain network measurement. At the same time, the agility of the supply chain network is measured, and its changing rules and optimization methods are summarized. The experimental results show that the proposed complex network theory can accurately measure the agility of agile supply chain network. The purpose of this paper is to provide a method to turn agile supply chain system into intelligent information system through mathematical modeling.","","978-1-7281-6106-8","10.1109/ICICAS48597.2019.00163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051272","complex network theory, agile supply chain network, estimated value, agility measurement, intelligent information system","","Big Data;complex networks;information technology;Internet;mathematical analysis;network theory (graphs);optimisation;production engineering computing;supply chain management;supply chains","complex network theory;agile supply chain network measurement;information technology;big data support;network sharing;mathematical analysis;optimization techniques;internet of objects","","","","12","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"Improving the Quality of Requirements Engineering Process in Software Development with Agile Methods: a Case Study Telemedicine Startup XYZ","A. S. Wibawa; E. K. Budiardjo; K. Mahatma","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia","2021 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS)","9 Feb 2022","2021","","","1","5","XYZ is a telemedicine startup company that uses Scrum, an Agile methodology, as a software development method. The company uses Scrum to deliver good products and services to customers on time, even with limited requirements. However, the company faced problems in product development, so the company could not release the product on time. Based on interviews with internal experts, the company has issues determining the priority scale of requirements and change requirement management, where both problems are part of requirement engineering. This study discusses the problems of the company XYZ regarding the requirement engineering process, especially the problem of determining the priority scale of requirements and change requirement management. This research uses the CMMI-Dev 1.3 specific process area to assess the requirement engineering process in the company using sub-specific practices in the Requirement Development (RD) and Requirement Management (REQM) process areas. Researchers conducted interviews with product managers to appraise sub-specific RD and REQM practices with current activities in the company. The results of this study are recommendations to improve the quality of the requirement engineering process by using Objective Key Result (OKR) and Action Priority Matrix (APM).","","978-1-6654-3709-7","10.1109/ICADEIS52521.2021.9701962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701962","Action Priority Matrix;Agile;CMMI-Dev 1.3;Objective Key Result;Requirement Engineering;Scrum","Electronic learning;Requirements management;Telemedicine;Companies;Software;Product development;Requirements engineering","Capability Maturity Model;DP industry;formal specification;product development;project management;software development management;software engineering;software houses;software prototyping;software quality;telemedicine","requirements engineering process;case study telemedicine startup XYZ;software development method;product development;change requirement management;requirement engineering process","","","","14","IEEE","9 Feb 2022","","","IEEE","IEEE Conferences"
"Smart Water Quality Analysis using IoT and Big Data Analytics: A Review","E. E. -D. Hemdan; Y. M. Essa; A. El-Sayed; M. Shouman; A. N. Moustafa","Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Principle Data and Knowledge. Bayer, Berlin, Germany; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt; Computer Science and Engineering Department. Faculty of Electronic Engineering, Menofia University, Menouf, Egypt","2021 International Conference on Electronic Engineering (ICEEM)","15 Jul 2021","2021","","","1","5","In recent times, water quality monitoring, observing, and testing have become a significant research study with the advancement on the Internet of Things, and Big Data analytics research ideas. The relationship between water demand and supply is very crucial for every country and is likewise a complex challenge to satisfy this requirement around the world. Water is compulsory for human survival being on the earth. Therefore, for survival, the preservation and taking care of the existing water resource are also equally substantial. Moreover, for a healthier society, access to clean and safe water resources is also imperative. To recognize the water quality effects and provide an automated water quality mentoring and a testing system can support in guaranteeing the safety of the water. This paper presents a study on water quality analysis using IoT and Big Data analytics. This can help in developing an agile environment that can handle the massive flow of water big data generated by the smart sensors spread everywhere around us.","","978-1-6654-1842-3","10.1109/ICEEM52022.2021.9480628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9480628","ater Quality;Internet of Things;Cloud Computing;and Big Data Analytics","Technological innovation;Water quality;Big Data;Safety;Mentoring;Internet of Things;Water resources","Big Data;data analysis;environmental science computing;intelligent sensors;Internet of Things;public domain software;water quality;water resources;water supply","smart water quality analysis;IoT;water quality monitoring;significant research study;Internet of Things;Big Data analytics research ideas;water demand;complex challenge;human survival;taking care;existing water resource;clean water resources;safe water resources;water quality effects;automated water quality mentoring;testing system;water big data","","2","","17","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Construction of a Social Security Monitoring and Early Warning Platform Driven by Big Data","J. Yu; J. Guo; L. Globa; S. Li; M. Zhang; X. Li; J. Liu","Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Institute of Telecommunication Systems of National Technical University of Ukraine, Igor Sikorsky Kyiv Polytechnic Institute, Kyiv, Ukraine; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Qilu University of Technology, Shandong Academic of Sciences, Jinan, China; Shandong Normal University, Jinan, China","2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","19 Jul 2021","2021","4","","370","373","This article focuses on the existing sensitive information early warning mechanism and auxiliary decision-making is not sound, the emergency command and control is not agile, the application system business is solidified, and the existing monitoring and early warning service mode deals with multi-source, heterogeneous terrorism-related data, data utilization inefficiency and limited data processing service functions, the inability to achieve intelligent control of the process, and the inability to achieve precise monitoring, as well as the multi-dimensional and in-depth intelligent analysis of sensitive data. Research on distributed real-time transmission and distribution of big data based on multi-source and multi-channel adaptation, multi-source, heterogeneous big data distributed online real-time processing based on S4/Strom and distributed memory computing, position-based social security event monitoring, and semi-supervised system self-evolution and other key technologies, proposed to build a big data-driven social security monitoring and early warning platform system.","2693-2776","978-1-7281-8535-4","10.1109/IMCEC51613.2021.9482215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482215","data-driven;early warning platform;big data;data mining","Systematics;Government;Semantics;Process control;Big Data;Real-time systems;Natural language processing","Big Data;computerised monitoring;decision making;intelligent control;terrorism","warning platform driven;existing sensitive information;auxiliary decision-making;emergency command;application system business;existing monitoring;early warning service mode;multisource;heterogeneous terrorism-related data;data utilization inefficiency;limited data processing service functions;intelligent control;precise monitoring;in-depth intelligent analysis;sensitive data;distributed real-time transmission;multichannel adaptation;heterogeneous big data;real-time processing;distributed memory computing;position-based social security event monitoring;semisupervised system self-evolution;big data-driven social security monitoring;early warning platform system","","1","","8","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"IoT Agile Framework Enhancement","B. Gabr; M. A. Azer","Wireless intelligent networks centre (WINC), Nile University, Egypt; National Telecommunication Institute, Nile University, Egypt","2018 1st International Conference on Computer Applications & Information Security (ICCAIS)","23 Aug 2018","2018","","","1","4","Internet of Things (IoT) is considered as a trend nowadays. Devices connected to the internet interact with surrounding; this poses strong challenges in handling big data with a certain level of security. In this paper IoT devices will be divided in to two categories high vulnerability devices and low vulnerability devices. The classification depends on the ease of attacks. In order to ensure the security of IoT devices, an agile approach is used to secure high vulnerability devices as first step and then low vulnerability devices by applying encryption algorithms.","","978-1-5386-4427-0","10.1109/CAIS.2018.8441993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441993","Internet of Things;Agile approach;Encryption algorithms","Encryption;Internet of Things;Cloud computing;Software algorithms","Big Data;cryptography;Internet of Things","IoT agile framework enhancement;low vulnerability devices;agile approach;encryption algorithms;high vulnerability devices;Internet interact;IoT devices;Big Data","","1","","11","IEEE","23 Aug 2018","","","IEEE","IEEE Conferences"
"Talent management in agile software development: The state of the art","T. J. Gandomani; A. Mashmool; M. Dashti; S. Khosravi; M. N. Sarpiri; M. Radnejad; M. Afshari; S. Mansouri","Dept. of Computer Science, Shahrekord University, Shahrekord, Iran; Dept. of Computer Engineering, University of Birjand, Birjand, Iran; Data Science Research Center, Shahrekord University, shahrekord, Iran; Dept. of Computer Engineering, University of Birjand, Birjand, Iran; Dept. of Computer Engineering, Isfahan Branch, Islamic Azad University, Isfahan, Iran; Dept. of Computer Engineering, Isfahan Branch, Islamic Azad University, Isfahan, Iran; Data Science Research Center, Shahrekord University, shahrekord, Iran; Dept. of Computer Engineering, Dolatabad Branch, Islamic Azad University, Isfahan, Iran","2021 3rd East Indonesia Conference on Computer and Information Technology (EIConCIT)","17 May 2021","2021","","","156","160","With increasing competition in the software market, software companies are using new management strategies to increase their competitiveness. In recent years, with the prevalence of agile methodologies in software development, paying attention to human resources, and selecting and managing talented human resources have become inevitable. This should be achieved by adopting appropriate talent management processes. However, in software engineering, talent management has not yet been seriously considered. Due to the critical role of agile methodologies in human resources, and the authority and freedom of individuals in agile teams, the benefit of talent management in these methodologies is vital. As a starting point, this article tries to provide a concise overview of talent management in agile software development and address the ambiguities and research gaps facing software researchers in this regard. The initial results of this study show that several ambiguities such as appropriate models of talent management applicable in agile methodologies, how to use them, effective factors in talent assessment, and the relationship between talent management and the quality of teamwork are some of the most noticeable research gaps in this area.","","978-1-6654-0514-0","10.1109/EIConCIT50028.2021.9431902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431902","Agile software development;talent management;human capital;agile team management;research trends","Agile software development;Psychology;Companies;Market research;Software;Teamwork;Information technology","DP industry;human resource management;organisational aspects;software development management;software prototyping","agile software development;software market;software companies;software engineering;software researchers;talented human resource management","","","","48","IEEE","17 May 2021","","","IEEE","IEEE Conferences"
"Customizing and Deploying Data Science Roadmapping: A Case Study of an Oil and Gas Company","K. Kayabay; M. O. Gökalp; E. Gökalp; S. M. Alagöz; P. E. Eren; A. Koçyiğit","Department TÜBİTAK ULAKBİM, Data Informatics Middle East Technical University Network Technologies, Ankara, Türkiye; Data Analytics Center TÜPRAŞ, Ankara, Türkiye; Computer Engineering Department, Hacettepe University, Ankara, Türkiye; Data Analytics Center TÜPRAŞ, İstanbul, Türkiye; Information Systems Middle East Technical University, Ankara, Türkiye; Information Systems Middle East Technical University, Ankara, Türkiye","2022 IEEE International Conference on Technology Management, Operations and Decisions (ICTMOD)","28 Mar 2023","2022","","","1","6","Many organizations still face challenges leveraging data science in production and need strategic planning for organization-wide data science efforts and assets. Data Science Roadmapping (DSR) customizes the widely used Technology Roadmapping to facilitate such planning in organizations, aligning market, business, data, technology, and organization perspectives. This paper employs the action research method to customize and apply DSR in an oil and gas company. The approach mostly met the expectations regarding objectives and outcomes, the first step toward generalizability. The case study provides researchers and practitioners insights into roadmapping customization, remote and agile roadmap development process, and strategic planning for technology adoption in a large organization. Lastly, we identify the future research directions using the recent roadmapping literature.","2159-5119","978-1-6654-7027-8","10.1109/ICTMOD55867.2022.10082858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10082858","technology roadmapping;data science;big data;high-performance computing;data strategy","Technology management;Oils;Companies;Production;Data science;Strategic planning;Faces","gas industry;organisational aspects;petroleum industry;production engineering computing;research and development;strategic planning","action research method;agile roadmap development process;Data Science Roadmapping;DSR;oil and gas company;organization perspectives;organization-wide data science efforts;remote roadmap development process;roadmapping customization;strategic planning;technology adoption","","","","36","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"ENIAD: A Reconfigurable Near-data Processing Architecture for Web-Scale AI-enriched Big Data Service","J. Zhang; J. Li","Department of Electrical and Systems Engineering, University of Pennsylvania, Hot Chips 33, August 22-24,2021; Department of Electrical and Systems Engineering, University of Pennsylvania, Hot Chips 33, August 22-24,2021","2021 IEEE Hot Chips 33 Symposium (HCS)","20 Oct 2021","2021","","","1","8","To meet the surging demands required by AI-enriched Big Data services, cloud vendors are turning toward domain specific accelerators for improved efficiency, scalability and performance. ENIAD, the first end-to-end infrastructure for AI-enriched Big Data serving in real time, accelerates both deep neural network inferencing and billion-scale indexing at the data-center scale. Exploiting near- data computation, reconfigurable computing and rapid/agile hardware deployment flow, ENIAD serves state-of-the-art, online built indexing service with high efficiency at low batch sizes. A high-performance, index (data)-adaptable FPGA soft processor is at the heart of the system and able to serve 10x larger index size with 14x lower latency compared to state-of-the-art CPU and GPU architectures.","2573-2048","978-1-6654-1397-8","10.1109/HCS52781.2021.9567229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567229","","Heart;Scalability;Graphics processing units;Computer architecture;Big Data;Turning;Real-time systems","AI chips;Big Data;deep learning (artificial intelligence);field programmable gate arrays;inference mechanisms","ENIAD;indexing service;index-adaptable FPGA soft processor;reconfigurable near-data processing architecture;web-scale AI-enriched Big Data service;AI-enriched Big Data services;domain specific accelerators;end-to-end infrastructure;AI-enriched Big Data serving;deep neural network inferencing;billion-scale indexing;data-center scale;data computation;reconfigurable computing","","","","0","IEEE","20 Oct 2021","","","IEEE","IEEE Conferences"
"Design and Research of Insurance Survey Claims System Based on Big Data Analysis","J. Wu; J. Wang; Y. Liu","Dalian Neusoft University of Information, Dalian, China; Dalian Neusoft University of Information, Dalian, China; Dalian Neusoft University of Information, Dalian, China","2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS)","5 Dec 2019","2019","","","211","214","In order to overcome the cumbersome procedures of insurance investigation and claim settlement and the difficulty of precise promotion of insurance services for specific customers, this paper proposes an insurance investigation and claim system based on big data analysis. This method is developed on the basis of agile model. It has case information management, investigation information management, claim settlement management, intelligent insurance recommendation, etc. Intelligent customer service and other core functions, relying on Web, mobile applications and social networks for data collection, filtering and real-time analysis of the collected large data information, using Hadoop framework to convert structured data into semi-structured or unstructured data, storage of data information, through advanced analysis, prediction model Type and visual query, mining and analyzing the extracted data, and finally displaying the results after analysis. The experimental results show that the insurance survey and claim system completes the business processing of one-click report, survey photos upload, efficient claim settlement and insurance recommendation, speeds up the claim processing speed, and realizes the personalized service and precise marketing of customer insurance.","","978-1-7281-5050-5","10.1109/ICVRIS.2019.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920755","Insurance;Claim Settlement;Intelligence","Insurance;Companies;Customer services;Big Data;Data models;Data analysis","Big Data;customer services;data analysis;data mining;insurance data processing;Internet;social networking (online)","insurance survey claims system;big data analysis;cumbersome procedures;insurance investigation;precise promotion;insurance services;specific customers;claim system;agile model;case information management;investigation information management;claim settlement management;intelligent insurance recommendation;intelligent customer service;real-time analysis;data information;structured data;unstructured data;advanced analysis;prediction model;visual query;efficient claim settlement;personalized service;precise marketing;customer insurance","","3","","5","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Work-in-progress: Data Science Challenge-X: self-directed, competence-based, project-based learning","F. Benites; M. Schlatter; M. Messerli; R. Custer","School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland; School of Engineering, FHNW, Switzerland","2022 IEEE Global Engineering Education Conference (EDUCON)","11 May 2022","2022","","","2033","2036","We discuss in this paper the implementation of a project-based self-direct learning competency-based project module in our Bachelor Data Science programme. The goal of the course is to integrate in a later stage all project modules, which are now divided in two: one with and one without external industry partners, treating different aspects of data science with a pre-defined goal and clear objectives for the project. Switching for a competency-based learner-based paradigm with agile aspects and intrinsic focus, we define the core project goals as secondary and develop core data science competences which are acquired by the students and reflected in a learning journal.","2165-9567","978-1-6654-4434-7","10.1109/EDUCON52537.2022.9766710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766710","project-based learning;intrinsic motivation;self-directed learning","Industries;Conferences;Switches;Data science;Engineering education","computer aided instruction;data analysis","data science challenge;competence-based learning;self-direct learning competency-based project module;Bachelor Data Science programme;competency-based learner-based paradigm;core project goals;core data science competences;learning journal;project-based learning","","","","9","IEEE","11 May 2022","","","IEEE","IEEE Conferences"
"An Optimization Model to Evaluate Dynamic Assignment Capability of Agile Organization","Y. Feng; H. Huang; G. Cheng; C. Chen; J. Huang; Z. Liu; K. Huang","National University of Defense Technology, Changsha, Hunan, CN; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China; College of System Engineering, National University of Defense Technology, Changsha, China","2018 4th International Conference on Big Data and Information Analytics (BigDIA)","3 Feb 2019","2018","","","1","6","Recently the planning under the uncertain and competitive environment is the hot topic in the agile organization. Many studies highlight how to rapidly make or change the plans with detecting advance information. One of the widely used solutions is to evaluate the agile organization's decision-making capability based the time-domain metrics. However, the dynamic assignment capability always changed during task operating within time-domain. It caused that the planning used the wrong organization capability in the most time. In this paper, we develop an improved simulated annealing algorithm to address this problem. In order to discretize the time-domain, we propose a horizon partition that is based on the task dynamic state. Finally, the optimization model is tested in a toy example. Compared with the traditional models, the results show the proposed model has better outcomes for accurately estimating dynamic agile organization capability.","","978-1-5386-6888-7","10.1109/BigDIA.2018.8632798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632798","Operational System of Systems (SoS);Agile organization;Adaptive Optimization;Simulated Annealing;Decision Making","Task analysis;Computational modeling;Optimization;Organizations;Decision making;Mathematical model","decision making;organisational aspects;simulated annealing;time-domain analysis","task dynamic state;optimization model;dynamic agile organization capability;time-domain metrics;simulated annealing algorithm;dynamic assignment capability;agile organization decision-making capability;horizon partition","","2","","30","IEEE","3 Feb 2019","","","IEEE","IEEE Conferences"
"Facilitating the Management of Agile and Devops Activities: Implementation of a Data Consolidator","G. A. K. Doukoure; E. Mnkandla","School of Computing, University of South Africa(UNISA), Pretoria, South Africa; School of Computing, University of South Africa(UNISA), Johannesburg, South Africa","2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)","16 Sep 2018","2018","","","1","6","Organizations are confronted with a growing array of methodologies, tools and cloud offerings to address their business needs. On one hand, engineers and operations staff can leverage innovative DevOps oriented approaches for Continuous Delivery, Continuous Integration, containerization etc. On the other hand, project and operation leads are increasingly relying on agile methodologies to manage software development and release lifecycles. The number of tools available and used to run agile project tasks effectively is increasing and can yield an immense number of unmanageable information views for stakeholders. This paper focuses on the consolidation of these views through an information system built during a case study at South African SME, GZ Consulting Services. By designing an information system which is used as a central portal to aggregate data from internal systems used by the firm, we argue that an organization could better manage its agile and DevOps activities.","","978-1-5386-3060-0","10.1109/ICABCD.2018.8465451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465451","Agile;Dev-Ops;Project Management;Activity Theory;SME","Software;Tools;Cloud computing;Organizations;Project management;Portals","cloud computing;information systems;portals;software development management;software engineering;software prototyping","information system;data consolidator;cloud offerings;Continuous Delivery;Continuous Integration;agile methodologies;software development;release lifecycles;agile project tasks;innovative DevOps","","1","","15","IEEE","16 Sep 2018","","","IEEE","IEEE Conferences"
"Towards Prediction of Security Attacks on Software Defined Networks: A Big Data Analytic Approach","E. Unal; S. Sen-Baidya; R. Hewett","Department of Computer Science, Texas Tech University, Lubbock, TX, USA; Department of Computer Science, Texas Tech University, Lubbock, TX, USA; Department of Computer Science, Texas Tech University, Lubbock, TX, USA","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","4582","4588","Cyber-physical systems (CPS) tightly integrate physical and computing processes by monitoring and control data interacting between them via underlying networks. Software Defined Network (SDN) Technology has increasingly become essential in many advanced computer networks, including those in modern CPS, to provide flexible and agile network development. Despite many benefits that SDN offers, malicious attacks that can eventually prevent network services are unavoidable. Among the most predominant attacks on SDN controller layer, Link Discovery Attack and ARP (Address Resolution Protocol) Spoofing Attack are fundamental in that they are the gateways of many other SDN threats and attacks. To defend these attacks, most existing techniques either rely on relatively complex data validation techniques or use thresholds that can be subjective and unable to detect more than one type of attacks at a time if one deciding factor is used. While Big data technology, particularly machine learning, has been widely used for intrusion/anomaly detection, little has been done in SDN. This paper explores how well this technology can be used to predict these SDN attacks. By employing typical machine learning algorithms on simulated data of routing in SDN when attacks occur, preliminary results, obtained from four machine learning models, show the average area under ROC curve of over 96% and 92% for sample size 50,970 (12 switches) and 60,000 (20 switches), respectively. Further experiments show near-linear scaling in training time for the best performing algorithm when sample size grows up to 100,000.","","978-1-5386-5035-6","10.1109/BigData.2018.8622524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622524","Software-Defined Networking;SDN-specific security;Link Discovery attack;ARP Spoofing attack;Machine Learning;Data Analytic Applications","Control systems;Protocols;Software defined networking;Security;Big Data;Machine learning;Computer architecture","Big Data;computer network security;cyber-physical systems;data analysis;IP networks;learning (artificial intelligence);software defined networking","security attacks;Big data analytic approach;cyber-physical systems;flexible network development;agile network development;malicious attacks;SDN controller layer;SDN attacks;software defined network technology;computer networks;CPS;ARP spoofing attack;link discovery attack;address resolution protocol spoofing attack;machine learning;intrusion-anomaly detection","","6","","23","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Counterfactual Regret Minimization for Anti-Jamming Game of Frequency Agile Radar","H. Li; Z. Han; W. Pu; L. Liu; K. Li; B. Jiu","Shenzhen Research Institute of Big Data, China; Shenzhen Research Institute of Big Data, China; Shenzhen Research Institute of Big Data, China; The Chinese University of Hong Kong, Shenzhen, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China","2022 IEEE 12th Sensor Array and Multichannel Signal Processing Workshop (SAM)","22 Jul 2022","2022","","","111","115","The competition between radar and jammer is one important issue in modern electronic warfare, which in principle can be viewed as a non-cooperative game with two players. In this work, the competition between a frequency agile (FA) radar and a noise-modulated jammer is considered. As modern FA radar adopts coherent processing with several pulses, the competition is hence in a multiple-round way where each pulse can be modeled as one round interaction between the radar and jammer. To capture such multiple-round property as well as imperfect information inside the game, i.e., radar and jammer are unable to know the upcoming signal, we propose an extensive-form game formulation for such competition. Since the number of game information states grows exponentially with respect to number of pulses, finding Nash Equilibrium (NE) strategies may be a computationally intractable task. To effectively solve the game, a learning-based algorithm called deep Counterfactual Regret Minimization (CFR) is utilized. Numerical simulations demonstrates the effectiveness of deep CFR algorithm for approximately finding NE and obtaining the best response strategy.","2151-870X","978-1-6654-0633-8","10.1109/SAM53842.2022.9827883","National Natural Science Foundation of China(grant numbers:62101350); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827883","Frequency agile radar;anti-jamming problem;extensive form game","Signal processing algorithms;Games;Radar;Approximation algorithms;Minimization;Numerical simulation;Numerical models","game theory;jamming;learning (artificial intelligence)","modern electronic warfare;frequency agile radar;noise-modulated jammer;modern FA radar adopts coherent processing;extensive-form game formulation;game information states;deep Counterfactual Regret Minimization;anti-jamming game","","","","16","IEEE","22 Jul 2022","","","IEEE","IEEE Conferences"
"Understanding How the Ad Hoc use of Big Data Analytics Impacts Agility: A Sensemaking-Based Model","R. Hosoya; T. Kamioka","Graduate School of Commerce and Management, Hitotsubashi University, Kunitachi, Tokyo, Japan; Graduate School of Commerce and Management, Hitotsubashi University, Kunitachi, Tokyo, Japan","2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)","16 Sep 2018","2018","","","1","8","As business environments become increasingly complex and turbulent, organizations are required to be more agile. Use of big data analytics (BDA) can be a differentiator for organizations seeking to improve agility to quickly sense and respond to novel and complex events. Usage of BDA comprises two types: the routine use and the ad hoc use. The latter is more associated with the unplanned analysis of big data to understand unexpected events, and its effects have not been studied in distinction to the former in the analytics literature. We draw on sensemaking, the organizational theory of the process of understanding novel and complex events, to investigate how the ad hoc use of BDA improves agility of organizations. Analysis of a survey of 107 business executives and senior managers demonstrated the positive effects of the ad hoc use of BDA on agility, through mediation by sensemaking.","","978-1-5386-3060-0","10.1109/ICABCD.2018.8465446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465446","big data;analytics;ad hoc use;sensemaking;agility","Big Data;Organizations;Data models;Business intelligence;Industries","Big Data;business data processing;data analysis;organisational aspects","BDA;sensemaking-based model;business environments;business executives;big data analytics;big data unplanned analysis","","1","","54","IEEE","16 Sep 2018","","","IEEE","IEEE Conferences"
"Big Data Hysteria, Cognizance and Scope","R. Harsh; G. Acharya; S. Chaudhary","CSE Dept, M.E.C., Bikaner, Rajasthan, India; Industrial Engg & Management, Jaipur, Rajasthan, India; Industrial Engg & Management, Jaipur, Rajasthan, India","2018 4th International Conference for Convergence in Technology (I2CT)","9 Apr 2020","2018","","","1","8","In real time scenario, every second man and machine have been generating a huge amount of data. Social networking sites like Facebook, tweeter, Instagram, search engine google, yahoo and video shearing websites like YouTube and many real time applications generates enormous quantity of data. These data-sets have different attributes (i.e. volume, velocity, complexity etc.) in it, known as `Big Data'. To manage, process and analyze big data, we require advance hardware platform, software stack and analytics techniques. Big data Analytics emerges as a major application for future data-sets, generating by parallel and distributes systems. This paper has discussed about hype on Big Data, its characteristics, different considerations (i.e. Hardware, Software, Platform, N oSql Data Base, Languages). It has summarized the Techniques of Big Data and light up on scope with other technologies (i.e. IoT, Agile, Lean Six Sigma).","","978-1-5386-5232-9","10.1109/I2CT42659.2018.9057878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057878","Big Data;Volume;Inherent properties;Big Data Management;Analytics techniques","Big Data;Hardware;Software;Google;Data visualization;Tools;Data mining","Big Data;data analysis","Big Data hysteria;big data analytics;NoSql Data Base;social networking sites;software stack;hardware platform","","","","35","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"To Offload or Not? An Analysis of Big Data Offloading Strategies from Edge to Cloud","R. Singh; J. Kovacs; T. Kiss","Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK; Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK; Department of Computer Science and Engineering, Centre for Parallel Computing, University of Westminster, London, UK","2022 IEEE World AI IoT Congress (AIIoT)","13 Jul 2022","2022","","","046","052","Large reductions in completion times can result from transfer of Big Data tasks from edge nodes to cloud resources, which can reduce the completion times by up to 97 % and meet client deadlines for computational tasks with responsive and agile solutions. Using scientific programs of varying computational complexity to model resource-intensive tasks, we demonstrate that the task complexity of the computational jobs, the Wide Area Network (WAN) speed and the potential overload of edge servers (as reflected by CPU workloads) are crucial for achieving total reductions in task completion time edge-cloud orchestrators are situated in edge nodes. With continuous access to the parameters of Wireless Local Area Network (WLAN) speed (for data exchanges between client and edge resources), WAN speed (for data exchanges between edge and cloud resources) edge server CPU workload and the complexities in Big Data analytics requirements, accurate edge-to-cloud offloading decisions can be made to minimise total task completion time by the use of cloud computing resources. This work supports the major research efforts have been recently made to develop novel resource orchestration solutions to flexibly link edge nodes with centralised cloud resources so as to maximise the efficiency with which such a continuum of resources can be accessed by users.","","978-1-6654-8453-4","10.1109/AIIoT54504.2022.9817276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817276","Application-level orchestration;Cloud-to-Edge con-tinuum;Big Data analytics;WLAN;WAN;Computational complexity;Server workload","Wide area networks;Cloud computing;Wireless LAN;Computational modeling;Big Data;Servers;Task analysis","Big Data;cloud computing;computational complexity;data analysis;resource allocation;wide area networks;wireless LAN","offload;Big Data offloading strategies;completion times;Big Data tasks;edge nodes;client deadlines;computational tasks;responsive solutions;agile solutions;computational complexity;resource-intensive tasks;task complexity;computational jobs;Wide Area Network speed;edge servers;total reductions;task completion time edge-cloud orchestrators;Wireless Local Area Network speed;data exchanges;WAN speed;Big Data analytics requirements;edge-to-cloud offloading decisions;total task completion time;cloud computing resources;novel resource orchestration solutions;centralised cloud resources","","4","","18","IEEE","13 Jul 2022","","","IEEE","IEEE Conferences"
"Open Data Lake to Support Machine Learning on Arctic Big Data","A. M. Olawoyin; C. K. Leung; A. Cuzzocrea","Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada; iDEA Lab University of Calabria, Rende, Italy","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","5215","5224","The era of big data is evolving with the introduction of the data lake concept. While a data warehouse provides a well-structured model to manage big data, a data lake accepts data of any types and formats with or without schema and provides access to the data for diverse communities of users. A data lake provides flexible, agile, and scalable solution to manage the ever-increasing volume of big data we are witnessing in the world today, including many siloed data collected over the years by researchers through Arctic expeditions. In this paper, we present our conceptual model of a data lake for integrating the diverse huge amount of data collected by researchers during Arctic expedition. We also design a baseline metadata using a data-driven approach to manage the disparately huge structured, semi-structured, and unstructured data collected from the Arctic region. The resulting open data lake not only effectively manages big Arctic data but also supports machine learning on these big data.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671453","big data;data management;data lake;open data;reusability;FAIR principle;CARE principle;Arctic data;Arctic expedition;machine learning;data mining","Renewable energy sources;Visual analytics;Machine learning;Production;Metadata;Lakes;Data warehouses","Big Data;data analysis;data warehouses;lakes;learning (artificial intelligence);meta data","data-driven approach;unstructured data;big Arctic data;Arctic big data;data lake concept;data warehouse;siloed data;open data lake;machine learning;baseline metadata;structured data;semistructured data","","9","","78","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Machine Learning Experiments with Artificially Generated Big Data from Small Immunotherapy Datasets","A. Yunas Mahmoud; D. Neagu; D. Scrimieri; A. Rashad Ahmed Abdullatif","Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England; Faculty of Engineering and Informatics, University of Bradford, Bradford, England","2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA)","23 Mar 2023","2022","","","986","991","Big data and machine learning result in agile and robust healthcare by expanding raw data into useful patterns for data-enhanced decision support. The available datasets are mostly small and unbalanced, resulting in non-optimal classification when the algorithms are implemented. In this study, five novel machine learning experiments are conducted to address the challenges of small datasets by expanding these into big data and then utilising Random Forests. The experiments are based on personalised adaptable strategies for both balanced and unbalanced datasets. Multiple datasets from cryotherapy and immunotherapy are considered, however, hereby only immunotherapy is used. In the first experiment, artificially generated data is presented by increasing the observations of the dataset, each new data is four-time larger than the previous one, resulting in better classification. In the second experiment, the effect of volume on classification is considered based on the number of attributes. The attributes of each new dataset are built based on conditional probabilities. It did not make any difference, in obtained classification, when the number of attributes is increased to more than 879. In the third simulation experiment, classes of data are classified manually by dividing the data into a two-dimensional plane. This experiment is first performed on small data and then on expanded big data: by increasing observations, an accuracy of 73.68% is attained. In the fourth experiment, the visualisation of the enlarged data did not provide better insights. In the fifth experiment, the impact of correlations among datasets’ attributes on classification is observed, however, no improvements in performance are achieved. The experiments generally improved performance by comparing the classification results using the original and artificial data.","","978-1-6654-6283-9","10.1109/ICMLA55696.2022.00165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10069649","Immunotherapy;Big data;Machine learning;Classification;Random Forests;Warts;Cryotherapy;Health-care","Training;Machine learning algorithms;Correlation;Sensitivity;Immunotherapy;Data visualization;Big Data","Big Data;learning (artificial intelligence);pattern classification;probability;random forests","agile healthcare;artificial data;artificially generated big data;artificially generated data;balanced datasets;data-enhanced decision support;enlarged data;expanded big data;fifth experiment;fourth experiment;increasing observations;machine learning result;multiple datasets;nonoptimal classification;novel machine learning experiments;original data;personalised adaptable strategies;raw data;robust healthcare;small immunotherapy datasets;unbalanced datasets","","","","22","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"An Agile Sample Maintenance Approach for Agile Analytics","H. Zhang; Y. Zhang; Z. He; Y. Jing; K. Zhang; X. S. Wang","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China","2020 IEEE 36th International Conference on Data Engineering (ICDE)","27 May 2020","2020","","","757","768","Agile analytics can help organizations to gain and sustain a competitive advantage by making timely decisions. Approximate query processing (AQP) is one of the useful approaches in agile analytics, which facilitates fast queries on big data by leveraging a pre-computed sample. One problem such a sample faces is that when new data is being imported, re-sampling is most likely needed to keep the sample fresh and AQP results accurate enough. Re-sampling from scratch for every batch of new data, called the full re-sampling method and adopted by many existing AQP works, is obviously a very costly process, and a much quicker incremental sampling process, such as reservoir sampling, may be used to cover the newly arrived data. However, incremental update methods suffer from the fact that the sample size cannot be increased, which is a problem when the underlying data distribution dramatically changes and the sample needs to be enlarged to maintain the AQP accuracy. This paper proposes an adaptive sample update (ASU) approach that avoids re-sampling from scratch as much as possible by monitoring the data distribution, and uses instead an incremental update method before a re-sampling becomes necessary. The paper also proposes an enhanced approach (T-ASU), which tries to enlarge the sample size without re-sampling from scratch when a bit of query inaccuracy is tolerable to further reduce the sample update cost. These two approaches are integrated into a state-of-the-art AQP engine for an extensive experimental study. Experimental results on both real-world and synthetic datasets show that the two approaches are faster than the full re-sampling method while achieving almost the same AQP accuracy when the underlying data distribution continuously changes.","2375-026X","978-1-7281-2903-7","10.1109/ICDE48307.2020.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101582","","Engines;Maintenance engineering;Reservoirs;Query processing;Data warehouses;Monitoring;Encyclopedias","Big Data;data analysis;query processing;sampling methods;software maintenance;software prototyping","agile analytics;approximate query processing;Big Data;incremental update methods;data distribution;adaptive sample update;agile sample maintenance;AQP engine;incremental sampling process;full re-sampling method;T-ASU","","","","33","IEEE","27 May 2020","","","IEEE","IEEE Conferences"
"Research and Implementation of Intelligent Platform for Targeted Employment Poverty Alleviation Based On Cloud Computing and Big Data","C. Jiang","School of Library, Shandong University of Political Science and Law, Jinan, China","2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)","28 Feb 2022","2021","","","500","504","With the development of Internet technology, big data technology provides technical support for China’s targeted poverty alleviation. The key to targeted poverty alleviation lies in providing employment. Employment poverty alleviation is the most direct, realistic and effective way for poor workers to get rid of poverty. How to establish an information communication platform between the poor and enterprises is a key problem to be solved urgently. This paper uses cloud computing, big data and intelligent decision making technology to develop the big data “Internet plus” platform for precision employment and poverty alleviation. It has solved the problems of asymmetric information among enterprises, the poor and government departments, lack of effective supply and demand docking platform, unbalanced regional distribution of employment posts and labor force, inaccurate employment services, long employment chain and difficult tracking services. This paper describes in detail the architecture design, targeted employment framework process, deployment and implementation for the platform adopting scrum and continuous integration development method. The platform has been successfully online, exploring employment poverty alleviation for about one year, successfully solved the employment of nearly 2,000 poor labor forces and 5,000 needy students in secondary vocational and higher vocational education, cooperated with more than 100 large-scale well-known enterprises in manufacturing, logistics and service industry, formed a systematic targeted employment poverty alleviation model, scheme and experience. Compared with the existing systems in the literature, the advantages and transformation effect of this platform are remarkable. The platform construction experience of this paper can provide reference for the application of big data, cloud computing and other technologies in other fields of national construction.","","978-1-6654-0692-5","10.1109/CISAI54367.2021.00102","Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719060","Targeted Employment;Big Data;Targeted Poverty Alleviation;Platform;Cloud Computing","Cloud computing;Target tracking;Systematics;Employment;Force;Government;Decision making","Big Data;cloud computing;decision making;further education;Internet;logistics;service industries;software development management;vocational training","poor enterprises;cloud computing;precision employment;poor government departments;demand docking platform;employment posts;inaccurate employment services;long employment chain;targeted employment framework process;000 needy students;systematic targeted employment poverty alleviation model;platform construction experience;intelligent platform;Internet technology;big data technology;targeted poverty alleviation;providing employment;information communication platform","","1","","9","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Harnessing The Power of the Internet of Things (IoT) to Achieve an Agile Business Education Model: A Visionary Paper","A. Qasim; G. A. E. Refae; S. Eletter; A. R. Al-Chahadah","College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Al Ain University, Abu Dhabi, UAE; College of Business, Alzaytoonah University, Amman, Jordan","2021 8th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)","11 Feb 2022","2021","","","1","4","The emergence of artificial intelligence, big data, and the Internet of Things (IoT) has shifted human-human, human-machine, and machine-machine interaction to a new level. This shift is affecting all aspects of society’s behavior toward the adoption of technology. One important pillar of society that is especially impacted by this radical change is that of education. The advancement of new technologies as well as the occurrence of unexpected global events has forced education systems in many countries to look differently at traditional educational issues and work toward becoming a more agile education system. This means being responsive to any unpredicted changes that may occur in the education environment. Indeed, the agility of business schools and technological adaptability is one of the standards required by program accreditation organizations (i.e., AACSB). This paper discusses the application of IoT in business education, focusing on the opportunities, challenges, and paths forward this presents.","","978-1-6654-5868-9","10.1109/IOTSMS53705.2021.9704939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9704939","IoT;Business Education;Education Agility;Higher Education","Education;Standards organizations;Transforms;Organizations;Internet of Things;Security;Problem-solving","accreditation;Big Data;computer aided instruction;educational courses;educational institutions;Internet of Things;management education","unpredicted changes;education environment;business schools;technological adaptability;IoT;agile business education model;visionary paper;artificial intelligence;big data;human-human machine;machine-machine interaction;radical change;unexpected global events;education systems;traditional educational issues;agile education system;AACSB;program accreditation organizations","","","","16","IEEE","11 Feb 2022","","","IEEE","IEEE Conferences"
"A Service Driver Based Application Execution and Development Method in Multi-cloud Context","S. Zhang; L. Ni; K. Han","College of Information and Communication, National University of Defense Technology, Xi’an, China; College of Information and Communication, National University of Defense Technology, Xi’an, China; College of Information and Communication, National University of Defense Technology, Xi’an, China","2021 IEEE International Conference on Data Science and Computer Application (ICDSCA)","23 Dec 2021","2021","","","33","37","To reduce the cost of cloud tenants and avoid the phenomenon of vendor lock-in, multi-cloud technique is proposed and competent for this goal. However, it leads to another difficultly on supporting application development and runtime update process in the multi-cloud context. The key points for this problem are: (i) implementing application runtime switch among cloud services for varied service requirements and status; (ii) supporting runtime agile and low-cost update, and redevelopment for emerging new cloud services. To overcome this problem and advance multi-cloud applications execution, we present a support technique based on service driver concept. Service driver can help applications shield the heterogeneity and switch among cloud services. To support the implementation of service driver, we have finished the following three areas: (i) proposing a multi-cloud application service access model which is implemented through multi-agent system technique; (ii) presenting a multi-cloud application runtime service update and invocation process; (iii) introducing a multi-cloud application development framework. Furthermore, to help and direct developers to design and implement multi-cloud application, we describe a multi-cloud application (re)development method. This method includes multi-cloud application development process and runtime multi-cloud application agile redevelopment process. Finally, we interpret the multi-cloud application development support techniques and methods via case study.","","978-1-6654-4054-7","10.1109/ICDSCA53499.2021.9650251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650251","multi-cloud application;development method;service driver;service switch;agile redevelopment","Runtime;Costs;Conferences;Switches;Computer applications;Data science;Multi-agent systems","cloud computing;multi-agent systems","multiagent system technique;multicloud application development process;runtime multicloud application agile redevelopment process;multicloud application development support techniques;multicloud context;cloud tenants;multicloud technique;runtime update process;cloud services;service driver concept;multicloud application service access model","","","","12","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"Big Data Analytics Role in Managing Complex Supplier Networks and Inventory Management","D. J. Anusha; M. Panga; A. Hadi Fauzi; A. Sreeram; A. Issabayev; N. Arailym","Department of Computer Science & Engineering, Sri Padmavati Mahila Visvavidyalayam, Tirupati, India; Economic Prestige Institute of Management and Research Indore; Business Administration Department, Faculty of Political and Social Sciences, Universitas Padjadjaran, Indonesia; Operations & IT ICFAI Business School, (A Constituent of IFHE University), Hyderabad, India; Department of Architecture, International Education Corporation, Almaty, Kazakhstan; Department of Design, International Education Corporation, Almaty, Kazakhstan","2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)","27 Apr 2022","2022","","","533","538","In today's world, competition is not only restricted between the marketing aspects of two companies or big firms. The competition has expanded between the supply chain management perspectives of two firms. In order to sustain within the current competitive environment supply chain professionals of a firm are struggling hard to handle large-scale data, that is important to reach an integrated, efficient, effective as well as agile supply chain process within their business. As a result, explosive growth of data volume and amount of data within business, made it mandatory for the supply chain processionals to use an effective data analytic tool in order to manage these data. The main aim of this study is to identify use of various data analytic tools in order to manage large data of supply process and inventory management process with several advantages and disadvantages. As per the literature findings, it has been observed that use of data analytic tools within an organisation can be helpful to investigate new insights of the supply chain process, which can be able to detect different parts and elements of that process. A mixed method approach has been incorporated within this research paper by collecting primary and secondary both data collection process. Total 50 employees engaged with inventory and supply chain management of different firm are chosen to conduct a survey. Secondary data are collected from secondary sources. As per the findings, it can be stated that big data analytics plays a positive role in organization for managing large data.","","978-1-6654-7884-7","10.1109/ICSCDS53736.2022.9761008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761008","Supply chain management;Inventory management;large-scale data;machine learning algorithm;Data processing. NoSQL;Regression;IoT;Cloud-computing;challenges","Data analysis;Supply chain management;Supply chains;Companies;Inventory management;Big Data;Explosives","Big Data;data analysis;inventory management;organisational aspects;personnel;production engineering computing;professional aspects;supply chain management;supply chains","big data analytics role;complex supplier networks;big firms;supply chain management perspectives;data analytic tools;inventory management process;environment supply chain professionals;organisational aspects;employees","","","","15","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Web Development of Direct-to-consumer Genetics Testing","K. Azizatikarna; D. E. Parung; D. Amirullah; A. A. Hidayat; T. W. Cenggoro; A. Budiarto; Simon; B. Pardamean","Genetics Indonesia, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia; Genetics Indonesia, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2022 4th International Conference on Cybernetics and Intelligent System (ICORIS)","6 Feb 2023","2022","","","1","6","As the cost of genetic testing becomes more affordable each year, direct-to-customer (DTC) genetic testing services witness rapid market growth. This has encouraged the development of an easy-to-use website application to optimize potential customers to obtain informed choice regarding the offered DTC genetic testing as well as purchasing information. We present a wireframing process as a part of the agile software development process to build a web portal prototype for an Indonesia-based genetic testing service called DNAku. The approach in building the prototype used in this case is a part of the Agile Software Development Method. In brief, the wireframing stage resulted in this work consists of three main important outcomes. The first one is the use case diagram as a blueprint of this web-based system. A site map is then proposed as an extended version of the use case diagram which visualizes the whole pages with the links. Finally, based on this site map a series of page mock-ups are designed using Hyper Text Marking Language (HTML) and Cascading Style Sheets (CSS). The result of the prototype can be used as the basis for the next development stage, which is the coding stage based on the collected feedback from users. Considering the continuous application development via the wireframing method by taking into account the cycle of feedbacks from involved parties, this approach can strengthen the infrastructure to sustain DTC genetic business model, which has a niche market in Indonesia.","","978-1-6654-5395-0","10.1109/ICORIS56080.2022.10031450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031450","agile;genetic testing;prototype;website development;wireframing","Visualization;Costs;Buildings;Prototypes;Agile software development;Genetics;Encoding","hypermedia markup languages;Internet;portals;program testing;Web sites","agile software development method;agile software development process;continuous application development;direct-to-consumer genetics testing services;DTC genetic business model;DTC genetic testing;easy-to-use Website application;Indonesia-based genetic testing service;informed choice;purchasing information;rapid market growth;site map;use case diagram;Web development;Web portal prototype;Web-based system;wireframing method;wireframing process;wireframing stage","","","","36","IEEE","6 Feb 2023","","","IEEE","IEEE Conferences"
"Big Data Analytics APIs Architecture for Formative Assessors","W. Mahfouz; H. -D. Wuttke","Faculty of Computer Science and Automation, Ilmenau University of Technology, Germany; Faculty of Computer Science and Automation, Ilmenau University of Technology, Germany","2021 IEEE Frontiers in Education Conference (FIE)","20 Dec 2021","2021","","","1","9","This Research to Practice Full Paper is driven by the question: Within limited time resources available to trainers in projects for Big Data Analytics (BDA) problems, how can they define project requirements for Formative Assessment (FA) actions? The paper suggests BDA APIs architecture as helping tool for formative assessors. It helps them effectively produce and adapt visual diagnostic reports for FA-actions in agile based requirements (i.e. features) definition. The paper presents two core architectures: Architecture for a parametrized feature-descriptor-system to define/refine a BDA API feature and its visual diagnostic reports, and an initial resources architecture for BDA API to initialize an analytics algorithm with its input big data sets. Clarifying visually the trainee's challenges (i.e. incremental features in a BDA API) is our main FA action. The FA action is designed based on Csikszentmihalyi's flow model to support a trainee in matching balance between his/her challenges and his/her skills. To test the architecture's functions, the paper has test setups for two formal projects (each has 1 to 6 trainees) and two informal projects (each has 1 to 3 trainees). The projects are to attack BDA problems in learning analytics and in image automatic classification. The test results show that the visual diagnostic reports produced by the trainers are very effective in clarifying visually incremental BDA API features not only for simple classifiers (i.e. classical data mining algorithms) but also for complex classifiers (i.e. deep learning algorithms). The results show also how visual diagnostic reports are easily produced for comparing the algorithm performances using different input big data sets, whereas other reports are produced for comparing performances between different algorithms, using one input data set. Related works are also discussed to show the architecture's differences and advantages. Its main advantages are: 1) it enables the trainers to use deep learning algorithms beside classical data mining algorithms in its BDA API parameterizable feature descriptors for visual diagnostic reports. 2) The descriptors can be extended, reused, shared, and scaled out to help trainers in other universities providing flow model based FA actions. 3) Finally, it has extensions to integrate other theoretical frameworks like Buckingham Shum and Deakin Crick's framework for dispositional learning analytics instead of the used flow model.","2377-634X","978-1-6654-3851-3","10.1109/FIE49875.2021.9637431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637431","assessment in engineering education;planning for formative assessment;Big Data Analytics","Deep learning;Visualization;Analytical models;Data analysis;Conferences;Big Data;Data models","application program interfaces;Big Data;data analysis;data mining;feature extraction;image classification;learning (artificial intelligence);medical computing","trainers;visually incremental BDA API;deep learning algorithms;visual diagnostic reports;different input big data sets;classical data mining algorithms;BDA API parameterizable feature descriptors;Big Data Analytics APIs Architecture;formative assessors;Big Data Analytics problems;project requirements;BDA APIs architecture;FA-actions;core architectures;feature-descriptor-system;BDA API feature;initial resources architecture;analytics algorithm;incremental features;main FA action;BDA problems","","1","","21","IEEE","20 Dec 2021","","","IEEE","IEEE Conferences"
"A reconciliation model of agile C2 organization based on converged networks","W. Zhou; W. Bao; X. Sun; J. Wan; Y. Xu; Y. Gao","College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; College of Information and Communication, National University of Defense Technology, Xi'an, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; International Studies College, National University of Defense Technology, Nanjing, China","2020 6th International Conference on Big Data and Information Analytics (BigDIA)","2 Apr 2021","2020","","","58","65","With the promotion of information technology and big data technology, and the traction of new operational concepts such as Mosaic Warfare and Joint Global Operations, the research and practice of agile command & control(C2) organization has become a hot issue in the field of C2. One of the focal points of the debate is the contrast between the traditional hierarchy structure of C2 organizations and the edge structure. Is the traditional hierarchy structure of C2 necessarily in conflict with the edge structure? Can these two organizational structure models be reconciled to achieve organizational agility transformation? How to reconcile these two models of organizational structure? In order to solve the above problem, we put forward a kind of suitable reconciliation model of agile C2 organization considering our actual situation. On this basis, we use ontology modeling method to form characteristics of adaptive and intelligent cross-domain integrated solutions, through the establishment of agile ontology and reasoning mechanism of C2 organization.","","978-1-6654-2232-1","10.1109/BigDIA51454.2020.00018","National Science Foundation of China(grant numbers:71702186); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384531","command & control;agility;organization mode;reconciliation model;converged networks","Command and control systems;Adaptation models;Analytical models;Organizations;Ontologies;Data models;Cognition","Big Data;command and control systems;ontologies (artificial intelligence)","agile C2 organization;converged networks;information technology;Big Data technology;operational concepts;traditional hierarchy structure;edge structure;organizational structure models;organizational agility transformation;suitable reconciliation model;agile ontology;reasoning mechanism;joint global operations","","","","40","IEEE","2 Apr 2021","","","IEEE","IEEE Conferences"
"Literature Review on Big Data Analytics and Demand Modeling in Supply Chain","P. K. T; M. T. N; R. S. Hegadi","BMS Institute of Technology and Management, Bengaluru, India; Dept. of ISE, BMS Institute of Technology and Management, Bengaluru, India; Dept. of Computer Science, Solapur University, Maharashtra, India","2018 International Conference on Electrical, Electronics, Communication, Computer, and Optimization Techniques (ICEECCOT)","20 Feb 2020","2018","","","1246","1252","New digital technologies have been introduced into our business and social environments, causing a major change that is recognized as the digital transformation in recent years. While environmental shifts suggest that most of the organization starts using advanced technologies such as Internet of Things(IoT), Mobile applications, Blackchain, Intelligence Things, catboats and many more in their supply chain planning to gain an early competitive advantage and these technologies generates enormous amount of data that the traditional business intelligence system difficult to handle processing of vast data in real-time or nearly real time causes abstraction to the insight discovery, demand modeling and supply chain optimization, Big Data initiatives for demand modeling and supply chain optimization promise to answer these challenges by incorporating various services, methods and tools for more agile and adaptably analytics and decision making, there by this paper focus on reviewing the level of analytics and the forecasting methods being used in the supply chain, understating the fundamentals of supply chain and role of demand modeling, there by proposing a high level framework for supply chain analytics in the context of big data with the knowledge of data science, artificial intelligence, big data echo system and supply chain.","","978-1-5386-5130-8","10.1109/ICEECCOT43722.2018.9001513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001513","Supply chain;Demand modeling;Big data Analytics;Forecasting methods;supply chain framework","Supply chains;Predictive models;Big Data;Data models;Forecasting;Analytical models;Real-time systems","Big Data;competitive intelligence;data analysis;decision making;supply chain management;technology management","Big Data analytics;demand modeling;digital technologies;digital transformation;supply chain planning;Big Data initiatives;supply chain optimization;decision making;supply chain analytics;competitive advantage","","","","11","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Nexus of Internet of Things (IoT) and Big Data: Roadmap for Smart Management Systems (SMgS)","M. Roy; A. Roy","Management and Engineering for Manufacturing, University of Connecticut, Storrs, CT, USA; Management, Marketing and Entrepreneurship, University of Scranton, Scranton, PA, USA","IEEE Engineering Management Review","19 Jun 2019","2019","47","2","53","65","Disruptive technologies are emerging at a breakneck speed and changing the characteristics of businesses by making them smart. The aim of this paper is to show how industries can use Smart Management System (SMgS) to be competitive in the 21st century. Internet of Things (IoT) will be the key to connecting and communicating among different parts of the smart industries using sensor-like devices, and big data will be continuously collected and analyzed to improve performance. The SMgS will generate new possibilities for better product design, improved qualities, agile supply chain, and enhanced customer satisfaction. It will also help industries to achieve lean and sustainable systems with fewer efforts than traditional approaches. We demonstrate how early adopters have already implemented IoT and are currently generating big data. These efforts have resulted in significant improvements in streamlining their operations. The advantages of IoT and big data applications in different sectors are discussed here with several examples from the industry leaders. The reasons behind why many companies are still waiting to adopt IoT despite being enthusiastic about it are also suggested. Embracing SMgS is crucial for companies to gain a differential competitive advantage in the era of Industry 4.0.","1937-4178","","10.1109/EMR.2019.2915961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712560","IoT;smart management system;big data;lean;sustainability","Internet of Things;Industries;Companies;Big Data;Stakeholders","Big Data;customer satisfaction;Internet of Things;product design;production engineering computing;supply chain management","IoT;big data applications;SMgS;Smart Management systems;breakneck speed;Smart Management System;agile supply chain;enhanced customer satisfaction;lean systems;sustainable systems;Internet of Things;Industry 4.0","","17","","42","IEEE","10 May 2019","","","IEEE","IEEE Journals"
"Structured Data for Product Performance Improvement","P. Peter; C. Parendo",Collins Aerospace; Collins Aerospace,"2021 Annual Reliability and Maintainability Symposium (RAMS)","22 Nov 2021","2021","","","1","5","SUMMARY & CONCLUSIONSAftermarket reliability data is a cornerstone to understand the performance of one's products against requirements. A successful aftermarket data system goes beyond the basics of supplying reliability figures. Its attributes also include additional metrics for an effective alerting and reporting system to enable proactive response to aftermarket issues. While these system features are key, the implementation and maintenance methodology of the system is crucial to its success. This is because these systems involve big data. In the case presented, it is data which spans several years, for a variety of model numbers on a variety of aircraft platforms or applications. Each set of circumstances yields different reliability figures and associated metrics. With this big data, it is equally crucial to its success to have a methodology to address data integrity, the speed of data, and the portability of data. Our solution with this successful methodology of these features is called Structured Data.A good aftermarket data system is a backbone for any successful organization. A good system in the aerospace industry goes beyond ATA Spec 2000 [1] formatted data and standard reliability figures such as MTBUR (Mean Time Between Unscheduled Removal) and MTBF (Mean Time Between Failure). It is also beyond implementing a Failure Reporting and Corrective Action System (FRACAS). A comprehensive system in the aerospace industry includes several additional measures (i.e. frequency, severity, risk) to represent the Voice of the Customer. And with a built-in mechanism for proactive response to the data, the system can then be considered World-Class.While designing a system with these features is important, its success also hinges upon the methodology of implementation and maintenance. As stated earlier, aftermarket data is considered big data due to the volume of highly specific data. With this big data, it is critical to success to address data integrity, the speed of data, and the portability of data all within a user-friendly experience. For data integrity, do we trust the data? This takes on many forms from cross referencing input and output data to determining an accurate mixed fleet factor. For speed of data, do we have a system in place to handle the cadence of data efficiently? For portability, do we structure our data in such a way where we can be agile to serve potential changes to our system or new systems as our company evolves? For a user-friendly experience, can we structure the data for intuitive analysis for all stakeholders? Thus in the proposed system, all of these aspects of data integrity, the speed of data, the portability of data, and formatting the data per stakeholders are addressed. Our solution with this successful methodology of these features is called Structured Data.The benefits of this newly developed Structured Data extend beyond ATA Spec 2000 in which it is based. The data is structured in a dynamic and interactive environment. This environment includes intuitive analysis and a system of prioritization for corrective action. The key benefit of this Structured Data system is proactive response to aftermarket data analysis.","2577-0993","978-1-7281-8017-5","10.1109/RAMS48097.2021.9605770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605770","Product performance;Reliability metrics;MTBUR / MTBF;FRACAS;Voice of Customer;Big data;Data integrity Speed of data;Portability of data;Natural Language Programming (NLP)","Databases;Data integrity;Data visualization;Big Data;Maintenance engineering;Data systems;Frequency measurement","aerospace industry;aircraft maintenance;Big Data;data analysis;failure analysis;logistics;maintenance engineering;production engineering computing;reliability","good aftermarket data system;proactive response;big data;data integrity;cross referencing input;aftermarket data analysis;reliability data;effective alerting;reporting system;reliability figures;structured data system;product performance improvement","","","","3","IEEE","22 Nov 2021","","","IEEE","IEEE Conferences"
"Design Method Of Frequency-Agile Radar Frequency Hopping Sequence Based On CNN Network And Chaotic Sequence","P. An; Z. Shang; S. Yan; D. Wang","The Second Research Institute of China Aerospace Science and Industry Corporation, Beijing Institute of Remote Sensing Equipment, Beijing, China; The Second Research Institute of China Aerospace Science and Industry Corporation, Beijing Institute of Remote Sensing Equipment, Beijing, China; Science and Technology on Optional Radiation Laboratory, Beijing Institute of Environment Features, Beijing, China; Science and Technology on Optional Radiation Laboratory, Beijing Institute of Environment Features, Beijing, China","2022 International Conference on Big Data, Information and Computer Network (BDICN)","20 Apr 2022","2022","","","702","707","With the development of modern radar anti-jamming technology, frequency-agile radar has developed rapidly. To counter jamming signals, the operating frequency of the frequency-agile radar transmitting pulse has strong random performance. The chaotic sequence has great random performance, and the sequence generated by the chaotic sequence also has great randomness. Therefore, this paper first generates data through the chaotic sequence and binary quantization method and uses the autocorrelation performance as the criterion, The optimal threshold corresponding to the optimal frequency hopping sequence of the same chaotic sequence is screened out. The selected random Frequency hopping point sequence with better performance has great ambiguity function performance, that is, target detection performance. First, divide the value range of the optimal threshold, use the chaotic sequence and the optimal threshold as the standard data, turn the threshold optimization problem into a pattern recognition classification problem, and use the standard data as the training set to train the neural network. In the end, the CNN network has a great classification ability can better realize the Frequency hopping point sequence generation.","","978-1-6654-8476-3","10.1109/BDICN55575.2022.00136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758437","CNN network;chaotic sequence;binary quantization;autocorrelation;target detection","Training;Quantization (signal);Neural networks;Radar;Object detection;Pattern recognition;Convolutional neural networks","convolutional neural nets;correlation methods;frequency hop communication;jamming;object detection;optimisation;radar computing;radar signal processing","chaotic sequence;modern radar anti-jamming technology;operating frequency;frequency-agile radar transmitting pulse;strong random performance;great random performance;optimal threshold;optimal frequency hopping sequence;selected random frequency hopping point sequence;frequency-agile radar frequency hopping sequence;CNN network;frequency hopping point sequence generation;jamming signals;binary quantization method;autocorrelation performance;target detection performance;threshold optimization problem;neural network","","","","6","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"A Design of Childhood Stunting Assessment Feature with Agile UX Approach","R. Rahutomo; A. S. Perbangsa; F. Asadi; R. Nirwantono; B. Pardamean","Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program – Master of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2022 8th International HCI and UX Conference in Indonesia (CHIuXiD)","13 Jan 2023","2022","1","","1","6","multidisciplinary collaboration between public health, system engineering, and UX is able to generate a solution in healthcare problem like stunting. The principle of Agile UX gathers requirements to generate an application design. Currently, various website and mobile applications are available to be utilized for stunting research. StuntingDB is one of many web-based applications that specialized in stunting data management. The application required several types of users to operate hierarchically. This research focused on Public Health Officers’ workflow that require a solution to in the form of assessment module for stunting DBMS by using Agile UX principle. The method collaborates agile team and UX team to solve Public Health Officer's difficulty in changing stunting status at pre-saved child patient's profile. Collaboration of both agile team and UX team successfully proposed an application design that system design.","","978-1-6654-7664-5","10.1109/CHIuXiD57244.2022.10009800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009800","information technology;usage index;shariah- compliant companies","Human computer interaction;Pediatrics;Collaboration;Companies;Mobile applications;Public healthcare;System analysis and design","health care;Internet;software prototyping","Agile UX principle;childhood stunting assessment feature;healthcare problem;mobile applications;multidisciplinary collaboration;stunting data management;system engineering;web-based applications;website applications","","","","35","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"Advanced Data Analytics in Logistics Demand Forecasting","A. Agatić; E. Tijan; S. Hess; T. P. Jugović","Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime Logistics and Management, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia; Department of Maritime and Transportation Technology, Faculty of Maritime Studies, University of Rijeka, Rijeka, Croatia","2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)","15 Nov 2021","2021","","","1387","1392","The logistics demand forecasting is increasingly influenced by digitalization processes in logistics business. Traditional approach to logistics demand forecasting based on human expertise and statistical assessment is still very present, but the use of Big Data, Artificial Intelligence and Machine Learning becomes more prominent. By using these technologies, logistics demand forecasting becomes not only more reliable but also more agile and self-adjusting, with better insight into changing market conditions in the real-time perspective. In this paper, the Authors research the evolution of Data Analytics in logistics demand forecasting. and provide an insight to the features of Big Data, Artificial Intelligence and Machine Learning used for Advanced Data Analytics in logistics demand forecasting.","2623-8764","978-953-233-101-1","10.23919/MIPRO52101.2021.9596820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596820","logistics demand forecasting;Advanced Data Analytics;Big Data;Artificial Intelligence;Machine Learning","Data analysis;Demand forecasting;Machine learning;Companies;Big Data;Tools;Real-time systems","Big Data;data analysis;demand forecasting;learning (artificial intelligence);logistics;production engineering computing","logistics demand forecasting;advanced data analytics;digitalization process;logistics business;Big Data;artificial intelligence;machine learning","","1","","35","","15 Nov 2021","","","IEEE","IEEE Conferences"
"Role of Joint 5G-IoT Framework for Smart Grid Interoperability Enhancement","H. Shahinzadeh; A. -s. Mirhedayati; M. Shaneh; H. Nafisi; G. B. Gharehpetian; J. Moradi","Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Najafabad Branch, Islamic Azad University, Najafabad, Iran; Smart Microgrid Research Center, Najafabad Branch, Islamic Azad Universityy, Najafabad, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Young Researchers and Elite Club, Khomeinishahr Branch, Islamic Azad University, Esfahan, Iran","2020 15th International Conference on Protection and Automation of Power Systems (IPAPS)","16 Mar 2021","2020","","","12","18","The ever-growing development in communication technology and very fast advances in data science are transferring the power systems in a new era. The level of autonomy is improving by means of Internet-of-Things (IoT), while the level of intelligence is improving through artificial intelligence. The applications of big data analytics and cloud computing techniques in smart grids are also new topics, which have been paid particular attention recently. These paradigms can be used in both grid-scale and local-scale, while the central grid operation center has interoperability with an abundant number of sub-controllers, and aggregators in a wide variety of scales. On the one hand, the system operator must deal with multiple parameters with different kinds of uncertainties. On the other hand, the new structures are evolving toward transactive energy trading models in microgrids. In such a circumstance, a myriad of elements is producing critical data, which should be acquired, transferred, stored, analyzed, and finally, proper controlling actions must be sent. These data are producing at different intervals, even in a fraction of a second. This matter makes it possible to maintain grid security and better real-time operation as well as to get better demand responsiveness. A smart grid consists of many embedded or interconnected systems that are linked to each other through various communication platforms in the cyber layer. A flexible, highly-autonomous, and intelligent smart grid entails an agile communication system, whether wired or wireless. However, cellular networks have prominent benefits. Hence, 5G technology, which is state-of-the-art technology in this field, can be deployed. The communication infrastructure links many components to each other in cyber-physical smart grids. The velocity of data exchange has a profound importance for some purposes, while 5G technology can be the best solution. The joint integration of IoT and 5G procures more reliability, resiliency, security, and economy.","","978-1-6654-1229-2","10.1109/IPAPS52181.2020.9375539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9375539","Smart Grids;5G;Internet of things (IoT);Communication infrastructure;Blockchain;Big data analytics","5G mobile communication;Data science;Smart grids;Power system reliability;Security;Reliability;Interoperability","artificial intelligence;Big Data;cellular radio;cloud computing;data analysis;distributed power generation;Internet;Internet of Things;open systems;power engineering computing;smart power grids","communication infrastructure;cyber-physical smart grids;data exchange;economy;joint 5G-IoT framework;smart grid interoperability enhancement;communication technology;fast advances;data science;power systems;Internet-of-Things;artificial intelligence;big data analytics;grid-scale;local-scale;central grid operation center;abundant number;system operator;transactive energy trading models;critical data;proper controlling actions;different intervals;grid security;real-time operation;embedded systems;interconnected systems;communication platforms;intelligent smart grid;agile communication system;state-of-the-art technology","","4","","23","IEEE","16 Mar 2021","","","IEEE","IEEE Conferences"
"MAP: Design, Development, Deployment, and Maintenance of Industrie 4.0 AI Applications","A. Dagnino; M. Kolomycki; A. Kucheria","GBS IS Innovation and Emerging Services ABB Inc, Cary, USA; GBS IS Innovation and Emerging Services ABB Ltd, Krakow, Poland; GBS IS Innovation and Emerging Services ABB Inc, Cary, USA","2022 IEEE Eighth International Conference on Big Data Computing Service and Applications (BigDataService)","27 Sep 2022","2022","","","108","113","This paper presents a proven process and method to design, develop, deploy, and maintain Industrie 4.0 Big Data Artificial Intelligence (AI) scalable solutions at ABB called modular adaptive process (MAP). The method follows a hybrid DevOps-Agile-Waterfall approach that takes advantage of different elements of all three methodologies to bring to fruition Artificial Intelligence (AI) and Machine Learning (ML) solutions. The described methodology has three phases that include Definition, Development, and Deployment. An important and novel concept that will be discussed is the development of a Value-based Work Breakdown Structure (VWBS) that facilitates DevOps development. Another important discussion is related to the re-training of AI/ML models once the application is deployed.","","978-1-6654-5890-0","10.1109/BigDataService55688.2022.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898260","Artificial Intelligence;Machine Learning;DevOps;Agile;Industrie 4.0;value-based WBS;Model re-training;UX","Industries;Electric breakdown;Design methodology;Computational modeling;Machine learning;Big Data;Maintenance engineering","artificial intelligence;Big Data;cloud computing;learning (artificial intelligence);project management","MAP;AI applications;proven process;Industrie 4.0 Big Data Artificial Intelligence scalable solutions;modular adaptive process;hybrid DevOps-Agile-Waterfall approach;described methodology;DevOps development","","","","11","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"The adoption of Design Thinking, Agile Software Development and Co-creation concepts A case study of Digital Banking innovation","E. Indriasari; H. Prabowo; F. L. Gaol; B. Purwandari","Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science, Bina Nusantara University, Jakarta, Indonesia; Computer Science, Bina Nusantara University, Jakarta, Indonesia; Universitas Indonesia, Jakarta, Indonesia","2021 International Conference on Platform Technology and Service (PlatCon)","20 Jan 2022","2021","","","1","6","Acceleration of technology, especially the mobile internet, causes changes all aspects of human life, including in the banking sector. New emerging technology such as Artificial Intelligence, Blockchain, Big Data, and Cloud computing change the business and operation of the bank. The bank's services have become more personalized, furthermore change customers' lifestyles. Banks are competing to create innovations and breakthroughs to create added value and building a digital ecosystem with fintech and big tech companies in the era of sharing economy. This case study explores the process of creating digital innovation in banking institutions by focusing on adopting design thinking (DT), agile software development (ASD), and co-creation concepts for building digital banking platforms. The case study involved IT executives from four banks in Indonesia. Data were taken through semi-structured interviews and analyzed using NVIVO12. The implication of this research is to accelerate the process of digital banking innovation and produce high-quality digital banking platforms in terms of features and technology.","","978-1-6654-1766-2","10.1109/PlatCon53246.2021.9680763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680763","Digital Innovation;Digital Banking;Agile Software Development;Design Thinking;Co-creation","Technological innovation;Buildings;Ecosystems;Agile software development;Focusing;Banking;Sharing economy","bank data processing;innovation management;software prototyping","banking sector;Big Data;digital ecosystem;tech companies;digital innovation;banking institutions;agile software development;co-creation concepts;digital banking innovation;high-quality digital banking platforms;design thinking;cloud computing;mobile Internet;artificial intelligence;blockchain;bank services;customer lifestyles;fintech;sharing economy;ASD;IT executives;Indonesia;NVIVO12","","1","","37","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"The Effect of Big Data Analytics in Enhancing Agility in Cybersecurity Incident Response","A. Naseer; A. M. Siddiqui","Department of Computer Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Department of Electrical Engineering, National University of Sciences and Technology, Islamabad, Pakistan","2022 16th International Conference on Open Source Systems and Technologies (ICOSST)","18 Jan 2023","2022","","","1","8","The ongoing automation of business operations is putting enterprises at risk of cyber attacks more than ever before. Incident response teams are employed by the enterprises for the identification, management, and elimination of cybersecurity attacks along with for the recovery of business operations timely and effectively. In this paper, we argue that to effectively react to the cybersecurity attacks enterprises should build agility in their incident response method and big data analytics performs an effective role in developing agility in incident response. Grounded on twenty-one in depth expert interviews, we develop a framework that explains the salient features and effect of big data analytics in the incident response method at three stages, i.e., manual analysis, basic analysis, and advanced analysis. The agile properties of flexibility, innovation and swiftness are instilled in the incident response method by practicing big data analytics at higher stages of analysis. The results informed that the key features of big data analytics can be firstly utilize to estimate the existing analytical capability and secondly as an assisting tool to enhance incident response method capability.","2770-8225","978-1-6654-6477-2","10.1109/ICOSST57195.2022.10016853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016853","Big data analytics;incident response;cybersecurity;agility;analytical capability","Technological innovation;Automation;Manuals;Big Data;Interviews;Cyberattack;Business","Big Data;computer crime;data analysis","big data analytics;business operations;cybersecurity attacks;cybersecurity incident response;incident response method capability;incident response teams","","","","42","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Machine Learning-based Estimation of Story Points in Agile Development: Industrial Experience and Lessons Learned","M. Abadeer; M. Sabetzadeh","Privacy Analytics Inc., an IQVIA company Ottawa, Canada; EECS, University of Ottawa, Ottawa, Canada","2021 IEEE 29th International Requirements Engineering Conference Workshops (REW)","27 Oct 2021","2021","","","106","115","Estimating story points is an important activity in agile software engineering. Story-point estimation enables software development teams to, among other things, better scope products, prioritize requirements, allocate resources and measure progress. Several machine learning techniques have been proposed for automated story-point estimation. However, most of these techniques use open-source projects for evaluation. There are important differences between open-source and commercial projects with respect to story authoring. The goal of this paper is to evaluate a state-of-the-art machine learning technique, known as Deep-SE [3], for estimating story points in a commercial project. Our dataset is comprised of 4,727 stories for a data anonymization product developed by a 27-member agile team at a healthcare data science company, IQVIA. Over this dataset, Deep-SE achieved a mean absolute error of 1.46, significantly better than three different baselines. Model performance nonetheless varied across stories, with the estimation error being larger for stories that had higher points. Our results further indicate that model performance is correlated with certain story characteristics such as the level of detail and the frequency of vague terms in the stories. An important take-away from our study is that, before organizations attempt to introduce machine learning-based estimation into agile development, they need to better embrace agile best practices, particularly in relation to story authoring and expert-based estimation.","","978-1-6654-1898-0","10.1109/REW53955.2021.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582288","Agile Development;Story-point Estimation;Machine Learning","Systematics;Conferences;Semantics;Estimation;Machine learning;Predictive models;Software measurement","learning (artificial intelligence);product development;software development management;software prototyping","agile development;agile software engineering;software development teams;automated story-point estimation;open-source projects;commercial projects;story authoring;estimation error;story characteristics;machine learning-based estimation;expert-based estimation;healthcare data science company;Deep-SE;IQVIA","","1","","23","IEEE","27 Oct 2021","","","IEEE","IEEE Conferences"
"Automated Guided Vehicles Challenges for Artificial Intelligence","R. Cupek; J. C. -W. Lin; J. H. Syu","Silesian University of Technology, Gliwice, Poland; Western Norway University of Applied Sciences, Bergen, Norway; National Taiwan University, Taipei, Taiwan","2022 IEEE International Conference on Big Data (Big Data)","26 Jan 2023","2022","","","6281","6289","The use of Artificial Intelligence (AI) to support the Automated Guided Vehicles (AGV) that are used by industry poses a number of challenges that are specific to smart internal logistics systems that are necessary for agile manufacturing. On the one hand, it might seem that experience with the autonomous navigation system that are used in autonomous vehicles can be easily transferred to AGV. However, in this paper, the authors highlight specific problems that are associated with the navigation system of AGV, which has to reflect its operation in an industrial environment with high level of interaction with other production systems and human staff. On the other hand, it may seem that the wealth of experience from using AI in smart manufacturing can be easily transferred to the use of AGV. However, the authors show that although AGV are production tools, the challenges that are associated with the use of AI can significantly differ from other smart manufacturing areas. The number of challenges that are specific to use of AI for AGV is also discussed. This paper systematizes these challenges and discusses the most promising AI methods that can be used for the internal logistics systems that are based on AGV.","","978-1-6654-8045-1","10.1109/BigData55660.2022.10021117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021117","Artificial Intelligence (AI);Automated Guided Vehicles (AGV);Smart Manufacturing;Internal Logistics;Explainable AI (XAI)","Industries;Production systems;Remotely guided vehicles;Navigation;Big Data;Artificial intelligence;Autonomous vehicles","agile manufacturing;artificial intelligence;automatic guided vehicles;logistics;production engineering computing","agile manufacturing;AGV;artificial intelligence;authors highlight specific problems;automated guided vehicles;autonomous navigation system;autonomous vehicles;guided vehicles challenges;human staff;internal logistics systems;production systems;smart internal logistics systems;smart manufacturing areas","","","","55","IEEE","26 Jan 2023","","","IEEE","IEEE Conferences"
"Interactive Visualization for Statistical Modelling through a Shiny App in R","A. Khedr; S. Hilal","MSc. in Big Data Science and Analytics, University of Bahrain, Sakhir, Kingdom of Bahrain; College of Science, University of Bahrain, Sakhir, Kingdom of Bahrain","2021 International Conference on Data Analytics for Business and Industry (ICDABI)","29 Dec 2021","2021","","","332","337","The importance of analytics and visualization tools has been growing over the last decades to handle big data which steamed from all aspects of life. The focus of this paper was on visualization as a crucial tool in presenting complex raw data and modelling results to provide easy-to-understand actionable information that facilitate decision-making. However, limited research distinguished between “data visualization” and “model visualization”, which has been clearly made in this paper. Furthermore, this paper aimed to shed light on the importance of interactive visualizations to compliment statistical data modelling using R and Shiny for its advanced capabilities. Specifically, a methodology has been proposed based on a hybrid development lifecycle that adopts the Agile Software Development Lifecycle and the Data Analytics Lifecycle. Finally, by presenting a case study to model the dynamics of COVID-19, it was found that R and Shiny alongside the proposed hybrid development lifecycle significantly reduced the amount of time required to build visually interactive applications. The reported results highlighted the effectiveness of the adopted approach in assisting and guiding researchers and developers in building interactive applications that leverage Big Data Analytics.","","978-1-6654-1656-6","10.1109/ICDABI53623.2021.9655841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9655841","Data Analytics;Interactive Applications;R;Shiny;Visualization","COVID-19;Analytical models;Data analysis;Smoothing methods;Buildings;Data visualization;Big Data","Big Data;data analysis;data visualisation","crucial tool;complex raw data;data visualization;model visualization;interactive visualization;compliment statistical data;hybrid development lifecycle;Agile Software Development Lifecycle;Data Analytics Lifecycle;visually interactive applications;building interactive applications;leverage Big Data Analytics;statistical modelling;Shiny app;visualization tools","","","","48","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"The Review for Visual Analytics Methodology","Z. Ahmad; S. Yaacob; R. Ibrahim; W. F. Wan Fakhruddin","Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Advanced Informatics Department, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Social Science and Humanity Faculty, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia","2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","27 Jun 2022","2022","","","1","10","Big data usage evolves from previously looking into the capacity of big data's descriptive and diagnostic perspectives into currently feeding the demands for predictive big data analytics. The needs come about due to organizations that crave predictive analytics capabilities to reduce risk, make intelligent decisions, and generate different customer experiences. Similarly, visual analytics play an essential role in understanding and fitting the analytics prediction in their business decision. Hence, the combination of descriptive, diagnostics and predictive within Visual Analytics emerges as a balanced field to provide understandable predictive insight. Due to the organizational demand and multi-discipline area, the approach to developing visual analytics is still uncertain in the Big Data Project Lifecycle from methodological perspectives. While there are a few potential methodological approaches that could be used for visual analytics, they are scattered across numerous academic research and industrial practice. To date, there is no coherent review and analysis of the work that has been explored specifically for Visual Analytics methodology. This paper reports on a review of previous literature concerning how Visual Analytics has been executed in the big data life cycle to address the gap. The review is organized in this study from three perspectives: i) general ICT -related methodology (e.g. SDLC, Agile, DevOps), ii) Data Science-related methodology (e.g. CRISP-DM, SEMMA, KDD) and iii) Visual Analytics-related methodologies in which each method will be benchmarked based on the Visual Analytics major part of reality, computer and human, in terms of its width, depth, and flows. This study found insufficiencies, non-specific and vague conditions in handling the Visual Analytics when using current methodological approaches based on the review conducted. The paper also highlights the Visual Analytics-related methodological review, which can shed some light on the approaches and ways of implementing analytics in the big data lifecycle, which can be beneficial for future studies in proposing a more comprehensive methodology for Visual Analytics in the big data lifecycle.","","978-1-6654-6835-0","10.1109/HORA55278.2022.9800100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800100","process;methodology;visual analytics;big data analytics","Human computer interaction;Systematics;Visual analytics;Robot kinematics;Project management;Organizations;Big Data","Big Data;data analysis;data mining;data visualisation","predictive analytics capabilities;analytics prediction;Visual Analytics methodology;big data life cycle;Visual Analytics-related methodologies;big data lifecycle;predictive big data analytics","","","","80","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"SLA-Based Agile VM Management in Cloud & Datacenter","N. Sharma; S. Maurya","Govt. Women Engineering College, Ajmer, India; Govt. Women Engineering College, Ajmer, India","2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)","11 Oct 2019","2019","","","252","257","Cloud Computing is the main root technology to provide various services over the internet in the current scenario, which is basically powered via virtual machines (VMs) over commodity hardware. As soon as a task arrives in the cloud or data center that task is assigned to a VM as per the task scheduler and resource allocation policy. Whenever cloud or data center do not have sufficient spare resources over VM to assign a task, a new VM is created over host machine which have spare resource capacity in the cloud and/or data center. The VM creation should be in such a manner that will follow the Service Level Agreement (SLA) to maintain the Quality of Service (QoS) for the client. We have proposed SLA-based agile VM management algorithm to minimize the VM creation time and VM response time. We use ghost VM to increase the efficiency of cloud, allocation of new VM is from the ghost VM, and using the average creation time is reduced up to 11.98%. We propose two algorithms first for Admission control and second for Rescheduling of VM's. Our aim is to reduce the time taken in the rescheduling of the VM. Currently, we are assuming excess VM which are eligible to Garbage Collection do not put overhead over the cloud and they can be handled via background service, and with do not affect foreground services directly and they are handled via the separate management service.","","978-1-7281-0211-5","10.1109/COMITCon.2019.8862260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862260","Cloud computing;VM management;cloud efficiency;data-center","Cloud computing;Resource management;Servers;Task analysis;Virtual machining;Admission control","cloud computing;computer centres;contracts;Internet;quality of service;resource allocation;scheduling;virtual machines","data center;task scheduler;resource allocation policy;spare resource capacity;SLA-based agile VM management algorithm;VM creation time;VM response time;ghost VM;excess VM;datacenter;cloud computing;management service","","5","","27","IEEE","11 Oct 2019","","","IEEE","IEEE Conferences"
"SMARTD Web-Based Monitoring and Evaluation System","A. Budiarto; M. F. Kacamarga; T. Suparyanto; S. Purnamasari; R. E. Caraka; H. H. Muljo; B. Pardamean","Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; School of Mathematical Sciences, The National University of Malaysia, Kuala Lumpur, Malaysia; Accounting Information Systems Program, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia","2018 Indonesian Association for Pattern Recognition International Conference (INAPR)","27 Jan 2019","2018","","","172","176","Sustainable Management of Agricultural Research and Technology Dissemination (SMARTD) is a national program organized by Indonesian Agency for Agricultural Research and Development (IAARD), The Ministry of Agriculture of the Republic of Indonesia. It provides funding to increase research capacity in all units under IAARD. Because of the large scope of this program, a good monitoring and evaluation system is needed to ensure its effectiveness. A web-based application is proposed to complement the existing manual monitoring system. Design Thinking method and SCRUM are used as the approach to develop system. This system was developed using PHP 5 with Code Igniter framework and the database was developed using MySQL. This system has successfully implemented to all units under IAARD and are running smoothly for daily reporting system.","","978-1-5386-9422-0","10.1109/INAPR.2018.8627034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627034","Information System;Monitoring;Evaluation;Web Application;Reporting System","Monitoring;Computer science;Design methodology;Conferences;Bioinformatics;Data science","agriculture;Internet;process monitoring;SQL","IAARD;SMARTD web-based monitoring;evaluation system;national program;design thinking method;Sustainable Management of Agricultural Research and Technology Dissemination;Indonesian Agency for Agricultural Research and Development;SCRUM;PHP 5;Code Igniter framework;MySQL","","7","","15","IEEE","27 Jan 2019","","","IEEE","IEEE Conferences"
"All-Fiber Laser With Agile Mode-Switching Capability Through Intra-Cavity Conversion","H. Wu; J. Lu; L. Huang; X. Zeng; P. Zhou","College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai University, Shanghai, China; College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China; Shanghai Institute for Advanced Communication and Data Science, Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai University, Shanghai, China; College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China","IEEE Photonics Journal","9 Mar 2020","2020","12","2","1","9","Agile mode switching between LP01 and LP11 modes in an all-fiber laser is demonstrated by exploiting an acoustically induced fiber grating within the laser cavity. The laser exploits a cladding pump configuration and can deliver up to 5.85 W of stable output power in LP11 mode at 1070.07 nm and 6.06 W in LP01 mode at 1070.48 nm, with a slope efficiency near 50%. Complete mode-switching speed with 250 Hz and partial mode-switching speed with 1 kHz are demonstrated. Based on the obtained switching time between LP11 and LP01 mode, the maximum complete mode-switching speed is calculated to be ~555.56 Hz. Moreover, variable output beam profiles could be obtained by adjusting the frequency of the modulation signal applied on the acoustically induced fiber grating. This paper could provide an example of realizing a high-power, mode-switchable fiber laser source for practical use.","1943-0655","","10.1109/JPHOT.2019.2911270","National Natural Science Foundation of China(grant numbers:61805280,91750108); Open Research Fund of State Key Laboratory of Pulsed Power Laser Technology(grant numbers:SKL2018ZR06); Science and Technology Commission of Shanghai Municipality(grant numbers:16520720900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691732","Mode switching;agile;acoustically-induced fiber grating;high order mode","Optical fiber polarization;Optical fiber couplers;Laser modes;Fiber lasers;Optical fiber devices;Fiber gratings","diffraction gratings;fibre lasers;laser beams;laser cavity resonators;laser modes;optical modulation;optical pumping;optical switches","modulation signal frequency;slope efficiency;LP01 modes;mode-switchable fiber laser source;variable output beam profiles;switching time;partial mode-switching speed;stable output power;cladding pump configuration;laser cavity;acoustically induced fiber grating;all-fiber laser;LP11 modes;intracavity conversion;agile mode-switching capability;wavelength 1070.48 nm;frequency 250.0 Hz;frequency 1.0 kHz;power 6.06 W;wavelength 1070.07 nm","","5","","32","OAPA","14 Apr 2019","","","IEEE","IEEE Journals"
"SMVS: A Web-based Application for Graphical Visualization of Malay Text Corpus","N. B. Ahmat Baseri; J. A. Bakar; A. Ahmad; H. Jafferi; M. F. Zamri","School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia; School of Computing, Universiti Utara Malaysia, Kedah, Malaysia","2020 IEEE 10th Symposium on Computer Applications & Industrial Electronics (ISCAIE)","5 Jun 2020","2020","","","30","35","Information visualization is an interesting field nowadays. A good information visualization ensures distraction of misleading information is not included in the visualization. Many studies have been conducted on the Quranic corpus. The advancement technology coupled with modern approach of the computer technology can support the learners to understand Qur'an easily. Smart Malay Visualization System (SMVS) is a Python Flask framework web application which help users efficiently to produce the most basic data visualization from a big data. This web application displayed information from the state-of-the-art corpus which is identified through text. Agile development has been adapted to prepare this web application. Six phases of the methodology have been implemented in this study which are requirements, analysis, planning, design, implementation, testing, and deployment. Natural Language Processing approach has been used to visualize the data. Twenty most informative word from each verse has been visualized using Frequency Distribution and has been embedded to the web application. This work focuses on the Malay translation of the Qur'an corpus.","","978-1-7281-5033-8","10.1109/ISCAIE47305.2020.9108705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108705","Big data;data visualization;knowledge representation;Qur'an knowledge;natural language processing","","Big Data;data visualisation;information retrieval;Internet;natural language processing;Python;software prototyping;text analysis","SMVS;graphical visualization;Malay text corpus;information visualization;Quranic corpus;computer technology;Smart Malay Visualization System;basic data visualization;big data;Natural Language Processing approach;informative word;Malay translation;Python Flask framework Web application;SMVS;frequency distribution;Web-based application;agile development","","","","20","IEEE","5 Jun 2020","","","IEEE","IEEE Conferences"
"HerdMonitor: Monitoring Live Migrating Containers in Cloud Environments","A. E. González; E. Arzuaga","Department of Electrical and Computer Engineering, University of Puerto Rico, Mayagüez, PR; Department of Computer Science and Engineering, University of Puerto Rico, Mayagüez, PR","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","2180","2189","Cloud computing uses pools of virtual machines to provide shared computing resources. Provisioning and management of these resources are generally done using statistical algorithms to help decide how to better utilize available compute power; recently, this has been performed mostly by using live migration of virtual machines. Nowadays containers deliver the flexibility to handle many software environments and tasks in a lighter-weight virtualization scheme, providing a more agile alternative to virtual machines for certain applications. Application checkpointing coupled with a container manager allows the live migration of a container. In this work, we present Herd-Monitor, a resource monitoring system to gather performance metrics of containers and their respective compute hosts. This data can be used to analyze the utilization of available resources, characterize workloads, and develop forecast models. With the analysis of the data provided by the monitoring system, we can fine-tune resource provisioning policies, with the end goal of constructing a cloud resource provisioning platform that enables an improvement in usage and execution of container workloads through the use of live migration. The design, development, performance evaluation and characterization of our lightweight resource monitoring tool that enables offline and real-time resource utilization analysis of live migration workloads as well as the performance impact on their hosts are presented.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378473","Cloud computing;Containers;Live Migration;Big Data Infrastructure;Software Systems to Support Big Data Computing;Performance Monitoring;Data Streaming;Cloud Architecture;Realtime Monitoring","Cloud computing;Containers;Tools;Big Data;Virtual machining;Software;Monitoring","cloud computing;performance evaluation;resource allocation;virtual machines","cloud environments;cloud computing;virtual machines;statistical algorithms;software environments;lighter-weight virtualization scheme;resource monitoring system;performance metrics;resource provisioning policies;cloud resource provisioning platform;container workloads;performance evaluation;lightweight resource monitoring tool;resource utilization analysis;live migration workloads;live migrating containers monitoring;compute hosts;herd-monitor","","1","","20","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Nanoservice Infrastructure Notation (NINo) and the ASPIRE Interns","C. T. Pascale; M. Rice; S. Sharma",NA; NA; NA,"2020 IEEE Integrated STEM Education Conference (ISEC)","12 Apr 2021","2020","","","1","1","NINo is a future DevOps / Data Science pipeline tool that is being developed by JHU APL and two ASPIRE interns. The goal of this capability is to expose function-level capabilities, via either a simple application or configuration file, for use in Docker [1], Serverless Architectures [2], or data science/analytic pipelines. The goal is similar to efforts such as Metaparticle [3] and Source-to-Image[4] that aim to lower the barrier to horizontal scaling of data processing and analysis capabilities. In previous years ASPIRE interns have developed tools to ease the acceptance of DevOps principles in JHU APL. They have created a web application, Harmonia, that asked users a few simple questions and supplied the scaffolding for a software project with artifacts to support sound software engineering processes. The lack of user interest has driven us to a more focused objective. NINo will focus on easing deployment to cloud environments. Ideally, any person could develop cloud-based data science services. The team and its work has been organized in an asynchronous and agile manner. There have been three members working on three subsystems: configuration, framework/integration, and artifact generation. An incremental and prototype-driven approach has allowed for creation of increasingly more functional software as internship has proceeded. Interns have been given extensive control over their development processes and have investigated the programming frameworks used. While the initial stages have not resulted in a complete system, the interns have improved their programming skills and complete common coding challenges. The team is close to integration testing and initial demonstration. As the academic year closes, team members will work on design improvement, refactoring, and generation of future feature requests from prospective users. One summer intern will focus on developing a user interface for configuring and observing results.","2330-331X","978-1-7281-7520-1","10.1109/ISEC49744.2020.9397808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397808","","Pipelines;Tools;Data science;User interfaces;Software;Programming profession;Testing","cloud computing;software engineering;software maintenance;user interfaces","agile manner;artifact generation;incremental prototype-driven approach;team members;feature requests;prospective users;summer intern;user interface;nanoservice infrastructure notation;NINo;ASPIRE interns;JHU APL;function-level capabilities;Docker;Serverless Architectures;horizontal scaling;data processing;DevOps principles;web application;software project;sound software engineering processes;user interest;focused objective;cloud environments;cloud-based data science services;asynchronous manner","","","","0","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"Agile approach to a CS2-based course using the Jupyter notebook in lab classes","H. Guerra; L. M. Gomes; A. Cardoso","NIDeS, Faculty of Sciences and Technology, University of the Azores Centro Algoritmi, University of Minho, Ponta Delgada, Portugal; NIDeS, Faculty of Sciences and Technology, University of the Azores Centro Algoritmi, University of Minho, Ponta Delgada, Portugal; CISUC, University of Coimbra, Coimbra, Portugal","2019 5th Experiment International Conference (exp.at'19)","21 Oct 2019","2019","","","177","182","In introductory programming courses, there is a need for a change in teaching strategies for practicing programming, which must be influenced by productive learning experiences connected with real world scenarios and methodologies. The abundance of data from different sources, online experimentation, and simulators and virtual/remote labs should also play a fundamental role when we think in new teaching strategies for these courses. In this paper, we show how agile methodologies, widely used in industry and manufacturing, combined with online experimentation, can be both applied to a CS2-based course in the era of data engineering. And, then, a new approach of teaching lab classes in CS2-based course is introduced, benefiting from the Scrum framework, to student-centered learning activities on lab classes, and from the concept of Jupyter notebook to online experimentation.","","978-1-7281-3637-0","10.1109/EXPAT.2019.8876536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876536","online experimentation;data engineering;agile methodologies;Jupyter;CS2-based course;programming labs","Education;Programming profession;Data science;Data structures;Software;Problem-solving","computer aided instruction;computer science education;educational courses;teaching","agile approach;CS2-based course;Jupyter notebook;introductory programming courses;teaching strategies;productive learning experiences;online experimentation;student-centered learning activities","","4","","17","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Case study: Factors that hinder and support the adoption of Pair Programming in an agile software development company","P. Dhoodhanath; R. Quilling","School of Management, Information Technology and Governance, University of KwaZulu-Natal (eThekwini), Durban, South Africa; School of Management, Information Technology and Governance, University of KwaZulu-Natal (eThekwini), Durban, South Africa","2020 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","1 Sep 2020","2020","","","1","7","Pair programming is the XP practice that is the least adopted in software development departments or companies; although previous research suggests there are numerous benefits that can be realised from its use. It is suggested that this practice, which involves two programmers working collaboratively on the same task and following a prescribed approach, produces high quality code, in shorter timeframes, with increased knowledge-sharing and improved developer productivity. This paper investigates the factors that support, and deter, pair programming adoption in a case study at a software development company in the eThekwini (Durban) region, South Africa. The survey and interviews indicate that the most positive influences are the support from senior and peer staff and the company's willingness to provide the necessary hardware, software and physical layout to enable the use of pair programming. The biggest challenge was the personality mix in a pair, for example introvert/extrovert pairs, where extroverts can dominate pair collaboration. This company has specific managerial guidelines and practices which are used to mitigate the challenges and provide support to, not only make pair programming a more operationally feasible option, but also reap its benefits.","","978-1-7281-6770-1","10.1109/icABCD49160.2020.9183869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183869","pair programming;XP (extreme programming);software developer","Programming;Software;Companies;Industries;Productivity;Agile software development;Collaboration","DP industry;groupware;programming;project management;software development management;software prototyping;software quality;source code (software)","agile software development company;XP practice;software development departments;pair programming adoption;pair collaboration;high quality code;eThekwini company;Durban region;South Africa","","","","17","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Electrically Small, Planar, Frequency-Agile, Beam-Switchable Huygens Dipole Antenna","Z. Wu; M. -C. Tang; R. W. Ziolkowski","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, College of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, College of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Antennas and Propagation","16 Dec 2021","2021","69","12","8271","8281","An electrically small, planar, frequency-agile, beam-switchable Huygens dipole antenna is investigated in this article. The near-field resonant parasitic (NFRP) design incorporates an Egyptian axe dipole (EAD) and a capacitively loaded loop (CLL) that function as the electric and magnetic NFRP elements, respectively. A varactor diode is integrated into each of these NFRP elements to facilitate simultaneous tuning of its operating frequency and switching its main beam direction. By changing the capacitance values of these two varactor diodes, the antenna realizes two independent, antipodal, unidirectional endfire radiating states with similar realized gain (RG) and front-to-back ratio (FTBR) values within virtually the same frequency-agile ranges. The experimental results demonstrate that the developed antenna exhibits a 5% frequency-agile fractional impedance bandwidth in both of its two oppositely directed endfire states. The antenna is electrically small at the highest frequency of this bandwidth ( ${ka}_{high} < 0.86$ ) and has measured relatively high radiation efficiency (RE >67.7%), peak RG (2.1–3.19 dBi), and FTBR (5.61–13.4 dB) values, together with stable and uniform radiation patterns, over this frequency-agile range.","1558-2221","","10.1109/TAP.2021.3090580","National Natural Science Foundation of China(grant numbers:62061006); Graduate School, Chongqing University(grant numbers:CYB20066); Chongqing Natural Science Foundation(grant numbers:cstc2019jcyjjqX0004); Australian Research Council(grant numbers:DP160102219); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464275","Beam-switchable antennas;electrically small antennas (ESAs);frequency-agile antennas;Huygens dipole antennas (HDAs);planar antennas","Antenna measurements;Dipole antennas;Frequency measurement;P-i-n diodes;Varactors;Substrates;Capacitance","antenna radiation patterns;broadband antennas;dipole antennas;electromagnetic wave polarisation;loop antennas;varactors","varactor diode;independent endfire radiating states;antipodal endfire radiating states;unidirectional endfire radiating states;front-to-back ratio;frequency-agile range;highest frequency;beam-switchable huygens dipole antenna;near-field resonant parasitic design;Egyptian axe dipole;capacitively loaded loop;electric NFRP elements;magnetic NFRP elements;operating frequency;main beam direction;capacitance values;noise figure 5.61 dB to 13.4 dB","","4","","29","IEEE","24 Jun 2021","","","IEEE","IEEE Journals"
"Frequency Agile, Sub-wavelength, Metamaterial-inspired Huygens Dipole Antenna","L. Vincelj; S. Hrabar; R. W. Ziolkowski","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia","2022 Sixteenth International Congress on Artificial Materials for Novel Wave Phenomena (Metamaterials)","31 Oct 2022","2022","","","X-475","X-477","Near-field resonant parasitic based Huygens sources have been of special interest in many antenna applications recently. Unidirectional patterns with high directivity, high radiation efficiencies and large front-to-back-ratio values, as well as compact dimensions, have made them an attractive choice for space-limited wireless platforms. It is demonstrated with CST simulations that the frequency of operation of a sub-wavelength, metamaterial-inspired Huygens dipole antenna and, hence, its cardioid pattern, can be easily adjusted across a broad bandwidth using tunable lumped reactive elements.","","978-1-6654-6584-7","10.1109/Metamaterials54993.2022.9920708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920708","","Wireless communication;Dipole antennas;Capacitors;Resonant frequency;Bandwidth;Metamaterials;Broadband communication","antenna radiation patterns;dipole antennas;metamaterials;near-field communication","metamaterial-inspired Huygens dipole antenna;Huygens sources;antenna applications;unidirectional patterns;high radiation efficiencies;frequency agile Huygens dipole antenna;sub-wavelength Huygens dipole antenna;near-field resonant parasitic based Huygens sources;high directivity;large front-to-back-ratio values;compact dimensions;space-limited wireless platforms;CST simulations;cardioid pattern;broad bandwidth;tunable lumped reactive elements","","","","5","IEEE","31 Oct 2022","","","IEEE","IEEE Conferences"
"Model of Learning Management System Based on Artificial Intelligence in Team-Based Learning Framework","B. Pardamean; T. Suparyanto; T. W. Cenggoro; D. Sudigyo; A. Anugrahana; I. Anugraheni","Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Bioinformatics and Data Science, Research Center, Bina Nusantara University, Jakarta, Indonesia; Elementary School Teacher Education, Sanata Dharma University, Yogyakarta, Indonesia; Elementary School Teacher Education, Satya Wacana Christian University, Salatiga, Indonesia","2021 International Conference on Information Management and Technology (ICIMTech)","14 Sep 2021","2021","1","","37","42","The presence of various innovations and technology of Artificial Intelligence (AI) has now begun to be adopted by Indonesia in many aspects including in the industrial sector. The utilization of AI also can offer a new paradigm in learning and teaching strategies. The development of learning strategies continues also performed to obtain the variations of learning that involve student activity. Team-Based Learning (TBL) is one of the teaching strategies that can improve the quality of the learning process and student activity in groups. By starting to integrate digital-based learning resources in the learning and teaching process, the TBL strategy can potentially be an alternative to new learning strategies that are relevant to be applied in the era of the educational revolution 4.0. The main focus of this research is to develop and evaluate the application of AI in a digital-based TBL strategy that will be implemented in the form of personalized learning about student learning styles. This research was developed based on the learning strategy development of the research method. However, this article more focuses on developing the AI application design that will be applied. The application design was developed based on the agile development method, especially SCRUM. The result of this study is an additional feature that was implemented on a Learning Management System (LMS) based on the Modular Object-Oriented Dynamic Learning Environment (MOODLE).","","978-1-6654-4937-3","10.1109/ICIMTech53080.2021.9535088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535088","artificial intelligence;team-based learning;personalized learning;moodle","Learning management systems;Technological innovation;Instruments;Object oriented modeling;Education;Learning (artificial intelligence);Media","further education;learning (artificial intelligence);learning management systems;software prototyping;teaching","teaching process;digital-based TBL strategy;student learning styles;AI application design;agile development method;learning management system;modular object-oriented dynamic learning environment;artificial intelligence;team-based learning framework;industrial sector;educational revolution 4.0;SCRUM","","2","","33","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"Drone Swarm ""Agile Suppression"" Tactics","Y. Feng; B. Wang; Z. Li; X. Xiong",NA; NA; NA; NA,"CIBDA 2022; 3rd International Conference on Computer Information and Big Data Applications","22 Sep 2022","2022","","","1","5","Unmanned aerial vehicle (UAV) swarm, as a new quality power growth point of electronic warfare, has been widely paid attention to all over the world. This article will open innovative uav swarm combined with operational concept of ""agile suppression"", from the principle of methods, the implementation method, grasp the key points, four aspects such as the core, for example, elaborated the uav swarm ""agile suppression methods and value, the advantages of uav swarm fighting for the future research laid the theoretical basis of related, as our system of battlefield electromagnetic power advantage added.","","978-3-8007-5876-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9899058","","","","","","","","","","22 Sep 2022","","","VDE","VDE Conferences"
"Drone Application Model for Image Acquisition of Plantation Areas and Oil Palm Trees Counting","H. Sastrohartono; A. P. Suryotomo; S. Saifullah; T. Suparyanto; A. S. Perbangsa; B. Pardamean","Department of Agricultural Engineering, Faculty of Agricultural Technology, Instiper Yogyakarta, Yogyakarta, Indonesia; Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta, Yogyakarta, Indonesia; Department of Informatics, Universitas Pembangunan Nasional Veteran Yogyakarta, Yogyakarta, Indonesia; Bioinformatics and Data Science Research Center Bina Nusantara University, Jakarta, Indonesia; Information Systems Department, School of Information Systems Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, BINUS Graduate Program - Master of Computer Science Bina Nusantara University, Jakarta, Indonesia","2022 International Conference on Information Management and Technology (ICIMTech)","21 Oct 2022","2022","","","167","171","The area of oil palm plantations in Indonesia increased by 7% from 14 million ha in 2017 to 15 million ha in 2021. The vast land requires the support of effective and efficient management techniques to maintain sustainable productivity. The high-performance computing technologies, Internet of Things (IoT), Big Data, Artificial Intelligence, spatial modeling, and drones are the answers to these needs. This study aims to design an application that can obtain plantation image data and analyze the calculation of the number of oil palm trees. The image of oil palm plantations is obtained from processing photo data from drones through a mosaic and composite process. This study also employed Scrum and UML as a system model development method. The image of the oil palm plantation area is used to build a tree counting model using the Viola-Jones algorithm. The oil palm tree count information generated by this system can then be used by management for fertilizing, harvesting, and monitoring the condition of oil palm trees.","","978-1-6654-5090-4","10.1109/ICIMTech55957.2022.9915223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915223","drone;oil palm;Viola-Jones;tree counting;Scrum;UML","Productivity;Oils;Unified modeling language;Transportation;Packaging;Spatial databases;Internet of Things","agriculture;crops;geophysical image processing;image classification;Internet of Things;renewable materials;vegetation;vegetation mapping","plantation image data;oil palm plantations;photo data;drones;system model development method;oil palm plantation area;oil palm tree count information;drone application model;image acquisition;plantation areas;oil palm trees counting;14 million ha;15 million ha;effective management techniques;efficient management techniques;high-performance computing technologies;Big Data;spatial modeling","","","","31","IEEE","21 Oct 2022","","","IEEE","IEEE Conferences"
"A Way of Students' Ability Cultivation of ”Five-one” for Software Engineering Major under Background of New Engineering","J. Yu; Y. Mei; J. Zhang; D. Zhang; Y. Chen; C. Zhu; N. Wu; L. Zhu","College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China; College of Computer Engineering, Anhui Sanlian University, Hefei, China","2020 International Conference on Big Data and Informatization Education (ICBDIE)","28 Jul 2020","2020","","","178","181","Based on the individualized development of students for software engineering major under background of new engineering education, a possible way of students' ability cultivation of “Five-one” is put forward. As a case study of Anhui Sanlian University, from the three levels of interest and hobby, practical ability, and scientific research expansion to construct of the framework of “Five-one” on students' ability cultivation, and good results on implementation are achieved. Finally, further work is expected in the future. Firstly, a sustainable agile curriculum selecting system should be developed soon. Secondly, a platform for innovative practice should be established based on Outcomes-Based Education (OBE) by the form of school-enterprise cooperation.","","978-1-7281-5900-3","10.1109/ICBDIE50010.2020.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150172","new engineering;software engineering;ability cultivatio;Five-one;agile;Outcomes-Based Education(OBE)","Software engineering;Engineering education;Technological innovation;Software;Training;Writing","computer science education;educational courses;educational institutions;engineering education;innovation management;software engineering","software engineering major;engineering education;students ability cultivation;Anhui Sanlian University;sustainable agile curriculum selecting system;outcomes-based education;school-enterprise cooperation","","3","","15","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Towards Agile Integration: Specification-based Data Alignment","C. Giossi; D. Maier; K. Tufte; E. Gall; M. Barnes","Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR; Dept. of Mechanical Engineering, Portland State University, Portland, OR; Dept. of Computer Science, Portland State University, Portland, OR","2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI)","10 Sep 2020","2020","","","333","340","Utilizing data sets from multiple domains is a common procedure in scientific research. For example, research on the performance of buildings may require data from multiple sources that lack a singular standard for data reporting. The Building Management System might report data at regular 5minute intervals, whereas an air-quality sensor might capture values only when there has been significant change from the previous value. Many systems exist to help integrate multiple data sources into a single system or interface. However, such systems do not necessarily make it easy to modify an integration plan, for example, to accommodate data exploration, new and changing data sets or shifts in the questions of interest. We propose an agile data-integration system to enable quick and adaptive analysis across many data sets, concentrating initially on the data alignment step: combining data values from multiple time-series based data sets whose time schedules. To this end, we adopt a Domain Specific Language approach where we construct a domain model for alignment, provide a specification language for describing alignments in the model and implement an interpreter for specification in that language. Our implementation exploits a rank-based join in SQL that produces faster alignment times than the commonly suggested method of aligning data sets in a database. We present experiments to demonstrate the advantage of our method and exploit data properties for optimization.","","978-1-7281-1054-7","10.1109/IRI49571.2020.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191394","data integration;time series;data alignment","Schedules;Buildings;Databases;Temperature measurement;Task analysis;Ventilation;Data integration","building management systems;data analysis;data structures;formal specification;scheduling;sensors;specification languages;SQL;time series","data properties;agile integration;specification-based data alignment;scientific research;data reporting;building management system;air-quality sensor;multiple data sources;integration plan;data sets;agile data-integration system;data alignment step;data values;multiple time-series;Domain Specific Language approach;specification language;time 5.0 min","","","","9","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"On the Relationship Between Organizational Structure Patterns and Architecture in Agile Teams","D. A. Tamburri; R. Kazman; H. Fahimi","Jheronimus Academy of Data Science, Eindhoven University of Technology, Eindhoven, The Netherlands; SEI-CMU, Hawaii University, Honolulu, HI, USA; CGI Corp., Rotterdam, The Netherlands","IEEE Transactions on Software Engineering","6 Jan 2023","2023","49","1","325","347","Forming members of an organisation into coherent groups or teams is an important issue in any large-scale software engineering endeavour, especially so in agile software development where teams rely heavily on self-organisation and organisational flexibility. But is there a recurrent organisational structure pattern in agile software engineering teams? and if so what does that pattern imply, in terms of software architecture quality? We address these questions using mixed-methods research in industry featuring interviews, surveys, and Delphi studies of real agile teams. In our study of 30 agile software teams we found that, out of seven organisational structure patterns that recur across our dataset, a single organisational pattern occurs over 37% of the time. This pattern: (a) reflects young communities (1-12 months old); (b) disappears in established ones (13+ months); and (c) reflects the highest number of architecture smells reported. Finally, we observe a negative correlation between a proposed organisational measure and architecture smells. On the one hand, these insights may serve to aid architects in designing not only their architectures but also their communities to best support their co-evolution. On the other hand, we observe that organisational structures in software engineering influence much more than simply software architectures, and we expect our results to lay the foundations of more structured and rigorous approaches to organisational structure studies and use in software engineering research and practice.","1939-3520","","10.1109/TSE.2022.3150415","European Commission(grant numbers:825480); Horizon 2020 Framework Programme; SODALITE; National Science Foundation(grant numbers:CCF-1817267); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712241","Software organisational structures;human aspects in software engineering;social software engineering;empirical software engineering;industrial mixed-methods research","Organizational aspects;Computer architecture;Software architecture;Software;Social networking (online);Organizations;Periodic structures","object-oriented programming;software architecture;software development management;software maintenance;software prototyping;software quality;team working","agile software development;agile software engineering teams;Delphi studies;large-scale software engineering endeavour;recurrent organisational structure pattern;single organisational pattern;software architecture quality","","","","105","CCBYNCND","11 Feb 2022","","","IEEE","IEEE Journals"
"Developing a Virtual Smart Total Learning Environment for Future Teaching-Learning System","M. A. Akour; A. Das","A’Sharqiyah University, Sultanate, Oman; Cotton University, India","2020 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","8 Mar 2021","2020","","","576","579","The world of education system after this COVID19 pandemic will have to change its dimension to map the needs of learners. The proposed framework is focused on transforming the learning experience into two possible ways like online and on-campus learning through groundbreaking & agile methodologies. The new interfaces for learners will be included like Gamification, animated tutorial etc. The framework designed here is the outcome of the e-learning experiences of the authors and it tries to add all relevant technologies with cutting-edge research to provide inspirational and transformative knowledge to learners of all ages, social status, communities who form worldwide communities of special-learners. It will rise to the occasion to use its open source technology along with the emerged technologies like IoT, 5G etc, to transcend physical and social borders. This framework is a total learning environment as it will incorporate all possible latest technologies like big data and machine learning. The e-learning system possesses features like personalized e-learning, anomaly detection, student performance monitoring, dynamic content preparations, students' satisfaction monitoring etc. The new framework will include big data, cloud applications, machine learning and artificial intelligence to make the system faster, efficient and smart. The new features will make the e-learning system based on Virtual Smart Total Learning Environment (VSTLE) more technologically sound and efficient in processing, predicting, evaluating and making storage backup. This framework is designed in such a way that the minimum human intervention will be needed for its functioning. As a result, the final output will be more accurate as compared to other e-learning systems available.","2470-6698","978-1-7281-6942-2","10.1109/TALE48869.2020.9368373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9368373","smart;virtual;learning-environment;machine learning;big data;adaptive learning","Electronic learning;Pandemics;Education;Machine learning;Tutorials;Big Data;Monitoring","computer aided instruction;Internet;learning (artificial intelligence);teaching","education system;learning experience;e-learning experiences;relevant technologies;special-learners;open source technology;total learning environment;big data;machine learning;personalized e-learning;teaching-Learning system;Virtual Smart Total Learning Environment;anomaly detection;student performance monitoring;dynamic content preparations","","1","","12","IEEE","8 Mar 2021","","","IEEE","IEEE Conferences"
"Design-Computational Thinking, Transfer and Flavors of Reuse: Scaffolds to Information and Data Science for Sustainable Systems in Smart Cities","C. -S. Lee; K. D. Wong","Sunway University, Universiti Tunku Abdul Rahman, Malaysia; Daniel Wireless Software Pte. Ltd., Singapore, Singapore","2018 IEEE International Conference on Information Reuse and Integration (IRI)","6 Aug 2018","2018","","","225","228","This paper investigates how to increase understanding of design and sustainable systems by scaffolding cognitive access and transfer of learning using eclectic approaches to experiment with networks of design potentials. Cognitive access simulates multi-criteria case indexing, refined from knowledge induction derived from analyses of random but related cases based on search strategies. Randomization of the search space encourages emergence of heuristic solutions, fuzzy though informed transfers and further refinement of schema. We investigate the type of navigational structures/design resulting from creative reuse/refactoring and lean management; and whether there will be evidences of knowledge induction from randomized search scaffolded by Case-based Reasoning (CBR), which leads to heuristic transfer and learning. Examples from two courses carried out August-December 2017 within the participatory design-agile framework for engagement in Smart Cities are assessed for creative reuse regarding: a) people, process and tools; b) domain engineering; c) component mining and d) open source vs. systematic reuse. Findings confirm longitudinal insights: CBR-informed but emergent search leading to more efficient and higher quality heuristic transfer and learning is scaffolded by systemic modelling and design dependent on four factors.","","978-1-5386-2659-7","10.1109/IRI.2018.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424711","Technology and Engineering Management;design centering;Project management;creativity;reuse, integration","Creativity;Information systems;Tools;Project management;Navigation;Systematics;Smart cities","case-based reasoning;data mining;smart cities;sustainable development","design-computational thinking;sustainable systems;eclectic approaches;knowledge induction;search strategies;randomization;search space;heuristic solutions;informed transfers;lean management;randomized search;learning;participatory design-agile framework;systematic reuse;systemic modelling;smart cities;case-based reasoning;multicriteria case indexing;navigational structures;CBR","","4","","25","IEEE","6 Aug 2018","","","IEEE","IEEE Conferences"
"Toward Automatized Handling of Future Agile Networks Employing Various Optical Switching Functionalities","K. Ishii; S. Namiki","National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan","2019 24th OptoElectronics and Communications Conference (OECC) and 2019 International Conference on Photonics in Switching and Computing (PSC)","29 Aug 2019","2019","","","1","3","Various optical switch systems will be required to support future wide application network areas having different requirements. A bottom-up modeling approach which will realize a common platform for automatized operation of physical layer is discussed.","","978-4-88552-321-2","10.23919/PS.2019.8818061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818061","Photonic Networking/Switching System Designs and Architectures for Computing and Big Data;Software defined networking (SDN) for computing and big data control","Optical switches;Optical filters;Optical fiber networks;Optical reflection;Optical fibers","optical fibre networks;optical switches","automatized handling;optical switching functionality systems;bottom-up modeling approach","","","","32","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Comparative Analysis of Machine Learning Techniques in Effort Estimation","Ritu; Y. Garg","Guru Nanak Dev Engineering College, Ludhiana, Punjab, India; Department of Computer Science & Engineering, APEX Institute of Technology, Chandigarh University, Mohali, Punjab, India","2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON)","15 Aug 2022","2022","1","","401","405","In Software engineering effort estimation provides an important role for software development and managing project cost, quality, and time. Since last decades, software estimation has been receiving significant attention from researchers and substantial research has been performed using various techniques and algorithms of machine learning. This paper suggests different machine learning techniques such as Naïve Bayes, Random Forests Logistic Regression, stochastic gradient boosting, decision tree, and story point for estimation to assess prediction more efficiently. Nowadays uses of these approaches by software development industries for software estimation aim to tackle deficiencies of parametric and traditional estimation techniques, rise project. A comparative study of the mentioned techniques is presented and examined in this paper to critically evaluate the performance of these techniques.","","978-1-6654-9602-5","10.1109/COM-IT-CON54601.2022.9850592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850592","Effort;efficiency;software;estimation;techniques","Software algorithms;Estimation;Machine learning;Parallel processing;Prediction algorithms;Software;Scrum (Software development)","Bayes methods;decision trees;financial data processing;learning (artificial intelligence);regression analysis;software cost estimation;software engineering","mentioned techniques;comparative analysis;Software engineering effort estimation;managing project cost;substantial research;Naïve Bayes;Random Forests Logistic Regression;stochastic gradient boosting;software development industries;software estimation aim;parametric estimation techniques;traditional estimation techniques","","","","40","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Integration of Machine Learning in Agile Supply Chain Management","V. Ghabak; A. Seetharaman","Business Administration, SP Jain School of Global Management, Mumbai, India; Business Administration, SP Jain School of Global Management, Singapore","2023 15th International Conference on Computer and Automation Engineering (ICCAE)","3 May 2023","2023","","","6","12","One essential component of any manufacturing industry's success is a successful supply chain. Customer expectations have increased due to the quick growth of information and communication technologies, which has also made the world more competitive. Global production and manufacturing have now transitioned to Industry 4.0. The ""Internet of Things,"" ""Big Data,"" and ""Artificial Intelligence"" are the dominant digital technologies in this. Consequently, in the near future, supply chain management (SCM) will manage not only the flow of raw materials, semi-finished goods, finished goods, and services from the manufacturer to the customer, but also the flow of the most recent data for current and future supply chain visibility & sustainability. For this many companies around the world have tapped one of the advanced technique - Machin Learning (ML) for early risk identification & management, material planning & forecasting, raw material price forecasting etc. As a result, purpose of this paper is to explain a conceptual framework which illuminates factors influencing integration of Machin learning (ML) in Agile Supply chain management, its benefits, and challenges to implement.","2154-4360","979-8-3503-9622-5","10.1109/ICCAE56788.2023.10111340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10111340","machine learning;agile supply chain management;industry 4.0;supply chain risk management;advanced technologies","Analytical models;Supply chain management;Supply chains;Machine learning;Companies;Predictive models;Big Data","","","","","","42","IEEE","3 May 2023","","","IEEE","IEEE Conferences"
"Smart Factory Production and Operation Management Methods based on HCPS","J. Yu; Y. Sun; W. Zheng; X. Zhou","School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Nanjing University, Nanjing, China; School of Management and Engineering, Research Center for Novel Technology of Intelligent Equipment, Nanjing University, Nanjing, China","2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)","4 Nov 2020","2020","","","1","6","The human-cyber-physical system (HCPS) is a composite intelligent system comprising humans, cyber systems, and physical systems with the aim of achieving specific manufacturing goals at an optimized level. Smart factory is an important carrier of a new-generation intelligent manufacturing. In order to achieve the comprehensive collaboration of human-machine-thing and other elements in the smart factory, the HCPS is introduced to the smart factory in this paper. Firstly, a smart factory model is constructed based on human-cyber-physical (HCPS). Then, according to the characteristics of big data, Internet-of-Things(IoT) and artificial intelligence(AI), the management methods of smart factory is proposed, including production design, resource intelligent management and knowledge discovery. Finally, a guiding technology architecture of human-centered smart factory production and operation management is given. The smart factory based on HCPS is of great significance to realize the full use of various resources, and agile management.","","978-1-7281-6855-5","10.1109/ICNSC48988.2020.9238110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238110","Human-cyber-physical system;Smart Factory;Production and Operation;Management Methods","Collaboration;Production;Knowledge discovery;Dynamic scheduling;Sensors;Optimization;Smart manufacturing","Big Data;cyber-physical systems;data mining;factory automation;intelligent manufacturing systems;Internet of Things;production engineering computing;production facilities","HCPS;cyber systems;physical systems;resource intelligent management;knowledge discovery;human-centered smart factory production;human-cyber-physical system;composite intelligent system;operation management;manufacturing goals;new-generation intelligent manufacturing;human-machine-thing;Big Data;Internet-of-Things;IoT;artificial intelligence;production design;technology architecture;agile management","","1","","23","IEEE","4 Nov 2020","","","IEEE","IEEE Conferences"
"AGV Congestion Avoidance using Threshold-modulating Oscillator in Cellular Manufacturing","T. Itou; H. Wakayama; K. Konishi; K. Tadano; Y. Maenol; M. Ogawa","Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Dept. of Electrical and Information Systems, Osaka Prefecture University, Osaka, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan","2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)","25 Oct 2018","2018","1","","975","982","Control of automated guided vehicles (AGVs) for avoiding congestion must be stable and adaptive in agile production such as cellular manufacturing. In this study, we propose a flexible AGV-dispatch algorithm based on the synchronization phenomenon of a coupled oscillators. The dynamics of a production system is formulated as that of relaxation oscillators. Through controlling the threshold of the relaxation oscillators, the proposed algorithm can synchronize AGV-dispatch timing even with fluctuating production speeds. Phase-plane analysis is applied to investigate the qualitative behavior of the dynamical system the algorithm. In addition, through numerical simulation, we demonstrate that our AGV-dispatch algorithm can improve the congestion index of AGVs by 30%.","1946-0759","978-1-5386-7108-5","10.1109/ETFA.2018.8502643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502643","","Workstations;Synchronization;Oscillators;Heuristic algorithms;Cellular manufacturing","automatic guided vehicles;cellular manufacturing;collision avoidance;dispatching;industrial robots;numerical analysis","coupled oscillators;production system;relaxation oscillators;AGV-dispatch timing;production speeds;phase-plane analysis;dynamical system;congestion index;AGV congestion avoidance;threshold-modulating oscillator;cellular manufacturing;automated guided vehicles;agile production;flexible AGV-dispatch algorithm;synchronization phenomenon;numerical simulation;congestion avoidance","","1","","23","IEEE","25 Oct 2018","","","IEEE","IEEE Conferences"
"CRISIS: Integrating AIS and Ocean Data Streams Using Semantic Web Standards for Event Detection","A. Soares; R. Dividino; F. Abreu; M. Brousseau; A. W. Isenor; S. Webb; S. Matwin","Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Defence Research and Development Canada (DRDC), Halifax, Nova Scotia; Institute for Big Data Analytics, Halifax, Nova Scotia","2019 International Conference on Military Communications and Information Systems (ICMCIS)","19 Sep 2019","2019","","","1","7","Information deluge is still an issue in the maritime environment, creating situations where data are sometimes underutilized or in more extreme cases, not utilized, in the decision-making process. In part, this is due to the high volume of incoming data that are available to the operational community. However, better exploitation of these data streams can be accomplished through techniques that focus on the semantics of the incoming stream, to discover information-based alerts that generate knowledge that is only obtainable when considering the totality of the streams. In this paper, we present an agile data architecture for real-time data representation, integration, and querying situations over heterogeneous data streams using Semantic Web Technologies, with the goal of improved knowledge interoperability. We apply the framework to the maritime ship traffic domain to discover real-time traffic alerts by querying and reasoning across multiple streams.","","978-1-5386-9383-4","10.1109/ICMCIS.2019.8842749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842749","","Marine vehicles;Semantics;Real-time systems;Ontologies;Standards;Resource description framework","data integration;data structures;decision making;Internet;marine engineering;open systems;query processing;semantic Web;software architecture;software prototyping;traffic engineering computing","ocean data streams;Semantic Web standards;event detection;information deluge;maritime environment;decision-making process;operational community;semantics;information-based alerts;agile data architecture;real-time data representation;querying situations;heterogeneous data streams;Semantic Web Technologies;improved knowledge interoperability;maritime ship traffic domain;real-time traffic alerts;multiple streams;integrating AIS","","14","","26","Crown","19 Sep 2019","","","IEEE","IEEE Conferences"
"IndustEdge: A Time-Sensitive Networking Enabled Edge-Cloud Collaborative Intelligent Platform for Smart Industry","Y. Wang; S. Yang; X. Ren; P. Zhao; C. Zhao; X. Yang","National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Department of Computing, Imperial College London, London, U.K.; National Engineering Laboratory for Big Data Analytics and School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Industrial Informatics","5 Jan 2022","2022","18","4","2386","2398","An edge-cloud collaborative intelligent (ECCI) platform is of great significance for the agile development and rapid deployment of ECCI applications, which are essential for realizing smart industry in the era of Industry 4.0. However, the existing platforms lack considering the high real-time latency demand of industrial operations, which severely hinders the development of smart industry and may even lead to severe industrial accidents. To effectively reduce the response latency of industrial applications, in this article, we propose an ECCI platform IndustEdge. It takes time-sensitive networking as the deterministic transport for the link layer, and provides an extensible ECCI orchestration component to reduce the system level latency. Furthermore, IndustEdge has an ECCI algorithm library for different collaborative modes and provides the complete life cycle management for ECCI applications. We implement platforms for both the real-world prototype and emulated-world emulation, and conduct two case studies to evaluate the effectiveness of IndustEdge.","1941-0050","","10.1109/TII.2021.3104003","National Key Research and Development Program of China(grant numbers:2017YFB1010004); National Natural Science Foundation of China(grant numbers:61772410,61802298,U1811461,11690011); China Postdoctoral Science Foundation(grant numbers:2020T130513,2019M663726); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531530","Edge cloud collaborative intelligence (ECCI);edge computing platform;Industry 4.0;smart industry;time -sensitive networking (TSN)","Collaboration;Cloud computing;Industries;Emulation;Real-time systems;Bridges;Prototypes","cloud computing;computer networks;distributed processing;industrial accidents;intelligent manufacturing systems;product life cycle management;production engineering computing","time-sensitive networking enabled edge-cloud collaborative intelligent platform;smart industry;ECCI applications;industrial operations;severe industrial accidents;industrial applications;ECCI algorithm library;high real-time latency demand;ECCI orchestration component;agile development;Industry 4.0;life cycle management;emulated-world emulation;IndustEdge","","7","","29","IEEE","8 Sep 2021","","","IEEE","IEEE Journals"
"Exploiting Page Table Locality for Agile TLB Prefetching","G. Vavouliotis; L. Alvarez; V. Karakostas; K. Nikas; N. Koziris; D. A. Jiménez; M. Casas","Barcelona Supercomputing Center, Universitat Politecnica de Catalunya; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya; National Technical University of Athens; National Technical University of Athens; National Technical University of Athens; Texas A&M University; Barcelona Supercomputing Center, Universitat Politecnica de Catalunya","2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)","4 Aug 2021","2021","","","85","98","Frequent Translation Lookaside Buffer (TLB) misses incur high performance and energy costs due to page walks required for fetching the corresponding address translations. Prefetching page table entries (PTEs) ahead of demand TLB accesses can mitigate the address translation performance bottleneck, but each prefetch requires traversing the page table, triggering additional accesses to the memory hierarchy. Therefore, TLB prefetching is a costly technique that may undermine performance when the prefetches are not accurate.In this paper we exploit the locality in the last level of the page table to reduce the cost and enhance the effectiveness of TLB prefetching by fetching cache-line adjacent PTEs ""for free"". We propose Sampling-Based Free TLB Prefetching (SBFP), a dynamic scheme that predicts the usefulness of these ""free"" PTEs and prefetches only the ones most likely to prevent TLB misses. We demonstrate that combining SBFP with novel and state-of-the-art TLB prefetchers significantly improves miss coverage and reduces most memory accesses due to page walks.Moreover, we propose Agile TLB Prefetcher (ATP), a novel composite TLB prefetcher particularly designed to maximize the benefits of SBFP. ATP efficiently combines three low-cost TLB prefetchers and disables TLB prefetching for those execution phases that do not benefit from it. Unlike state-of-the-art TLB prefetchers that correlate patterns with only one feature (e.g., strides, PC, distances), ATP correlates patterns with multiple features and dynamically enables the most appropriate TLB prefetcher per TLB miss.To alleviate the address translation performance bottleneck, we propose a unified solution that combines ATP and SBFP. Across an extensive set of industrial workloads provided by Qualcomm, ATP coupled with SBFP improves geometric speedup by 16.2%, and eliminates on average 37% of the memory references due to page walks. Considering the SPEC CPU 2006 and SPEC CPU 2017 benchmark suites, ATP with SBFP increases geometric speedup by 11.1%, and eliminates page walk memory references by 26%. Applied to big data workloads (GAP suite, XSBench), ATP with SBFP yields a geometric speedup of 11.8% while reducing page walk memory references by 5%. Over the best state-of-the-art TLB prefetcher for each benchmark suite, ATP with SBFP achieves speedups of 8.7%, 3.4%, and 4.2% for the Qualcomm, SPEC, and GAP+XSBench workloads, respectively.","2575-713X","978-1-6654-3333-4","10.1109/ISCA52012.2021.00016","Ministry of Science and Technology; Generalitat de Catalunya; Ministry of Economy; European Social Fund; Ministry of Economy; Ministry of Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499825","virtual memory;address translation;translation lookaside buffer;page table locality;prefetching","Prefetching;Memory management;Big Data;Benchmark testing","buffer storage;cache storage;microprocessor chips;paged storage;performance evaluation","page walks;address translations;SBFP;TLB misses;ATP;novel composite TLB;state-of-the-art TLB prefetcher;appropriate TLB prefetcher;eliminates page;page walk memory references;page table locality;Agile TLB;page table entries prefetching;translation performance bottleneck;free TLB prefetching;frequent translation lookaside buffer misses","","6","","62","IEEE","4 Aug 2021","","","IEEE","IEEE Conferences"
"A Method of Verification in Chisel Based Deep Learning Accelerator Design","Z. Li; Y. Chen; D. Zhao","Beijing University of Post and Telecommunications, Beijing, China; Beijing University of Post and Telecommunications, Beijing, China; The Institute of Computing Technology of the Chinese Academy of Sciences, Beijing","2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)","14 Dec 2020","2020","1","","789","792","Chisel is a new generation of hardware construction language (HCL) for agile development. More and more developers have developed their project in agile design. At the same time, a considerable part of Verilog-based design has also been released in agile design versions. However, there is no comprehensive verification flow for Chisel based design. Due to the difficulties of verification in Chisel based design, it is a tough task to attach Chisel based design on Verilog based design. We purpose a feasible verification flow in chisel-based deep learning accelerator (DLA) design, which is composed by performance equivalence check at module-level and function equivalence check at pin-level. Compared to Universe Verification Method in RTL level codes that cost considerable time and funds, this verification flow improves the verification efficiency and reduce the difficulty of debug.","","978-1-7281-5224-0","10.1109/ICIBA50161.2020.9277284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277284","deep learning accelerator;verification;Chisel","Hardware design languages;Hardware;Acceleration;Pins;Deep learning;Programming;Field programmable gate arrays","deep learning (artificial intelligence);electronic engineering computing;hardware accelerators;hardware description languages;logic design","verification flow;agile development;agile design versions;Verilog based design;chisel-based deep learning accelerator;universe verification method;hardware construction language;function equivalence check;RTL level codes;debug reduction;debug difficulty","","1","","8","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"DSEOM: A Framework for Dynamic Security Evaluation and Optimization of MTD in Container-Based Cloud","H. Jin; Z. Li; D. Zou; B. Yuan","National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Cluster and Grid Computing Lab, Services Computing Technology and System Lab, Big Data Security Engineering Research Center, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Dependable and Secure Computing","13 May 2021","2021","18","3","1125","1136","Due to the lightweight features, the combination of container technology and microservice architecture makes container-based cloud environment more efficient and agile than VM-based cloud environment. However, it also greatly amplifies the dynamism and complexity of the cloud environment and increases the uncertainty of security issues in the system concurrently. In this case, the effectiveness of defense mechanisms with fixed strategies would fluctuate as the updates occur in cloud environment. We refer this problem as effectiveness drift problem of defense mechanisms, which is particularly acute in the proactive defense mechanisms, such as moving target defense (MTD). To tackle this problem, we present DSEOM, a framework that can automatically perceive updates of container-based cloud environment, rapidly evaluate the effectiveness change of MTD and dynamically optimize MTD strategies. Specifically, we establish a multi-dimensional attack graphs model to formalize various complex attack scenarios. Combining with this model, we introduce the concept of betweenness centrality to effectively evaluate and optimize the implementation strategies of MTD. In addition, we present a series of security and performance metrics to quantify the effectiveness of MTD strategies in DSEOM. And we conduct extensive experiments to illustrate the existence of the effectiveness drift problem and demonstrate the usability and scalability of DSEOM.","1941-0018","","10.1109/TDSC.2019.2916666","National Key Research and Development Program of China(grant numbers:2017YFB0802205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726136","Container;microservice;moving target defense;cloud computing","Cloud computing;Containers;Security;Computer architecture;Complexity theory;Virtualization;Tools","cloud computing;graph theory;security of data;virtual machines","DSEOM;dynamic security evaluation;container technology;microservice architecture;container-based cloud environment;VM-based cloud environment;proactive defense mechanisms;MTD strategies","","13","","53","OAPA","30 May 2019","","","IEEE","IEEE Journals"
"APCC: Agile and Precise Congestion Control in Datacenters","R. Zhou; G. Yuan; D. Dong; S. Huang","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China","2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","4 Jun 2021","2020","","","649","656","Modern datacenter networks exhibit complicated and time-varying traffic patterns, from long-running flows to burst short-lived flows. Recently in-network-telemetry (INT) is employed by datacenter transports to perform precise congestion control (CC). Current INT-based CC works well for long flows, however, suffers from serious performance downgrades when BDP-level small flows burst in the first RTT, due to the reason that current INT information from the receivers (host-based INT) needs at least one RTT to respond. In this paper, we make the first attempt to propose an agile and precise congestion control, called APCC, in datacenter networks, working for traffic patterns that is a mix of BDP-level short flows and long flows. APCC explores INT information from switches (switch-based INT) to feedback the congestion information eagerly, and effectively manage BDP-level flows. APCC utilizes the switch-based INT to schedule the complicated and time-varying traffic stably and precisely, and achieve low latency, high bandwidth and network stability simultaneously. We conduct extensive experiments to evaluate the performance of APCC. The experiment results show that with data centers load containing many BDP-level flows such as Cache Follower and Web Server, switch-based INT shows huge potential of improving the long tail effect on completion time (FCT). APCC reduces tail delay by 21.7%-28.9% under normal circumstances, and can still reduce tail delay by 9.1% under more severe conditions comparing with HPCC. Moreover, APCC shows better convergence.","","978-1-6654-1485-2","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00107","National Key R&D Program of China(grant numbers:2018YFB0204300); National Natural Science Foundation of China(grant numbers:61802416); National Natural Science Foundation of China(grant numbers:62002368); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443722","datacenter networks;congestion control;in-network telemetry (INT);switch-based INT;host-based INT","Schedules;Data centers;Network topology;Switches;Receivers;Traffic control;Web servers","computer centres;computer networks;telecommunication congestion control;telecommunication traffic;telemetry","datacenter transports;in-network-telemetry;long-running flows;time-varying traffic patterns;modern datacenter networks;long tail effect;network stability;congestion information;switch-based INT;BDP-level short flows;APCC;precise congestion control;agile congestion control;host-based INT;current INT information;RTT;flows burst;current INT-based CC","","2","","19","IEEE","4 Jun 2021","","","IEEE","IEEE Conferences"
"Frequency-Hopping MIMO Radar-Based Communications: An Overview","K. Wu; J. A. Zhang; X. Huang; Y. J. Guo","Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia","IEEE Aerospace and Electronic Systems Magazine","6 Apr 2022","2022","37","4","42","54","Enabled by the advancement in radio frequency technologies, the convergence of radar and communication systems becomes increasingly promising and is envisioned as a key feature of future sixth-generation networks. Recently, the frequency-hopping (FH) MIMO radar has been introduced to underlay dual-function radar-communication (DFRC) systems. Superior to many previous radar-centric DFRC designs, the symbol rate of FH-MIMO radar-based DFRC (FH-MIMO DFRC) can exceed the radar pulse repetition frequency. However, many practical issues, particularly those crucial to achieving effective data communications, are unexplored or unsolved. To promote the awareness and general understanding of the novel DFRC, this article is devoted to providing a timely introduction of FH-MIMO DFRC. We comprehensively review many essential aspects of the novel DFRC: channel/signal models, signaling strategies, modulation/demodulation processing, and channel estimation methods, to name a few. We also highlight major remaining issues in FH-MIMO DFRC and suggest potential solutions to shed light on future research directions.","1557-959X","","10.1109/MAES.2021.3081176","NSW Defence Innovation Network; NSW State Government(grant numbers:DINPP-19-20 10.01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656537","Multi-Functional RF Systems (MFRFS);joint communication and radar/radio sensing (JCAS);dual-function radar-communication (DFRC);frequency hopping (FH);MIMO radar;frequency-agile radar (FAR);timing offset and channel estimation","Communication systems;Sensors;Radar antennas;MIMO radar;Wireless communication;Radio frequency;Channel models","antenna arrays;channel estimation;data communication;demodulation;interference suppression;MIMO radar;radar antennas;radar signal processing","FH-MIMO DFRC;radar pulse repetition frequency;effective data communications;novel DFRC;frequency-hopping MIMO radar-based communications;radio frequency technologies;dual-function radar-communication systems;previous radar-centric DFRC designs;FH-MIMO radar-based DFRC","","7","","30","IEEE","20 Dec 2021","","","IEEE","IEEE Magazines"
"Research on the application of service choreography in the intelligent customer service system","Z. Shuo; Y. Rui; X. Yin; Z. Yan; Z. Wei; A. Yeteng; H. Wei; C. Long; K. Na; X. Liyang","State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China; State Grid Customer Center, Tianjin, China","2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)","10 Apr 2023","2023","","","1238","1242","The background of this paper is to study the situation that the intelligent customer service system needs different response processes in different scenarios, including the high cost of developing and managing these processes. This paper applies the process engine framework Zeebe, which configures the sequence of various question-and-answer processes and other automatically triggered external processes through flexible scheduling. This application enables the system to respond flexibly to business process changes and achieve rapid and agile responses to new requirements. This system can be customized for different scenarios. The advantages of this system are that it reduces development costs and improves system scalability.","","978-1-6654-6253-2","10.1109/EEBDA56825.2023.10090735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10090735","Intelligent customer service;business process;service choreography;Zeebe","Electrical engineering;Costs;Customer services;Scalability;Manuals;Big Data;Scheduling","business data processing;customer services;Web services","-answer processes;automatically triggered external processes;business process changes;different response processes;intelligent customer service system;process engine framework Zeebe;question;service choreography;system scalability","","","","6","IEEE","10 Apr 2023","","","IEEE","IEEE Conferences"
"A Microservices Platform for Monitoring and Analysis of IoT Traffic Data in Smart Cities","A. De Iasio; A. Furno; L. Goglia; E. Zimeo","University of Sannio, Benevento, Italy; ENTPE, IFSTTAR LICIT UMR T9401, Univ. of Lyon, Lyon, France; University of Sannio, Benevento, Italy; CINI Smart City Lab, University of Sannio, Benevento, Italy","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","5223","5232","The ongoing digitization of cities, enabled by the diffusion of interconnected sensors and devices, makes it possible to continuously collect and analyze huge streams of data at extremely large spatio-temporal scales and fine resolutions. These data can be used to monitor, detect and anticipate different kinds of infrastructure vulnerabilities and anomalies, as well as to implement more personalized services that could improve citizens' life. In this new context, full of opportunities, it is difficult to foresee and develop, in advance, the set of applications and services that can be potentially useful for administrators and citizens to solve the manifold compelling needs a city may have to face. Novel ICT paradigms and technologies can help designing agile, general-purpose smart city platforms aimed at supporting the collection and treatment of large-scale, multi-source (streams of) data and the development of novel applications that could fulfill diverse functional requirements under strict non-functional constraints. This paper presents the reference architecture, a prototype implementation and a city-scale case-study evaluation of PROMENADE, a platform that exploits IoT/Fog/Cloud paradigms, microservices and DevOps infrastructures to guarantee continuous development of robust and reliable applications for real-time monitoring and analysis of traffic data generated by IoT devices in large smart cities. The prototype has been evaluated in a case study concerning the quasi real-time detection of road networks vulnerabilities via centrality measures from on-line traffic conditions, emulated from off-line real datasets available for the city of Lyon, France.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006025","IoT Platform;Microservices;Smart cities;Traffic monitoring;Resilience","Smart cities;Real-time systems;Big Data;Roads;Cloud computing;Monitoring","cloud computing;Internet of Things;road traffic;smart cities;traffic engineering computing","diverse functional requirements;nonfunctional constraints;continuous development;robust applications;reliable applications;real-time monitoring;IoT devices;smart cities;quasireal-time detection;road networks vulnerabilities;on-line traffic conditions;microservices platform;IoT traffic data;interconnected sensors;huge streams;spatio-temporal scales;fine resolutions;infrastructure vulnerabilities;personalized services;citizens;general-purpose smart city platforms","","6","","45","IEEE","24 Feb 2020","","","IEEE","IEEE Conferences"
"Collaborative Cloud-Edge-End Task Offloading in Mobile-Edge Computing Networks With Limited Communication Capability","C. Kai; H. Zhou; Y. Yi; W. Huang","Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei, China","IEEE Transactions on Cognitive Communications and Networking","9 Jun 2021","2021","7","2","624","634","Mobile edge computing (MEC) is an emerging computing paradigm for enabling low-latency, high-bandwidth and agile mobile services by deploying computing platform at the edge of network. In order to improve the cloud-edge-end processing efficiency of the tasks within the limited computation and communication capabilities, in this article, we investigate the collaborative computation offloading, computation and communication resource allocation scheme, and develop a collaborative computing framework that the tasks of mobile devices (MDs) can be partially processed at the terminals, edge nodes (EN) and cloud center (CC). Then, we propose the pipeline-based offloading scheme, where both MDs and ENs can offload computation-intensive tasks to a particular EN and CC, according to their computation and communication capacities, respectively. Based on the proposed pipeline offloading strategy, a sum latency of all MDs minimization problem is formulated with the consideration of the offloading strategy, computation resource, delivery rate and power allocation, which is a non-convex problem and difficult to deal with. To solve the optimization problem, by using the classic successive convex approximation (SCA) approach, we transform the non-convex optimization problem into the convex one. Finally, simulation results indicate that the proposed collaboration offloading scheme with the pipeline strategy is efficient and outperforms other offloading schemes.","2332-7731","","10.1109/TCCN.2020.3018159","National Natural Science Foundation of China(grant numbers:61971176,61901156); Anhui Provincial Natural Science Foundation(grant numbers:2008085QF281); Fundamental Research Funds for the Central Universities of China(grant numbers:PA2020GDKC0008,JZ2019HGBZ0144); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171865","Mobile edge computing;collaborative offloading;delivery rate","Task analysis;Resource management;Cloud computing;Wireless communication;Collaboration;Servers;Pipelines","cloud computing;convex programming;groupware;mobile computing;resource allocation","pipeline-based offloading scheme;computation-intensive tasks;MDs minimization problem;nonconvex optimization problem;collaboration offloading scheme;collaborative cloud-edge-end task offloading;mobile-edge computing networks;agile mobile services;collaborative computation offloading;communication resource allocation scheme;collaborative computing framework;mobile devices;cloud center","","47","","43","IEEE","20 Aug 2020","","","IEEE","IEEE Journals"
"Mission Replanning for Multiple Agile Earth Observation Satellites Based on Cloud Coverage Forecasting","Y. Gu; C. Han; Y. Chen; W. W. Xing","School of Astronautics, Beihang University, Beijing, China; School of Astronautics, Beihang University, Beijing, China; School of Astronautics, Beihang University, Beijing, China; School of Integrated Circuit Science and Engineering, Beihang University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","5 Jan 2022","2022","15","","594","608","Recent decades have witnessed a tremendous growth in the number of Earth observation satellites (EOSs), which presents a huge challenge for mission planning. For the EOSs with optical sensors particularly, the observation mission is significantly influenced by the uncertainty of cloud coverage, which has been identified as the most dominant factor for the invalidation of remote sensing images. To overcome this uncertainty, uncertainty programming methods, namely, chance constraint programming (CCP), stochastic expectation model, and robust optimization, are put forth. Despite their success, these approaches are limited in that they simplified the complex cloud coverage uncertainty, which may be different from the true cloud conditions, and they did not take the true cloud information into consideration. Motivated by these recent trends toward Big Data of satellite cloud images and machine learning for spatiotemporal prediction, this article explores a dynamic replanning scheme for multiple EOSs based on cloud forecasting. Specifically, we propose a new approach mainly in the following three steps: first, proactive scheduling based on a CCP is implemented and uploaded via ground control; second, cloud forecasting can be continuously conducted relying on the predictive recurrent neural network and the latest satellite cloud image; and third, mission replanning can be conducted according to the initial schedule and relatively accurate cloud information. Simulation results show that the cloud forecasting method is effective, and the replanning approach presents highly efficient and accurate scheduling results.","2151-1535","","10.1109/JSTARS.2021.3135529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652077","Agile Earth observation satellite (AEOS);artificial neural network;cloud forecasting;mission replanning;uncertainty programming","Clouds;Planning;Uncertainty;Forecasting;Satellites;Earth Observing System;Earth","artificial satellites;clouds;constraint handling;geophysical image processing;learning (artificial intelligence);optimisation;path planning;planning;recurrent neural nets;remote sensing;scheduling;stochastic processes","multiple agile Earth observation satellites;mission planning;optical sensors;remote sensing images;uncertainty programming methods;CCP;stochastic expectation model;complex cloud coverage uncertainty;satellite cloud images;dynamic replanning scheme;multiple EOSs;latest satellite cloud image;cloud forecasting method;replanning approach","","6","","48","CCBY","15 Dec 2021","","","IEEE","IEEE Journals"
"Gear: Enable Efficient Container Storage and Deployment with a New Image Format","H. Fan; S. Bian; S. Wu; S. Jiang; S. Ibrahim; H. Jin","National Engineering Research Center for Big Data Technology and System; National Engineering Research Center for Big Data Technology and System; National Engineering Research Center for Big Data Technology and System; Department of Computer Science and Engineering, University of Texas at Arlington, U.S; Inria, Univ. Rennes, CNRS, IRISA, France; National Engineering Research Center for Big Data Technology and System","2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)","4 Oct 2021","2021","","","115","125","Containers have been widely used in various cloud platforms as they enable agile and elastic application deployment through their process-based virtualization and layered image system. However, different layers of a container image may contain substantial duplicate and unnecessary data, which slows down its deployment due to long image downloading time and increased burden on the image registry. To accelerate the deployment and reduce the size of the registry, we propose a new image format, named Gear image, that consists of two parts: a Gear index describing the structure of the image's file system and a set of files that are required when running an application. The Gear index is represented as a single-layer image compatible with the existing deployment framework. Containers can be launched by pulling a Gear index and on demand retrieving files pointed to by the index. Furthermore, the Gear image enables a file-level sharing mechanism, which helps remove duplicate data in the registry and avoid repeated downloading of identical files by a client. We implement a prototype of the container framework, named Gear, supporting the new image format. Evaluation shows that Gear saves 54 % storage capacity in the registry, speeds up container startup by up to ${5\times}$, and reduces 84 % bandwidth demands.","2575-8411","978-1-6654-4513-9","10.1109/ICDCS51616.2021.00020","National Key Research and Development Program(grant numbers:2018YFB1003600); National Science Foundation of China(grant numbers:62032008,61872155); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546503","container;image format;deployment time;registry","Cloud computing;Gears;File systems;Conferences;Prototypes;Bandwidth;Containers","cloud computing;image retrieval;peer-to-peer computing;storage management;virtualisation","bandwidth demand;storage capacity;image file system;cloud platform;Gear image;on demand file retrieval;image downloading time;image registry;container image;layered image system;process-based virtualization;elastic application deployment;agile application deployment;container storage;container startup;image format;file-level sharing mechanism;deployment framework;single-layer image;Gear index","","3","","38","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"A Simulator and Compiler Framework for Agile Hardware-Software Co-design Evaluation and Exploration","T. Sorensen; A. Manocha; E. Tureci; M. Orenes-Vera; J. L. Aragón; M. Martonosi","UC, Santa Cruz; Princeton University; Princeton University; Princeton University; Universidad de Murcia; Princeton University","2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD)","25 Nov 2020","2020","","","1","9","As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and hardware-software co-design. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support heterogeneous combinations of general-purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we describe our compiler and simulator pair: DEC++ and MosaicSim. Together, they provide a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. The simulator and corresponding compiler were developed as part of the DECADES project, a multi-team effort to design and tape out a new heterogeneous architecture. We will present two case-studies in important data-science applications where DEC++ and MosaicSim enable straightforward design space explorations for emerging full-stack systems.","1558-2434","978-1-6654-2324-3","","DARPA SDH Program(grant numbers:FA8650-18-2-7862); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256600","performance modeling;heterogeneous systems;hardware-software co-design. LLVM simulation","Kernel;Computer architecture;Python;Programming;Transistors;Market research;Space exploration","hardware-software codesign;multiprocessing systems;parallel processing;performance evaluation;program compilers;software prototyping","modular simulator;hardware-software co-design explorations;compiler;straightforward design space explorations;agile hardware-software;Moore's Law;dennard scaling;heterogeneous parallelism;simulation-based performance assessments;architectural exploration;agile exploration;simulator pair;DECADES project;programming model","","","","34","","25 Nov 2020","","","IEEE","IEEE Conferences"
"Reinforcement Learning-Based and Parametric Production-Maintenance Control Policies for a Deteriorating Manufacturing System","A. S. Xanthopoulos; A. Kiatipis; D. E. Koulouriotis; S. Stieger","Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; Fujitsu Technology Solutions GmbH, Munich, Germany; Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; Fujitsu Technology Solutions GmbH, Munich, Germany","IEEE Access","14 Feb 2018","2018","6","","576","588","The model of a stochastic production/inventory system that is subject to deterioration failures is developed and examined in this paper. Customer interarrival times are assumed to be random and backorders are allowed. The system experiences a number of deterioration stages before it ultimately fails and is rendered inoperable. Repair and maintenance activities restore the system to its initial and previous deterioration state, respectively. The duration of both repair and maintenance is assumed to be stochastic. We address the problem of minimizing the expected sum of two conflicting objective functions: the average inventory level and the average number of backorders. The solution to this problem consists of finding the optimal tradeoff between maintaining a high service level and carrying as low inventory as possible. The primary goal of this research is to obtain optimal or near-optimal joint production/maintenance control policies, by means of a novel reinforcement learning-based approach. Furthermore, we examine parametric production and maintenance policies that are often used in practical situations, namely, Kanban, (s, S), threshold-type condition based maintenance and periodic maintenance. The proposed approach is compared with the parametric policies in an extensive series of simulation experiments and it is found to clearly outperform them in all cases. Based on the numerical results obtained by the experiments, the behavior of the parametric policies as well as the structure of the control policies derived by the Reinforcement Learning-based approach is investigated.","2169-3536","","10.1109/ACCESS.2017.2771827","BigStorage: Storage-Based Convergence Between HPC and Cloud to Handle Big Data project from the European Union through the Marie Skłodowska-Curie Actions framework(grant numbers:H2020-MSCA-ITN-2014-642963); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114172","Inventory control;preventive maintenance;reinforcement learning;intelligent manufacturing systems","Maintenance engineering;Production facilities;Stochastic processes;Learning (artificial intelligence);Electronic mail;Optimization","kanban;learning (artificial intelligence);manufacturing systems;Markov processes;optimisation;preventive maintenance;stock control","backorders;periodic maintenance;novel reinforcement learning-based approach;manufacturing systems;stochastic production;repair activities;inventory system;Kanban policy;threshold-type condition based maintenance;optimisation;Markov processes;preventive maintenance;customer interarrival times;deterioration failures;parametric production-maintenance control policies","","44","","29","OAPA","17 Nov 2017","","","IEEE","IEEE Journals"
"Energy-Efficient Resource Allocation with Flexible Frame Structure for Heterogeneous Services","W. Sui; X. Chen; S. Zhang; Z. Jiang; S. Xu","Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Shanghai Institute for Advanced Communication and Data Science","2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)","21 Oct 2019","2019","","","749","755","The key objective of the fifth generation (5G) wireless technology is to support services with vastly variable requirements, which necessitates the flexible numerology and frame structure for radio resource allocation. In this paper, flexible 2-dimensional resource allocation is investigated to maximize the energy efficiency (EE) for service transmissions with heterogeneous latency requirements. Exploiting the frequency and time diversities of the resource grid, frequency-selective resource allocation, together with an agile ""on-off"" operation of the power amplifier (PA) are performed by the proposed sliding window-based (SW) algorithm with scalability. Simulation results further demonstrate that the SW algorithm can achieve similar EE performance as the exhaustive method with a substantially lower complexity.","","978-1-7281-2980-8","10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8875273","Flexible numerology, flexible frame structure, heterogeneous services, energy efficiency, resource allocation","Resource management;5G mobile communication;Time-frequency analysis;Frequency diversity;Radio spectrum management;OFDM","5G mobile communication;energy conservation;resource allocation;telecommunication power management","heterogeneous services;fifth generation wireless technology;radio resource allocation;2-dimensional resource allocation;resource grid;frequency-selective resource allocation;sliding window-based algorithm;energy-efficient resource allocation;flexible frame structure;5G wireless technology","","10","","20","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Evaluation of stochastic bounds on the remaining completion time of products in a buffered sequential workflow","M. Biagi; L. Carnevali; K. Tadano; E. Vicario","Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering, University of Florence, Florence, Italy; Data Science Research Labs NEC Corporation, Kawasaki, Japan; Department of Information Engineering, University of Florence, Florence, Italy","2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)","25 Oct 2018","2018","1","","456","463","Agile production systems face major issues in satisfying fickle market needs in highly demand-driven industry sectors, such as electronics and mechatronics. In this context, the time needed to complete the production of an item tends to be highly variable, and online estimation of the remaining completion time may suffer the lack of adequate sensor data, especially in existing manufacturing systems. To solve this issue, we propose a new analytical technique for the evaluation of an upper and a lower stochastic bound on the remaining completion time of a product, considering an assembly line made of sequential workstations with transfer blocking and buffer capacity. The approach notably encompasses service times with non-Markovian distribution, and avoids the limitation of existing works requiring the system to be at steady state at the inspection time. The technique is experimented on a case study and validated through simulation, providing an empirical analysis of its complexity.","1946-0759","978-1-5386-7108-5","10.1109/ETFA.2018.8502542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502542","Assembly lines;inspection;stochastic bounds;remaining completion time;non-Markovian durations","Workstations;Inspection;Wireless sensor networks;Stochastic processes;Steady-state;Manufacturing systems","agile manufacturing;optimisation;production control;stochastic processes","stochastic bounds;remaining completion time;buffered sequential workflow;agile production systems;demand-driven industry sectors;inspection time;assembly line;sequential workstations;non-Markovian distribution","","1","","28","IEEE","25 Oct 2018","","","IEEE","IEEE Conferences"
"Agile Approach on the Performance Prediction of ARM TrustZone-based Mandatory Access Control Security Enhancement","Z. Li; Y. Ding; X. Chen; P. Dong; C. Huang; L. Song; P. Wang","School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China; School of Computer Science National University of Defence Technology, Changsha, China","2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","22 Dec 2021","2021","","","1083","1090","Mandatory Access Control (MAC) is one of the most important security mechanisms of Linux, but it may be threatened by vulnerabilities in kernel space. Currently, the ARM TrustZone-based MAC (TZ-MAC) security enhancement method has been proposed to protect the key security function of MAC with the hardware-based trusted execution environment. However, given that each call to the hook set of the TZ-MAC security modules will cause switching between the normal and secure worlds of ARM TrustZone, the specific design of the TZ-MAC framework will substantially affect system performance, and may even be considerably slow to prevent the security module from being applied. Therefore, when researchers design a security module, they need an agile method to predict the performance cost brought by the hook set realized, to assist the optimization of the design scheme and improve system performance. This study presents a performance prediction method of TZ-MAC based on the statistical analysis of the Linux Security Modules (LSM) hook calls. This method is universal for different TZ-MAC frameworks, security modules, and benchmarks. Moreover, the proposed method can predict only the performance based on the security module design of TZ-MAC, and the implementation of the module is not needed. An agile approach of performance prediction for TZ-MAC is conducted based on the performance prediction method. For two different TZ-MAC implementation ideas, we constructed prediction data sets based on the classic benchmarks, namely, LMbench and UnixBench, and verified the effectiveness of our method. The tests based on the security module SELinux show that over 50% of the overhead is caused by 3% of the LSM hook functions, which indicates the direction for future optimization.","","978-1-6654-3574-1","10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00150","National Natural Science Foundation of China; Key Technologies Research and Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644816","Performance Evaluation;TrustZone;Mandatory Access Control","Access control;Costs;Statistical analysis;System performance;Linux;Prediction methods;Switches","authorisation;Linux;statistical analysis;trusted computing","ARM TrustZone-based MAC security enhancement method;key security function;TZ-MAC security modules;Linux security modules;prediction data sets;SELinux;ARM TrustZone-based mandatory access control security enhancement;hardware-based trusted execution","","","","21","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Sidelobe Coherency Recovery Technique of Interpulse Diversity based on Inverse Filtering","Q. Ge; D. Zhao; Y. Yao; G. Wu","Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China; Nanjing Research Institute of Electronic Technology, Nanjing, China","2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)","14 Dec 2020","2020","1","","185","189","Transmitting the pulse-to-pulse agile waveforms will break up the sidelobe coherency of impulse responses, which makes the static clutter fail to be completely suppressed, and has a negative impact on radar detection. In this paper, inspired by inverse filtering, we propose an effective method for designing pulse-compression filters that recover the sidelobe coherency of the agile waveforms. By selecting an appropriate window function in the frequency-domain, the impulse responses can be all identical while achieving marked sidelobe level improvement. Furthermore, we analyse the echoes of targets with different speeds and point out the situation which would happen in modern radar application. Simulations are conducted to verify the effectiveness of this method.","","978-1-7281-5224-0","10.1109/ICIBA50161.2020.9277065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277065","interpulse diversity;inverse filtering;sidelobe coherency recovery;low sidelobe level;clutter suppression","Frequency-domain analysis;Radar clutter;Radar detection;Object detection;Information filters;Clutter;Information technology","filtering theory;object detection;pulse compression;radar detection;radar signal processing","sidelobe level improvement;sidelobe coherency recovery technique;interpulse diversity;inverse filtering;pulse-to-pulse agile waveforms;impulse responses;static clutter;radar detection;pulse-compression filters;appropriate window function","","","","11","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"SymPlot: A Web-Tool to Visualise Symbolic Musical Data","P. Muñoz-Lago; A. Llorens; E. Parada-Cabaleiro; Á. Torrente","Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain; Instituto Complutense de Ciencias Musicales (ICCMU), Universidad Complutense de Madrid, Spain","2020 24th International Conference Information Visualisation (IV)","11 Mar 2021","2020","","","537","543","Some complex musical parameters might be especially difficult to understand for someone with no theoretical expertise in music. Musicians and music scholars alike normally evaluate such parameters visually by departing from scores, which present the musical events at once. Yet for the under-standing of such symbolic representations, musical training is essential, making scores mostly incomprehensible for amateurs. Data visualisation has been applied to meaningfully represent complex musical parameters, thus enabling music amateurs to grasp concepts such as texture or structure. Although scores are one of the ""primary"" sources to understand music, previous work shows a strong bias towards the visualisation of acoustic data, in detriment of the visualisation of symbolic information. To bridge the gap, we present SymPlot, a web-based open source tool to automatically visualise textural density, scoring, and structure from MusicXML files. Due to the multidisciplinary nature of the topic, in this project we have applied the Scrum's agile methodology, an iterative incremental approach specifically tailored for interdisciplinary projects. The tool, aimed at enhancing musical understanding in amateurs and students, as well as in scholars of other disciplines who need to incorporate music into their discourses, i.e., historians, philologists, etc., enables visualisation of local features at various hierarchical levels, highlighting similarities both within and across scores. Our evaluation of SymPlot-based on a five-level rating-scale test performed by 50 participants-suggests that colours increase users' understanding of complex musical parameters.","2375-0138","978-1-7281-9134-8","10.1109/IV51561.2020.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373167","visualisation;music;data science;digital humanities;score;computational musicology;symbolic music data","Training;Image color analysis;Data visualization;Music;Tools;Iterative methods","data visualisation;Internet;music","visualise symbolic musical data;complex musical parameters;musical events;musical training;data visualisation;music amateurs;Web-based open source tool;MusicXML files;Scrum's agile methodology;iterative incremental approach;five-level rating-scale test","","","","35","IEEE","11 Mar 2021","","","IEEE","IEEE Conferences"
"Design and Implementation of Operating Management Platform of Dispatching and Control Cloud Application based on Container Technology","X. Ma; Q. Yang; L. Tao; Y. Huang; P. Zhang; Z. Zhang","Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China; State Grid Jibei Electric Power Company, Beijing, China; Beijing Key Lab of Research and System Evaluation of Power Dispatching Automation Technology (China Electric Power Research Institute), Beijing, China","2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)","14 Dec 2020","2020","1","","898","902","With the development of dispatching and control cloud platform, the existing virtual resource management mechanism has been unable to meet the requirements of rapid construction, agile delivery and convenient management of applications. The emergence of container technology provides a good solution. Combined with the Docker technology and the requirements of application lifecycle management, this paper proposes an operating management platform of dispatching and control cloud application based on container technology, introduces the overall architecture of the platform, designs and implements function modules including image management, application management and resource scheduling. With the platform designed in this paper, applications can realize the rapid construction, efficient deployment and convenient management, meet the requirements of flexible elastic expansion and directional scheduling, generally provide strong support for the development and use of the dispatching and control cloud platform.","","978-1-7281-5224-0","10.1109/ICIBA50161.2020.9276832","State Grid Corporation of China(grant numbers:5442DZ190011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276832","Docker technology;application management;resource scheduling;dispatching and control cloud","Servers;Dispatching;Containers;Cloud computing;Production;Databases;User interfaces","cloud computing;formal specification;resource allocation;scheduling;virtualisation","agile delivery;resource scheduling;operating management platform;application lifecycle management;Docker technology;virtual resource management;container technology;control cloud application","","","","6","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Development of Ship Detection Using OPENCV YOLO Method on Unmanned Prototype Boat for Monitoring National Sea","A. P. W. Aldryani; H. Tjahjadi; I. A. Dahlan; I. Kholis; R. Istoni; A. F. Bangun; A. C. Tambunan; J. K. S. Pigome","Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Lecturer of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Electrical Engineering, University of Indonesia, Depok, Indonesia; Electrical Engineering, Technical University of Malaysia Melaka, Melaka, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia; Sergenat Cadet of Military Electrical Engineering, Republic of Indonesia Defense University, Bogor, Indonesia","2022 7th International Workshop on Big Data and Information Security (IWBIS)","25 Oct 2022","2022","","","7","12","Indonesia is a vast archipelago and a large sea area. Quoting from the Preamble of the 1945 Constitution states that the purpose of the Government of the Republic of Indonesia is to protect the entire Indonesian nation and its homeland. Therefore, defensive aspects need to be taken into special account. The Sea Defense System requires an agile unmanned mini-sea boat maneuvering capability which is able to secure the sea area according to its function and detect foreign ships. Indonesia needs to be more vigilant and detect its underwater defenses so that intruders do not attempt to violate the sovereignty of the Republic of Indonesia. This research is intended as a solution by designing a mini marine prototype to protect and strengthen Indonesian sea border. The system is developed using OpenCV and YOLO (You Only Look Once) method to detect ship. It is developed on an laptop which run on Linux. This research yields the results of the ship detection system by percentage of precision confidence level range 54–96% and several factors of undetectable condition, namely camouflaged ship, half body of ship image, and sunset condition.","","978-1-6654-8950-8","10.1109/IWBIS56557.2022.9924891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924891","unmanned;mini sea-boat;prototype;detection;sea","Portable computers;Linux;Conferences;Government;Prototypes;Boats;Information security","boats;remotely operated vehicles;ships","agile unmanned mini-sea boat maneuvering capability;sea area;foreign ships;underwater defenses;Republic of Indonesia;mini marine prototype;Indonesian sea border;ship detection system;ship image;OPENCV YOLO method;unmanned prototype boat;1945 Constitution states;Indonesian nation;defensive aspects;Sea Defense System;national sea monitoring;You Only Look Once method","","","","10","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"Interplay of Machine Learning and Software Engineering for Quality Estimations","H. Abubakar; M. S. Obaidat; A. Gupta; P. Bhattacharya; S. Tanwar","Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; College of Computing and Informatics, University of Sharjah, Sharjah 27272, UAE, King Abdullah II School of Information Technology, University of Jordan, Amman 11942, Jordan, University of Science and Technology Beijing, Beijing, China; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India","2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)","18 Nov 2020","2020","","","1","6","In this era, the agile mindset has innovated the traditional software engineering (SE) process through the integration of DevOps flow engines, scrum iterations, and automation of continuous integration (CI) and continuous deployment (CD) cycles. However, the CI/CD integration requires manual code-revisions and refactoring at large scales. Recently, machine-learning (ML) is employed in SE that allows legacy codes to be highly dynamic, less coupling in related modules, automatic code versioning, and refactoring, with less coupling among related modules. However, over time, ML models tend to become bulky, with increasing monotonic losses during model training. To address this, SE techniques like code revisions are employed over ML codes to allow low-order training losses, that enables seamless and precise workflow structures. Motivated from the aforementioned discussions, the paper presents a systematic review of the close interplay of SE and ML and possible interactions in different applications. Suitable research questions and case studies are presented for possible adoption scenarios that depict the close ML-SE interplay share with each other, with the concluding remarks. The paper forms useful insights for ML engineers, data science practitioners, and SE quality estimators towards the building of efficient and scalable software solutions.","","978-1-7281-7315-3","10.1109/CCCI49893.2020.9256507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256507","Machine learning;Software Engineering;Effort estimation;Quality estimation","Software;Maximum likelihood estimation;Data models;Software algorithms;Training;Task analysis;Mathematical model","data analysis;learning (artificial intelligence);software development management;software maintenance;software prototyping;workflow management software","legacy codes;related modules;automatic code versioning;refactoring;ML models;monotonic losses;model training;SE techniques;code revisions;ML codes;low-order training losses;ML-SE interplay share;ML engineers;SE quality estimators;efficient software solutions;scalable software solutions;machine learning;quality estimations;agile mindset;traditional software engineering process;DevOps flow engines;scrum iterations;manual code-revisions;machine-learning;data science practitioners","","1","","23","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Management Consulting Business Models: Operations through and for Digital Transformation","C. Jerónimo; L. Pereira; H. Sousa","BRU-IUL, ISCTE Business School, Lisboa, Portugal; BRU-IUL, ISCTE Business School, Lisboa, Portugal; BRU-IUL, ISCTE Business School, Lisboa, Portugal","2019 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)","12 Aug 2019","2019","","","1","6","Management consulting as a service has become part of almost every company’s daily business. The growth is being exponential, even with all the non-consensual issues and controversies in the industry. However, the market is increasingly competitive, with new competitors coming from everywhere. At the same time, the world is changing at a speed never seen before, and the challenges are several: automatization, scarcity of resources, democratization of the information, big data, and regulation are some examples. Thus, it’s not possible for consulting firms to keep providing the market needs without adapting continuously their own business models. The companies that can outperform these challenges more efficiently will win against the competitors. Investigate which strategies and mechanisms adopt to be agile and flexible enough, in which sectors invest the most, and how reinvent their business model in order to be resilient in a fast changing and technological world are the main objectives of this research. Several interviews with the top management of fifteen of the biggest consulting companies in Portugal were conducted. The results suggested that companies are now trying to differentiate by the services delivered, and these business models’ adaptation to the digital transformation is rather than a reality, a need.","","978-1-7281-3401-7","10.1109/ICE.2019.8792592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792592","Management Consulting;Digital Transformation;Business Models","Industries;Companies;Interviews;Technological innovation;Adaptation models;Big Data","Big Data;business data processing;consultancies;marketing","digital transformation;consulting companies;management consulting business models;big data;market needs","","","","19","IEEE","12 Aug 2019","","","IEEE","IEEE Conferences"
"Energy Efficient Double Critic Deep Deterministic Policy Gradient Framework for Fog Computing","B. Krishnamurthy; S. G. Shiva","Department of Computer Science, Siddaganga Institute of Technology, Tumakuru, Karnataka, India; Department of Computer Science, University of Memphis, Memphis, Tennessee, USA","2022 IEEE World AI IoT Congress (AIIoT)","13 Jul 2022","2022","","","521","527","-Nowadays the data is growing at a faster pace and the big data applications are required to be more agile and flexible. There is a need for a decentralized model to carry out the required substantial amount of computation across edge devices as they has led to the innovation of fog computing. Energy consumption among the edge devices is one of the potential threatening issues in fog computing. Their high energy demand also contributes to higher computation cost. In this paper Double Critic (DC) approach is enforced over the Deep Deterministic Policy Gradient (DDPG) technique to design the DC-DDPG framework which formulates high quality energy efficiency policies for fog computing. The performance of the proposed framework is outstanding compared to existing works based on the metrics like energy consumption, response time, total cost, and throughput. They are measured under two different fog computing scenarios i.e., fog layer with multiple entities in a region and fog layer with multiple entities in multiple regions. Mathematical modeling reveals that the energy efficiency policies formulated are of high quality as they satisfy the quality assurance metrics, such as empirical correctness, robustness, model relevance, and data privacy.","","978-1-6654-8453-4","10.1109/AIIoT54504.2022.9817157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817157","Deterministic Policy Gradient;Fog computing;Energy;Q-learning;Double Critic","Measurement;Energy consumption;Costs;Computational modeling;Throughput;Energy efficiency;Data models","Big Data;cloud computing;deep learning (artificial intelligence);energy conservation;energy consumption;gradient methods;power aware computing;software quality","Big Data;edge devices;energy consumption;energy efficiency double critic deep deterministic policy gradient;fog computing;DC-DDPG;mathematical modeling;quality assurance metrics","","","","18","IEEE","13 Jul 2022","","","IEEE","IEEE Conferences"
"ACT Testbot and 4S Quality Metrics in XAAS Framework","D. Chhillar; K. Sharma","Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India; Department of Computer Science and Engineering, Bhagwant University, Ajmer, Rajasthan, India","2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)","11 Oct 2019","2019","","","503","509","The purpose of this paper is to analyze all Cloud based Service Models, Continuous Integration, Deployment and Delivery process and propose an Automated Continuous Testing and testing as a service based TestBot and metrics dashboard which will be integrated with all existing automation, bug logging, build management, configuration and test management tools. Recently cloud is being used by organizations to save time, money and efforts required to setup and maintain infrastructure and platform. Continuous Integration and Delivery is in practice nowadays within Agile methodology to give capability of multiple software releases on daily basis and ensuring all the development, test and Production environments could be synched up quickly. In such an agile environment there is need to ramp up testing tools and processes so that overall regression testing including functional, performance and security testing could be done along with build deployments at real time. To support this phenomenon, we researched on Continuous Testing and worked with industry professionals who are involved in architecting, developing and testing the software products. A lot of research has been done towards automating software testing so that testing of software product could be done quickly and overall testing process could be optimized. As part of this paper we have proposed ACT TestBot tool, metrics dashboard and coined 4S quality metrics term to quantify quality of the software product. ACT testbot and metrics dashboard will be integrated with Continuous Integration tools, Bug reporting tools, test management tools and Data Analytics tools to trigger automation scripts, continuously analyze application logs, open defects automatically and generate metrics reports. Defect pattern report will be created to support root cause analysis and to take preventive action.","","978-1-7281-0211-5","10.1109/COMITCon.2019.8862212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862212","Cloud;ACT (Automated Continuous Testing);TestBot;Continuous Testing;Continuous Integration;Continuous Delivery;Continuous Deployment;XaaS (Everything as a Service);T-Model;Auto Bug Logging and Tracking;4S Quality Metrics","Testing;Tools;Cloud computing;Security;Computer bugs;Software as a service","automatic testing;cloud computing;data analysis;program debugging;program testing;security of data;software metrics;software prototyping;software quality","automation scripts;metrics reports;XAAS framework;metrics dashboard;bug logging;test management tools;agile environment;testing tools;regression testing;security testing;software product;testing process;ACT TestBot tool;data analytics tools;service models;agile methodology;software testing;continuous integration tools;automated continuous testing;bug reporting tools;4S quality metrics;cloud based service models;testing as a service","","","","18","IEEE","11 Oct 2019","","","IEEE","IEEE Conferences"
"Best Practices for Engineering AI-Infused Applications: Lessons Learned from Microsoft Teams","A. Begel","Microsoft Research, Redmond, WA, USA","2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)","26 Sep 2019","2019","","","1","1","Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML.","2575-4793","978-1-7281-2264-9","10.1109/CESSER-IP.2019.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836177","AI, Machine Learning, Industry Practice","Industries;Software engineering;Software;Conferences;Machine learning;Organizations","DP industry;learning (artificial intelligence);software development management;software engineering","early AI applications;machine learning;software industry;Microsoft software teams;nine-stage AI workflow process;AI/ML-based applications;data science tools;agile-like software engineering processes;AI-infused applications","","3","","0","IEEE","26 Sep 2019","","","IEEE","IEEE Conferences"
"Transitioning from Legacy Air Traffic Management to Airspace Management through Secure, Cloud-Native Automation Solutions","A. Solomon; Z. Crawford","Digital Aviation Solutions Thales, Arlington, VA, USA; Digital Aviation Solutions Thales, Arlington, VA, USA","2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)","15 Nov 2021","2021","","","1","8","Advancements in Cloud-native services, Machine-Learning (ML), Artificial Intelligence (AI), and Rapid Application Development (RAD) using the Agile methodology has led countless industries to achieving desirable levels of automation while reducing cost and improving quality software deployments, timely / iterative delivery, and accountability. Coupling this framework with the principle of security as a shared responsibility further enhances the efficacy of an integrated Development, Security, and Operations (DevSecOps) Team within organizations to deliver secured digital solutions. Air Navigation Service Providers (ANSPs) around the world are currently exploring and embracing the digital evolution shifting from monolithic, legacy automation platforms to an application framework of microservices to allow for flexible operations as capabilities and airspace operations evolve. Specific to the US, the ATM automation system of today is comprised of both safety and non-safety critical systems, with mission-essential, efficiency-critical, and mission-support services that are predominately maintained and evolved through multi-year, one contractor-led programs. Although the system has proven resilient, it has not proven to be agile and flexible to allow for advances in capabilities on-board aircraft or in the data integration and sharing with other NAS automation systems. This creates significant overhead in development, sustainability, and operations of the current automation system, and leaves modernization efforts—in terms of new capabilities—in constant investment decision planning cycles, costing agencies not just money, but more time to innovate. To advance aviation into a new generation of interoperability leveraging collaborative frameworks and application specific capabilities, ANSPs must adapt to innovative methods to collect, process, and deliver critical and essential aeronautical, weather, and flight information to air traffic control operators and ultimately to airspace users. Doing so can not only lead to sustaining NAS automation systems while reducing the costs to develop and operate these systems, but it also provides an opportunity to present strategies on how to dramatically reduce the time and integration efforts needed to deploy new capabilities. Leveraging cloud-native technologies and services is a way to realize this automation evolution vision for ANSPs.This paper examines the migration from today’s systems to secure, cloud-native platforms to prove that Mission Services and Mission Applications can be rapidly available / deployable to operators who provide separation and flow management services, using a cyber-secured cloud-native environment. Aeronautical data typically used for tactical decision making is now seen as crucial to the decision-making process in Air Traffic Management (ATM). Integrating global and localized datasets into a digital aviation data platform enhances the capabilities of the solutions and opens the possibilities of leveraging big data analytics and microservices to compute trajectory predictions (TP), demand capacity balancing (DCB), arrival and departure sequencing, airspace delay, among others, in real-time to achieve operator-driven mission objectives. Technology has reached a state of maturity, especially in cloud and hybrid cloud solutions, to support safety of life operations, like ATM. This paper identifies approaches that are being considered for that migration to support the integration of new airspace entrants, the use of application services to provide a dynamic, evolutionary ATM platform, and addresses some of the safety and security strategies that must be considered for this evolution.","2155-7209","978-1-6654-3420-1","10.1109/DASC52595.2021.9594313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594313","Automation;ATM;Cloud-native;Microservices","Automation;Costs;Online banking;Clouds;Safety;Stakeholders;Security","aerospace computing;air traffic control;aircraft navigation;Big Data;cloud computing;data analysis;decision making;learning (artificial intelligence);open systems","airspace management;cloud-native services;machine learning;artificial intelligence;rapid application development;agile methodology;air navigation service providers;monolithic automation platforms;legacy automation platforms;airspace operations;ATM automation system;mission-support services;data integration;innovative methods;air traffic control operators;airspace users;integration efforts;cloud-native technologies;cloud-native platforms;mission applications;flow management services;cyber-secured cloud-native environment;aeronautical data;tactical decision making;digital aviation data platform;big data analytics;airspace delay;operator-driven mission objectives;hybrid cloud solutions;airspace entrants;application services;ATM platform;mission services;NAS automation systems;quality software deployments;cloud-native automation solutions;legacy air traffic management","","","","7","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"Generalized Linear Optical Sampling Technique Realized by Using Non-Pulse Electro-Optic Frequency Comb Sampling Source","B. Xu; X. Fan; S. Wang; Z. He","Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, State Key Laboratory of Advanced Optical Communication Systems and Networks, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai, China","IEEE Access","29 Jun 2020","2020","8","","114259","114265","We propose a novel generalized linear optical sampling (GLOS) technique realized by using an electro-optic frequency comb (EOFC) as the sampling signal. GLOS technique is demonstrated as a bandwidth compression process in frequency domain instead of gating effect in time domain. An EOFC without the limitation to be ultra-short pulse serves as sampling signal is pre-measured. In experiments, the waveforms are sampled by an EOFC with agile repetition rates and bandwidths. After a demodulation process with pre-measured information, the original signal under test in both intensity and phase fields can be recovered. The results obtained from the proposed method are consistent with those from traditional linear optical sampling technique. Besides, with a high average mode power, EOFC-based GLOS technique realizes more than 10 dB SNR improvement and has ability to detect weak signal with a power of -47.3 dBm. Our demonstration opens the way for cost-effective comb sources to be used in optical sampling fields.","2169-3536","","10.1109/ACCESS.2020.3003780","National Natural Science Foundation of China (NSFC)(grant numbers:61775132,61735015,61620106015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121264","Linear optical sampling;electro-optic frequency comb;repetition rate agility;SNR improvement","Optical pulses;Bandwidth;Optical signal processing;Frequency-domain analysis;Time-domain analysis;Interference;Optical modulation","demodulation;frequency-domain analysis;optical modulation;signal detection;signal sampling;time-domain analysis","nonpulse electrooptic frequency comb sampling source;sampling signal;bandwidth compression process;frequency domain;time domain;ultra-short pulse;premeasured information;EOFC-based GLOS technique;cost-effective comb sources;optical sampling fields;generalized linear optical sampling technique;demodulation process","","4","","33","CCBY","19 Jun 2020","","","IEEE","IEEE Journals"
"Diaspore: Diagnosing Performance Interference in Apache Spark","S. Shah; Y. Amannejad; D. Krishnamurthy","Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada; Mathematics and Computing Department, Mount Royal University, Calgary, AB, Canada; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada","IEEE Access","27 Jul 2021","2021","9","","103230","103243","Apache Spark is being increasingly used to execute big data applications on cluster computing platforms. To increase system utilization, cluster operators often configure their clusters such that multiple co-located applications can simultaneously share the resources of a cluster node. With resource sharing, applications can compete with each other for shared node resources thereby interfering with each other's performance. Many Spark applications take a long time to execute. Performance interference from other applications can thus cause a Spark application to fail or take even longer time to execute thereby wasting cluster resources and frustrating users. This motivates the need for an automated technique that can detect interference quickly and also diagnose the root cause of the interference to facilitate mitigation of the problem. Most existing approaches are not designed to offer quick interference detection and diagnosis. For example, they typically require extensive training data for every application of interest under various possible input data sizes and resource allocations. In this paper, we systematically investigate the design of a Machine Learning (ML) based technique that addresses this open problem. We implement a tool called Diaspore that integrates our findings. We evaluate the tool with a diverse set of 13 Spark applications executing on a real cluster. Experimental results show that Diaspore requires only small scale training data, i.e., executions under small input sizes and resource allocations. Furthermore, our results show that the tool can offer accurate predictions for applications not present in the training data. Consequently, Diaspore reduces the training time needed to offer predictions. Finally, the feature engineering underlying Diaspore ensures that the tool can detect and diagnose interference quickly in an online manner by sampling only a small fraction of a long running application's execution. This can allow cluster operators to mitigate interference in an agile manner.","2169-3536","","10.1109/ACCESS.2021.3098426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490641","Interference detection;big data;machine learning","Interference;Sparks;Task analysis;Measurement;Training;Resource management;Training data","Big Data;cluster computing;learning (artificial intelligence);resource allocation","Diaspore;cluster operators;Apache Spark;cluster computing platforms;co-located applications;cluster node;resource sharing;shared node resources;Spark application;cluster resources;frustrating users;quick interference detection;extensive training data;possible input data sizes;resource allocations;scale training data;performance interference diagnosis;Big Data applications;machine learning","","","","33","CCBYNCND","19 Jul 2021","","","IEEE","IEEE Journals"
"DeepCP: Deep Learning Driven Cascade Prediction-Based Autonomous Content Placement in Closed Social Network","Q. Wu; M. Wu; X. Chen; Z. Zhou; K. He; L. Chen","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Financial Technology, Tencent Inc., Shenzhen, China","IEEE Journal on Selected Areas in Communications","26 Jun 2020","2020","38","7","1570","1583","Online social networks (OSNs) are emerging as the most popular mainstream platform for content cascade diffusion. In order to provide satisfactory quality of experience (QoE) for users in OSNs, much research dedicates to proactive content placement by using the propagation pattern, user's personal profiles and social relationships in open social network scenarios (e.g., Twitter and Weibo). In this paper, we take a new direction of popularity-aware content placement in a closed social network (e.g., WeChat Moment) where user's privacy is highly enhanced. We propose a novel data-driven holistic deep learning framework, namely DeepCP, for joint diffusion-aware cascade prediction and autonomous content placement without utilizing users' personal and social information. We first devise a time-window LSTM model for content popularity prediction and cascade geo-distribution estimation. Accordingly, we further propose a novel autonomous content placement mechanism CP-GAN which adopts the generative adversarial network (GAN) for agile placement decision making to reduce the content access latency and enhance users' QoE. We conduct extensive experiments using cascade diffusion traces in WeChat Moment (WM). Evaluation results corroborate that the proposed DeepCP framework can predict the content popularity with a high accuracy, generate efficient placement decision in a real-time manner, and achieve significant content access latency reduction over existing schemes.","1558-0008","","10.1109/JSAC.2020.2999687","National Science Foundation of China(grant numbers:U1711265,61972432); Fundamental Research Funds for the Central Universities(grant numbers:17lgjc40); Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2017ZT07X355); Pearl River Talent Recruitment Program(grant numbers:2017GC010465); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107092","Social network analysis;cascade prediction;autonomous content placement","Social networking (online);Generative adversarial networks;Gallium nitride;Quality of experience;Prediction algorithms;Optimization;Feature extraction","data privacy;learning (artificial intelligence);recurrent neural nets;social networking (online)","deep learning driven cascade prediction-based autonomous content placement;closed social network;online social networks;OSNs;content cascade diffusion;proactive content placement;open social network scenarios;popularity-aware content placement;joint diffusion-aware cascade prediction;content popularity prediction;generative adversarial network;DeepCP framework;data-driven holistic deep learning framework;autonomous content placement mechanism CP-GAN;time-window LSTM model;cascade geo-distribution estimation","","2","","33","IEEE","3 Jun 2020","","","IEEE","IEEE Journals"
"Digital Inclusion in Nothern England: Training Women from Underrepresented Communities in Tech: A Data Analytics Case Study","O. T. Aduragba; J. Yu; A. I. Cristea; M. Hardey; S. Black","Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK","2020 15th International Conference on Computer Science & Education (ICCSE)","22 Sep 2020","2020","","","162","168","The TechUPWomen programme takes 100 women from the Midlands and North of England, particularly from underrepresented communities, with degrees or experience in any subject area, retrains them in technology and upon graduation guarantees an interview with a company. The retraining programme, developed by the Partner Universities in conjunction with the Industrial Partners, has modules at level 6/7 including: Technology: coding, data science, cyber security, machine learning, agile project management; Workplace readiness skills: public speaking, clear communication, working as a team. In this paper, we introduce, for the first time, the TechUPWomen programme, and we analyse its temporal evolution and special features via a data analytics nowcasting approach. Deepening these women’s experience with applied upskilling includes one-to-one mentoring (100-100), strong networking, residentials, close industry connection with two directions (non-technical & technical) and four job-focussed final tracks: business analyst, agile project manager, data scientist, developer. TechUPWomen also has significant representation of traditionally underrepresented communities, with focus on enabling instead of teaching approach. Beside the originality of the unique combination of features of the programme, this is, to the best of our knowledge, the first analysis based on data analytics of a women in tech(nology) retraining programme, based on nowcasting. Results show that the approach is effective; topic analysis shows that frequent topics include joy, BAME, networking, residential, industry, learning.","2473-9464","978-1-7281-7267-5","10.1109/ICCSE49874.2020.9201693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201693","TechUPWomen;Underrepresented Communities;Digital Inclusion;Data Analytics;Computer Science Education","Twitter;Computer science;Industries;Data analysis;Education;Biological system modeling","computer based training;computer science education;data analysis;educational institutions;gender issues;teaching","Partner Universities;Industrial Partners;data science;cyber security;machine learning;agile project management;Workplace readiness skills;public speaking;TechUPWomen programme;analyse its temporal evolution;agile project manager;digital inclusion;nothern England;data analytics nowcasting;underrepresented communities;women training;business analyst;data scientist;data developer;computer science education","","","","38","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"Automated Robot (Car) using Artificial Intelligence","S. Mishra; C. S. Minh; H. Thi Chuc; T. V. Long; T. T. Nguyen","Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Informatics and Computer Engineering, International School, Vietnam National University, Hanoi, Vietnam; Management and Information System, International School, Vietnam National University, Hanoi, Vietnam; Head, Department of Science and Technology, International School, Vietnam National University, Hanoi, Vietnam","2021 International Seminar on Machine Learning, Optimization, and Data Science (ISMODE)","29 Mar 2022","2022","","","319","324","This paper discusses about researching an automated robot car using artificial intelligence; training its neural network using AlexNet model, using YOLO (you only look once algorithm) for object detection phase and for practical deduction and judging component we have used Open Neural Network Exchange (ONNX) format. Our Robot Car model is agile and cost efficient. It detects objects efficiently in front of it and movement of it is smooth. It moves through sensors in motors which makes it different than other models in the world.","","978-1-6654-0544-7","10.1109/ISMODE53584.2022.9743130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743130","Deep learning;NVIDIA Jetson Nano;ISBot;AlexNet;YOLO (You Only Look Once);Open Neural Network Exchange (ONNX);Convolutional Neural Network (CNN);Stochastic Gradient Descent (SGD);Intersection over Union (IoU)","Training;Seminars;Costs;Neural networks;Object detection;Machine learning;Data science","automobiles;control engineering computing;mobile robots;neural nets;object detection","judging component;Open Neural Network Exchange format;artificial intelligence;automated robot car;AlexNet;object detection phase;ONNX format;you only look once algorithm;YOLO","","","","14","IEEE","29 Mar 2022","","","IEEE","IEEE Conferences"
"Data security compliance management and control technology based on scene orchestration","D. Wang; R. Yang; X. Gao","State Grid Big Data Center, Beijing, China; State Grid Key Laboratory of Information & Network Security, Nanjing, China; State Grid Key Laboratory of Information & Network Security, Nanjing, China","2021 13th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)","23 Apr 2021","2021","","","401","408","The digital economy has entered the fast lane, and data has become a core production factor and a key strategic resource. Data flows to create value, and it also brings various security compliance risks. How to balance the relationship between data “protection” and “utilization” is a difficult problem. This topic is oriented to the security and compliance needs of data used in different business scenarios, and proposes a data process compliance management and control and data security capability agile invocation mechanism based on scenario orchestration technology, and is used in scenarios such as power data analysis, testing, and outsourcing. Application verification has been carried out to effectively realize the integration of business and security capabilities, management and technology integration, and online and offline integration.","2157-1481","978-1-6654-3892-6","10.1109/ICMTMA52658.2021.00093","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410067","scenario orchestration;agile invocation;compliance management and control;integration of business and security","Data analysis;Mechatronics;Data security;Process control;Data protection;Production;Data models","business data processing;data analysis;data protection;formal verification;outsourcing;security of data","control technology;scene orchestration;digital economy;security compliance risks;data protection;data utilization;business scenarios;data process compliance management;power data analysis;technology integration;data security compliance management;data security capability agile invocation mechanism;scenario orchestration;application verification;online integration;offline integration;outsourcing","","","","12","IEEE","23 Apr 2021","","","IEEE","IEEE Conferences"
"BotCensor: Detecting DGA-Based Botnet Using Two-Stage Anomaly Detection","B. Qi; J. Jiang; Z. Shi; R. Mao; Q. Wang","Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN; Institute of Information Engineering Chinese Academy of Sciences, Beijing, Beijing, CN","2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)","6 Sep 2018","2018","","","754","762","Nowadays, most botnets utilize domain generation algorithms (DGAs) to build resilient and agile command and control (C&C) channels. Specifically, botmasters employ DGAs to dynamically produce a large number of random domains and only register a small subset for their actual C&C servers with the purpose to defend them from takeovers and blacklisting attempts. While many approaches and models have been developed to detect DGA-based botnets, they suffer from several limitations, such as difficulties of DNS traffic collection, low feasibility and scalability, and so forth. In this paper, we present BotCensor, a new system that can determine if a host is infected with certain DGA malware with two-stage anomaly detection. In the first stage, we preliminarily attempt to identify malicious domains using a Markov model, and in the second stage, we re-examine the hosts that requested aforementioned malicious domains using novelty detection algorithms. Our experimental results show that our approach performs very well on identifying previously unknown DGA-generated domains and detects DGA bots with high efficiency and efficacy. Our approach not only can be regarded as security forensics tools, but also can be used to prevent malware infections and spread.","2324-9013","978-1-5386-4388-4","10.1109/TrustCom/BigDataSE.2018.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8455977","DGA-based botnet detection, Two-stage anomaly detection, Markov model, Novelty detection algorithms, DNS traffic","Botnet;Anomaly detection;Servers;Markov processes;IP networks;Malware;Security","computer network security;Internet;invasive software;IP networks","BotCensor;two-stage anomaly detection;domain generation algorithms;DGA-based botnets;DNS traffic collection;DGA malware;malicious domains;novelty detection algorithms;DGA bots;DGA-generated domains","","3","2","","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"RTA: an Efficient SIMD Architecture for Ray Tracing","R. Yan; L. Huang; H. Guo; Y. Lü; L. Yang; N. Xiao; L. Shen; Y. Wang","School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; Huawei 2012 Labs, Beijing, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China","2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","28 Mar 2023","2022","","","43","50","In recent years, real-time ray tracing has attracted considerable attention with the increasing demand for photo-realistic graphics and rapid advances in CPUs/GPUs. However, efficient hardware architecture is challenging due to branches and high computation intensity for ray tracing. In this paper, we present a novel ray tracing hardware architecture called RTA (Ray Tracing Accelerator) to improve hardware efficiency. RTA has two key features: 1) an area-efficient T&I pipeline adopts three optimization strategies; 2) the configuration of two Ray Traversal units has the highest ray tracing efficiency. Combined with these, we implement our system at RTL level with agile chip development. Experimental results demonstrate that RTA's performance achieves $2.83\times$ higher than other academic and commercial architectures in a similar area.","","979-8-3503-1993-4","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00040","NSFC(grant numbers:61872374); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074637","computer graphics;hardware architecture;ren-dering;ray tracing","Graphics;High performance computing;Computational modeling;Pipelines;Computer architecture;Ray tracing;Real-time systems","graphics processing units;parallel processing;ray tracing","photo-realistic graphics;ray tracing accelerator;ray traversal units;realtime ray tracing;SIMD architecture","","","","33","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"A Framework for Partitioning Support Vector Machine Models on Edge Architectures","M. Sahi; M. A. Maruf; A. Azim; N. Auluck","Department of Computer Science and Engineering, Indian Institute of Technology, Ropar, India; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Ontario, Canada; Department of Electrical, Computer and Software Engineering, Ontario Tech University, Ontario, Canada; Department of Computer Science and Engineering, Indian Institute of Technology, Ropar, India","2021 IEEE International Conference on Smart Computing (SMARTCOMP)","8 Oct 2021","2021","","","293","298","Current IoT applications generate huge volumes of complex data that requires agile analysis in order to obtain deep insights, often by applying Machine Learning (ML) techniques. Support vector machine (SVM) is one such ML technique that has been used in object detection, image classification, text categorization and Pattern Recognition. However, training even a simple SVM model on big data takes a significant amount of computational time. Due to this, the model is unable to react and adapt in real-time. There is an urgent need to speedup the training process. Since organizations typically use the cloud for this data processing, accelerating the training process has the advantage of bringing down costs. In this paper, we propose a model partitioning approach that partitions the tasks of Stochastic Gradient Descent based Support Vector Machines (SGD-SVM) on various edge devices for concurrent computation, thus reducing the training time significantly. The proposed partitioning mechanism not only brings down the training time but also maintains the approximate accuracy over the centralized cloud approach. With a goal of developing a smart objection detection system, we conduct experiments to evaluate the performance of the proposed method using SGD-SVM on an edge based architecture. The results illustrate that the proposed approach significantly reduces the training time by 47%, while decreasing the accuracy by 2%, and offering an optimal number of partitions.","2693-8340","978-1-6654-1252-0","10.1109/SMARTCOMP52413.2021.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556256","partitioning;edge computing;SGD-SVM","Training;Support vector machines;Performance evaluation;Adaptation models;Computational modeling;Image edge detection;Text categorization","Big Data;gradient methods;image classification;Internet of Things;learning (artificial intelligence);object detection;support vector machines","partitioning Support Vector Machine models;edge architectures;current IoT applications;complex data;agile analysis;deep insights;ML technique;object detection;image classification;text categorization;simple SVM model;big data;computational time;training process;data processing;model partitioning approach;Support Vector Machines;edge devices;training time;partitioning mechanism;centralized cloud approach;smart objection detection system;SGD-SVM;edge based architecture","","","","15","IEEE","8 Oct 2021","","","IEEE","IEEE Conferences"
"The Design of a Compact, Wide Bandwidth, Non-Foster-Based Substrate Integrated Waveguide Filter","T. Shi; M. -C. Tang; R. W. Ziolkowski","College of Communication Engineering, Chongqing University, Chongqing, China; College of Communication Engineering, Chongqing University, Chongqing, China; Global Big Data Technologies Centre, University of Technology Sydney, Ultimo, NSW, Australia","2018 IEEE Asia-Pacific Conference on Antennas and Propagation (APCAP)","18 Nov 2018","2018","","","54","56","A compact, wideband, half-mode substrate integrated waveguide (HM-SIW) filter with internal non-Foster element is demonstrated. First, its passive version is simulated and measured. Next, by integrating an ideal tunable capacitor at the end of the central stub of the HM-SIW resonator, the frequency-agile characteristic of the tunable HM-SIW filter is investigated. Finally, a negative impedance converter (NIC) is developed to replace this tunable capacitor to design a new nonFoster filter. The non-Foster-based HM-SIW filter was realized. Its measured results indicate that it has an operational fractional bandwidth of 10.8% and an electrical size 0.118×0.292 λg2, which is a 3.93 times bandwidth increase and a ~12% electrical size reduction compared to its passive, fixed capacitance version.","2381-5523","978-1-5386-5648-8","10.1109/APCAP.2018.8538271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538271","Half-mode substrate integrated waveguide filter;negative impedance converter;non-Foster element;wide bandwidth","Resonator filters;Bandwidth;Microwave filters;Resonant frequency;Band-pass filters;Filtering theory;Capacitors","capacitors;impedance matching;negative impedance convertors;substrate integrated waveguides;waveguide filters","half-mode substrate integrated waveguide filter;ideal tunable capacitor;HM-SIW resonator;frequency-agile characteristic;tunable HM-SIW filter;operational fractional bandwidth;non-Foster-based HM-SIW filter;internal non-Foster element;non-Foster-based substrate integrated waveguide filter;negative impedance converter","","2","","9","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Research and Practice of Container System","H. Jin","National Engineering Research Center for Big Data Technology and System Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","2021 International Symposium on Theoretical Aspects of Software Engineering (TASE)","30 Sep 2021","2021","","","13","14","Container technology has been widely used in various real-world situations, like cloud platforms, CI/CD, and DevOps. By enabling a layered image system and OS-level virtualization, container technology can provide agile deployment and isolate execution environment for applications. However, existing container systems fail to support containers efficiently and securely. On the one hand, coarse-grained image management makes the deployment and update of applications time-consuming when the corresponding images need to be delivered in network. On the other hand, shared OS kernel may arise resource contention and security issues. This talk shows our research and practice of container systems. Specifically, I will introduce approaches of image management for fast container deployment, OS kernel isolation for secure and high-performance container execution environment, and container live migration for mitigating resource contention.","","978-1-6654-4163-6","10.1109/TASE52547.2021.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546738","","Cloud computing;Containers;Security;Kernel;Virtualization;Software engineering","cloud computing;operating system kernels;operating systems (computers);security of data;virtual machines;virtualisation","container system;container technology;cloud platforms;layered image system;OS-level virtualization;agile deployment;existing container systems;coarse-grained image management;applications time-consuming;corresponding images;shared OS kernel;resource contention;fast container deployment;OS kernel isolation;high-performance container execution environment","","","","11","IEEE","30 Sep 2021","","","IEEE","IEEE Conferences"
"Determining Viability of Deep Learning on Cybersecurity Log Analytics","C. Lorenzen; R. Agrawal; J. King","Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS; Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS; Information Technology Laboratory, U.S. Army Engineer Research and Development Center, Vicksburg, MS","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","4806","4811","The Department of Defense currently maintains a network known as the Defense Research Engineering Network (DREN), which provides various Department of Defense (DoD) sites across the nation connectivity to HPC resource centers. To ensure the security of the DREN system, a defense system known as the Cybersecurity Environment for Detection, Analysis, and Reporting (CEDAR) was created. CEDAR contains a variety of cybersecurity sensors, which constantly monitor and record real time network activity on the DREN. Over time, CEDAR has accumulated massive quantities of valuable cybersecurity data, which necessitates a form of automation in the process of reviewing this data. We propose the application of deep learning techniques to CEDAR data in an attempt to automatically detect potentially malicious activity in a more agile and adaptable manner. These deep learning techniques can be carried out in a high performance computing (HPC) environment, allowing for the rapid utilization of large amounts of data. Our most effective model is able to classify CEDAR alerts as malicious with an accuracy sufficient to greatly reduce human analyst workloads.","","978-1-5386-5035-6","10.1109/BigData.2018.8622165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622165","Deep Learning;Cybersecurity;High Performance Computing","Computer security;Encoding;Deep learning;Graphics processing units;Feature extraction;Training","computer network security;data analysis;learning (artificial intelligence);military computing;neural nets;parallel processing;pattern classification;system monitoring","cybersecurity log analytics;Defense Research Engineering Network;nation connectivity;HPC resource centers;defense system;cybersecurity sensors;deep learning techniques;CEDAR data;high performance computing environment;cybersecurity data;Department of Defense;DREN system security;Cybersecurity Environment for Detection Analysis and Reporting;real time network activity monitoring;potentially malicious activity detection;HPC environment;CEDAR alert classification","","5","","18","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Investment in Research & Development or Size Expansion? The Case of Internet of Things Companies","H. S. LEE; B. K. SIA; S. C. CHONG; C. W. LOW","Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia; Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia; Faculty of Accountancy, Management and Economics New Era University College, Kajang, Malaysia; Faculty of Accountancy and Management, Universiti Tunku Abdul Rahman, Kajang, Malaysia","2020 IEEE 8th Conference on Systems, Process and Control (ICSPC)","7 Jan 2021","2020","","","69","73","The Internet of Things (IoT) is at the height of its hype cycle and one can argue that the IoT construct will subsume housing, infrastructures, industrial plants, and other systems in the near future. Big data that is associated with IoT could control systems, affect automation and the process industries require R&D support to shape the concept into a functional asset that resolves the problems of users. Hence, investment in research and development (R&D) as an integral part of any IoT project could be the first step towards project success. The objective of this study is to examine the effects of an investment in R&D and size expansion on the firm value of the top Internet of Things companies. This study examines the top 20 Internet of Things companies in the world spanning the period from 2012 to 2019. By using the panel regression random effect model, this study yields two main conclusions. First, the expansion of size by the companies has a significant impact on promoting the firm value. Second, investment in R&D is negatively associated with the firm value of the IoT companies at the initial stage but the lag effect of investment in R&D is associated positively with the firm value. The significant size expansion impact on the firm value in the IoT firms suggests that the agile size could lead to more efficient use of resources and easy identification of growth opportunities. The second conclusion demonstrates the need for a budget allocation for the investment in R&D for the technological progression and scientific advancement in the IoT companies. Although it takes a few years to observe the significant impacts of investment in R&D on IoT firms, in the long term, it could improve the performance of IoT companies in driving the proliferation of connected devices to enhance human productivity and efficiency.","","978-1-7281-8861-4","10.1109/ICSPC50992.2020.9305758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305758","Research and development;internet of things;size expansion;return on invested capital","Research and development;Companies;Investment;Internet of Things;Technological innovation;Process control;Industries","Internet of Things;investment;productivity;project management;regression analysis;research and development","investment;Internet of Things companies;IoT project;panel regression random effect model;agile size;human productivity;research-and-development;budget allocation;Big Data","","","","14","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"An Adaptive Multi-objective Memetic Algorithm: a Case of Observation Scheduling for Active-imaging AEOS","S. Lu; Z. Chang; Z. Zhou; F. Yao","Technology Department, Zhongke Tianzhi operation control (Shenzhen) Technology Co., Ltd, Shenzhen, China; School of Business Administration, Hunan University, Changsha, China; School of Business Administration, Hunan University, Changsha, China; School of System Engineering, National University of Defense Technology, Changsha, China","2021 7th International Conference on Big Data and Information Analytics (BigDIA)","6 Dec 2021","2021","","","285","294","Observation scheduling problem for agile earth observation satellites (OSPFAS) plays a critical role in management of agile earth observation satellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call the novel problem as observation scheduling problem for AEOS with variable image duration (OSWVID). A cumulative image quality and a detailed energy consumption is proposed to build OSWVID as a bi-objective optimization model. A multi-objective memetic algorithm, $\text{ALNS}+\text{NSGA}-\text{II}$, is designed to solve OSWVID. Considering the heuristic knowledges summarized in our previous research, several operators are designed for improving it. Based on existing instances, we analyze the critical parameters optimization, operators evolution, and efficiency of the algorithm according to extensive simulation experiments.","","978-1-6654-2466-0","10.1109/BigDIA53151.2021.9619648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619648","Scheduling;Active imaging;Cumulative image quality;Multi-objective optimization;Memetic algorithm","Image quality;Earth;Memetics;Adaptation models;Energy consumption;Schedules;Satellites","artificial satellites;image processing;imaging;optimisation;scheduling","adaptive multiobjective memetic algorithm;active-imaging AEOS;observation scheduling problem;agile earth observation satellites;OSPFAS;variable image duration;OSWVID;cumulative image quality;bi-objective optimization model;operators evolution;energy consumption","","2","","26","IEEE","6 Dec 2021","","","IEEE","IEEE Conferences"
"Science Autonomy and Planetary Missions: ML and Data Science Applied to the ExoMars Mission","V. Da Poian; E. Lyness; R. Danell; B. Theiling; W. Brinckerhoff","NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD; NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD; Danell Consulting, Winterville, NC; NASA Goddard Space Flight Center, Greenbelt, MD; NASA Goddard Space Flight Center, Microtel LLC, Greenbelt, MD","2023 IEEE Aerospace Conference","15 May 2023","2023","","","1","7","Future planetary science instruments will be capable of producing far more data than can be transmitted back to Earth, potentially leaving valuable scientific data on a planet's surface. Instruments will need to carefully identify the subset of total data to be prioritized for return, as transmission of the full data volume, even after compression, will not be feasible. The concept of science autonomy, where instruments collect measurement data, perform selected science data analyses onboard, and then autonomously act upon those analyses through self-adjustment and tuning of instrument parameters, can be used to identify and produce an optimal and compact data set for return, maximizing the value of each bit returned to Earth. Furthermore, the selection of the next operation(s) to be run following preliminary measurements, without requiring ground-in-the-loop communication, increases mission efficiency and enables successful yet shorter duration missions to hazardous planetary environments. This capability allows missions to prioritize the most compelling or time-critical data, yielding a more efficient and productive scientific investigation overall. In this paper, we present our implementation using different machine learning (ML) techniques (i.e., clustering, classification) for analyzing science data from the Mars Organic Molecule Analyzer (MOMA) instrument onboard the ExoMars rover Rosalind Franklin. MOMA is a dual-source (laser desorption and gas chromatography) mass spectrometer that will search for past or present life on the Martian surface and subsurface through analysis of soil samples. We use data collected from the MOMA flight-like engineering model to develop mass-spectrometry-focused ML techniques. This effort, in preparation for operating on Mars, is aimed at 1) helping the ExoMars science and operations team quickly analyze new data and support them in their decision-making process regarding subsequent operations and, 2) getting a better understanding of the challenges to enable science autonomy in future missions. We also present two significant challenges we faced in this development that are particular to space missions and will be common to most, if not all, robotic planetary missions. First, the lack of sufficient data volume from these unique and highly optimized instruments to train neural networks, and second the lack of sufficient results from the system to fully trust its output. To tackle the first challenge, we analyze the performance of ML algorithms after adding augmented data. We discuss adopting transfer learning techniques to fine-tune a NN trained on large amounts of commercial instrument data so that it can operate on our limited MOMA dataset. For the ‘trust’ challenge—as it is not always clear what we are looking for in planetary science—we must consider agile ML applications and demonstrate that these will not filter out potentially critical data. We will discuss our concept of a Trust Readiness Level for science autonomy akin to the NASA Technology Readiness Level. This initial project for advanced autonomy illustrates some key first steps of a longer-term objective to enable the spacecraft and instruments themselves to make real-time adjustments during operations as direct human oversight will not be possible for missions going further away in our solar system and beyond.","1095-323X","978-1-6654-9032-0","10.1109/AERO55745.2023.10115830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10115830","","Earth;Space vehicles;Mars;Instruments;Space missions;Transfer learning;Surface emitting lasers","","","","","","5","IEEE","15 May 2023","","","IEEE","IEEE Conferences"
"HCOBASAA: Countermeasure Against Sinkhole Attacks in Software-Defined Wireless Sensor Cognitive Radio Networks","L. Sejaphala; M. Velempini; S. V. Dlamini","Department of Computer Science, University of Limpopo, Limpopo, South Africa; Department of Computer Science, University of Limpopo, Limpopo, South Africa; Mareka Institute, Council for Scientific & Industrial Research, CSIR, Pretoria, South Africa","2018 International Conference on Advances in Big Data, Computing and Data Communication Systems (icABCD)","16 Sep 2018","2018","","","1","5","Software-defined wireless sensor cognitive radio network is one of the emerging technologies which is simple, agile, and flexible. The sensor network comprises of a sink node with high processing power. The sensed data is transferred to the sink node in a hop-by-hop basis by sensor nodes. The network is programmable, automated, agile, and flexible. The sensor nodes are equipped with cognitive radios, which sense available spectrum bands and transmit sensed data on available bands, which improves spectrum utilization. Unfortunately, the Software-defined wireless sensor cognitive radio network is prone to security issues. The sinkhole attack is the most common attack which can also be used to launch other attacks. We propose and evaluate the performance of Hop Count-Based Sinkhole Attack detection Algorithm (HCOBASAA) using probability of detection, probability of false negative, and probability of false positive as the performance metrics. On average HCOBASAA managed to yield 100%, 75%, and 70% probability of detection.","","978-1-5386-3060-0","10.1109/ICABCD.2018.8465449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465449","sinkhole attack;software-defined wireless sensor cognitive radio network;change in position","Wireless sensor networks;Base stations;Cognitive radio;Databases;Communication system security;Detection algorithms","cognitive radio;telecommunication security;wireless sensor networks","HCOBASAA;probability of detection;probability of false negative;probability of false positive;performance metrics;Hop Count-Based Sinkhole Attack detection Algorithm;sensor nodes;sink node;Software-defined wireless sensor cognitive radio network","","3","","13","IEEE","16 Sep 2018","","","IEEE","IEEE Conferences"
"Prevalence of GitOps, DevOps in Fast CI/CD Cycles","S. Gupta; M. Bhatia; M. Memoria; P. Manani","Computer Science & Engineering, Amity School of Engineering & Technology, Amity University, Noida, India; Computer Science & Engineering, Amity School of Engineering & Technology, Amity University, Noida, India; Department of Computer Science & Engineering, Uttaranchal University, Dehradun, Uttarakhand, India; Department of Computer Science & Engineering, Uttaranchal University, Dehradun, Uttarakhand, India","2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON)","15 Aug 2022","2022","1","","589","596","Today, when we are surrounded by technology, software and applications are making our lives more efficient and easy because of the operations and processes controlled by them. Since the technology is constantly changing at a very high pace, improving and modifying with each development, there is a constant need of is faster and more frequent delivery of the software and applications. Today, most software and applications are built in such a way that they could run across multiple operating environments. Software development is performed using agile principles and the most critical part of it is Continuous Delivery and Continuous Integration (CI/CD). CI/CD aims at automating the process of testing, building, and deploying the commitments made by the developer to the code repository. The use of Container-based applications solves a number of complex problems that are found on CI/CD such as portability, elasticity, visibility, and version control. This modular approach enables a simpler, faster, more secure, and more efficient way of development by more focused teams responsible for specific containers. In this context, a new point of interest in the development process, GitOps, which is more agile, reliable, fast, and efficient in its approach towards better performance levels with cloud-native. The main objective of this paper is to understand the Kubernetes GitOps process by day 2 operations, to access the benefits of implementing GitOps in the Kubernetes environment, and to implement Kubernetes GitOps on AWS.","","978-1-6654-9602-5","10.1109/COM-IT-CON54601.2022.9850786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850786","GitOps;DevOps;CI/CD;Continuous Delivery;Continuous Integration;AWS","Productivity;Codes;Process control;Machine learning;Syntactics;Parallel processing;Elasticity","cloud computing;configuration management;process control;software development management;software engineering;software prototyping","Continuous Delivery;Continuous Integration;Container-based applications;version control;Kubernetes GitOps process;day 2 operations;high pace;frequent delivery;multiple operating environments;software development","","","","17","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Towards privacy-aware software design in small and medium enterprises","L. Campanile; M. Iacono; M. Mastroianni","Dipartimento di Matematica e Fisica, Università Degli Studi Della Campania Luigi Vanvitelli, Caserta, Italy; Dipartimento di Matematica e Fisica, Università Degli Studi Della Campania Luigi Vanvitelli, Caserta, Italy; Dipartimento di Informatica, Università Degli Studi di Salerno, Fisciano (SA), Italy","2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","13 Dec 2022","2022","","","1","8","The legal definition of privacy regulations, like GDPR in the European Union, significantly impacted on the way in which software, systems and organizations should be designed or maintained to be compliant to rules. While the privacy community stated proper risk assessment and mitigation approaches to be applied, literature seems to suggest that the software engineering community, with special reference to companies, did actually concentrate on the specification phase, with less attention for the test phase of products. In coherence with the privacy-by-design approach, we believe that a bigger methodological effort must be put in the systematic adaptation of software development cycles to privacy regulations, and that this effort might be promoted in the industrial community by focusing on the relation between organizational costs vs technical features, also leveraging the benefits of targeted testing as a mean to lower operational privacy enforcement costs.","","978-1-6654-6297-6","10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927958","Software design;Privacy;GDPR;Risk analysis;Software development life cycle (SDLC);Agile methodology;Nonfunctional requirements;Privacy-by-design","Training;Privacy;Costs;Systematics;Unified modeling language;Solids;Software systems","data protection;law;risk management;small-to-medium enterprises;software engineering","European Union;GDPR;privacy regulations;privacy-aware software design;privacy-by-design approach;risk assessment;small and medium enterprises;software development cycles;software engineering;specification phase","","","","19","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"The Making of Continuous Colormaps","P. Nardini; M. Chen; F. Samsel; R. Bujack; M. Böttinger; G. Scheuermann","Institute of Computer Science, University of Leipzig, Leipzig, Germany; Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Center for Agile Technology, University of Texas at Austin, Austin, TX, USA; Data Science at Scale Team, Los Alamos National Laboratory, Los Alamos, NM, USA; German Climate Computing Center (DKRZ), Hamburg, Germany; Institute of Computer Science, University of Leipzig, Leipzig, Germany","IEEE Transactions on Visualization and Computer Graphics","12 May 2021","2021","27","6","3048","3063","Continuous colormaps are integral parts of many visualization techniques, such as heat-maps, surface plots, and flow visualization. Despite that the critiques of rainbow colormaps have been around and well-acknowledged for three decades, rainbow colormaps are still widely used today. One reason behind the resilience of rainbow colormaps is the lack of tools for users to create a continuous colormap that encodes semantics specific to the application concerned. In this paper, we present a web-based software system, CCC-Tool (short for Charting Continuous Colormaps) under the URL https://ccctool.com, for creating, editing, and analyzing such application-specific colormaps. We introduce the notion of “colormap specification (CMS)” that maintains the essential semantics required for defining a color mapping scheme. We provide users with a set of advanced utilities for constructing CMS's with various levels of complexity, examining their quality attributes using different plots, and exporting them to external application software. We present two case studies, demonstrating that the CCC-Tool can help domain scientists as well as visualization experts in designing semantically-rich colormaps.","1941-0506","","10.1109/TVCG.2019.2961674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939459","CCC-Tool;charting continuous colormaps;colormap specification;perceptual uniformity;colormap analysis","Image color analysis;Data visualization;Tools;Semantics;Guidelines;Standards;Software systems","data visualisation;formal specification","rainbow colormaps;colormap specification;charting continuous colormaps;semantically rich colormaps;visualization techniques;application specific colormaps;Web based software system;CCC tool","","13","","91","IEEE","23 Dec 2019","","","IEEE","IEEE Journals"
"How to Efficiently Predict Dengue Incidence in Kuala Lumpur","D. N. Pham; T. Aziz; A. Kohan; S. Nellis; J. b. A. Jamil; J. J. Khoo; D. Lukose; S. AbuBakar; A. Sattar; H. H. Ong","Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; Data Science, GCS Agile Pty Ltd, Victoria, Australia; TIDREC, University of Malaya, Kuala Lumpur, Malaysia; IIIS, Griffith University, Queensland, Australia; Artificial Intelligence Lab, MIMOS Berhad, Kuala Lumpur, Malaysia","2018 Fourth International Conference on Advances in Computing, Communication & Automation (ICACCA)","29 Jul 2019","2018","","","1","6","Mosquito-borne diseases are rapidly spreading in all regions of the world with an estimation of 2.5 billion people globally are at risk. The recent surge in dengue outbreaks has caused severe affliction to Malaysian society. Hence, the ability to predict a dengue outbreak and mitigate its damage and loss proactively is very critical. In this paper, we study the possibility of applying machine learning (ML) and deep learning (DL) approaches to predict the number of confirmed dengue fever (DF) cases in Kuala Lumpur. We identified several contribution factors correlate to a dengue outbreak. In addition to the two frequently used factors (daily mean temperature and daily rainfall), we also took into account the enhanced vegetation index (EVI), humidity and wind speed as input factors to our prediction engines. We collected and cleansed data on these factors and the daily DF incidents in Kuala Lumpur from 2002 to 2012. We then used these data to train and evaluate our 3 ML/DL models. Among the three models, GA_RNN was the best performer and achieved a MAE of 10.95 for DF incidence prediction.","2642-7354","978-1-5386-7167-2","10.1109/ICACCAF.2018.8776790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776790","dengue outbreak prediction;machine learning;deep learning","Indexes;Predictive models;Sociology;Statistics;Diseases;Data models;Pediatrics","atmospheric temperature;diseases;environmental factors;learning (artificial intelligence);rain;regression analysis","machine learning;daily mean temperature;daily rainfall;DF incidence prediction;daily DF incidents;prediction engines;contribution factors;confirmed dengue fever cases;deep learning;dengue outbreak;recent surge;mosquito-borne diseases;Kuala Lumpur","","8","","25","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Let's DO - Automotive Platform for Interoperability","R. ElHakim; A. Elqadi; M. Torky; M. Zayed; I. Farag; M. Agamawi","Innovation Department, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Driving Systems and Functions, CDA Valeo, Cairo, Egypt; Innovation Department, CDA Valeo, Cairo, Egypt; Smart Service Center Valeo, Cairo, Egypt","2021 4th International Conference on Information and Computer Technologies (ICICT)","15 Jul 2021","2021","","","294","299","Developing automotive software applications is one of the most challenging and time-consuming activities in the automotive product development cycle. As of today, classical automotive software applications communicate exclusively using vehicle-specific communication protocols such as Controller Area Network (CAN) and FlexRay communication buses. Automotive applications communicate using transport layer messages that are defined and configured for each vehicle system (car model). This hard-wired design makes out-of-the box integrations between heterogeneous automotive products virtually impossible. It also renders automotive integration projects to digital world (smart devices, cloud, big data, IoT gadgets) hard to develop and maintain. We present in this paper Let's DO, a novel platform for interoperability and data exchange between different noncoherent products, systems and devices (both automotive and nonautomotive). Let's DO platform abstracts automotive communication protocol messages in a unified message standard transported over IP-based Ethernet networks enabling interoperability, quick prototyping, code reuse, and allowing more agile and efficient automotive software development cycles.","","978-1-6654-1399-2","10.1109/ICICT52872.2021.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476917","Automotive Software;Prototyping;Digital Transformation","Cloud computing;Protocols;Ethernet;Big Data;Software;Product development;Smart devices","automobile industry;automobile manufacture;automobiles;automotive components;automotive engineering;controller area networks;Internet of Things;IP networks;open systems;product development;production engineering computing;protocols;software prototyping","out-of-the box integration;agile automotive software development cycles;automotive communication protocol messages;noncoherent products;data exchange;car model;FlexRay communication buses;CAN;controller area network;interoperability;IP-based Ethernet network;vehicle-specific communication protocols;automotive product development cycle;unified message standard;automotive integration projects;heterogeneous automotive products;vehicle system;transport layer messages","","1","","21","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Deep Learning in Mobile and Wireless Networking: A Survey","C. Zhang; P. Patras; H. Haddadi","Institute for Computing Systems Architecture, School of Informatics, University of Edinburgh, Edinburgh, U.K.; Institute for Computing Systems Architecture, School of Informatics, University of Edinburgh, Edinburgh, U.K.; Dyson School of Design Engineering, Imperial College London, London, U.K.","IEEE Communications Surveys & Tutorials","22 Aug 2019","2019","21","3","2224","2287","The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.","1553-877X","","10.1109/COMST.2019.2904897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666641","Deep learning;machine learning;mobile networking;wireless networking;mobile big data;5G systems;network management","Deep learning;Tutorials;Wireless communication;5G mobile communication;Neural networks;Big Data","5G mobile communication;learning (artificial intelligence);neural nets;telecommunication computing;telecommunication network management;telecommunication traffic","deep learning;mobile wireless networking infrastructure;5G systems;mobile traffic volumes;network resources management;encyclopedic review;fine-grained analytics real-time extraction;user experience;algorithm-driven applications","","830","","574","IEEE","13 Mar 2019","","","IEEE","IEEE Journals"
"Chatbot Driven Web-based Platform for Online Safety and Sexual Exploitation Awareness and Reporting in Namibia","M. N. Rita; F. B. Shava","Department of Computer Science, Namibia University of Science and Technology, Windhoek, Namibia; Department of Computer Science, Namibia University of Science and Technology, Windhoek, Namibia","2021 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","30 Aug 2021","2021","","","1","5","Technological devices have become a commodity, access to information can be achieved within seconds, connecting people across the globe is easy and possible. Where there is growth, exploitation lurks too. Online sex offenders have taken this opportunity to seduce, groom and make contact with children online. The objective of the research was to design an interactive website with a reporting mechanism that serves as a safe haven where children can find awareness materials and report online incidences of abuse. The use of chatbots on such a website can be beneficial, as queries reported can be attended to. The research used the Software Development Life Cycle (SDLC) focusing on Agile Method to develop the interactive website prototype and chatbot. Qualitative primary data was collected from 42 pre-teens and teens selected from 2 private and 1 public schools in Windhoek, Namibia. The schools were purposefully selected to reflect the extent of the challenge as they offer Computer Studies or Computer Science subject, the children mostly have access to digital technologies daily. Results from the study yielded opinions that teens and pre-teens would make use of the chatbot and reporting portal, and also supported it by sharing innovative ideas for a platform that they would want to utilise. The prototype was evaluated for Usability by five participants using the unmonitored remote usability testing and the feedback was used to further refine the design.","","978-1-7281-8592-7","10.1109/icABCD51485.2021.9519375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519375","Online Safety;Online Sex Offender;Children;Awareness;Interactive Website","Pediatrics;Prototypes;Tools;Chatbots;Software;Safety;Stakeholders","chatbots;computer crime;interactive systems;Internet;portals;software development management;software prototyping;Web sites","agile method;interactive Web site prototype;qualitative primary data;pre-teens;private schools;public schools;Namibia;children;digital technologies;chatbot driven Web-based platform;online safety;sexual exploitation awareness;technological devices;online sex offenders;reporting mechanism;safe haven;awareness materials;software development life cycle;SDLC;Windhoek;computer studies;computer science subject;reporting portal;unmonitored remote usability testing","","1","","25","IEEE","30 Aug 2021","","","IEEE","IEEE Conferences"
"Securing Distributed SDN Controller Network from Induced DoS Attacks","S. G.; S. N. H.; R. P. Rustagi; O. Sharma","PES University; PES University; Department of Computer, Science and Engineering, KS Institute of Technology, Bengaluru, India; Department of Computer, Science and Engineering PES University, Bengaluru, India","2019 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)","2 Apr 2020","2019","","","9","16","With the escalation in security breaches on organizations and institutions that store, maintain and work with critical data, there is a need for a security-enhancing and risk-mitigating solution that works on the fly and is feasible to implement. Software Defined Networks is a networking paradigm that makes the network agile by disaggregating hardware and software. SDN helps enhance security with the help of micro-segmentation. The controller maintains a central view of the network, and its ability to monitor and store network information helps optimize routing. The centralization nature of the controller makes it vulnerable to DoS attacks which can be catastrophic for network functioning. The objective of this paper is to secure the distributed SDN controller architecture against DoS attacks. The proposed architecture is robust, scalable, and uses Big Data techniques to process streams of network traffic in real-time and Machine Learning to detect and mitigate DoS attacks.","","978-1-7281-6334-5","10.1109/CCEM48484.2019.000-4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051954","Software Defined Networks, DoS Attack, RyuController, Zodiac FX, Kafka, Storm","","Big Data;computer network security;learning (artificial intelligence);optimisation;software defined networking;storage management;telecommunication network routing;telecommunication traffic","induced DoS attacks;security breaches;critical data storage;risk-mitigating solution;networking paradigm;microsegmentation;centralization nature;network information monitoring;network functioning;distributed SDN controller architecture;Big Data techniques;network traffic;software defined networks;security-enhancing solution;distributed SDN controller network security;routing optimization;machine learning;DoS attack detection;DoS attack mitigation","","1","","22","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"Advancing Design and Runtime Management of AI Applications with AI-SPRINT (Position Paper)","H. Sedghani; D. Ardagna; M. Matteucci; G. A. Fontana; G. Verticale; F. Amarilli; R. Badia; D. Lezzi; I. Blanquer; A. Martin; K. Wawruch",Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Politecnico di Milano; Barcelona Super Computing Center; Barcelona Super Computing Center; Universitat Politècnica de València; Dresden University of Technology; 7Bulls,"2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)","9 Sep 2021","2021","","","1455","1462","The adoption of Artificial intelligence (AI) technologies is steadily increasing. However, to become fully pervasive, AI needs resources at the edge of the network. The cloud can provide the processing power needed for big data, but edge computing is close to where data are produced and therefore crucial to their timely, flexible, and secure management. In this paper, we introduce the AI-SPRINT project, which will provide solutions to seamlessly design, partition, and run AI applications in computing continuum environments. AI-SPRINT will offer novel tools for AI applications development, secure execution, easy deployment, as well as runtime management and optimization: AI-SPRINT design tools will allow trading-off application performance (in terms of end-to-end latency or throughput), energy efficiency, and AI models accuracy while providing security and privacy guarantees. The runtime environment will support live data protection, architecture enhancement, agile delivery, runtime optimization, and continuous adaptation.","0730-3157","978-1-6654-2463-9","10.1109/COMPSAC51774.2021.00216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529477","Cloud computing;fog computing;edge computing;AI and machine learning;Cloud trust security & privacy","Privacy;Runtime environment;Costs;Computational modeling;Biological system modeling;Time to market;Tools","artificial intelligence;Big Data;data flow analysis;data protection;security of data","Big Data;edge computing;AI-SPRINT project;AI applications development;runtime management;AI-SPRINT design tools;runtime environment;data protection;runtime optimization;artificial intelligence technologies","","1","","38","IEEE","9 Sep 2021","","","IEEE","IEEE Conferences"
"Infoxication in the Genomic Data Era and Implications in the Development of Information Systems","A. L. Palacio; Ó. P. López","Universitat Politècnica de València, Valencia, Spain; Universitat Politècnica de València, Valencia, Spain","2019 13th International Conference on Research Challenges in Information Science (RCIS)","21 Oct 2019","2019","","","1","9","We live in an age where data acquisition is no longer a problem and the real challenge is how to determine which information is the right one to take important and sometimes difficult decisions. Infoxication (also known as Infobesity or Information Overload) is a term used to describe the difficulty of adapting to new situations and effectively making decisions when there is too much information to manage. With the advent of the Big Data, infoxication is affecting critical domains such as Health Sciences, where tough decisions for patient's health is being taken every day based on heterogeneous, unconnected and sometimes conflicting information. In order to understand the magnitude of the challenge, based on the information publicly available about the genetic causes of the disease and using data quality assessment techniques, we performed an exhaustive analysis of the DNA variations that have been associated to the risk of suffering migraine headache. The same analysis has been repeated 8 months after, and the results have allowed us to exemplify i) how fragile is the information in this domain, ii) the difficulty of finding repositories of contrasted and reliable data, and iii) the need to have information systems that, far from integrating and storing huge volumes of data, are able to support the decision-making process by providing mechanisms agile and flexible enough to be able to adapt to the changing user needs.","2151-1357","978-1-7281-4844-1","10.1109/RCIS.2019.8877003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877003","Infoxication;Genomics;Information Systems;SILE method","Bioinformatics;Genomics;Diseases;DNA;Task analysis;Databases","Big Data;data acquisition;decision making;diseases;DNA;genomics;health care;information systems;medical information systems","information systems;data acquisition;infoxication;Big Data;critical domains;health sciences;patient health;disease;decision-making process;genomic data;data quality assessment techniques;DNA variations","","","","20","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Smart Services Maturity Level in Germany","F. Kaltenbach; P. Marber; C. Gosemann; T. Bölts; A. Kühn","Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany; Faculty of Engineering, Pforzheim University, Pforzheim, Germany","2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)","16 Aug 2018","2018","","","1","7","Digitization of business processes is changing the industry. Enterprises using data as efficiently and smart as possible, can often create a clear competitive advantage and be more responsive to their customer needs. Through the smart use of data, new business models can be created. The most well-known changes of digitization are taking place in the B2C market. The B2B market is affected by this change too. Enterprises recognize the ongoing shift to a service-oriented society and therefore should be able to react directly to the customer needs. Service based business models, such as implementing Smart Services, are developed and intergarted in existing enterprise offerings. This paper reports upon a study of the maturity level regarding Smart Services of three selected German enterprises. The aim is to highlight the the impact of the ongoing digital transformation and map the maturity levels with regards to digitization and Smart Services. The case studies offer a first assessment about the current situation of Smart Services, using sub-categories to pinpoint developments, in manufacturing enterprises. The analysis shows that the maturity levels of these enterprises depend on their technology management, financial resources and corporate culture. The three cases have a high maturity level and already implemented Smart Services in their business model strategy. Nevertheless, there is still potential for improvement, especially regarding `Simultaneous Engineering' and `Automation Level'. It can be stated that within these enterprises financial resources, critical awareness as well as know-how of digitization and Smart Services are available. The cases were organizationally rather set in rigid structures. In order to reach an even higher degree of maturity and thus to remain competitive in the future, the enterprises should fundamentally rethink their corporate culture. These case studies may be considered as a pilot study into this topic, with refinements and improvements to further studies possible.","","978-1-5386-1469-3","10.1109/ICE.2018.8436329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8436329","digitization;agile culture;internet of things;intelligent services;industry 4.0","Industries;Companies;Manufacturing;Big Data;Data models;Automation","business data processing;organisational aspects;technology management","digitization;service-oriented society;service based business models;manufacturing enterprises;digital transformation;business processes;B2C market;B2B market;smart services maturity level;German enterprises;technology management;corporate culture;financial resources","","5","","25","IEEE","16 Aug 2018","","","IEEE","IEEE Conferences"
"A Fast Self-Jamming Cancellation Architecture and Algorithm for Passive RFID Sensor System","C. Shen; H. Xiong; X. Wang; F. Mei; T. T. Ye","School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science, Memorial University of Newfoundland, St. John’s, NL, Canada; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China","IEEE Communications Letters","9 Jun 2021","2021","25","6","2009","2013","In this letter, we propose a fast self-jamming cancellation (SJC) architecture for Ultra High Frequency (UHF) radio-frequency identification (RFID) interrogators. The core SJC architecture includes a Field Programmable Gate Array (FPGA) as the RFID baseband processor, a radio frequency (RF) agile transceiver which has two transmitting ports as the RF front-end, and a combiner. By detecting the amplitude and phase of the interference carrier, the SJC algorithm transmits a suppression carrier through the second transmitting port of the agile RF transceiver. The suppression carrier could effectively suppress the self-jamming carrier without designing complex circuits. Our test results showed the isolation between the transmitting and receiving port achieves 100dB at UHF band, and the cancellation processes can be finished within 0.4ms.","1558-2558","","10.1109/LCOMM.2021.3066177","Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B0101030002); Shenzhen Science and Technology Program(grant numbers:JCYJ20190809115803580); High-level University Fund(grant numbers:G02236002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380725","UHF RFID interrogator;interference cancellation;self-jamming;carrier leakage canceler;passive sensor system","Radiofrequency identification;Radio frequency;Interference;Computer architecture;Baseband;Field programmable gate arrays;Backscatter","field programmable gate arrays;interference suppression;jamming;radio transceivers;radiofrequency identification;sensors","self-jamming carrier;receiving port;fast self-jamming cancellation architecture;passive RFID sensor system;core SJC architecture;field programmable gate array;RFID baseband processor;radio frequency agile transceiver;transmitting port;RF front-end;interference carrier;SJC algorithm;RF transceiver;ultra high frequency radio-frequency identification;transmitting ports;phase amplitude detection;suppression carrier transmission;UHF band","","4","","26","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Software Engineering for Machine Learning: A Case Study","S. Amershi; A. Begel; C. Bird; R. DeLine; H. Gall; E. Kamar; N. Nagappan; B. Nushi; T. Zimmermann","Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; University of Zurich, Zurich, Switzerland; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA","2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)","19 Aug 2019","2019","","","291","300","Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.","","978-1-7281-1760-7","10.1109/ICSE-SEIP.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804457","artifical intelligence;machine learning;software engineering;process;data","Software;Machine learning;Software engineering;Buildings;Organizations;Data models","learning (artificial intelligence);software prototyping","nine-stage workflow process;Microsoft teams;large-scale AI solutions;machine learning applications;software teams;data science tools;agile-like software engineering processes","","279","","37","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"GELAB – The Cutting Edge of Grammatical Evolution","K. K. Gupt; M. A. Raja; A. Murphy; A. Youssef; C. Ryan","Department of Electrical and Electronic Engineering, Technological University of the Shannon: Midlands Midwest, Limerick, Ireland; Regulated Software Research Center (RSRC), Dundalk Institute of Technology (DkIT), Dundalk, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland; Bio-Computing and Developmental Systems (BDS) Research Group, University of Limerick, Limerick, Ireland","IEEE Access","22 Apr 2022","2022","10","","38694","38708","The advent of cloud-based super-computing platforms has given rise to a Data Science (DS) boom. Many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration. Machine Learning (ML) tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike. Coupled with modern-day computing power, ML tools can be looked at as hammers that can deal with even the most stubborn nails. ML tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly. In order to keep pace with these requirements, a new enterprise, referred to as MLOps has blossomed in recent years. MLOps combines the process of ML and DS with an agile software engineering technique to develop and deliver solutions in a fast and iterative way. One of the key challenges to this is that ML and DS tools should be efficient and have better usability characteristics than were traditionally offered. In this paper, we present a novel software for Grammatical Evolution (GE) that meets both of these expectations. Our tool, GELAB, is a toolbox for GE in Matlab which has numerous features that distinguish it from existing contemporary GE software. Firstly, it is user-friendly and its development was aimed for use by non-specialists. Secondly, it is capable of hybrid optimization, in which standard numerical optimization techniques can be added to GE. We have shown experimentally that when hybridized with meta-heuristics GELAB has an overall better performance as compared with standard GE.","2169-3536","","10.1109/ACCESS.2022.3166115","Science Foundation Ireland (SFI)(grant numbers:#16/IA/4605,#13/RC/2094); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751757","Grammatical evolution;diversity;hybrid optimization","Germanium;Matlab;Software;Optimization;Grammar;Statistics;Sociology","cloud computing;learning (artificial intelligence);optimisation;software prototyping","ML tools;intelligent solutions;MLOps;agile software engineering technique;cutting edge;cloud-based super-computing platforms;industrial giants;grammatical evolution;data science boom;machine learning;GE software;DS tools;hybrid optimization;metaheuristics GELAB","","","","35","CCBYNCND","8 Apr 2022","","","IEEE","IEEE Journals"
"Artificial Intelligence Aided Next-Generation Networks Relying on UAVs","X. Liu; M. Chen; Y. Liu; Y. Chen; S. Cui; L. Hanzo","Queen Mary University of London; Princeton University; Queen Mary University of London; Queen Mary University of London; The Chinese University of Hong Kong, Shenzhen; University of Southampton","IEEE Wireless Communications","24 Feb 2021","2021","28","1","120","127","In this article, we propose artificial intelligence (AI) enabled unmanned aerial vehicle (UAV) aided wireless networks (UAWN) for overcoming the challenges imposed by the random fluctuation of wireless channels, blocking and user mobility effects. In UAWN, multiple UAVs are employed as aerial base stations, which are capable of promptly adapting to the randomly fluctuating environment by collecting information about the users' position and tele-traffic demands, learning from the environment and acting upon the satisfaction level feedback received from the users. Moreover, AI enables the interaction among a swarm of UAVs for cooperative optimization of the system. As a benefit of the AI framework, several challenges of conventional UAWN may be circumvented, leading to enhanced network performance, improved reliability and agile adaptivity. As a further benefit, dynamic trajectory design and resource allocation are demonstrated. Finally, potential research challenges and opportunities are discussed.","1558-0687","","10.1109/MWC.001.2000174","Natural Science Foundation of China(grant numbers:NSFC61629101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9267780","","Resource management;Artificial intelligence;Wireless communication;Three-dimensional displays;Social networking (online);Optimization;Big Data","aircraft communication;autonomous aerial vehicles;cooperative systems;learning (artificial intelligence);mobility management (mobile radio);multi-robot systems;next generation networks;optimisation;random processes;resource allocation;telecommunication computing;telecommunication network reliability;telecommunication traffic;wireless channels","aerial base stations;tele-traffic demands;satisfaction level feedback;AI framework;enhanced network performance;agile adaptivity;artificial intelligence aided next-generation networks;unmanned aerial vehicle;random fluctuation;wireless channels;user mobility effects;multiple UAVs;UAWN;UAV aided wireless networks;cooperative optimization;dynamic trajectory design;resource allocation;improved reliability","","28","","15","IEEE","24 Nov 2020","","","IEEE","IEEE Magazines"
"Key Technologies of Large Power Grid Security and Stability Intelligent Sand Table Deduction","W. Li; Y. Huang; X. Chen; W. Li; S. Zhang","State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Key Laboratory of Power Grid, China Electric Power Research Institute, State Grid Energy Internet Research Institute, Safety and Energy Conservation, Beijing, China; State Grid Zhejiang Electric Power CO. LTD, Hangzhou, China","2020 IEEE Sustainable Power and Energy Conference (iSPEC)","18 Feb 2021","2020","","","2702","2707","Existing power system simulation systems focus on calculations and lack effective analysis and display capabilities, which limits the application level of simulation calculation results. Aiming at the problem of power grid simulation data analysis and display combined with simulation calculation and artificial intelligence, this paper proposes the new connotation of large power grid safety and stability sand table deduction technology, and the corresponding data analysis model and agile analysis model. The work in this paper provides the necessary ideas and technical foundation for the establishment of a new grid simulation analysis environment combining human, artificial intelligence and simulation calculation.","","978-1-7281-9164-5","10.1109/iSPEC50848.2020.9351210","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351210","Sand Table Deduction;Grid Simulation Analysis;Artificial Intelligence;Visual Analysis","Analytical models;Visualization;Data analysis;Big Data;Data models;Power grids;Artificial intelligence","artificial intelligence;data analysis;power engineering computing;power grids;power system security;power system simulation;power system stability","power grid security;stability intelligent sand table deduction;power grid simulation data analysis;artificial intelligence;power grid safety;stability sand table deduction technology;data analysis model;agile analysis model;grid simulation analysis environment;human intelligence;power system simulation systems","","","","18","IEEE","18 Feb 2021","","","IEEE","IEEE Conferences"
"Learning Service Semantics for Self-Organization in Distributed Environments: Concepts and Research Directions","G. Bent; G. de Mel; R. Ganti; T. La Porta; G. Pearson; T. Pham; S. Stein; L. Tassiulas; I. Taylor","ETS, IBM Research, Hursley, UK; IBM Research, Hartree Centre, Warrington, UK; IBM TJ Watson Research Center, NY, USA; The Pennsylvania State University, University Park, PA, USA; Defence Science and Technology Laboratory, UK; US Army Research Laboratory, Adelphi, MD, USA; University of Southampton, Southampton, UK; Yale University, New Haven, CT, USA; Cardiff University, Cardiff, UK","MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)","3 Jan 2019","2018","","","1080","1085","A key challenge in performing analytics in distributed environments is to automatically compose services to dynamically match operational tasks to information requirements, accounting for impact, in a many-to-many temporally and spatially complicated and complex situations. In dynamic and agile environments, such as coalition environments, the state of the network and resources cannot be completely known in advance nor controlled due to the evolving nature of the network and constraints that may preclude partners from accessing complete state information about different parts of the system. In addition, there may be requests made to the system that have not been made before, requiring services to be created on the fly. Motivated by these observations, in this paper, we present a critical analysis of gaps in the state-of-the-art and our vision to address those through novel theoretical contributions. We envision that such formalized and theorized fundamentals will enable service elements to automatically configure themselves to perform analytic tasks based on user specified goals by taking account of context-be it system or user context.","2155-7586","978-1-5386-7185-6","10.1109/MILCOM.2018.8599809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8599809","","Task analysis;Semantics;Data models;Dynamic scheduling;Brain modeling;Big Data;Machine learning","distributed processing;research and development;service-oriented architecture","service elements;service semantics;distributed environments;research directions;information requirements;dynamic environments;agile environments;coalition environments;context-be it system;user context","","","","31","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"Dynamic allocation of traffic light plans as a traffic reduction strategy","M. L. Suarez; L. E. Alvarez; P. A. Camacho; L. C. Marin; B. Vasquez; G. Gutierrez; R. A. Aranzazu; M. Carranza; F. G. Montoya; A. Valdes; C. Gonzalez; M. Jaramillo; S. Henao","Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223; Engineering and Traffic Light Operation Center (CIOS). Secretary of Mobility, Colombia Cra 80 No 65-223","MOVICI-MOYCOT 2018: Joint Conference for Urban Mobility in the Smart City","17 Feb 2019","2018","","","1","7","The city of Medellin, like other cities in the world, is facing major mobility issues caused by the accelerated growth of the vehicle fleet in the last decade. The efficient operation of the traffic light network plays a fundamental role in the search for solutions to achieve an agile, comfortable, safe and sustainable mobility. For this reason, the Municipal Administration has made important investments in its updating and technological modernization that allows actions for a better performance. Currently the traffic lights of the city are operated by classic programming models, mostly at fixed times in different time zones and others in modes actuated and semi-actuated as scheduled, without responding to changing traffic conditions, making it necessary to search for autonomous traffic regulation systems that adapt their behavior according to the conditions. While adaptive systems based on a wide sensorisation for obtaining information online are an alternative, their current costs of implementation, maintenance and operation, has led to evaluate the new global trends in terms of information capture, storage, processing and use in the optimization of the operation of the traffic signal network. This is how the city of Medellin has been consolidating a Big Data storage system and has developed a technological platform capable of receiving it and executing actions on the traffic light system when it identifies that there are events that generate traffic variations different from normal or daily conditions, which has allowed to improve mobility conditions according to the results obtained, which will be detailed later. This first part of this document is an introduction of the different modes of operation of a traffic light network commonly used; the second part contains a brief description of the city's traffic light network; in the third part, the collaborative data systems are studied; the fourth part develops the solution scheme adopted by Medellin based on the collaborative data system; subsequently the results of the implementation of the system in a specific crossroads of the city are presented; and it ends with some brief conclusions in this regard.","","978-1-78561-963-2","10.1049/ic.2018.0012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643139","Traffic light;Jams Optimization;Collaborative;WAZE;Big Data","","","","","1","","","","17 Feb 2019","","","IET","IET Conferences"
"lunule: An Agile and Judicious Metadata Load Balancer for CephFS","Y. Wang; C. Li; X. Shao; Y. Chen; F. Yan; Y. Xu","University of Science and Technology of China, Hefei, Anhui, China; Anhui Province Key Laboratory of High Performance Computing, USTC, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China; University of Nevada, Reno, Reno, Nevada, USA; Anhui Province Key Laboratory of High Performance Computing, USTC, Hefei, Anhui, China","SC21: International Conference for High Performance Computing, Networking, Storage and Analysis","18 Oct 2022","2021","","","1","14","For a decade, the Ceph distributed file system (CephFS) has been widely used to serve the ever-growing big data in many key fields ranging from Internet services to AI computing. To scale out the massive metadata access, CephFS adopts a dynamic subtree partitioning method, splitting the hierarchical namespace and distributing subtrees across multiple metadata servers. However, this method suffers from a severe imbalance problem that may result in poor performance due to its inaccurate imbalance prediction, ignorance of workload characteristics, and unnecessary/invalid migration ac-tivities. To eliminate these inefficiencies, we propose Lunule, a novel CephFS metadata load balancer, which employs an imbalance fac-tor model for accurately determining when to trigger re-balance and tolerate benign imbalanced situations. Lunule further adopts a workload-aware migration planner to appropriately select sub-tree migration candidates. Compared to baselines, Lunule achieves better load balance, increases the metadata throughput by up to 315.8%, and shortens the tail job completion time by up to 64.6% for five real-world workloads and their mixture, respectively. Be-sides, Lunule is capable of handling the metadata cluster expansion and the client workload growth, and scales linearly on a cluster of 16 MDSs.","2167-4337","978-1-4503-8442-1","10.1145/3458817.3476196","National Science Foundation(grant numbers:CAREER-2048044,IIS-1838024,CCF-1756013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910055","","File systems;System performance;High performance computing;Web and internet services;Tail;Metadata;Throughput","","","","2","","49","","18 Oct 2022","","","IEEE","IEEE Conferences"
"Knowledge-Based Digital Twin for Predicting Interactions in Human-Robot Collaboration","T. B. Tuli; L. Kohl; S. A. Chala; M. Manns; F. Ansari","Chair for Manufacturing Automation and Assembly (FAMS), PROTECH-Institute for Production Technology, University of Siegen, Siegen, Germany; Research Group of Smart and Knowledge-Based Maintenance, Institute of Management Science TU Wien, Vienna, Austria; Data Science and AI, Fraunhofer FIT, Sankt Augustin, Germany; Chair for Manufacturing Automation and Assembly (FAMS), PROTECH-Institute for Production Technology, University of Siegen, Siegen, Germany; Research Group of Smart and Knowledge-Based Maintenance, Institute of Management Science TU Wien, Vienna, Austria","2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )","30 Nov 2021","2021","","","1","8","Semantic representation of motions in a human-robot collaborative environment is essential for agile design and development of digital twins (DT) towards ensuring efficient collaboration between humans and robots in hybrid work systems, e.g., in assembly operations. Dividing activities into actions helps to further conceptualize motion models for predicting what a human intends to do in a hybrid work system. However, it is not straightforward to identify human intentions in collaborative operations for robots to understand and collaborate. This paper presents a concept for semantic representation of human actions and intention prediction using a flexible task ontology interface in the semantic data hub stored in a domain knowledge base. This semantic data hub enables the construction of a DT with corresponding reasoning and simulation algorithms. Furthermore, a knowledge-based DT concept is used to analyze and verify the presented use-case of Human-Robot Collaboration in assembly operations. The preliminary evaluation showed a promising reduction of time for assembly tasks, which identifies the potential to i) improve efficiency reflected by reducing costs and errors and ultimately ii) assist human workers in improving decision making. Thus the contribution of the current work involves a marriage of machine learning, robotics, and ontology engineering into DT to improve human-robot interaction and productivity in a collaborative production environment.","","978-1-7281-2989-1","10.1109/ETFA45728.2021.9613342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613342","human-robot interaction;digital twin;human action models;ontology;machine learning","Productivity;Digital twin;Semantics;Knowledge based systems;Collaboration;Predictive models;Ontologies","cost reduction;decision making;groupware;human-robot interaction;knowledge based systems;learning (artificial intelligence);ontologies (artificial intelligence);production engineering computing;productivity;robotic assembly","human-robot collaborative environment;digital twin;assembly operations;hybrid work system;human intentions;semantic representation;semantic data hub;domain knowledge base;knowledge-based DT concept;robotics;productivity;agile design;ontology interface;assembly tasks;cost reduction;decision making;machine learning;ontology engineering","","7","","52","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Automated Risk Management Based Software Security Vulnerabilities Management","R. R. Althar; D. Samanta; M. Kaur; D. Singh; H. -N. Lee","Data Science Department, CHRIST University, Bangalore, Karnataka, India; Department of Computer Science, CHRIST University, Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India; QMS, First American India Private Ltd., Bangalore, Karnataka, India","IEEE Access","5 Sep 2022","2022","10","","90597","90608","An automated risk assessment approach is explored in this work. The focus is to optimize the conventional threat modeling approach to explore software system vulnerabilities. Data produced in the software development processes are better leveraged using Machine Learning approaches. A large amount of industry knowledge around security vulnerabilities can be leveraged to enhance current threat modeling approaches. Work done here is in the ecosystem of software development processes that use Agile methodology. Insurance business domain data are explored as a target for this study. The focus is to enhance the traditional threat modeling approach with a better quantitative approach and reduce the biases introduced by the people who are part of software development processes. This effort will help bridge multiple data sources prevalent across the software development ecosystem. Bringing these various data sources together will assist in understanding patterns associated with security aspects of the software systems. This perspective further helps to understand and devise better controls. Approaches explored so far have considered individual areas of software development and their influence on improving security. There is a need to build an integrated approach for a total security solution for the software systems. A wide variety of machine learning approaches and ensemble approaches will be explored. The insurance business domain is considered for the research here. CWE (Common Weaknesses Enumeration) mapping from industry knowledge are leveraged to validate the security needs from the industry perspective. This combination of industry and company data will help get a holistic picture of the software system’s security. Combining the industry and company data helps lay down the path for an integrated security management system in software development. The risk management framework with the quantitative threat modeling process is the work’s uniqueness. This work contributes toward making the software systems secure and robust with time.","2169-3536","","10.1109/ACCESS.2022.3185069","Institute of Information & communications Technology Planning & Evaluation (IITP) grant; Korea government (MSIT) (Artificial Intelligence Graduate School Program (GIST))(grant numbers:2019-0-01842); MSIT(Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program(grant numbers:IITP-2021-0-01835); IITP(Institute of Information & Communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802103","Quantitative threat modeling;software security;machine learning;quantitative risk assessment;integrated security management system","Software;Security;Industries;Software systems;Data models;Risk management;Computer crime","deep learning (artificial intelligence);risk management;security of data;software engineering","automated risk management;software security vulnerabilities management;automated risk assessment approach;conventional threat modeling approach;machine learning approaches;insurance business domain data;bridge multiple data sources;software development ecosystem;integrated security management system;quantitative threat modeling process;agile methodology;CWE;common weaknesses enumeration","","2","","41","CCBY","21 Jun 2022","","","IEEE","IEEE Journals"
"Neural Fictitious Self-Play for Radar Antijamming Dynamic Game With Imperfect Information","K. Li; B. Jiu; W. Pu; H. Liu; X. Peng","National Laboratory of Radar Signal Processing, Xidian University, Xian, China; National Laboratory of Radar Signal Processing, Xidian University, Xian, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; National Laboratory of Radar Signal Processing, Xidian University, Xian, China; Research Academy of Rocket, Beijing, China","IEEE Transactions on Aerospace and Electronic Systems","5 Dec 2022","2022","58","6","5533","5547","One emerging issue in modern electronic warfare is the competition between the radar and jammer, which in principle can be viewed as a noncooperative game with two players. In practice, the interaction between the radar and jammer involves multiple rounds as well as partial observation. This makes the competition become a dynamic game with imperfect information. Antijamming strategy design for such kind of a game is still unclear. In this work, the competition between a frequency agile radar and a transmit/receive time-sharing jammer is considered. We utilize an extensive-form game (EFG) with imperfect information to model the multiple rounds interaction between the radar and jammer. For the established EFG, finding Nash equilibrium (NE) strategies is a computationally-intractable task since the number of information states grows exponentially with respect to game stages. Instead, a sampled-based learning method called neural fictitious self play algorithm is used to find approximate NE strategies (ANES). Simulation results show that ANES can be obtained and outperform the common elementary and advanced strategies from the perspective of detection performance.","1557-9603","","10.1109/TAES.2022.3175186","Fund for Foreign Scholars in University Research and Teaching Programs(grant numbers:B18039); Shaanxi Innovation Team Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775208","Antijamming strategies design;approximate Nash equilibrium (NE);dynamic games;electronic warfare;extensive-form game (EFG);imperfect information","Jamming;Radar;Games;Receivers;Nash equilibrium;Radar signal processing;Passive radar","game theory;jamming;learning (artificial intelligence)","emerging issue;extensive-form game;frequency agile radar;game stages;imperfect information;information states;modern electronic warfare;multiple rounds interaction;neural fictitious self play algorithm;neural fictitious self-play;noncooperative game;radar antijamming dynamic game;time-sharing jammer","","2","","46","IEEE","16 May 2022","","","IEEE","IEEE Journals"
"Data vault modelling as alternative to dimensional modelling to embrace complexity in data driven decision systems: a critical systems perspective","R. Goede","Unit for Data Science and Computing, North-West University, Potchefstroom, South Africa","2022 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)","6 Apr 2023","2022","","","1","5","We live in a complex world where uncertainty is the only certainty. Today's compelling business problem is replaced tomorrow with a problem which was not even imagined yesterday. Data driven decision systems are used by managers in support of their strategic decisions and should be agile and flexibility to survive in our ever change world of complex decisions. The argument presented in this conceptual paper is that data vault modeling is inherently better equipped than dimensional modelling to handle the turbulations of our complex world. The paper investigates the underlying assumptions of dimensional modelling and data vault modelling in terms of requirements collection and the resulting data modelling techniques. It uses critical systems thinking as guiding philosophy to reflect on the benefits of understanding and modelling a variety of perspectives in a problem situation. Critical systems thinking also promotes equal opportunity and accountability. It is argued that both these aspirations can better be achieved by using dimensional modeling as alternative to dimensional modelling. We hope to promote the development of sustainable data driven decision systems which can stand the test of our turbulent times.","","978-1-6654-5305-9","10.1109/CSDE56538.2022.10089249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10089249","data driven decision systems;data vault modelling;dimensional modelling;critical systems thinking","Computer science;Uncertainty;Philosophical considerations;Computational modeling;Data engineering;Data models;Equal opportunities","business data processing;data models;decision making","business problem;data driven decision systems;data modelling techniques;data vault modeling;dimensional modelling","","","","18","IEEE","6 Apr 2023","","","IEEE","IEEE Conferences"
"AD4ML: Axiomatic Design to Specify Machine Learning Solutions for Manufacturing","A. G. V. Zacarias; R. Ghabri; P. Reimann","University of Stuttgart, GSaME, Stuttgart, Germany; University of Stuttgart, IPVS, Stuttgart, Germany; University of Stuttgart, GSaME, Stuttgart, Germany","2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI)","10 Sep 2020","2020","","","148","155","Machine learning is increasingly adopted in manufacturing use cases, e.g., for fault detection in a production line. Each new use case requires developing its own machine learning (ML) solution. A ML solution integrates different software components to read, process, and analyze all use case data, as well as to finally generate the output that domain experts need for their decision-making. The process to design a system specification for a ML solution is not straight-forward. It entails two types of complexity: (1) The technical complexity of selecting combinations of ML algorithms and software components that suit a use case; (2) the organizational complexity of integrating different requirements from a multidisciplinary team of, e.g., domain experts, data scientists, and IT specialists. In this paper, we propose several adaptations to Axiomatic Design in order to design ML solution specifications that handle these complexities. We call this Axiomatic Design for Machine Learning (AD4ML). We apply AD4ML to specify a ML solution for a fault detection use case and discuss to what extent our approach conquers the above-mentioned complexities. We also discuss how AD4ML facilitates the agile design of ML solutions.","","978-1-7281-1054-7","10.1109/IRI49571.2020.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191629","manufacturing;machine-learning;design","Software;Machine learning;Complexity theory;Fault detection;Production;Software algorithms;Machine learning algorithms","decision making;learning (artificial intelligence);manufacturing data processing;production engineering computing","AD4ML;axiomatic design;fault detection;machine learning solution;software components;use case data;domain experts;ML algorithms;ML solution specifications","","","","16","IEEE","10 Sep 2020","","","IEEE","IEEE Conferences"
"Digital Transformation Impact Analysis towards Transition in the Role of Information Technology for Organization in New Digital Bank","Y. P. Sagala; M. A. Juniawan; V. A. Effendy; R. Putrianasari; W. Nuraini; V. A. Rahmatika; M. R. Shihab; B. Ranti","Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia; Faculty of Computer Science, University of Indonesia, Jakarta, Indonesia","2022 Seventh International Conference on Informatics and Computing (ICIC)","13 Jan 2023","2022","","","1","6","The role of Information Technology in the banking industry has been playing an important role in providing better services to customers and open new opportunities. Bank XYZ is a conventional bank that is transforming into a digital bank to improve bank XYZ's position in financial services sector, specifically in the banking industry. In the process of transforming into digital banking, Information Technology leadership in the organization is important. However, publications regarding the impact of digital transformation in Information Technology role and leadership, especially in the banking industry are scarce, so this research is importance. The benefit of this research is to be organization consideration for designing corporate information strategy & management and can be a reference and contribution of ideas that can enrich knowledge and further research about corporate information strategy & management. This study aims to identify digital transformation impact in IT role and leadership specifically in new digital bank. Qualitative approach with data collection from semi-structured interviews and document was used to identify the impact of digital transformation towards transition in the role of information technology and do benchmarking Bank XYZ's case with a few new digital banks in the world. Based on the comparison and benchmarking, learned lesson as an input for Bank XYZ to improve the digital transformation process into a digital bank. Integrated big data, agile team, automation process, cloud computing, machine learning, and artificial intelligence was the common capability of a digital bank.","","979-8-3503-4571-1","10.1109/ICIC56845.2022.10007003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007003","Digital Bank;Digital Transformation;Leadership;Role of Information Technology;Strategic","Industries;Leadership;Cloud computing;Automation;Digital transformation;Banking;Machine learning","bank data processing;banking;Big Data;business data processing;cloud computing;human factors;human resource management;information technology;learning (artificial intelligence);organisational aspects","bank XYZ's position;banking industry;benchmarking Bank XYZ's case;conventional bank;corporate information strategy & management;digital banking;digital transformation impact analysis;digital transformation process;Information Technology leadership;Information Technology role;new digital bank","","","","23","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"Blockchain as a Service for Software Defined Networks: A Denial of Service Attack Perspective","A. Bose; G. S. Aujla; M. Singh; N. Kumar; H. Cao","Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Chandigarh University, Mohali, India; Computer Science and Engineering Department, Thapar Institute of Engineering and Technology, Patiala, India; Key Lab of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Nanjing, China","2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","4 Nov 2019","2019","","","901","906","Software defined networking (SDN) is one of the most popular network technologies which provides an adaptive, agile and flexible network management and visibility. Although SDN architecture provides manifold benefits but on the same time its dependence on a logically centralized controller lead to the single point of failure. An attacker can easily capture the any forwarding device and restrict the availability of the controller using different prevalent attacks. Distributed denial of service (DDoS) is one of the most popular attack of this category which is quiet prevalent in SDN. Here, the aim of the attackers is to inject false script in the open flow tables through malicious switches which multiply exponentially. Therefore, in this paper, a blockchain as a service framework has been presented wherein BlockSDSec model is designed to provide security as a separate service for the SDN architecture. This work provides a mechanism to prevent the threats of DDoS at the switch level by embedding an security using blockchain onto the interaction channels of data and control planes. The load balancing at the controller level is achieved using a virtual controller. The proposed scheme is simulated using MiniNet Emulator to analyze the delay originating from usage of blockchain.","","978-1-7281-3024-8","10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890267","Blockchain, Distributed Denial of Service, Malicious Switch, Software Defined Networks, MiniNet","Blockchain;Control systems;Computer crime;Software;Computer architecture;Task analysis","centralised control;computer network management;computer network security;cryptocurrencies;software defined networking;telecommunication control;telecommunication switching","blockchain;software defined networks;flexible network management;SDN architecture;centralized controller;forwarding device;DDoS;open flow tables;malicious switches;control planes;virtual controller;denial of service attack perspective;BlockSDSec model;distributed denial of service;MiniNet Emulator","","17","","21","IEEE","4 Nov 2019","","","IEEE","IEEE Conferences"
"Predicting Visitor Distribution for Large Events in Smart Cities","J. Violos; S. Pelekis; A. Berdelis; S. Tsanakas; K. Tserpes; T. Varvarigou","Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Informatics and Telematics, Harokopio University of Athens, Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece","2019 IEEE International Conference on Big Data and Smart Computing (BigComp)","4 Apr 2019","2019","","","1","8","The prediction of the distribution of visitors in large events is a valuable piece of information in the context of smart cities. The organizers of large events leverage it for safety and coordination purposes and the Fog computing infrastructures for cost effective, agile and reliable allocation of the mobile apps and festival services workload along the continuum from edge devices to cloud. In this research we examine two sets of supervised Machine Learning techniques in order to predict the visitors' distribution in the next timesteps and evaluate them using real data from a large music event that took place in 2017 and 2018. To enrich the feature space of the predictive models we use and evaluate open data such as the weather and the popularity of artists. A further added value of the examined Machine Learning techniques, in comparison with the current state of the art in mobility prediction, is that they look into the phenomenon of visitors coming and going from the area of interest.","2375-9356","978-1-5386-7789-6","10.1109/BIGCOMP.2019.8679181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8679181","Smart Cities;Large Events;Fog Computing;Open Data;Points of Interest;Classification;Regression","Cloud computing;Smart cities;Sensors;Computer architecture;Edge computing;Reliability;Mobile applications","learning (artificial intelligence);mobile computing;smart cities","smart cities;events leverage;safety;Fog computing;reliable allocation;mobile apps;festival services workload;edge devices;supervised Machine;music event;predictive models;mobility prediction;visitor distribution;Machine Learning techniques","","4","","17","IEEE","4 Apr 2019","","","IEEE","IEEE Conferences"
"Neighbor Library-Aware Graph Neural Network for Third Party Library Recommendation","Y. Jin; Y. Zhang; Y. Zhang","School of Artificial Intelligence and Big Data, Hefei University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China","Tsinghua Science and Technology","6 Jan 2023","2023","28","4","769","785","Modern software development has moved toward agile growth and rapid delivery, where developers must meet the changing needs of users instantaneously. In such a situation, plug-and-play Third-Party Libraries (TPLs) introduce a considerable amount of convenience to developers. However, selecting the exact candidate that meets the project requirements from the countless TPLs is challenging for developers. Previous works have considered setting up a personalized recommender system to suggest TPLs for developers. Unfortunately, these approaches rarely consider the complex relationships between applications and TPLs, and are unsatisfactory in accuracy, training speed, and convergence speed. In this paper, we propose a new end-to-end recommendation model called Neighbor Library-Aware Graph Neural Network (NLA-GNN). Unlike previous works, we only initialize one type of node embedding, and construct and update all types of node representations using Graph Neural Networks (GNN). We use a simplified graph convolution operation to alternate the information propagation process to increase the training efficiency and eliminate the heterogeneity of the app-library bipartite graph, thus efficiently modeling the complex high-order relationships between the app and the library. Extensive experiments on large-scale real-world datasets demonstrate that NLA-GNN achieves consistent and remarkable improvements over state-of-the-art baselines for TPL recommendation tasks.","1007-0214","","10.26599/TST.2022.9010042","National Natural Science Foundation of China(grant numbers:62272001,61872002,62276146); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011160","Third-Party Library (TPL);TPL recommendation;Graph Neural Network (GNN);bipartite graph","Training;Convolution;Libraries;Graph neural networks;Software;Bipartite graph;Task analysis","graph theory;learning (artificial intelligence);neural nets;recommender systems","app-library bipartite graph;countless TPLs;end-to-end recommendation model;Graph Neural Networks;modern software development;Neighbor Library-Aware Graph Neural Network;NLA-GNN;personalized recommender system;simplified graph convolution operation;Third Party Library recommendation","","","","40","","6 Jan 2023","","","TUP","TUP Journals"
"Human as a Service: Towards Resilient Parking Search System With Sensorless Sensing","D. Wu; Z. Zeng; F. Shi; W. Yu; T. Wu; Q. Liu","Key Laboratory for Embedded and Network Computing of Hunan Province, Hunan University, Changsha, China; Key Laboratory for Embedded and Network Computing of Hunan Province, Hunan University, Changsha, China; Department of Computing, Imperial College London, London, U.K.; Department of Computer Science, University of Warwick, Coventry, U.K.; Hunan Key Laboratory of Geospatial Big Data Mining and Application, Hunan Normal University, Changsha, China; Department of Computer Science, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Intelligent Transportation Systems","10 Aug 2022","2022","23","8","13863","13877","The high demand for ubiquitous availability of reliable parking spaces in cities faces challenges on timely information sharing and low-cost infrastructure deployment. In this paper, we propose a mobile crowdsensing system, namely ParkHop, to aggregate on-street and roadside parking space information through sensorless sensing, and disseminate this information to urban drivers in a resilient manner. ParkHop targets special social groups that have stable work routines to serve as crowd workers. We propose a crowdsensing algorithm employing a joint estimator to process crowdsensed data, and evaluate the reliability of crowd workers based on the veracity of their answers to a series of control questions. In addition, the specific worker selection method to speed up the crowdsensing process and incentive scheme to achieve fair reward distribution have been carefully designed in ParkHop. Our system disseminates the availability of parking spaces and their up-to-date price information to drivers with on-demand needs via a publish-subscribe messaging pattern. The efficacy of ParkHop for aggregation and dissemination of parking space information has been evaluated in both real-world tests and simulations. Our results show the system is robust and agile enough to cope with different crowdsensing scenarios.","1558-0016","","10.1109/TITS.2021.3133713","National Natural Science Foundation of China(grant numbers:61972145,61932010); National Key Research and Development Program of China(grant numbers:2018YFB1305200); Intel Collaborative Research Institute for Urban IoT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658308","Sensorless sensing;mobile crowdsensing;resilient system;user reliability;smart parking","Reliability;Crowdsensing;Sensors;Servers;Aerospace electronics;Task analysis;Space vehicles","incentive schemes;information management;message passing;mobile computing;personnel","towards resilient parking search system;sensorless sensing;ubiquitous availability;reliable parking spaces;timely information sharing;low-cost infrastructure deployment;mobile crowdsensing system;on-street;roadside parking space information;urban drivers;resilient manner;ParkHop targets special social groups;stable work routines;crowd workers;crowdsensing algorithm;joint estimator;crowdsensed data;specific worker selection method;crowdsensing process;fair reward distribution;up-to-date price information;aggregation;different crowdsensing scenarios","","","","40","IEEE","21 Dec 2021","","","IEEE","IEEE Journals"
"An End-to-End Recommendation System for Urban Traffic Controls and Management Under a Parallel Learning Framework","J. Jin; H. Guo; J. Xu; X. Wang; F. -Y. Wang","Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; Enjoyor Co., Ltd., Hangzhou, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Intelligent Transportation Systems","1 Mar 2021","2021","22","3","1616","1626","A paradigm shift towards agile and adaptive traffic signal control empowered with the massive growth of Big Data and Internet of Things (IoT) technologies is emerging rapidly for Intelligent Transportation Systems. Generally, an adaptive signal control system fine-tunes signal timing parameters based on pre-defined control hyperparameters using instantaneous traffic detection information. Once traffic pattern changes, those hyperparameters (e.g., maximum and minimum green times) need to be adjusted according to the evolution of traffic dynamics over a very short-term period. Such adjustment processes are usually conducted by professional and experienced traffic engineers. Here we present a human-in-the-loop parallel learning framework and its utilization in an end-to-end recommendation system that mimics and enhances professional signal control engineers' behaviors. The system has been deployed into a real-world application for an extended period in Hangzhou, China, where signal control hyperparameters are recommended based on large-scale multidimensional traffic datasets. Experimental evaluations demonstrate significant improvements in traffic efficiency through the use of our signal recommendation system.","1558-0016","","10.1109/TITS.2020.2973736","China Post-Doctoral Science Foundation(grant numbers:2019M660136); Natural Science Foundation of Zhejiang Province(grant numbers:LY20E080023); National Natural Science Foundation of China(grant numbers:U1811463); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005386","Intelligent traffic control;traffic signal control;parallel learning;recommendation systems;deep neural networks","Control systems;Urban areas;Timing;Adaptive systems;Real-time systems;Recurrent neural networks;Process control","intelligent transportation systems;learning (artificial intelligence);road traffic control;traffic engineering computing","end-to-end recommendation system;urban traffic controls;agile traffic signal control;adaptive traffic signal control;Internet of Things technologies;intelligent transportation systems;adaptive signal control system;pre-defined control hyperparameters;instantaneous traffic detection information;traffic pattern changes;traffic dynamics;professional traffic engineers;signal control hyperparameters;large-scale multidimensional traffic datasets;traffic efficiency;signal recommendation system;human-in-the-loop parallel learning","","31","","37","IEEE","20 Feb 2020","","","IEEE","IEEE Journals"
"Contexts Enhance Accuracy: On Modeling Context Aware Deep Factorization Machine for Web API QoS Prediction","L. Shen; M. Pan; L. Liu; D. You; F. Li; Z. Chen","Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; National Science Library, Chinese Academy of Sciences, Beijing, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China; College of Computer and Communication Engineering, Northeastern University, Shenyang, China; Colleague of Information Science and Engineering, Yanshan University, Qinhuangdao, China","IEEE Access","18 Sep 2020","2020","8","","165551","165569","Service-oriented computing (SOC) promises a world of cooperating services loosely connected, constructing agile Web applications in heterogeneous environments conveniently. Web application interface (API) as an emerging technique attracts more and more enterprises and organizations to publish their deep computing functionalities and big data on the Internet, Web API has become the backbone to promote the development of SOC, thus forming the prosperous Web API economy. However, the number of available Web APIs on the Internet is massive and growing constantly, which causes the Web API overload problem. Quality of service (QoS) as an indicator is able to well differentiate the quality of Web APIs and has been widely applied for high quality Web API selection. Since testing QoS for massive Web APIs is resource-consuming, and the QoS performance depends on contextual information such as network and location, hence accurate QoS prediction has become very crucial for personalized Web API recommendation and high quality Web application construction. To address the above issue, this paper presents a context aware deep factorization machine model (CADFM for short) for accurate Web API QoS prediction. Specifically, we first carry out detailed data analysis using real-world QoS dataset and discover a positive relationship between QoS and contextual information, which motivates us to incorporate beneficial contexts for enhancing QoS prediction accuracy. Then, we treat QoS prediction as a regression problem and propose a context aware CADFM framework that integrates the contextual information via embedding technique. Particularly, we adopt MF and MLP for high-order and nonlinear interaction modeling, so as to learn the complex interaction between users and Web APIs accurately. Finally, the experimental results on real-world QoS dataset demonstrate that CADFM outperforms the classic and the state-of-the-art baselines, thereby generating the most accurate QoS predictions and increasing the revenue of Web APIs recommendation.","2169-3536","","10.1109/ACCESS.2020.3022891","National Natural Science Foundation of China(grant numbers:61772450,61379116); Hebei Natural Science Foundation(grant numbers:F2019203287); Hebei Postdoctoral Research Program(grant numbers:B2018003009); Science and Technology Research Project of Hebei University(grant numbers:QN2020183); Doctoral Fund of Yanshan University(grant numbers:BL18003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189762","Service-oriented computing;Web API;quality of service prediction;context aware;deep factorization machine","Quality of service;Context modeling;Predictive models;Context-aware services;Internet;Organizations;Software","application program interfaces;data analysis;Internet;learning (artificial intelligence);quality of service;regression analysis;service-oriented architecture;ubiquitous computing;Web services","service-oriented computing;agile Web applications;Web application interface;Web API overload problem;Web API selection;QoS performance;contextual information;personalized Web API recommendation;high quality Web application construction;context aware deep factorization machine model;QoS prediction accuracy;context aware CADFM framework;Web API recommendation;Web API QoS prediction;quality of service;data analysis;regression problem","","6","","44","CCBY","9 Sep 2020","","","IEEE","IEEE Journals"
"Artificial Intelligence For Media Operations Why AI algorithms will become a must for every network management system","T. Gunkel; B. Vandenberghe",Skyline Communications; Skyline Communications,"SMPTE 2018","13 Jan 2019","2018","","","1","22","Artificial intelligence already has a big impact on a lot of different segments in the media industry. With the broadcast industry moving to all-IP and data center deployments those environments are more agile and complex than ever before. With fast-evolving technologies and cycles, ever more mission critical systems and constantly changing operational practices and devops style operations, traditional network management systems (NMS) and their paradigms don't fit the bill anymore. This paper explores why machine-learning algorithms must find their way into network monitoring and management solutions to orchestrate a modern media data center dynamically and in a proactive way. The foundation for an AI-driven NMS platform is a solid big data storage architecture; a lack of profound data and data hygiene is often one of the biggest obstacles to successfully deploy big data projects. As in today's all-IP environments nothing is static anymore, an AI entity must be highly intelligent. Unsupervised learning is key to automatically adapt to changing environments. Augmented operation and a zero-configuration and zero-maintenance approach will be crucial to successfully deploy the right management strategy.","","978-1-61482-960-7","10.5594/M001813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8609872","NMS;artificial intelligence;machine learning;augmented operation;forecasting;intelligent fault detection;incident detection;deep root cause analysis;advanced analytics","","","","","","","","","13 Jan 2019","","","SMPTE","SMPTE Conferences"
"Competency Model for Programming Courses in Information Technology Education (ITE) Programs from Industry Perspective: A Delphi Method","J. E. E. Goh; C. V. Mojado; H. J. T. Manaligod","Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines; Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines; Information Systems Program, De La Salle – College of Saint Benilde, Manila, Philippines","2022 IEEE 14th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)","1 May 2023","2022","","","1","6","This study aimed to develop a competency model for software development courses in ITE programs as perceived by the IT industry in the Philippines in the new normal. A review of previous studies revealed existing software engineering competency models being referenced by the IT industry along with the Commission on Higher Education (CHED) General Education Curriculum (GEC) being referenced by the academe. However, things drastically changed during this global pandemic which may have affected these current standards. Thus, this study aimed to determine the current competency needs in the IT industry in the new normal in relation to the programming courses being offered by the ITE programs in the Philippines; A mixed method three-round Delphi technique was used to solicit a unified expert opinion from the point of view of nine (9) IT industry experts in the Philippines. Twenty-three (23) technical skills and eleven (11) soft skills were extracted from online interviews using thematic analysis. Out of 23 technical skills, nineteen (19) have consensus. The findings produced a competency model for software development courses in the new normal consisting of must-have technical skills, game-changer technical skills, and must-have soft skills. The must-have technical skills include Web Development, Cyber Security, Cloud Computing, Agile Project Management, Mobile Development, and DevOps. The game changer technical skills include Data Science and Data Analytics, Artificial Intelligence and Machine Learning, the Internet of Things, and Research and Development. And the must-have soft skills include Communication skills, Results-Oriented, and Collaboration skills.","2770-0682","978-1-6654-6493-2","10.1109/HNICEM57413.2022.10109471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109471","competency model;Delphi method;Information Technology Education (ITE);programming courses;software development","Industries;Computational modeling;Education;Machine learning;Games;Software;Internet of Things","","","","","","12","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"MosaicSim: A Lightweight, Modular Simulator for Heterogeneous Systems","O. Matthews; A. Manocha; D. Giri; M. Orenes-Vera; E. Tureci; T. Sorensen; T. J. Ham; J. L. Aragon; L. P. Carloni; M. Martonosi","Princeton University; Princeton University; Columbia University; Princeton University; Princeton University; Princeton University; Seoul National University; University of Murcia, Murcia, Spain; Columbia University; Princeton University","2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","26 Oct 2020","2020","","","136","148","As Moore's Law has slowed and Dennard Scaling has ended, architects are increasingly turning to heterogeneous parallelism and domain-specific hardware-software co-designs. These trends present new challenges for simulation-based performance assessments that are central to early-stage architectural exploration. Simulators must be lightweight to support rich heterogeneous combinations of general purpose cores and specialized processing units. They must also support agile exploration of hardware-software co-design, i.e. changes in the programming model, compiler, ISA, and specialized hardware. To meet these challenges, we introduce MosaicSim, a lightweight, modular simulator for heterogeneous systems, offering accuracy and agility designed specifically for hardware-software co-design explorations. By integrating the LLVM toolchain, MosaicSim enables efficient modeling of instruction dependencies and flexible additions across the stack. Its modularity also allows the composition and integration of different hardware components. We first demonstrate that MosaicSim captures architectural bottlenecks in applications, and accurately models both scaling trends in a multicore setting and accelerator behavior. We then present two case-studies where MosaicSim enables straightforward design space explorations for emerging systems, i.e. data science application acceleration and heterogeneous parallel architectures.","","978-1-7281-4798-7","10.1109/ISPASS48437.2020.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238641","heterogeneity;hardware-software co design;performance modeling;multi-core architectures;accelerators","Semiconductor device modeling;Program processors;Computational modeling;Parallel processing;Market research;Turning;Software","hardware-software codesign;parallel processing;program compilers;software architecture;software performance evaluation;software prototyping","heterogeneous parallel architectures;heterogeneous parallelism;general purpose cores;specialized processing units;domain specific hardware software codesigns;simulation based performance assessment;LLVM toolchain;compiler infrastructure;MosaicSim;modular simulator","","6","","39","IEEE","26 Oct 2020","","","IEEE","IEEE Conferences"
"IBM Z development transformation","E. C. McCain; P. Bastien; B. F. Belmar; B. Bhattacharya; K. K. Cheruiyot; M. Coq; R. Dartey; K. Deekaram; K. Ghadai; L. D. Lalima; J. Nettey; A. W. Owolabi; K. Phillips; T. M. Shiling; D. T. Schroeder; C. Slegel; B. Steen; D. A. Thorne; E. Venuto; J. D. Willoughby; D. Yaniv; N. Ziemis",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"IBM Journal of Research and Development","25 Aug 2020","2020","64","5/6","14:1","14:13","This article discusses how the product development cycle is being transformed with “Artificial Intelligence” (AI) for the first time in zSeries history. This new era of AI, under the project name IBM Z Development Transformation (zDT), has allowed the team to grow and learn new skills in data science. This transformation forces change structurally in how data is prepared and stored. In z14, there were incremental productivity gains with enhancements to automation with eServer Automation Test Solution and a technology data analysis engine called zDataAssist. However, in z15, AI will significantly accelerate our efficiency. This article explains how Design Thinking and Agile principles were used to identify areas that are of high impact and feasible to implement: 1) what and how data is collected via System Test Event Logging and Analysis engine, Problem ticket management system (Jupitr), and Processor data analysis engine (Xrings); 2) problem identification, analysis, and management (AutoJup) along with Intelligent Recovery Verification Assistant; 3) product design documentation search engine (AskTheMachine); and 4) prototype microprocessor allocation processes Intelligent Commodity Fulfillment System using Machine Learning. This article details the approach of these areas for z15, the implementation of these solutions under the zDT project, as well as the results and future work.","0018-8646","","10.1147/JRD.2020.3008122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138677","","Tools;Artificial intelligence;Automation;Engines;Databases;Hardware;Writing","","","","","","31","IBM","10 Jul 2020","","","IBM","IBM Journals"
"Strategic Information System Planning in the Industry 4.0 Era: A Systematic Literature Review","I. Mahendra; A. Ramadhan; A. Trisetyarso; E. Abdurachman; M. Zarlis","Computer Science Program, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia","2022 IEEE Creative Communication and Innovative Technology (ICCIT)","10 May 2023","2022","","","1","7","Information systems and technology have an important role in building the Company's competitive advantage in facing the Industrial Era 4.0. Strategic Information System Planning (SISP) helps companies formulate reliable information systems that are aligned with business strategies. The academic world should contribute in this regard, but currently, the amount of research related to SISP is very limited. This research is a systematic literature review, which aims to find out more about SISP research trends, research motivations and backgrounds, industries that have been handled, and the methods used in developing SISP. This research is expected to be a trigger for the emergence of new research to support the successful development of SISP in companies in various industries. The results of this research show that several topics are widely researched and need to be improved in the future, namely the alignment of IS strategies with business strategies, the development of specific SISPs in various industries, and the reliability of IS strategies by considering the application of the latest information technology, such as blockchain, artificial intelligence, big data, augmented reality, Internet of Things, and cloud computing. In addition, it is also necessary to develop a SISP framework that is more accommodating to changes in the business environment that is increasingly fast, agile, and collaborative, which includes aspects of business architecture, data/information architecture, technology architecture, information system security, governance, and human resources.","","978-1-6654-6877-0","10.1109/ICCIT55355.2022.10119002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10119002","Strategic Information System Planning;SISP;IS Strategic Planning;Systematic literature review","Industries;Systematics;Bibliographies;Computer architecture;Market research;Reliability;Security","","","","","","51","IEEE","10 May 2023","","","IEEE","IEEE Conferences"
"Guest Editorial Special Issue on Big Data and Computational Intelligence for Agile Wireless IoT","",,"IEEE Transactions on Emerging Topics in Computational Intelligence","25 May 2020","2020","4","3","202","205","The papers in this special section focus on Big Data and computational intelligence for agile Internet of Things (IOT) wireless networking technology. This technology is one of the main components that could empower a wide range of Internet-of-Things (IoT) applications including smart city, smart home, smart grid, e-health, smart transportation, etc. While providing an easily extensible solution for information exchange, wireless networks also have brought some crucial challenges due to the unstable characteristics of wireless communications. ","2471-285X","","10.1109/TETCI.2020.2990757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099340","","Special issues and sections;Computational intelligence;Big Data;Wireless sensor networks;Wireless communication","","","","","","0","IEEE","25 May 2020","","","IEEE","IEEE Journals"
"Panel: Addressing the Shortage of Big Data Skills with Inter-Disciplinary Big Data Curriculum","J. C. Nwokeji; R. Stachel; T. Holmes; F. Aqlan; E. C. Udenze; R. Orji","Compt. & Infor. Sci. Dept, Gannon University, Erie PA, USA; School of Business, Gannon University, Erie PA, USA; School of Business, Gannon University, Erie PA, USA; Industrial Engr. Dept, Penn. State Uni, Erie PA, USA; Physical Sciences Dept, Yakima Valley College, Yakima WA, USA; Computer Science Dept, Dalhousie University, Halifax, Canada","2019 IEEE Frontiers in Education Conference (FIE)","12 Mar 2020","2019","","","1","4","One major challenge faced by enterprises in contemporary era is the shortage of big data and analytics (BDA) professionals. These professionals possess skills to analyze and derive intelligence from big data generated by enterprises. Currently, universities and colleges have not been able to produce sufficient professionals to meet the ever-growing demand for data analytics skill sets. A possible reason for this may be the narrow focus and lack of interdisciplinary approach to big data analytics education. To address this challenge, this panel brings together practitioners, researchers and educators in big data and analytics; to explore the potentials for developing an interdisciplinary curriculum that will deliver data analytics skills to students across all other academic majors. This might help to produce more agile data analytics professionals and close the gap between demand and supply of those professionals.","2377-634X","978-1-7281-1746-1","10.1109/FIE43999.2019.9028350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9028350","Analytics;Big Data;Education;Curriculum","Big Data;Education;Data analysis;Online services;Industries;Business","","","","2","","13","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Actionable Analytics for Software Engineering","Y. Yang; D. Falessi; T. Menzies; J. Hihn","Stevens Institute of Technology; California Polytechnic State University, San Luis Obispo; North Carolina State University; Jet Propulsion Laboratory","IEEE Software","25 Dec 2017","2018","35","1","51","53","Although intensive research on software analytics has been going on for nearly a decade, a repeated complaint in software analytics is that industrial practitioners find it hard to apply the results generated from data science. This theme issue aims to reflect on actionable analytics for software engineering and to document a catalog of success stories in which analytics has been proven actionable and useful, in some significant way, in an organization. This issue features five articles covering promising analytical methods for improving change triage, strategic maintenance, and team robustness, as well as the success stories of applying analytical tools during an organizational transformation.","1937-4194","","10.1109/MS.2017.4541039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239931","actionable analytics;context-driven software engineering;software analytics;change triage;agile development;DevOps;software engineering;software development","","","","","15","","4","IEEE","25 Dec 2017","","","IEEE","IEEE Magazines"
